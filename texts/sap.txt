IBM Cloud

IBM Cloud for SAP |
IBM Power Virtual
Servers for SAP
Solution guide

Edition notices
This PDF was created on 2024-07-02 as a supplement to IBM Cloud for SAP | IBM Power Virtual Servers for SAP in the IBM Cloud docs. It might not be a complete set of
information or the latest version. For the latest information, see the IBM Cloud documentation at https://cloud.ibm.com/docs/sap.

Get started
IBM Cloud® for SAP is the continuation of a 50+ year IBM-SAP alliance across hardware, software, and services.
With over 60 IBM data centers worldwide, the IBM Cloud® SAP-Certified Infrastructure gives you the flexibility to run your SAP workloads in the IBM Cloud
when and where you need them. You can quickly address issues such as:
Rapidly expanding or contracting capacity
Moving SAP workloads to the cloud
Supplementing an existing private cloud architecture.
The following documentation provides design considerations and guidance for provisioning the infrastructure to support SAP workloads, including:
SAP Business Applications such as SAP S/4HANA or SAP BW/4HANA
SAP Technical Applications such SAP HANA database server and SAP NetWeaver application server
You can use this information to help planning your SAP installation and running your SAP workloads on IBM Cloud.
The following documentation does not replace any SAP implementation-related documentation.

Before you begin
Before you install the SAP software components on IBM Cloud, you need an:
SAP S-User ID to review the relevant SAP documentation and download SAP installation media
IBM ID to create an IBM Cloud account
This information is covered in the Pre-requisites for SAP Workloads topic group, under Necessary account credentials for SAP and IBM Cloud .

Summary of an SAP landscape installation onto Cloud IaaS
This table summarizes the SAP landscape installation steps for you and your team:
Task

Details

Read the Overview of IBM Cloud®
for SAP

Identify the various offerings that are available for your SAP landscape. Provides a high-level comparison of
your options.

Read the relevant documents in
the following topic groups:

Infrastructure environments section for your specific environment, such as IBM Power Systems
Infrastructure environment introduction
Infrastructure certified for SAP
Sizing process for SAP Systems
Read these documents to identify the detailed infrastructure options and design considerations that
apply to your SAP landscape.

Read the relevant SAP software
documentation.

Short lists of planning considerations are available to assist under topic groups:
SAP Business Applications
SAP Technical Applications
SAP AnyDB databases
Lists of usage, network, storage, database, and OS considerations are available for SAP Business
Applications, SAP Technical Applications, SAP AnyDB databases, SAP Development Applications.
References to SAP installation documents are also included.

Optional: Read the relevant SAP
Business Partner certified
solutions documents

Various SAP Open Ecosystem Partners are available from IBM Cloud, with documents on how to best use these
solutions for your SAP deployment.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 3

Optional: Read the relevant IBMSAP innovation solutions
documents

IBM Cloud® for SAP

Read and follow the documents in
the Pre-requisites for SAP
Workloads topic group

Prepare the credentials, account structure, connectivity, software downloads, support procedures, and
licensing that is needed before you begin your deployment.

Read and follow the Provisioning
topic groups in the How to section

For your specific infrastructure, follow the provisioning guidelines to set up the first servers at the sizes that are
required to run your SAP systems. Planning your SAP landscape with the business is crucial to success. It is
likely these documents might be read many months after the topics listed in the other steps.

Revisit Task 3, and follow the
relevant SAP software
documentation to install SAP on
the infrastructure

It is important to follow SAP guidance clearly, including any additional reference guidance available on SAP
Notes for your chosen applications. This stage is the same as installations into servers hosted at on-premises
data centers.

Table 1. Overview of your SAP landscape installation steps

Next steps
Review the following documentionat for your relevant configuration:
Fast Path of IBM Cloud Intel Bare Metal on Classic Infrastructure
Fast Path of IBM Cloud Intel Bare Metal Servers on VPC Infrastructure
Fast Path of IBM Cloud Intel Virtual Servers on VPC Infrastructure
Fast Path of IBM Power Virtual Servers
Fast Path of IBM Cloud for VMware on Classic Infrastructure

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 4

Overview of IBM Cloud® for SAP
Introduction
IBM Cloud® for SAP is for enterprises who believe that empowering their SAP workloads also empowers their business. IBM Cloud® for SAP provides your
enterprise with full cloud capabilities. So, you can run your mission-critical SAP workloads with secure, reliable, and compliant infrastructure, and take
advantage of options to append more cloud services to transform the business.
Our IBM Cloud® for SAP offerings are designed based on over 50+ years of IBM-SAP expertise (since 1972). The on-demand flexible compute options for
various SAP Business Application scenarios range from cloud-native SAP and burst compute all the way to high performance with enterprise-grade
availability.
IBM and SAP multi-decade alliance is why IBM was selected as one of SAP’s strategic infrastructure providers for hybrid cloud. Support for SAP's suite of
products is available through the highly scalable, open, and security-rich IBM Cloud. With this partnership, SAP applications can expand to major markets;
this expansion is made possible by more than 60 IBM Cloud data centers worldwide.
IBM Cloud® for SAP was launched in late 2014, with our SAP HANA certified Bare Metals as a strategic partner with SAP HANA Enterprise Cloud (HEC). Our
SAP HANA certified Bare Metals were first released as Infrastructure-as-a-Service in early 2017, the first Cloud Service Provider to provide highperformance Bare Metal IaaS for SAP HANA and SAP NetWeaver.
Using various configurations of the SAP Technical Applications, you can confidently run SAP Business Applications such as:
SAP S/4HANA
SAP BW/4HANA
SAP BO-BI
SAP CAR
...more
Our rigorous certification process with SAP make sure that your workloads are supported.
We deliver these cloud capabilities for SAP to improve your business, and provide more solutions from SAP Partners to accelerate your SAP
implementations.
IBM provides you with the most powerful available cloud building blocks so that you can design and implement SAP landscapes that meet your current
business needs and your requirements for the future.
Our infrastructure options are designed to support all your SAP workloads in different scenarios, including business applications based on:
SAP HANA
SAP AnyDB
SAP NetWeaver
Other SAP products that use other technologies (for example, older applications such as SAP Content Server, or newer applications such as SAP Data
Intelligence)
Our key offerings are SAP-certified Infrastructure-as-a-Service, which we append with more capabilities specific to SAP workloads.

Supported SAP Business Applications
SAP S/4HANA AnyPremise edition
SAP S/4HANA Cloud SaaS Extended edition (by request to SAP)
SAP BW/4HANA
SAP CAR
SAP Commerce (formerly SAP Hybris Commerce)
SAP ECC
SAP BW
SAP Business One
SAP Business Objects Business Intelligence Suite (BOBJ/BO-BI)
SAP Data Intelligence 3.x / SAP Data Hub 2.x
...more

Supported SAP Technical Applications
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 5

SAP HANA
SAP NetWeaver
SAPRouter
SAP Web Dispatcher
SAP Fiori Front-end Server
SAP Gateway
SAP Solution Manager
SAP Content Server
Adobe Document Services (ADS) for SAP
SAP Process Orchestration (PO) - Process Integration (PI)
SAP Landscape Management (LaMa)
SAP Secure Logon Server (SLS)
AnyDB - IBM Db2
AnyDB - Microsoft SQL Server
AnyDB - SAP MaxDB
AnyDB - SAP ASE
...more

Supported SAP Development Applications
$ SAP Cloud Platform (including SAP Cloud Connector)

SAP-certified Infrastructure-as-a-Service (IaaS) offerings
The IBM Cloud SAP-Certified IaaS gives you the flexibility to run your SAP workloads in the IBM Cloud when you need them, where you need them with
over 60 IBM data centers worldwide. You can quickly address issues such as:
Rapidly expanding and contracting capacity (as needed)
Migrating SAP workloads to the cloud
Supplementing existing on-premises virtualized infrastructure architectures.
The IBM Cloud® for SAP portfolio primarily consists of five offerings:
1. IBM Cloud Bare Metal
2. IBM Cloud Bare Metal with Intel Optane DC Persistent Memory
3. IBM Cloud Virtual Servers
4. IBM Power Virtual Servers (complementary offering from IBM Power Systems, with connection through IBM Cloud)
5. IBM Cloud for VMware
More information on the Infrastructure offerings within the IBM Cloud® for SAP portfolio, see Infrastructure certified for SAP.
These offerings are spread across two primary infrastructure environments, and one separated environment that uses IBM Power technologies:
IBM Cloud Classic Infrastructure environment. The original environment and network, formerly known as the Softlayer network.
IBM Cloud VPC Infrastructure environment. The latest environment and network, with the newest technologies and networking capabilities.
IBM Power Systems Infrastructure environment. The environment maintained by IBM Power Systems built of IBM Power enterprise components,
which has links to either Classic Infrastructure and VPC Infrastructure.
Tip: Our documents provide detailed considerations and information for building your SAP environments at each layer for all offerings. However, if
you are interested in quickly finding the information related specifically to one of the IaaS offerings, then you may consider using the Fast Path Site
Maps for Intel Bare Metal, Intel Virtual Servers, and IBM Power Virtual Servers and VMware SDDC.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 6

Certifications summary
SAP S/4HANA (AnyPremise edition), which uses SAP HANA scale-up.
SAP BW/4HANA, which uses SAP HANA scale-up.
SAP BW/4HANA, which uses SAP HANA scale-out.
Note: For more details on SAP S/4HANA scale-out with IBM Cloud, read SAP S/4HANA additional design considerations , which describes while
this is possible, IBM-SAP prefer to discuss first to understand the business requirements. This is to avoid transactional performance issues, which
may occur with SAP S/4HANA scale-out.

Benchmarks summary
SAP S/4HANA (AnyPremise edition), which uses SAP HANA scale-up (world record, as of writing - 2020-07-01).
SAP BW/4HANA, which uses SAP HANA scale-up (world record, as of writing - 2020-07-01)
SAP BW/4HANA, which uses SAP HANA scale-out

SAP's Platform-as-a-Service (PaaS) offerings
IBM Cloud also enables the use of cloud-native SAP technologies. IBM-SAP work on multiple open source projects together and both companies use
similar technology underpinnings. You can reduce your SAP implementation project timelines and long-term maintenance by adopting the "Side-by-Side
Extensibility" model that SAP recommends for custom development with their SAP Business Applications.
The portfolio includes a variation of SAP's Platform-as-a-Service, which is designed for increased security of cloud-native SAP extensions. This SAP PaaS
variation can be combined with IBM Cloud's various PaaS options, functions, and services.
Affiliate offerings for SAP's PaaS by request only:
SAP Cloud Platform Private Edition, using Red Hat OpenShift Virtualization
However, the core cloud-native SAP technologies are able to be used directly with Red Hat OpenShift on IBM Cloud or other IBM Cloud capabilities (such
as Cloud Foundry) in the same way as deploying to SAP Cloud Platform. This is because many of the cloud-native SAP technologies are built upon widely
supported cloud-native technologies. However, to deploy outside of the SAP Cloud Platform ecosystem requires general knowledge of cloud-native
technologies, and will require more manual effort (not described in this documentation series) because the SAP multitarget application (MTA) archive
format is not supported outside SAP Cloud Platform.
Cloud-native SAP technologies which are portable, directly to Red Hat OpenShift on IBM Cloud or Cloud Foundry from IBM Cloud, examples include:
SAP Fundamental Library Styles component library for UI Frameworks (Angular, React, Vue, and other frameworks)
SAPUI5 Framework (and upstream project OpenUI5)

SAP's Software-as-a-Service (SaaS) offerings
IBM Cloud is also available as an option underneath SAP's Software-as-a-Service (SaaS) products.
IBM Cloud offerings for SAP's SaaS by request only:
$ SAP S/4HANA Cloud SaaS, Extended Edition; using IBM Cloud SAP-certified IaaS _(IBM Cloud is a strategic premier partner,
requires PMC contract with a services partner)_

SAP Partner ecosystem solutions offerings
IBM Cloud provides numerous solutions from SAP's Partner ecosystem. These solutions can reduce SAP implementation project timelines or increase the
efficiency of SAP Systems that are running maintenance on IBM Cloud. IBM Cloud works closely with these SAP Partners (who are also IBM Business
Partners) to offer their capabilities from the IBM Cloud catalog.
These solutions from SAP Patners may not apply to all SAP software or all Infrastructure within the IBM Cloud® for SAP portfolio; please see the individual
sections under the SAP Partner certified solutions topic group.
This table summarises the available SAP Partner solutions:
SAP Partner

Solution name

Solution description

Actifio

Actifio Go for SAP HANA

Block-based backups for SAP HANA

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 7

Veeam

Veeam Backup & Replication for SAP HANA

Backint backups from SAP HANA

F5

F5 BigIP for SAP NetWeaver

Load balancing and traffic management for SAP
Table 1. Overview of SAP Partner solutions

Comparing the different SAP-certified IaaS offerings
When you compare the different SAP-certified IaaS offerings available on IBM Cloud, keep in mind that each offering was designed to provide flexibility for
various scenarios. Each offering provides different levels of performance criteria, security, and risk-acceptance.
Each of these SAP-certified offerings is available to support numerous different SAP Business or SAP Technical Applications. However they differ in the
performance they can achieve:
Bare Metal very offers high performance. This option has no software-related overheads as it is purely an OS and the SAP software that uses local
SSD storage. However, the SAP workload cannot move around as easily.
Intel Virtual Servers for VPC uses an IBM Cloud managed hypervisor. This option provides lower total cost of ownership when coupling Suspend
Discounts and Sustained Usage Discounts, with more flexibility and an abundance of extra features for security and networking. However, the
performance and sizing are lower than other options.
IBM Power Virtual Servers use the enterprise-grade IBM PowerVM Type 1. This option is a complementary offering from IBM Power Systems, with
connection through IBM Cloud, that provides significant scalability on robust hardware with significant flexibility and many more features available.
But, this option does not allow root-access control of IBM PowerVM underneath where some SAP tools would ordinarily provide integration.
Commonly this is paired with existing IBM Power or IBM Z infrastructure in on-premises data centers, to create a Hybrid Cloud model which drives
modernization using paired capabilities from either on-premises or Cloud that address the business needs (e.g. security, flexibility, speed etc.) and
business strategy
VMware is a Type 2 hypervisor. This option has a minor reduction in the available performance. But this option also has vastly more flexibility and
optimization in running SAP workloads, including:
Full root-access control to all VMware features
Capability to install more software that uses VMware capabilities (for example, SAP Landscape Management)
Ability to bridge the network with any existing VMware installations
This content is a high-level summary, for more details please see Infrastructure certified for SAP; in addition there are multiple pages describing each
profile available across the infrastructure options, or a compilation list of all profiles available is provided in the FAQ of Profile List with Benchmarks and
Specifications.
Our recommendation is to investigate what your current business requirements are and what are your future requirements for growth. This information
helps you understand the short-term and long-term needs for running your SAP Systems. After you know your short-term and long-term needs, complete
an SAP Sizing exercise.
This exercise provides you with enough information to establish what IaaS and surrounding needs you might have, which can help to evaluate decision
points such as:
Whether to move the existing SAP workload to cloud quickly or steadily (for example, avoid data center expiry fees versus potential business
disruption)
Whether to migrate the existing SAP ECC system to SAP S/4HANA, or build from the ground up on the cloud.
What your current sizings of your SAP Systems are, and their projected increases.
How to align your move to cloud and SAP rollouts to meet business needs. For example, connectivity to existing applications in on-premises data
centers, intermittent or offline locations such as factories or front-line business operators, mobile device connectivity while retaining security and
more.
The following documentation sections provide details to help understand how IBM Cloud® for SAP can empower your business and help you to make
informed decisions for your IaaS, PaaS, SaaS, and SAP Partner solution choices.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 8

Fast Path Site Maps
Fast Path of IBM Cloud Intel Bare Metal on Classic Infrastructure
This page is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as
SAP Sizing.
Use the links in this section to quickly access relevant documents that you are already familiar with.

Learn
An Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the
US) and a designated site location (also referred to as zone, which is a data center site). For more information:
IBM Cloud Classic Infrastructure environment introduction
Certified Infrastructure-as-a-Service for SAP HANA database server is available in many variations, each with different capabilities and sizes to fit many
different SAP workload scenarios. For more information:
Infrastructure certified for SAP - Bare Metal server
The following is an overview of the SAP-certified profiles with IBM Cloud Bare Metal servers for SAP HANA and SAP NetWeaver. For more information:
Intel Bare Metal server certified profiles for SAP HANA
Intel Bare Metal server certified profiles for SAP NetWeaver
Compute Profiles of SAP-certified Bare Metal on Classic Infrastructure
Your business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver Application Server,
and therefore determine how your applications are run in the available infrastructure. For more information:
Connectivity options within the IBM Cloud Classic Infrastructure network
Sample storage configurations on Classic Infrastructure
Your enterprise IT organization can select from a variety of operating systems from the IBM Cloud for SAP portfolio. For more information:
OS Bring your Own Image/License for IBM Cloud Intel Bare Metal
Depending on your scenarios, the following information may be also relevant:
SAP NetWeaver - Configure high availability in Classic Infrastructure
SAP on IBM Db2 using Intel Bare Metal
SAP MaxDB using Intel Bare Metal
SAP to IBM Cloud Bare Metal server Migration Acceleration Program

Tutorials
SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, using RHEL
SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, when you are using Windows Server

How To
Provisioning IBM Cloud Bare Metal server for SAP HANA and SAP NetWeaver:
Planning your deployment
Deploying your infrastructure

Help
Requesting support for SAP-certified IBM Cloud Bare Metal servers
SAP ONE Support process
FAQ - IBM Cloud for SAP
FAQ - Profile List with Benchmarks and Specifications

Fast Path of IBM Cloud for VMware on Classic Infrastructure
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 9

This page is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as
SAP Sizing.
Use the links in this section to quickly access relevant documents that you are already familiar with.

Learn
An Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the
US) and a designated site location (also referred to as zone, which is a data center site). For more information:
IBM Cloud Classic Infrastructure environment introduction
Certified Infrastructure-as-a-Service for SAP HANA database server is available in many variations, each with different capabilities and sizes to fit many
different SAP workload scenarios. For more information:
Infrastructure certified for SAP - VMware Software-Defined Data Center
The following is an overview of the SAP-certified profiles with IBM Cloud Bare Metal servers for SAP HANA and SAP NetWeaver. For more information:
VMware SSDC certified profiles for SAP HANA
VMware SDDC certified profiles for SAP NetWeaver
Compute Profiles of SAP-certified VMware on Classic Infrastructure
Your business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver Application Server,
and therefore determine how your applications are run in the available infrastructure. For more information:
Connectivity options within the IBM Cloud Classic Infrastructure network
Bring-your-own network (Subnet/CIDR/IP address range) - Classic Infrastructure with VMware
Networking Traffic Segregation security considerations - VMware on classic infrastructure separation of subnets
Your enterprise IT organization can select from a variety of operating systems from the IBM Cloud for SAP portfolio. For more information:
OS Bring your Own Image/License for VMware SDDC
Depending on your scenarios, the following information may be also relevant:
SAP to VMware SDDC Migration Acceleration Program

How To
Provisioning VMware SDDC for SAP HANA and SAP NetWeaver:
Planning your deployment
Deploying your infrastructure

Help
Requesting support for SAP-certified VMware SDDC
SAP ONE Support process
FAQ - IBM Cloud for SAP
FAQ - Profile List with Benchmarks and Specifications

Fast Path of IBM Cloud Intel Bare Metal Servers on VPC Infrastructure
This topic is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as
SAP Sizing.
Use the links in this section to quickly access relevant documents that you are already familiar with.

Learn
An Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the
US) and a designated site location (also referred to as zone, which is a data center site). For more information:
IBM Cloud VPC Infrastructure environment introduction
Certified Infrastructure-as-a-Service for SAP is available in many variations, each with different capabilities and sizes to fit many different SAP workload
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 10

scenarios. For more information:
Infrastructure certified for SAP - Intel Bare Metal servers on VPC Infrastructure
The following is an overview of the SAP-certified profiles with IBM Intel Virtual Servers for SAP HANA and SAP NetWeaver. For more information:
IBM Cloud Intel Bare Metal Server certified profiles for SAP HANA
IBM Cloud Intel Bare Metal Server certified profiles for SAP NetWeaver
Compute Profiles of SAP-certified IBM Cloud Bare Metal Server
Therefore, your business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver
Application Server, and how your applications are run in the available infrastructure. For more information:
Connectivity options within the IBM Cloud VPC Infrastructure network
Bring-your-own network (Subnet/CIDR/IP address range) - VPC Infrastructure
Networking Traffic Segregation security considerations - VPC Infrastructure separation of subnets
Your enterprise IT organization can select from various operating systems from the IBM Cloud for SAP portfolio. For more information:
OS Bring your Own Image/License for VPC Infrastructure
Depending on your scenarios, the following information might be also relevant:
SAP to VPC Infrastructure Migration Acceleration Program

How To
Provisioning IBM Cloud Virtual Servers for SAP HANA and SAP NetWeaver:
Planning your deployment
Deploying your infrastructure

Help
Requesting support for SAP-certified IBM Cloud Bare Metal Servers
SAP ONE Support process
FAQ - IBM Cloud for SAP
FAQ - Profile List with Benchmarks and Specifications

Fast Path of IBM Cloud Intel Virtual Servers on VPC Infrastructure
This page is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as
SAP Sizing.
Use the links in this section to quickly access relevant documents that you are already familiar with.

Learn
An Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the
US) and a designated site location (also referred to as zone, which is a data center site). For more information:
IBM Cloud VPC Infrastructure environment introduction
Certified Infrastructure-as-a-Service for SAP HANA database server is available in many variations, each with different capabilities and sizes to fit many
different SAP workload scenarios. For more information:
Infrastructure certified for SAP - IBM Intel Virtual Server
The following is an overview of the SAP-certified profiles with IBM Power Virtual Servers for SAP HANA and SAP NetWeaver. For more information:
IBM Cloud Intel Virtual Server certified profiles for SAP HANA
IBM Cloud Intel Virtual Server certified profiles for SAP NetWeaver
Compute Profiles of SAP-certified IBM Cloud Intel Virtual Server
Your business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver Application Server,
and therefore determine how your applications are run in the available infrastructure. For more information:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 11

Connectivity options within the IBM Cloud VPC Infrastructure network
Bring-your-own network (Subnet/CIDR/IP address range) - VPC Infrastructure
Networking Traffic Segregation security considerations - VPC Infrastructure separation of subnets
Your enterprise IT organization can select from a variety of operating systems from the IBM Cloud for SAP portfolio. For more information:
OS Bring your Own Image/License for VPC Infrastructure
Depending on your scenarios, the following information may be also relevant:
SAP to VPC Infrastructure Migration Acceleration Program

Tutorials
SAP NetWeaver deployment to Intel Virtual Server on VPC Infrastructure that uses RHEL

How To
Provisioning IBM Cloud Virtual Servers for SAP HANA and SAP NetWeaver:
Planning your deployment
Deploying your infrastructure
Using IBM Metrics Collector for SAP (IMCS) on Linux

Help
Requesting support for SAP-certified IBM Cloud Intel Virtual Servers
SAP ONE Support process
FAQ - IBM Cloud for SAP
FAQ - Profile List with Benchmarks and Specifications

Fast Path of IBM Power Virtual Servers
Use this collection of shortcuts to quickly access relevant documentation for each offering, excluding general information that applies to all offerings, such
as SAP Sizing.

Learn
An Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the
US) and a designated zone and or data center. For more information, see IBM Power Systems Infrastructure environment introduction .
Certified IaaS for SAP HANA database server is available in many variations. Each variation has different capabilities and sizes to fit different SAP workload
scenarios. For more information, see Infrastructure that is certified for SAP - IBM Power Virtual Server .
The following links give an overview of the SAP-certified profiles with IBM Power Virtual Servers for SAP HANA and SAP NetWeaver.
IBM Power Virtual Server certified profiles for SAP HANA
IBM Power Virtual Server certified profiles for SAP NetWeaver
Compute Profiles of SAP-certified IBM Power Virtual Servers
Your specific requirements determine the SAP solutions that are powered by the SAP HANA Database Server or SAP NetWeaver Application Server and
determine how your applications run in the available infrastructure. For more information, see the following links.
Mapping CPUs derived from SAPS to an IBM Power Virtual Server
Monitoring for IBM Power Systems Virtual Servers
Connectivity options within the IBM Power Virtual Server network, connection through IBM Cloud
SAP license key with IBM Power Systems Virtual Servers
Network Block Storage for IBM Power Virtual Servers
Sample storage configurations on IBM Power Infrastructure
Your enterprise IT organization can select from various operating systems from IBM Cloud® for SAP portfolio. For more information about available
operating systems, see the following links.
OS for IBM Power Virtual Servers
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 12

OS - Bring your own image and or license for IBM Power Virtual Servers
Depending on your scenarios, the following links provide helpful information.
SAP NetWeaver - Configure high availability for IBM Power Infrastructure
SAP on IBM Db2 by using IBM Power Virtual Servers
SAP MaxDB by using IBM Power Virtual Servers
SAP ASE by using IBM Power Virtual Servers
SAP to IBM Power Virtual Server Migration Acceleration Program

How to
For more information about provisioning IBM Power Virtual Server for SAP HANA and SAP NetWeaver manually, see the following links.
Planning your deployment
Deploying IBM Cloud VPC infrastructure that is used by SAP workloads that run on IBM Power Virtual Servers
Deploying IBM Cloud Power Virtual Services infrastructure that is used by SAP workloads
Deploying IBM PowerVS instances for SAP system
For more information about implementing high availability scenarios for SAP on IBM IBM® Power® Virtual Server, see the following links.
Implementing High Availability for SAP Applications on IBM® Power® Virtual Server
Creating instances for a high availability cluster on IBM® Power® Virtual Server
Implementing RHEL HA Add-On cluster on IBM® Power® Virtual Server
Configuring SAP HANA Scale-Up System Replication in a RHEL HA Add-On cluster
Configuring SAP HANA Cost-Optimized Scale-Up System Replication in a RHEL HA Add-On cluster
Configuring SAP HANA Active-Active (Read-Enabled) System Replication in a RHEL HA Add-On cluster
Configuring SAP HANA Multitier System Replication in a RHEL HA Add-On cluster
Configuring SAP HANA Multitarget System Replication in a RHEL HA Add-On cluster
Configuring high availability for SAP S/4HANA (ASCS and ERS) in a RHEL HA Add-On cluster
Configuring an active-passive NFS server in a Red Hat High Availability cluster
For more information about SAP hybrid cloud migration scenarios for SAP on IBM IBM® Power® Virtual Server moving to PowerVS, see the following links.
Migrating SAP between on-premises and IBM Cloud on IBM® Power® Virtual Server Overview
Hybrid Cloud Network Considerations for SAP on IBM® Power® Virtual Server
Migrating SAP S/4HANA Pre-Migration Steps Source
Creating the Target SAP HANA System on IBM Power Systems Virtual Servers pre-step
Migrating SAP S/4HANA using HANA System Replication

Help
Use the following links if you need more help.
Requesting support for SAP-certified IBM Power Virtual Servers
SAP ONE Support process for IBM Power
FAQ - SAP-certified IBM Power Virtual Servers
FAQ - Profile List with Benchmarks and Specifications

More resources for SAP HANA
The following links can help you install and configure your Power Virtual Server instances with SAP HANA on Linux®. Links with numerals in the title lead to
the SAP Support Portal.

Operating systems – General Linux®
For more information about SAP on Linux, see the following table.
Link

Description

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 13

2378874 - Installation SAP Solutions on Linux on IBM Power Systems (little
endian)

Installing SAP solutions on IBM Power Systems

2235581 - SAP HANA: Supported Operating Systems

Supported operating systems for SAP HANA

2369910 - SAP Software on Linux: General information

General information about SAP software on Linux

765424 - Linux: Released IBM Hardware - POWER-based servers

IBM Power-based servers

1122387 - Linux: SAP Support in virtualized environments

SAP support in virtualized environments

SAP on IBM Power Systems running Linux

Useful information about running Linux on Power

936887 - End of maintenance for Linux distributions

Maintenance calendar and product maturity

2679703 - Linux on IBM Power Systems - SAP monitoring recommendations

SAP monitoring recommendations

187864 - Linux: Locale Support on Linux

Locale support for Linux

SAP on IBM Power Systems running Linux

SAP on IBM Power Systems library

2382421 - Optimizing the Network Configuration on HANA- and OS-Level

Increasing efficiency on network for operating systems and SAP
HANA

401162 - Linux: Avoiding TCP/IP port conflicts and start problems

Avoiding network-related start issues

Table 1. Operating systems – general Linux

Operating systems – SUSE Linux
For more information about SAP on SUSE Linux, see the following table.
Link

Description

2205917 - SAP HANA DB: Recommended OS settings for SLES 12 / SLES for SAP Applications 12

SLES 12 recommended operating system
settings

1984787 - SUSE LINUX Enterprise Server 12: Installation notes

SLES 12 installation note

2578899 - SUSE Linux Enterprise Server 15: Installation Note

SLES 15 installation note

2684254 - SAP HANA DB: Recommended OS settings for SLES 15 / SLES for SAP Applications 15

SLES 15 recommended operating system
settings

2790462 - HANA Server connection is not available or timed out after you upgrade to SUSE 15 from
SUSE 12

Known issue when you upgrade from 12 to
15

1275776 - Linux: Preparing SLES for SAP environments

Preparing SLES for SAP environments

SUSE Best Practices Library

A useful collection of SUSE documentation

SUSE Enterprise Server for IBM POWER

IBM and SUSE
Table 2. Operating systems – SUSE Linux®

Operating systems – Red Hat Linux® (RHEL)
For more information about SAP on RHEL, see the following table.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 14

Link

Description

SAP Note 2772999 RHEL 8.x: Installation and Configuration

SAP Note 2777782 SAP HANA DB: Recommended OS Settings for RHEL 8

SAP Note 2382421 Optimizing the Network Configuration on HANA and OS-Level

SLES 15 installation note

2684254 - SAP HANA DB: Recommended OS settings for SLES 15 / SLES for SAP Applications 15

RHEL System Roles for SAP

Table 3. Operating systems – Red Hat Linux

SAP HANA-related information
For more information about SAP HANA, see the following table.
Link

Description

2000003 - FAQ: SAP HANA

Extensive overview of SAP HANA

1999880 - FAQ: SAP HANA System Replication

HSR central note

2000002 - FAQ: SAP HANA SQL Optimization

Useful tips to improve SQL processing times

SAP HANA Platform Landing page

Useful for installation guides and upgrade guides

SAP Guide Finder

Useful to locate user guides and information on updates

2380291 - SAP HANA 2.0 Cockpit Central Release Note

SAP HANA Cockpit central note
Table 4. SAP HANA-related information

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 15

Infrastructure environments
Classic Infrastructure environment introduction
An Infrastructure-as-a-Service (IaaS) environment consists of many components. These components are primarily compute, storage, a network from a
specified region (such as the US), and a designated site location (also referred to as zone, which is a data center site).

Deployment and management
IBM Cloud Classic Infrastructure offerings (such as Bare Metal Servers) are deployed through the IBM Cloud Classic Infrastructure console.
Alternatively, deployments can be made and managed by using:
IBM Cloud CLI
IBM Cloud Classic Infrastructure API (Softlayer API) calls that use an IBM Cloud Classic Infrastructure API key
Terraform Provider for IBM Cloud that uses an IBM Cloud Classic Infrastructure API key
For more information, see Managing IBM Power Virtual Servers (IAM) .

Locations - Data centers
With data centers across North and South America, Europe, Asia, and Australia, you can provision cloud resources where (and when) you need them. You
can choose from many regions globally, and each region has multiple data centers. Each data center is connected to the IBM Cloud global private network,
making data transfers faster and more efficient anywhere in the world.
For more information about IBM Cloud availability zones, data centers, and points of presence (PoPs), see the global regions and availability zones and
data centers map.

Networking
The classic infrastructure network, is robust, secure, and flexible; built upon matured networking principles combined with the latest in networking
hardware.
IBM Cloud Classic Infrastructure network
Global
Region
Data center
Data center Pod
VLAN (Public and Private)
Subnet (Public and Private)
Table 1. Networking component layers overview

Note: Classic Infrastructure was formerly known as Softlayer.
The IBM Cloud Classic Infrastructure network provides connectivity across a global footprint of over 60 IBM Cloud data centers and 28 points of presence
(PoPs). Connections are available to leading global network providers and communications service providers.
The IBM Cloud Classic Infrastructure network consists of three distinct and redundant network architectures that are seamlessly integrated in the secured
network-within-a-network topology (multiple isolated logical networks, for example VLANs). This configuration means if an outage occurs in a data center
on the public network, the traffic is routed and traverses through other established networks. Routing the traffic across other networks and through another
data center provides continued server availability.
The three distinct and redundant network architectures within the secured network-within-a-network topology are:
Public network: provides carrier grade internet connectivity to multi-home backbone carriers. On public IP, the connection is made to the IBM Cloud
network PoP closest to the origin request. Traffic travels directly across the IBM Cloud data center to the data center network backbone into the
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 16

correct data center, minimizing the network hops and handoffs between providers that add network latency.
Private network: provides complete control of the secured networking traffic without performance degradation if significant public network traffic
occurs at the same time; the private network has three functional areas:
Host to and from Host : network traffic in the private VLANs assigned to you. Bandwidth is free and unmetered.
Host to and from Backend Services: network traffic to and from the private VLAN to OS update servers, NTP, DNS resolvers, network storage
and more. Bandwidth is free and unmetered.
VPN and direct connections to and from VLAN: network traffic to and from an existing internal network over direct connection or VPN that
uses a distinct stand-alone network to the secure private VLAN. Bandwidth is free and unmetered.
Data center to Data center interconnectivity: provides secure connectivity between hosts across IBM Cloud data center locations. Bandwidth
is free and unmetered.
Management network: provides Out-Of-Band Management (OOBM) accessible through VPN (for example the built-in SSL VPN for administration) or
direct connection (for example IBM Cloud Direct Link). Network management allows Remote Console access through the IPMI network interface for
Bare Metals hosts on the private network. Bandwidth is free and unmetered.
This network-within-a-network topology design provides maximum accessibility, security, and control for your IT infrastructure. The topology provides the
ease of a public network with the security of a private network by keeping systems accessible to administrators and safely off-limits to external users.

Networking VLANs
The Virtual LAN (VLAN) assigned to you on the Classic Infrastructure network, provides an enterprise-grade private network with full isolation and security.
Each VLAN is either public or private, and each VLAN is assigned to a specific data center for a specific IBM Cloud Account.
The following information is a summary of Getting started with VLANs on Classic Infrastructure and About VLANs on Classic Infrastructure.
A VLAN can have multiple Subnets for you to use to segregate traffic, for example:
Public VLAN
Public Primary Subnet (default)
Public Secondary Portable Subnet
Public Secondary Static Subnet
Private VLAN
Private Primary Subnet (default)
Private Secondary Portable Subnet
If you want to separate different types of network traffic in your landscape, use subnets in your network design to separate network traffic and use more
Virtual LANs (VLANs) only when required.
Keep in mind that the additional VLANs and Subnets lead to traffic segregation, not increased performance; the increased performance is gained when
additional VLANs and Subnets are associated to a host. When multiple network interfaces are used, two performance increases are possible depending on
the use case:
Bonding of the network interfaces, creating a network path with the network throughput of both interfaces
Traffic segregation using two networks, then isolating high volumes of traffic to a specific network which avoids a single network becoming a
bottleneck. For example, a network for storage I/O only
By default, your server has a Primary Public IP address and Primary Private IP address. If you want your server to be private, you can turn off the public
interface by either:
Ordering your server as private-only
Using the console or the OS after the server is provisioned
Alternatively, the server can be attached to a public VLAN and private VLAN that is associated with a Gateway Appliance. In this arrangement, the server
has a DMZ with a public network facing VLAN and private network facing VLAN.

Networking subnets
In Classic Infrastructure, the VLAN has different types of Subnets. The following information is a summary of Getting started with subnet and IPs on
Classic Infrastructure and About subnets and IP on Classic Infrastructure .
Different types of subnets in Classic Infrastructure:
1. Public and Private Primary Subnet
Auto-assigned when provisioning resources (for example, Bare Metal) into a Public and Private VLAN
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 17

Primary subnets have limitations
2. Public and Private Secondary Portable Subnet
Appends new subnet to Public and Private VLAN
Provides IP addresses for assignment to any resource within a VLAN, can assign Portable IP to multiple resources as a Floating IP
Enables connection to multiple resources from a single Portable IP
3. Public Secondary Static Subnet
Appends new subnet to Public VLAN
Provides IP addresses for assignment to one resource within a VLAN (that uses the existing Primary IP or Portable IP of the resource as the
"routing endpoint")
Enables connection to one resource by using any of the Static IPs plus the original Primary IP or Portable IP.
4. Public Secondary Global Subnet also known as Global IP addresses
Appends single Internet-accessible IP from IBM Cloud private backbone to any VLAN worldwide
Provides single IP address for assignment to one resource within any VLAN worldwide (using the existing Primary IP or Portable IP of the
resource as the "routing endpoint")
Enables connection to one resource from any data center or VLAN on IBM Cloud backbone or from Public Internet

Networking connectivity
Issues with network connectivity can cause significant delays for your project. Plan your network carefully, regardless of how you plan to use your system.
Each provisioned server has network interfaces, available at a speed of 100 Mb/s, 1 Gb/s, and 10 Gb/s.
In general, you have two interface choices:
An external interface with a Public IP
An internal interface that is provided with a Private IP; in compliance with IETF RFC 1918. You can also choose a single internal interface with a
“private IP.”
Both options can be made redundant through:
On Linux®, a "bonding interface"
On Windows Server, a Windows Network Interface Card (NIC) Teaming
Depending on your use case, a Public IP might be acceptable for proof-of-concept (PoC) landscapes because the external IP might be easier to use.
However, this arrangement has some implications:
A potential security risk exists even though a basic firewall is installed and preconfigured.
If you want to use a public interface, be sure to choose a sufficiently high value for Public Bandwidth when you order your server. This value
determines the total amount of data that can be transferred through the interface during a one-month period. You either need to know the amount of
data that is transferred at least by the order of magnitude or switch to the second option.
Access to the resources on the IBM Cloud Classic Infrastructure is available with greater security:
Using the SSL Virtual Private Network (VPN), default available through the IBM Cloud Classic Infrastructure console
Using the IPSec Virtual Private Network (VPN)
Using a Gateway Appliance with Firewall, Network Address Translation (NAT)
Direct Link
These connectivity options can provide you with a higher bandwidth, which help you in transferring larger amounts of data into an IBM Cloud data center.
Note: It is advised that your networking department contact IBM Cloud Support after you determine the layout of your landscape and the
connectivity that is required on the SAP application layer.

Storage
Within Classic Infrastructure, three types of storage are available:
Local Disk Storage (SSD)
Network Block Storage (LUNs only) that uses IBM Cloud Block Storage (Classic)
Network File Storage (file system installed) that uses IBM Cloud File Storage (Classic)
Local disk storage is provided with your Bare Metal Servers and available in your choice of RAID configuration (by using a dedicated RAID Controller). It is
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 18

ideal for storage-intensive applications with high I/O needs, such as an OS, database, and application software. This storage is the perfect companion for
SAP HANA workloads.
Note: Bare Metals with local disk storage use disks physically inserted into the drive bays; it is not using a SmartNIC to present network block
storage as if it were local disk storage.
In addition to the local storage, you might require network storage (to expand beyond the Local SSD Disk total capacity, or for redundancy and backups).
These require more network consumption to access Network Block Storage and Network File Storage that are using the same physical network interfaces
and the impact should be validated.
Both IBM Cloud Block Storage for Classic or IBM Cloud File Storage for Classic can serve as either backup space or as storage for extra software
components that are installed on your server.
All IBM Cloud Block Storage for Classic or IBM Cloud File Storage for Classic is selected based on capacity (GB) and performance (IOPS) measurements.
IOPS are measured based on 16 KB block size with a 50/50 read/write mix. To achieve a maximum I/O throughput, it's advisable to look at the tier and
custom profiles available for storage and find the optimal combination of size and IOPS.
Storage volumes differ in performance, depending on their IOPS tier (see Tiered IOPS profiles or selecting a custom size (in GB and IOPS) that is based on
the size of the storage.
If you need more than the initially provisioned storage in your virtual server, you can attach extra volumes to a virtual server later. Contact

IBM Cloud

Support for extension options if the attached storage is insufficient for your workload.
For more information, see Getting started with Block Storage for Classic and Getting started with IBM Cloud File Storage for Classic .

Compute
Three primary types of IaaS are available within the IBM Cloud Classic Infrastructure:
1. Bare Metal server
2. Classic Virtual Servers (not SAP certified)
3. VMware, available in two options:
Intel Bare Metal and VMware vSphere (ESXi OS) , requires manual VMware setup and configuration
IBM Cloud for VMware Solutions Dedicated
Bare Metal and both VMware options are SAP-certified.
Classic Virtual Servers are not SAP-certified. For this type of IaaS, the IBM Cloud VPC Infrastructure environment provides Intel Virtual Servers which are
SAP-certified.
For more information, see Infrastructure certified for SAP.

IBM Cloud® Virtual Private Cloud (VPC) Infrastructure environment introduction
An Infrastructure-as-a-Service (IaaS) environment consists of many components - primarily compute, storage, and network from a specified region (such
as the US) and a designated site location (also referred to as a zone), which is a data center site.

Deployment and management
IBM Cloud VPC Infrastructure offerings, such as virtual or bare metal servers, are deployed through the IBM Cloud VPC Infrastructure console .
Alternatively, deployments can be made and managed by using:
IBM Cloud CLI
IBM Cloud VPC Infrastructure API calls that use an IBM Cloud API key
Terraform Provider for IBM Cloud by using an IBM Cloud API key
For more information, see Managing VPC Infrastructure (IAM).

Locations - availability zones
With availability zones across North and South America, Europe, Asia, and Australia, you can provision cloud resources where (and when) you need them.
Many regions are available globally, with multiple availability zones in each region. Each availability zone is connected to the IBM Cloud global private
network, making data transfers faster and more efficient anywhere in the world.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 19

For more information about IBM Cloud availability zones, data centers, and Points of Presence (PoPs), see the global regions, availability zones, and data
centers map.

Compute Resources
Two types of compute resource can be deployed in IBM Cloud VPC Infrastructure environment:
Intel Virtual Server Instances (VSIs)
Intel Bare Metal Servers
These compute resources are offered in different profiles that define CPU and RAM combinations.
For more information, see Infrastructure certified for SAP.

Networking
The IBM Cloud VPC infrastructure network, is robust, secure, and flexible; powered by the latest in networking hardware, with the best networking
capabilities. It allows definable isolation and creation of a network within the cloud.
IBM Cloud VPC Infrastructure network
Global
Resource Group
Region
VPC
Availability zone (with address prefix)
Subnet
Table 1. Networking component layers overview

Every IBM Cloud® Virtual Private Cloud is created for a region, and spans multiple availability zones.
When you deploy a VPC in an availability zone, an address prefix is used for that specified zone.
Each VPC Zone (and the address prefix) contains one or more subnets. You can define each subnet manually by choosing the IP range and the subnet mask,
or you can choose the number of IP addresses needed. A newly created compute resource is deployed into this subnet and can also be attached to further
subnets.

Networking connectivity
IBM Cloud® Virtual Private Cloud network overview demonstrates the connectivity for the environment. Issues with network connectivity can cause delays
for your project if you do not plan properly, regardless of how you plan to use your system.
In general, IBM Cloud VPC has a highly available, high-bandwidth network that is connected to every compute resource, be it bare metal servers or
physical servers, which, in the VSI case, serve a hypervisor. Each physical server (host), which serves a hypervisor, divides the network into virtual network
interfaces (vNICs) that are attached to the virtual server.
Depending on the profile of your virtual server, the total available network bandwidth to the virtual server is in the range of 4 Gbps to 64 Gbps. It's
important to consider that each vNIC has a maximum throughput of 16 Gbps, so to achieve maximum throughput, up to 4 additional vNICs must be
attached to the virtual server (that is, a virtual server might have a maximum of 5 vNICs attached).
If you need to connect to your virtual or bare metal server through the public internet (also known as inbound to a server), you can order a Floating IP and
attach to the server's vNIC, in other words: you can attach one Floating IP per server.
If you want to connect to the public internet from your server (also known as outbound from a server), you need to attach a Public Gateway to the VPC. This
gateway provides access to the internet for an entire subnet.
The following inter-connectivity options are available:
VPC zone to zone,
VPC to VPC,
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 20

VPC to Classic Infrastructure,
VPC to IBM Power Systems Infrastructure,
VPC to on-premises data centers by using a VPC VPN Gateway
When a connection to the public internet is not acceptable because of security measures, you can deploy an IPsec Gateway into your VPC to connect to
your server. For more information, see Connectivity to your SAP system landscape - VPC VPN Gateway . Or, you can have an even closer integration into
your backbone infrastructure by an IBM Cloud Direct Link. For more information, see Connectivity to your SAP system landscape - IBM Cloud Direct Link .
Server resources that are in IBM Cloud Classic Infrastructure can be connected through Transit Gateways. These virtual devices are used to connect your
private VLAN subnets in the Classic Infrastructure to your VPC subnets.
For more information, see About Networking for VPC and Setting up access to classic infrastructure .
Important: Extra requirements exist in Classic Infrastructure networking to enable the Transit Gateway, be sure to review documentation before
you change your Classic Infrastructure or VPC Infrastructure networking topology and configuration.

Note: It is advised that your networking department contact IBM Cloud Support after determining the layout of your landscape and the
connectivity that is required on the SAP application layer.

Networking protection
IBM Cloud® offers further protection mechanisms that can provide your Virtual Servers for VPC with a layer of security that you can configure and adapt
anytime. Two key principles are:
Network Access Control Lists (ACL) : Available for use by all subnets in all zones. ACLs attach to a subnet and provide subnet-level protection by
limiting a subnet's inbound and outbound traffic.
Security Groups: Available for use by all subnets on all zones that are attached to a vNIC of any server that provides instance-level protection by
acting as a firewall to restrict a vNIC inbound and outbound traffic.
For more information, see Security in your VPC.

Subnets to separate traffic
If you want to separate different network traffic types in your landscape, either because of security restrictions or because of throughput considerations,
you can configure and attach multiple subnets to your VPC and make them available to your compute resources, too.

Network Access Control List
Network Access Control Lists (ACLs) are used to manage allow and deny rules on a subnet level. ACLs are used to manage network traffic between
subnets, too. The default ACL for a subnet opens the subnet for all traffic. If you wanted more strict security measures, you would need to add rules to the
ACL. When you add rules, keep in mind that required services like DNS or OS patch and packages downloads might be affected by those rules. For more
information, see Security in your VPC.

Security Groups
A Security Group is a set of allow-only firewall rules. You can apply these rules to one or more bare metal servers or VSIs. You can also create a default
Security Group with Secure Shell (SSH) and ICMP (ping) during VPC creation, which allows ICMP and SSH from any IP address. These rules need to restrict
the IPs or IP ranges from which you are planning to access the VPC.

Storage
Block storage is provided with your virtual servers and uses input/output operations per second (IOPS) to determine storage needs. It is ideal for storageintensive applications with high I/O needs, such as an OS, and database and application software. This option is the perfect companion for SAP HANA
workloads.
All Block storage is selected based on capacity (GB) and performance (IOPS) measurements and is required to meet a specific SAP Workload.
IOPS values are measured based on 16 KB block size with a 50-50 read/write mix. To achieve a maximum I/O throughput, it's advisable to look at the tier
and custom profiles available for storage and find the optimal combination of size and IOPS.
Storage volumes differ in performance, depending on their IOPS tier. You can select among 3, 5, and 10 IOPS/GB (see

Tiered IOPS profiles). You can also

select a custom size (in GB and IOPS) that is based on the size of the storage.
If you need more than the initially provisioned storage in your server, you can attach extra volumes to a it later. Contact

IBM Cloud Support for extension

options if the attached storage is insufficient for your workload.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 21

Shared Storage
Block storage can be detached and attached to other servers at any time, but, only to one server at the same time.
No shared storage for servers is available in VPC at time of writing.

IBM Power Systems Infrastructure environment introduction
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services
An Infrastructure-as-a-Service (IaaS) environment consists of many components - primarily compute, storage, and network from a specified region (such
as the US) and a designated site location (also referred to as zone, which is a data center site).

Deployment and management
IBM Power Virtual Server is an IBM Power Systems enterprise Infrastructure-as-a-service (IaaS) offering.
These IBM Power Virtual Servers are physically located with low-latency connectivity to the IBM Cloud Classic Infrastructure or VPC Infrastructure. In the
data centers, the Power Virtual Servers are separated from the rest of the IBM Cloud servers with separate networks and direct-attached storage. This
infrastructure design enables Power Virtual Servers to maintain key enterprise software certification and support as its architecture is identical to certified
on-premises infrastructure. The internal networks are fenced but have connectivity options to the rest of environments and services on IBM Cloud.
IBM Power Systems Infrastructure offerings (such as IBM Power Virtual Server) are deployed using the IBM Power Infrastructure console available
through IBM Cloud.
Alternatively, you can create and manage deployments with any of the following methods:
IBM Power Infrastructure plug-in for IBM Cloud CLI
IBM Power Infrastructure API calls with an IBM Cloud API key
Terraform Provider for IBM Cloud with an IBM Cloud API key
For more information, see Managing IBM Power Virtual Servers (IAM) .

Locations - Data centers
With data centers across North and South America, Europe, Asia, and Australia, you can provision IBM Power Infrastructure resources where (and when)
you need them.
You can choose from multiple data centers globally.
Each data center with IBM Power Infrastructure uses a separate enterprise-grade network which is connected using IBM Cloud Direct Link to the IBM
Cloud global private network, making data transfers faster and more efficient anywhere in the world.
For more information about IBM Cloud availability zones / data centers and points of presence (PoPs) where IBM Power Infrastructure can be connected
to, see the global regions and availability zones / data centers map .

Networking
The IBM Power Systems Infrastructure network, is built upon IBM Power's enterprise-grade secure networking hardware and connectivity; it can be
bridged to the separate IBM Cloud networks (either Classic Infrastructure network or VPC Infrastructure network).
IBM Power Virtual Server Group network on IBM Cloud
Global
Resource Group
Region
Datacenter
Datacenter colocation Room

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 22

VLAN (Public and Private) used internally, effectively transparent to the administrator
Subnet (Public and Private)
Table 1. Networking component layers overview

Connectivity is available to the IBM Power Systems Infrastructure network leveraging connectivity options available from leading global network providers
and TelCo providers in addition to the connectivity options available using the IBM Cloud global footprint of more than 60 IBM Cloud data centers and 28
points of presence (PoPs).

Networking VLANs and Subnets
The following information is a summary of Configuring connectivity to Power Systems Virtual Server and Configuring and adding a private network subnet.
The Virtual LAN (VLAN) on the IBM Power Systems Infrastructure network, provides an enterprise-grade private network with full isolation and security.
Each VLAN is Public or Private, and is assigned to a specific data center for a specific IBM Cloud Account.
Each VLAN is associated with a single Subnet, for example:
Public VLAN (only one per region)
Public Subnet
Private VLAN
Private Subnet
A Public Subnet is the quickest and simplest way to connect to a IBM Power Virtual Server instance. The public network is protected by a firewall and only
the following network protocols are allowed:
SSH (port 22)
HTTPS (port 443)
Ping (ICMP)
IBM i 5250 console emulation with SSL (port 992)
Note: For the public network, other ports are blocked and can be routed through SSH.
A Private Subnet is required for the connection of your virtual instances with systems outside of the IBM data centers and for communication between
multiple instances in an SAP three-tier system. This subnet is an internal network that can be used to connect individual IBM Power Virtual Servers with
each other.
If you want to separate different types of network traffic in your landscape, you can order more subnets (and their respective VLANs).
Keep in mind that the additional VLANs and subnets lead to traffic segregation, not increased performance; the increased performance is gained when
additional VLANs and Subnets are associated to a host. When multiple network interfaces are used, two performance increases are possible depending on
the use case:
Bonding of the network interfaces, creating a network path with the network throughput of both interfaces
Traffic segregation using two networks, then isolating high volumes of traffic to a specific network which avoids a single network becoming a
bottleneck. For example, a network for storage I/O only
With IBM Power Virtual Server as an example, a single threaded Linux network interface may reach 100% CPU Thread utilization even though the
performance limits of the network path itself are still not reached. Additional network interfaces attached to another VLAN and Subnet will therefore
increase performance
By default, your server has a Private IP address. If you use public subnets, a public IP address is assigned in addition.

Networking connectivity
Issues with network connectivity can cause delays for your project if you do not plan properly, regardless of how you plan to use your system.
If you need to connect to your virtual server through the public internet, in other words, inbound to a virtual server, you can order Public IPs and attach
them to the virtual server per vNIC.
Various interconnectivity options available, for example:
IBM Power Systems Infrastructure bridged to IBM Cloud Classic Infrastructure
IBM Power Systems Infrastructure bridged to IBM Cloud VPC Infrastructure

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 23

IBM Power Systems Infrastructure bridged to on-premises data centers by using IBM Direct Link
IBM Cloud Direct Link on Classic must be used to connect your IBM Power Virtual Servers with your IBM Cloud Classic Infrastructure and VPC
Infrastructure resources.
After you configure Direct Link on Classic, you must configure routing on your virtual server instance. For more information, see

Adding routes on your

instance for the jump server.
Direct Link on Classic is also used for closer integration into your backbone infrastructure, for more information, see Connectivity to your SAP system
landscape.
For more explanation information about IBM Power Systems Infrastructure, see IBM Power Virtual Servers.
Note: Have your networking department contact the IBM Power Virtual Servers Support Team, handled by using IBM Cloud Support after you
determine the layout of your landscape and the connectivity that is required on the SAP application layer.

Storage
Within IBM Power Systems Infrastructure, there are two types of storage available:
Block Storage Tier 1 (storage for mission critical application with best characteristics, e.g. NVMe flash storage)
Block Storage Tier 3 (default storage type with optimized price/performance, e.g. SSD flash storage)
Note: Do not mix storage types on a IBM Power Virtual Server.
Block Storage is provided with your IBM Power Virtual Servers and storage requirements are defined using input/output operations per second (IOPS) and
the capacity (GB). High performance block storage is ideal for storage-intensive applications with high I/O needs, such as an OS, and database and
application software. For SAP HANA workloads, Tier 1 of block storage is supported only.
All Block Storage is selected based on capacity (GB), currently the performance (IOPS) measurement cannot be fine-tuned.
Block Storage for IBM Power Virtual Servers is powered underneath by IBM FlashSystem family connected through the Fibre Channel protocol.
For further information, see hardware specifications for IBM Power Virtual Servers .
Contact IBM Cloud Support for extension options if the attached storage is insufficient for your workload.

Compute
There is only one type of IaaS available within the IBM Power Systems Infrastructure environment:
1. IBM Power Virtual Servers
The IBM Power Virtual Servers are SAP-certified.
Currently following IBM Power Systems hardware are utilised by IBM Power Virtual Servers:
S922 – optimized for SAP NetWeaver application server
E980 – optimized for SAP HANA database server
For more information, see Infrastructure certified for SAP.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 24

Infrastructure certified for SAP
Certified Infrastructure-as-a-Service for SAP HANA database servers and for SAP NetWeaver based applications is available in many variations, each with
different capabilities and sizing available to fit many different SAP workload scenarios.
For the official and full platform list of Infrastructure-as-a-Service from IBM that is SAP certified and supported for SAP HANA, see the

SAP Certified and

Supported SAP HANA Hardware Directory - Certified IaaS Platforms - IBM Cloud. For an official list of SAP NetWeaver and SAP HANA supported bare metal
and virtual servers, see SAP Note 2927211.
Tip: The documents provide detailed considerations and information for building your SAP environments at each layer for all offerings. However, if
you are interested in quickly finding the information that is related specifically to one of the IaaS offerings, then you might consider using the Fast
Path Site Maps for Intel Bare Metal (Classic), Intel Bare Metal (VPC), Intel Virtual Servers (VPC), IBM Power Virtual Servers, and VMware SDDC.

Intel Bare Metal servers on Classic Infrastructure
IBM Cloud® Bare Metal Servers are physical servers with numerous customization capabilities.
The servers are dedicated for your use, or your customer's, and not shared in any part, including server resources, with other IBM Cloud customers.
These servers are managed by the account holder, either you, your customer, or your services partner, depending on your business operations.
These servers are provisioned with your choice of operating system (OS) image that is directly installed to bare metal.
Because customization is controlled on bare metal servers, fast provisioning times of in the range 1 - 4 hours are obtainable with worldwide availability.
For larger systems (greater 4 TB DRAM), there is a longer validation period for checking the hardware components (particularly RAM), but the machines are
usually available within 24 hours.
For more information about Bare Metal servers on Classic Infrastructure, see IBM Cloud Bare Metal Servers on ibm.com and IBM Cloud Bare Metal Servers
for Classic - server options on IBM Cloud Docs.

Intel Bare Metal servers on Classic Infrastructure with Intel Optane DC Persistent
Memory
Resource: Intel Optane SSD
In addition, the IBM Cloud Bare Metal Servers are also available with Intel® Optane DC Persistent Memory, which is engineered for high-performance SAP
production environments with ultra-high memory requirements and tuned by SAP to increase performance of SAP HANA 2.0 (SPS 03 and higher). Due to
the design of Intel Optane DC PMEM, which uses dense storage format factor in DIMM slots with direct CPU access, the new storage medium has ultra low
latency read/write and enables:
Improved SAP HANA Dynamic Tiering with improved cost-efficiency and without reducing performance
Reduced business downtime and improved RTO KPIs by moving the SAP HANA main data column store to Intel Optane DC Persistent Memory, with
all data immediately accessible after planned or unplanned maintenance windows.

Intel Virtual Servers on VPC Infrastructure
IBM® Virtual Servers are virtual machine servers with extensive customization capabilities.
The servers run on a hypervisor that is managed by IBM Cloud, providing you flexible compute by using a scalable infrastructure (available in multi-tenant
or dedicated single-tenant).
These servers are managed by the account holder, either you, your customer, or your services partner, depending on your business operations.
These servers are provisioned with your choice of operating system (OS) image that is installed to Virtual Servers.
IBM Cloud VPC Infrastructure is available for:
Intel Virtual Servers, based on the latest hardware designs with large improvements across networking performance (up to 80 Gbps), provision
times (5x faster), and a flexible selection of extra features
For more information about Virtual Servers on VPC Infrastructure, see What is IBM Cloud VPC? and IBM Cloud Virtual Server for VPC on ibm.com and IBM
Cloud Intel Virtual Servers on VPC Infrastructure on IBM Cloud Docs.

Intel Bare Metal servers on VPC Infrastructure
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 25

IBM Cloud® Bare Metal Servers are physical servers with numerous customization capabilities.
The servers are dedicated for your use, or your customer's, and not shared in any part, including server resources, with other IBM Cloud customers.
These servers are managed by the account holder, either you, your customer, or your services partner, depending on your business operations.
These servers are provisioned with your choice of operating system (OS) image that is directly installed to bare metal.
Because customization is controlled on bare metal servers, fast provisioning times of in the range 1 - 4 hours are obtainable with worldwide availability.
For larger systems (greater 3 TB DRAM), there is a longer validation period for checking the hardware components (particularly RAM), but the machines are
usually available within 24 hours.
For more information about Bare Metal servers on VPC Infrastructure, see Deploy IBM Cloud Bare Metal Servers on VPC Infrastructure on ibm.com and
About Bare Metal Servers for VPC on IBM Cloud Docs.

IBM Power Virtual Server
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services
IBM Power Virtual Servers are virtual machine servers with enterprise-grade performance and extensive customization capabilities. These IBM Power
Virtual Servers are also known as an IBM Power Logical Partitions (LPARs).
The servers run on IBM PowerVM (Type 1 hypervisor) managed by IBM Power Systems and facilitated by IBM Cloud are a form of Infrastructure-as-aService (IaaS) provisioned with your choice of operating system (IBM AIX or Linux®) image that is installed and infrastructure customization (such as
dedicated CPU performance or shared CPU for optimized costs). By using the IBM PowerVM underneath, the customization of the Virtual Servers is flexible,
with fast self-service provisioning available in worldwide locations - all with pay-as-you-use billing that makes it easier for you to scale up and out.
IBM Power Virtual Servers are colocated in the same IBM Cloud data centers that are used by both IBM Cloud Classic Infrastructure and VPC
Infrastructure, but are separated from the rest of the IBM Cloud servers with separate networks and storage. They can be connected to/from an onpremises network, the IBM Cloud Classic Infrastructure or IBM Cloud VPC Infrastructure networks by using IBM Cloud® Direct Link on Classic.
The IBM Power Virtual Servers can be used for several workload scenarios such as disaster recovery, development environments, partial IT infrastructure
moves and enabling you to stay competitive with flexible scaling of infrastructure capacity in a hybrid cloud deployment. This Infrastructure-as-a-Service
(IaaS) offering is designed for large mission-critical workloads where scale-up over 12 TB of memory and density of 6,000 SAPS per CPU Core are required
to meet performance.
As the IBM Power Virtual Servers are IaaS once provisioned are managed by the account holder; either you, your customer, or your services partner
depending on your business operations model.
IBM Power Systems clients who rely on on-premises data center deployments for their infrastructure, can now quickly and economically extend their IBM
Power resources into the cloud in a matter of minutes. The IBM Power Virtual Servers provide:
Straightforward billing: Hourly rates on Monthly Billing, with IBM PowerLinux customers can use Bring-your-own-License (BYOL), to use their own
licenses for the OS Images provided by IBM Power Virtual Servers and reduce costs of their Cloud environment.
Enterprise Hybrid Cloud deployment: run workloads on IBM Power in both Cloud IaaS and on-premises, accessing Cloud's self-service, fast
delivery, elasticity, and connectivity to other IBM Cloud® services. Although your Linux® workloads are running in IBM Power Virtual Servers, you keep
the same scalable, resilient, production-ready features that Power Systems hardware is known to provide.
Infrastructure customization: Flexibility of IBM Power Virtual Servers hardware capabilities:
Cores (CPU)
Memory (RAM)
Data volume size
Data volume type / performance tier
Network interfaces
PowerVM Host Pinning Policy (soft or hard)
PowerVM Host CPU Binding (dedicated or shared)
For more explanation information about IBM Power Virtual Servers, see IBM Power Virtual Servers on ibm.com and IBM Power Systems Virtual Servers on
IBM Cloud Docs.
Tip: If you'd like to compare your current environment's performance to what's available through the IBM Power Virtual Server service, see the
IBM Power Systems performance report. For a more condensed comparison, see IBM Power Systems CPW performance data comparison .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 26

Constructs for provisioning IBM Power Virtual Servers
As the IBM Power Virtual Server is a complementary offering from IBM Power Systems, it is accessed as an additional offering from the IBM Cloud catalog.
To begin using IBM Power Virtual Servers, an instantiation of an IBM Power Virtual Server resource group must first be made.
The below sections explain this in more detail.

Resource versus Resource Group
A resource in the context of IBM Power Virtual Servers is not a user, it's anything that you can create from the catalog, for example, an IBM Power Virtual
Server. A resource group contains multiple resources, for example, a set of servers used strictly for development activities. For more information, see
Creating resources.

Service versus instance
There is difference between an IBM Power Virtual Server service and an IBM Power Virtual Server instance. Think of the IBM Power Virtual Server service
as a container for all IBM Power Virtual Server instances at a specific geographic location. The IBM Power Virtual Server service is available from the
Resource list in the IBM Cloud® UI. The service can contain multiple IBM Power Virtual Server instances.
For example, you can have two IBM Power Virtual Server services, one in Dallas and another in Washington DC. Each service can contain multiple IBM
Power Virtual Server instances. For more information, see Getting started with IBM Cloud IBM Power Virtual Server .
Note: All instances of an SAP system must run in the same service. Multiple systems can be distributed through different services, in which case IT
operations teams must ensure that latency is acceptable for their scenarios.

IBM Power CPU type - dedicated or shared
For shared processors, you choose the number of CPUs that the new server is entitled to use. This number should correspond to the number of CPUs that
were the result of your sizing. The entitled CPUs should be sufficient for normal production operation and to cover workload during peak time. Don't count
on additional CPUs that you might get out of the shared processor pool for uncapped processors.
For dedicated processors, the number of dedicated CPUs should correspond to the number of CPUs that were the result of your sizing.
For more information about shared and dedicated processors, see Assigning the appropriate processor entitled capacity and Power Virtual Servers
processor types.
Note: Depending on the SAP workload, supported processor options are restricted. For more information, see SAP Note 2855850.

SAP HANA and IBM Power Virtual Server
See SAP Note 2947579 - SAP HANA on IBM Power Virtual Servers for SAP HANA support on IBM Power Virtual Servers.
SAP HANA workloads that use IBM Power Virtual Servers run on IBM Power System E980, with Block Storage powered by

IBM FlashSystem family

connected through the Fibre Channel protocol. For more information about these systems and how they're used inside the IBM Power Virtual Server
service, see the data sheet below:
Data sheet:
IBM Power System E980 (9080-M9S)
For further information, see hardware specifications for IBM Power Virtual Servers .

SAP NetWeaver and IBM Power Virtual Server
See SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers for SAP NetWeaver support on IBM Power Virtual Servers.
SAP NetWeaver and SAP AnyDB workloads that use IBM Power Virtual Servers are run on IBM Power System S922 and IBM Power System E980, with
Block Storage powered by IBM FlashSystem family connected through the Fibre Channel protocol. For more information about these systems and how
they're used inside the IBM Power Virtual Server service, see the following data sheets:
Data sheets:
IBM Power System S922 (9009-22A)
IBM Power System E980 (9080-M9S)
For further information, see hardware specifications for IBM Power Virtual Servers .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 27

VMware Software-Defined Data Center
IBM Cloud and VMware partner to bring the capabilities of VMware for SAP into Cloud by using VMware vSphere installed to IBM Cloud® Bare Metal Servers.
This enables secure single-tenant compute with full root control to the hypervisor, providing optimized performance with high agility, resiliency, and elastic
compute costs. Since Dec-2007, when VMware first announced support for SAP, there has been continuous improvement to VMware-SAP capabilities,
which provide flexible delivery of SAP project implementations and easier maintenance of SAP Systems; all these capabilities are available with VMware
and IBM Cloud.
In short, IBM Cloud provides two levels of VMware, which are both SAP-certified:
Intel Bare Metal and VMware vSphere (ESXi OS) , requires manual VMware setup and configuration
IBM Cloud for VMware Solutions Dedicated , fully automated VMware SDDC setup and configuration
includes optional BYOL and access to advanced VMware capabilities, such as VMware HCX for seamless bidirectional network extension and
connection to existing VMware clusters on-premises
For more information about IBM Cloud for VMware on Classic Infrastructure, see IBM Cloud for VMware . Additional information is available on:
IBM Cloud Intel Bare Metal and VMware vSphere (ESXi OS) for the manual VMware setup and configuration
IBM Cloud for VMware Solutions Dedicated for fully automated VMware SDDC setup and configuration

Compliance
IBM treats your data with the same safeguards as our own, the security is built to IBM’s rigorous standards and certified for compliance.
IBM Cloud is designed for organizations who are building a cloud environment, which is security-rich, open, hybrid Cloud (i.e., on-premises data center
workloads) and multi-cloud. Deployments to IBM Cloud include many secure and regulated workloads, by using our extensive IBM Cloud compliance
programs with clear delineation of roles and responsibilities.
IBM Cloud compliance programs provide compliance and trust certifications, which reaffirm IBM's commitment to protection of customer data and
applications. These compliance programs are for regulations, standards, and frameworks across Global, Government, Industry, and Regional.
More supplementary information to the IBM Cloud compliance programs is available on IBM Cloud service offering descriptions and terms which contain
links to individual "Data Processing and Protection data sheets" for IBM Cloud offerings.
Each IBM Cloud® for SAP offering uses different infrastructure configurations and approaches to providing the service and will therefore be certified
independent of each other. These certifications can be checked on the previous links or clarified by contacting IBM Cloud or your IBM representative.
Following is a small extract from the full list of recognized compliance, certifications, attestations, or reports available across the various IBM Cloud® for
SAP offerings:
ISO 27001
ISO 27017
ISO 27018
EU-US Privacy Shield Policy
GDPR Ready
Germany Federal Office for Information Security (BSI) C5
HIPAA for Healthcare USA
ITAR Compliant
PCI-DSS for Payment Card Industry USA
Singapore Multi-Tier Cloud Security Standard (MTCS)
SOC1 Type 2
SOC2 Type 2
SOC3
...more

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 28

Infrastructure profiles for SAP HANA database servers
Intel Bare Metal server certified profiles on Classic infrastructure for SAP HANA
Profiles list
Note: The published names are subject to change.
This table provides an overview of the SAP-certified profiles with Intel Bare Metal:
Profile

CPU Cores

CPU Threads (aka. vCPU)

Memory (RAM GB)

SAPS

SAP HANA Processing Type

BI.S3.H2.192 Appliance

36

72

192 GB

78,850

OLAP/OLTP (*)
SAP Business One (***)

BI.S3.H2.384 Appliance

36

72

384 GB

79,430

OLAP/OLTP (*)
SAP Business One (***)

BI.S3.H2.768 Appliance

36

72

768 GB

79,630

OLAP/OLTP (*)
SAP Business One (***)

BI.S4.H2.192 Appliance

32

64

192 GB

82,470

OLAP/OLTP (**)
SAP Business One (***)

BI.S4.H2.384 Appliance

32

64

384 GB

85,130

OLAP/OLTP (**)
SAP Business One (***)

BI.S4.H2.384_v3 Appliance

16

32

384 GB

60,420

OLAP/OLTP (**)

BI.S4.H2.768 Appliance

40

80

768 GB

112,830

OLAP/OLTP (**)
SAP Business One (***)

BI.S4.H2.768_v2 Appliance

48

96

768 GB

124,620

OLAP/OLTP (**)

BI.S4.H2.768_v3 Appliance

16

32

768 GB

60,420

OLAP/OLTP (**)

BI.S4.H2.1500 Appliance

56

112

1536 GB

147,220

OLAP/OLTP (**)

BI.S4.H2.3000 Appliance

56

112

3072 GB

135,127

OLAP/OLTP (**)

BI.S4.H4.3000 Appliance

112

224

3072 GB

285,970

OLAP/OLTP (**)

BI.S4.H4.6000 Appliance

112

224

6144 GB

285,970

OLAP/OLTP (**)

BI.S4.H8.6000 Appliance

224

448

6144 GB

550,670

OLAP/OLTP (**)

BI.S4.H8.12000 Appliance

224

448

12288 GB

550,670

OLAP/OLTP (**)

Table 1. SAP HANA servers

(*): RHEL 7.4 for SAP Solutions, RHEL 7.6 for SAP Solutions, RHEL 7.9 for SAP Solutions, RHEL 8.2 for SAP Solutions
SLES 12 SP2, SLES 12 SP4, SLES 12 SP5, SLES 15, SLES 15 SP1, SLES 15 SP2, SLES 15 SP3
(**): RHEL 7.6 for SAP Solutions, RHEL 7.9 for SAP Solutions, RHEL 8.2 for SAP Solutions, RHEL 8.6 for SAP Solutions
SLES 12 SP4, SLES 12 SP5, SLES 15, SLES 15 SP1, SLES 15 SP2, SLES 15 SP3, SLES 15 SP4
(***): SLES 12 SP4, SLES 15, SLES 15 SP1, SLES 15 SP2, SLES 15 SP3, SLES 15 SP4
Note: Please regard the supported operated systems mentioned in the footnotes.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 29

For more information see SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment .
A number of these Profiles are also available as "Boot-only" which have the same configuration but only the boot drives are inserted. This configuration
lets you customize the Local SSD Storage and the attachment of either Network Block or File storage options.

Understanding Bare Metal profile names
The Bare Metal profile names are contextual and sequential. This example uses an SAP HANA certified server to list and describe the naming conventions:
Profile name

Naming convention component

What it means

BI.S4.H2.1500

BI

Bluemix Infrastructure (former name of IBM Cloud)

S4

Series 4 (processor generation)
S2 is Intel Broadwell
S3 is Intel Skylake or Kaby Lake
S4 is Intel Cascade Lake

H

HANA-certified server

2

2-socket server

1500

1500 GB RAM
Table 2. Profile naming for SAP HANA

Profiles available on Hourly Consumption Billing
The following Bare Metal servers are available on Hourly Consumption Billing:
BI.S3.H2.192
BI.S3.H2.384
BI.S4.H2.192 Appliance
BI.S4.H2.384 Appliance
BI.S4.H2.768 Appliance
BI.S4.H2.1500 Appliance
BI.S4.H2.3000 Appliance
BI.S4.H2.192 (boot only)
BI.S4.H2.384 (boot only)
BI.S4.H2.768 (boot only)
BI.S4.H2.1500 (boot only)
BI.S4.H2.3000 (boot only)

Storage specifications
The following dual-socket servers are available in the Appliance delivery model for SAP HANA, with preconfigured disk storage.
Note: These Profiles do not use any Network Block or File storage options that are mounted to the Bare Metal server. These Profiles use only Local
SSD Storage devices that are physically attached through a RAID Controller inside the server.

BI.S3.H2.192 Appliance
Link to Profile: BI.S3.H2.192 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 30

RAID 1

2x 960 GB 5100

hdd0, hdd1

RAID1-A

960 GB

RAID 1

2x 960 GB 5100

hdd2, hdd3

RAID1-B

960 GB

Global hot spare

1x 960 GB 5100

hdd4

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

/dev/sdb

/dev/sdb1

/hana/shared

250

/dev/sdb2

/hana/data

remaining capacity

BI.S3.H2.384 Appliance
Link to Profile: BI.S3.H2.384 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB 5100

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 960 GB 5100

hdd2, hdd3, hdd4, hdd5

RAID1-B

1920 GB

Global hot spare

1x 960 GB 5100

hdd6

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/hana/shared

500

/dev/sdb

/dev/sdb1

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 31

/dev/sdb2

/hana/data

remaining capacity

BI.S3.H2.768 Appliance
Link to Profile: BI.S3.H2.768 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB 5100

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 960 GB 5100

hdd2, hdd3, hdd4, hdd5

RAID1-B

1920 GB

Global hot spare

1x 960 GB 5100

hdd6

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

800

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.192 Appliance
Link to Profile: BI.S4.H2.192 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB 5100

hdd0, hdd1

RAID1-A

960 GB

RAID 1

2x 960 GB 5100

hdd2, hdd3

RAID1-B

960 GB

Global hot spare

1x 960 GB 5100

hdd4

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

/dev/sda1

Name

Size (GB)

/boot

50

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 32

RAID1-B

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

250

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.384 and BI.S4.H2.384_v2 Appliance
Link to Profile: BI.S4.H2.384 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB 5100

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 960 GB 5100

hdd2, hdd3, hdd4, hdd5

RAID1-B

1920 GB

Global hot spare

1x 960 GB 5100

hdd6

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

500

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.768, BI.S4.H2.768_v2, and BI.S4.H2.768_v3 Appliance
Link to Profile: BI.S4.H2.768 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB 5100

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 960 GB 5100

hdd2, hdd3, hdd4, hdd5

RAID1-B

1920 GB

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 33

Global hot spare

1x 960 GB 5100

hdd6

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

800

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.1500 Appliance
Link to Profile: BI.S4.H2.1500 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB SSD SED

hdd0, hdd1

RAID1-A

960 GB

RAID 1

2x 3.8 TB SSD SED

hdd2, hdd3

RAID1-B

3.8 TB

Global hot spare

1x 3.8 TB SSD SED

hdd4

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.3000 Appliance
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 34

Link to Profile: BI.S4.H2.3000 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB SSD SED

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 3.8 TB SSD SED

hdd2, hdd3, hdd4, hdd5

RAID1-B

7.6 TB

Global hot spare

1x 3.8 TB SSD SED

hdd6

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H4.3000 Appliance
Link to Profile: BI.S4.H4.3000 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB SSD SED

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 3.8 TB SSD SED

hdd2, hdd3, hdd4, hdd5

RAID1-B

7.6 TB

Global hot spare

1x 3.8 TB SSD SED

hdd6

Disk mount points and Partitions
Array

Partition

Name

Size (GB)

RAID1-A

/dev/sda

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 35

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sda4

RAID1-B

/dev/sdb

BI.S4.H4.6000 Appliance
Link to Profile: BI.S4.H4.6000 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB SSD SED

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 3.8 TB SSD SED

hdd2, hdd3, hdd4, hdd5

RAID1-B

7.6 TB

Global hot spare

1x 3.8 TB SSD SED

hdd6

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H8.6000 Appliance
Link to Profile: BI.S4.H8.6000 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB SSD SED

hdd0, hdd1

RAID1-A

960 GB

RAID 10

4x 3.8 TB SSD SED

hdd2, hdd3, hdd4, hdd5

RAID1-B

7.6 TB

Global hot spare

1x 3.8 TB SSD SED

hdd6

Disk mount points and Partitions

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 36

Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H8.12000 Appliance
Link to Profile: BI.S4.H8.12000 Appliance

Physical Disk and RAID Configuration
RAID

Components

Drives

Array

Total Capacity

RAID 1

2x 960 GB SSD SED

hdd0, hdd1

RAID1-A

960 GB

RAID 10

8x 3.8 TB SSD SED

hdd2, hdd3, hdd4, hdd5, hdd6, hdd7, hdd8, hdd9

RAID2-A

15.2 TB

Global hot spare

1x 3.8 TB SSD SED

hdd10

Disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

Boot-only servers
By default, IBM Cloud Bare Metal Servers come with high-performance and highly reliable internal storage based on solid-state disks and highperformance RAID adapters.
For projects with different requirements, such as storage snapshots, that don't have a very high through-put requirement, IBM Cloud offers "boot-only

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 37

servers."
Boot-only servers have the same configuration as standard Bare Metal Servers, however, only the boot disks for the operating system are configured. The
storage required for the SAP file systems - /usr/sap , /hana/shared , /hana/data , and /hana/log - is not provided, significantly reducing the server
cost.
To run SAP HANA on a boot-only server, you must add IBM Cloud storage to the server.
SAP HANA Tailored Data Center Integration (TDI) requirements must be met to run SAP HANA as Production for the SAP System/s, or in a production-like
environment. To fulfill SAP HANA TDI key performance indicators (TDIs), storage performance must meet minimum values.

IBM Cloud File Storage for Classic with Boot-only services
To run SAP HANA in production and production-like setups that use IBM Cloud File Storage for Classic, based on the Network File System (NFS) protocol,
requires:
Minimum of 8 K IOPS for /hana/log
Minimum of 7 K IOPS for /hana/data
You can share storage areas for /hana/shared with /hana/log or /hana/data if these areas are too large for your particular use case.
For non-production use, you can use one storage area for /hana/shared , /hana/log , and /hana/data .
These minimums are for either Endurance or Performance options available with IBM Cloud File Storage for Classic:
Endurance storage is a predefined IOPS per GB of storage, for example, 0.25 up to 10 IOPS per GB.
Performance storage has different ranges of IOPS per GB, depending on the total size of the storage device. This option is more customizable.
This table compares the file storage (using NFS protocol) and the performance IOPS range for the capacity:
File Storage capacity (GB)

Performance custom IOPS

20-39

100-1,000

40-79

100-2,000

80-99

100-4,000

100-499

100-6,000

500-999

100-10,000

1,000-1,999

100-20,000

2,000-2,999

200-40,000

3,000-3,999

200-48,000

4,000-7,999

300-48,000

8,000-9,999

500-48,000

10,000-12,000

1,000-48,000

Up to 24,000

Up to 96,000 by special request

Up to 18,000

Up to 180,000 by special request
Table 3. IBM Cloud File Storage for Classic Performance storage GB and IOPS

BI.S4.H2.192 (boot only)
Link to Profile: BI.S4.H2.192 (boot only)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 38

Required configuration of disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

250

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.384 (boot only)
Link to Profile: BI.S4.H2.384 (boot only)

Required configuration of disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

500

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.768 (boot only)
Link to Profile: BI.S4.H2.768 (boot only)

Required configuration of disk mount points and Partitions
Array

Partition

Name

Size (GB)

RAID1-A

/dev/sda

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 39

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

800

/dev/sdb2

/hana/data

remaining capacity

/dev/sda4

RAID1-B

/dev/sdb

BI.S4.H2.1500 (boot only)
Link to Profile: BI.S4.H2.1500 (boot only)

Required configuration of disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

BI.S4.H2.3000 (boot only)
Link to Profile: BI.S4.H2.3000 (boot only)

Required configuration of disk mount points and Partitions
Array

Partition

RAID1-A

/dev/sda

RAID1-B

Name

Size (GB)

/dev/sda1

/boot

50

/dev/sda2

/

150

/dev/sda3

/usr/sap

150

/dev/sda4

/hana/log

remaining capacity

/dev/sdb1

/hana/shared

1024

/dev/sdb2

/hana/data

remaining capacity

/dev/sdb

Intel Bare Metal server with Intel Optane DC Persistent Memory certified profiles for SAP
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 40

HANA
Profiles list
The following table is an overview of the SAP-certified profiles for Intel Optane PMem on Bare Metal servers:
Profile

Cores

Speed

RAM

Storage

SAP HANA Processing Type

BI.S4.H2.1.5TB RAM + 1.5TB Persistent Memory

56

2.70 GHx

1536 GB

12 Drives

OLAP/OLTP (*)

BI.S4.H4.3TB RAM + 3TB Persistent Memory

112

2.70 GHz

3072 GB

12 Drives

OLAP/OLTP (*)

BI.S4.H8.6TB RAM + 6TB Persistent Memory

224

2.70 GHz

6144 GB

12 Drives

OLAP/OLTP (*)

BI.S4.H2.768GB RAM + 1.5TB Persistent Memory

56

2.70 GHx

768 GB

10

OLTP (*)

BI.S4.H2.1.5TB RAM + 3TB Persistent Memory

56

2.70 GHx

1536 GB

10

OLAP/OLTP (*)

BI.S4.H4.1.5TB RAM + 3TB Persistent Memory

112

2.70 GHx

1536 GB

10

OLAP/OLTP (*)

BI.S4.H4.3TB RAM + 6TB Persistent Memory

112

2.70 GHx

3072 GB

14

OLAP/OLTP (*)

BI.S4.H8.3TB RAM + 6TB Persistent Memory

224

2.70 GHx

3072 GB

14

OLAP/OLTP (*)

BI.S4.H8.6TB RAM + 12TB Persistent Memory

224

2.70 GHx

6144 GB

14

OLAP/OLTP (*)

BI.S4.H2.384GB RAM + 1.5TB Persistent Memory

56

2.70 GHx

384 GB

10

OLTP (*)

BI.S4.H2.768GB RAM + 3TB Persistent Memory

56

2.70 GHx

768 GB

12

OLTP (*)

BI.S4.H4.768GB RAM + 3TB Persistent Memory

112

2.70 GHx

768 GB

14

OLTP (*)

BI.S4.H4.1.5TB RAM + 6TB Persistent Memory

112

2.70 GHx

1536 GB

14

OLTP (*)

BI.S4.H8.1.5TB RAM + 6TB Persistent Memory

224

2.70 GHx

1536

14

OLTP (*)

BI.S4.H8.3TB RAM + 12TB Persistent Memory

224

2.70 GHx

3072 GB

12

OLTP (*)

1:1 DRAM:PMem

1:2 DRAM:PMem

1:4 DRAM:PMem

(*): RHEL 7.6 for SAP Solutions, RHEL 7.9 for SAP Solutions, RHEL 8.2 for SAP Solutions -- SLES 12 SP4, SLES 12 SP5, SLES 15, SLES 15 SP1, SLES 15 SP2,
SLES 15 SP3
Note: Please regard the supported operated systems mentioned in the footnotes.

Bare Metal profile names
The Bare Metal profile names are contextual and sequential. For more information, see Understanding Bare Metal profile names

Storage specifications
Name

HANA DB

Storage Needed (1TB shared plus

Size (TB)

DB size data)

Boot (Log)

Storage Array (Data +
Shared)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 41

BI.S4.H2.1.5TB RAM + 1.5TB
Persistent Memory

3

7

2x 960GB SSD
(RAID 1)

8 x 1.9TB SSD (RAID
10)

BI.S4.H4.3TB RAM + 3TB Persistent
Memory

6

13

2x 960GB SSD
(RAID 1)

8 x 3.8TB SSD (RAID
10)

BI.S4.H8.6TB RAM + 6TB Persistent
Memory

12

25

2x 960GB SSD
(RAID 1)

8 x 7.68TB SSD (RAID
10)

BI.S4.H2.768GB RAM + 1.5TB
Persistent Memory

2.25

5.5

2x 960GB SSD
(RAID 1)

6 x 1.9TB SSD (RAID
10)

BI.S4.H2.1.5TB RAM + 3TB Persistent
Memory

4.5

10

2x 960GB SSD
(RAID 1)

6 x 3.8TB SSD (RAID
10)

BI.S4.H2.768GB RAM + 3TB
Persistent Memory

3.75

8.5

2x 960GB SSD
(RAID 1)

10 x 1.9TB SSD (RAID
10)

BI.S4.H4.1.5TB RAM + 3TB Persistent
Memory

4.5

10

2x 960GB SSD
(RAID 1)

6 x 3.8TB SSD (RAID
10)

BI.S4.H4.3TB RAM + 6TB Persistent
Memory

9

19

2x 960GB SSD
(RAID 1)

10 x 3.8TB SSD (RAID
10)

BI.S4.H8.3TB RAM + 6TB Persistent
Memory

9

19

2x 960GB SSD
(RAID 1)

10 x 3.8TB SSD (RAID
10)

BI.S4.H8.6TB RAM + 12TB Persistent
Memory

18

37

2x 960GB SSD
(RAID 1)

10 x 7.68TB SSD (RAID
10)

BI.S4.H8.6TB RAM + 12TB Persistent
Memory

1.75

4.5

2x 960GB SSD
(RAID 1)

6 x 1.9TB SSD (RAID
10)

BI.S4.H4.768GB RAM + 3TB
Persistent Memory

3.75

8.5

2x 960GB SSD
(RAID 1)

10 x 1.9TB SSD (RAID
10)

BI.S4.H4.1.5TB RAM + 6TB Persistent
Memory

7.5

16

2x 960GB SSD
(RAID 1)

10 x 3.8TB SSD (RAID
10)

BI.S4.H8.1.5TB RAM + 6TB Persistent
Memory

7.5

16

2x 960GB SSD
(RAID 1)

10 x 3.8TB SSD (RAID
10)

BI.S4.H8.3TB RAM + 12TB Persistent
Memory

15

31

2x 960GB SSD
(RAID 1)

8 x 7.68TB SSD (RAID
10)

1:2 DRAM:PMem

1:4 DRAM:PMem

Intel Virtual Server certified profiles on VPC infrastructure for SAP HANA
Profiles list
Note: The published names are subject to change.
The following list gives you an overview of the SAP-certified profiles with Virtual Servers for VPC:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 42

Profile

vCPU

Memory (RAM GiB)

SAPS

SAP HANA
Processing Type

Memory Optimized
mx2-8x64
mx2d-8x64

8

64

10,280

SAP Business One (**)

mx2-16x128
mx2d-16x128

16

128

20,565

OLTP (*)
SAP Business One (**)

mx2-32x256
mx2d-32x256

32

256

41,130

OLTP (*)
SAP Business One (**)

mx2-48x384
mx2d-48x384

48

384

56,970

OLTP (*)
SAP Business One (**)

vx2d-16x224

16

224

17,046

OLTP (*)

vx2d-44x616

44

616

46,875

OLAP/OLTP (*)

vx2d-88x1232

88

1,232

93,750

OLAP/OLTP (*)

vx2d-144x2016

144

2,016

153,410

OLAP/OLTP (*)

vx2d-176x2464

176

2,464

187,500

OLAP/OLTP (*)

ux2d-8x224

8

224

8,623

OLTP (*)

ux2d-16x448

16

448

17,246

OLTP (*)

ux2d-36x1008

36

1,008

38,803

OLTP (*)

ux2d-48x1344

48

1,344

51,737

OLTP (*)

ux2d-72x2016

72

2,016

77,606

OLTP (*)

ux2d-100x2800

100

2,800

107,785

OLTP (*)

ux2d-200x5600

200

5,600

215,570

OLTP (*)

Very High Memory Optimized

Ultra High Memory Optimized

Table 1. IBM Cloud Virtual Servers for VPC certified for SAP HANA

(*): RHEL 7.6 for SAP Solutions, RHEL 7.9 for SAP Solutions, RHEL 8.1 for SAP Solutions, RHEL 8.2 for SAP Solutions, RHEL 8.4 for SAP Solutions, RHEL 8.6
for SAP Solutions, 8.8 for SAP Solutions, RHEL 9.0 for SAP Solutions, RHEL 9.2 for SAP Solutions
SLES 12 SP4, SLES 12 SP5, SLES 15, SLES 15 SP1, SLES 15 SP2, SLES 15 SP3, SLES 15 SP4, SLES 15 SP5
(**): SLES 12 SP4, SLES 15, SLES 15 SP1, SLES 15 SP2, SLES 15 SP3, SLES 15 SP4, SLES 15 SP5
Note: Please, regard the supported operated systems that are mentioned in the footnotes.
For more information, see SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment .

Understanding Virtual Server profile names
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 43

With IBM Cloud® Virtual Servers for Virtual Private Cloud, the profile families that are certified for SAP are: Memory Optimized, Very High and Ultra High
Memory Optimized.
All the Memory family profiles cater to memory intensive workloads, such as demanding database applications and in-memory analytics workloads,
and are especially designed for SAP HANA workloads.
For more information, see chapter x86-64 instance profiles.
The first letter of the profile name indicates the profile family that is mentioned the profile list:
First letter

Characteristics of the related profile family

m

Memory Optimized family, higher vCPU to memory ratio 1:8

v

Very High Memory Optimized family, very high vCPU to memory ratio 1:14

u

Ultra High Memory Optimized family, ultra high vCPU to memory ratio 1:28
Table 2. IBM Cloud® Virtual Servers for Virtual Private Cloud Profile Families

The Virtual Server profile names are contextual and sequential. See the following example:

Profile

Naming convention

What it means

name

component

mx216x128

m

Memory Optimized family

x

Intel x86_64 CPU Architecture

2

The generation for the underlying hardware

d

the optional 'd' in the name indicates that the server is equipped with one or more internal SSD
storage devices (*)

—

spacer

16

16 vCPU

x

spacer

128

128 GiB RAM
Table 3. Profile naming for SAP HANA

Note: (*) Note for Virtual Server Instances using instance storage on SSD: you must not place any SAP workload related data on such instance
storage, because data loss may occur in certain situations - see more information here: About instance storage.

Profiles available on Hourly Consumption Billing
All IBM Cloud Virtual Servers for VPC are available with Hourly Consumption Billing, which includes Suspend Discounts and Sustained Usage Discounts.
With Suspend Discounts, storage charges occur only if the server is in Shutdown state. With Sustained Usage Discount, the more a server is used, the less
the cost per hour.

Storage specifications
When the virtual server profiles for SAP HANA are initially provisioned, the servers all have one pre-configured volume (vda) attached with the following
basic layout:
File system

Partition

Storage type

Size (GB)

Nr. of
IOPS

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 44

/

vda1

Pre-configured boot volume

100

3,000

/boot

vda2

Pre-configured boot volume

0.25

3,000

Table 4. Storage configuration of the default virtual server deployment (boot volume)

IBM® Cloud Block Storage for Virtual Private Cloud
IBM® Cloud Block Storage for Virtual Private Cloud volumes for Virtual Servers can be created based on different volume profiles that provide different
levels of IOPS per gigabyte (IOPS/GB). For more information, see IOPS tiers.
You must consider the total IOPS required for your installation and the performance characteristics of your database. One option is to collocate multiple
directories into a single large volume with high IOPS, versus isolating directories into individual small volumes with an insufficient number of IOPS for the
workload characteristics.
For an overview of all available storage profiles, see VPC Block Storage Profiles.

Storage for SAP HANA - single-node
To fulfill the KPIs defined by SAP HANA, each profile needs different storage volumes that are listed in details in the following sections. These
configurations are mandatory storage configurations, not sample storage configurations, because they are the tested and certified storage layouts that
comply with SAP HANA Tailored Data Center Integration (TDI) Phase 5. It is highly recommended to stick to these specific specifications.
Important: Customers who want to choose different layouts are advised to follow the SAP HANA TDI Overview and SAP HANA TDI FAQ when
they order different storage sizes and types. Then, they must run SAP's performance measurement tool HCMT - see SAP Note 2493172 - SAP
HANA Hardware and Cloud Measurement Tools and follow the instructions of the HCMT guide.

Note: For all of the following layouts consider that the volume names might differ - we assume that the naming follows the sequence of ordering
the storage, that is, 1st order -> vdd , 2nd order -> vde , and so on. All block storage volumes must be ordered with the predefined profile of 10
IOPS/GB (high performance). One exception might be /hana/shared partition where 5 IOPS/GB (medium performance) are sufficient - but ONLY IF
you assigned a dedicated volume for this partition. For all profiles optional: one appropriately sized block storage volume or several equally sized
volumes that are gathered to a volume group, with the predefined profile of 5 IOPS/GB (medium performance) attached to the Virtual Server for
backups.
SAP's recommended file system layout must be available for SAP HANA deployment.

mx2-* profiles - Storage Layouts
The following table shows the required physical volumes, related volume groups, logical volumes, and their characteristics:
Profile

mx2-8x64

File

Logical

LV Size

system

Volume

(GB)

/hana/shared

hana_shared_lv

256

/hana/data

hana_data_lv

/hana/log

Volume Group

Physical

PV Size

Volume

(GB)

vdd

500

256

vde

500

hana_log_lv

988

vdf

500

/hana/shared

hana_shared_lv

384

vdd

500

/hana/data

hana_data_lv

616

vde

500

vdf

500

hana_vg

and
mx2-16x128

and
mx2-32x256

mx2-48x384

hana_vg

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 45

/hana/log

hana_log_lv

400

hana_log_vg

vdg

100

vdh

100

vdi

100

vdj

100

Table 5. Storage layout for mx2-* profiles based virtual servers

mx2-* profiles - Setup Instructions
See the step by step instructions for setting up the assets here. Mind the different volume names.
for the mx2-8x64, mx2-16x128 and mx2-32x256 profiles
for the mx2-48x384 profile

vx2d-* profiles - Storage Layouts
The following table shows the required volumes and related volume groups, if necessary, and their characteristics:
Profile

vx2d-16x224

vx2d-44x616

File

Logical

LV Size

system

Volume

(GB)

/hana/shared

hana_shared_lv

224

/hana/data

hana_data_lv

672

/hana/log

hana_log_lv

224

PV Size

Volume

(GB)

vde

1,120

n/a

vdd

616

/hana/data

n/a

vde

1,848

vdf

192

vdg

192

vdh

192

hana_log_lv

576

hana_log_vg

/hana/shared

n/a

vdd

1,232

/hana/data

n/a

vde

3,696

vdf

192

vdg

192

vdh

192

vdd

2,016

vde

1,024

/hana/log

vx2d-144x2016

hana_vg

Physical

/hana/shared

/hana/log

vx2d-88x1232

Volume Group

hana_log_lv

hana_log_vg

n/a

/hana/shared

/hana/data

576

hana_data_lv

4,096

hana_data_vg

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 46

/hana/log

vx2d-176x2464

hana_log_lv

/hana/log

hana_log_vg

n/a

/hana/shared

/hana/data

576

hana_data_lv

hana_log_lv

5,120

576

hana_data_vg

hana_log_vg

vdf

1,024

vdg

1,024

vdh

1,024

vdi

192

vdj

192

vdk

192

vdd

2,464

vde

1,280

vdf

1,280

vdg

1,280

vdh

1,280

vdi

192

vdj

192

vdk

192

Table 6. Storage for vx2* profile based virtual servers

vx2d-* profiles - Setup Instructions
See the step by step instructions for setting up the file systems here. The according volume sizes are captured in the table 6. Read the section

Adding

Block Storage for VPC to see how to attach the volumes to the HANA server. Some disks are governed by the Linux Logical Volume Manager LVM or lvm2.
Note: For each profile, consider the specified volume sizes in table 6 and always make sure that the correct disks are given for the respective
commands. The Linux command fdisk -l shows which disk is to the volume, for example /dev/vde .

vx2d-16x224
1. Create the volume group for LVM.
$ [root@vx2d-16x224 ~]# pvcreate /dev/vde
[root@vx2d-16x224 ~]# vgcreate hana_vg /dev/vde

2. After the volume group is created, three logical volumes are defined on top. These logical volumes reflect the file system size requirements for SAP
HANA.
$ [root@vx2d-16x224 ~]# lvcreate -L 224G -n hana_shared_lv hana_vg
[root@vx2d-16x224 ~]# lvcreate -L 224G -n hana_log_lv hana_vg
[root@vx2d-16x224 ~]# lvcreate -l 100%VG -n hana_data_lv hana_vg

3. Next, add these entries to /etc/fstab
$ LABEL=HANA_SHARED /hana/shared xfs defaults,inode64 0 0
LABEL=HANA_LOG /hana/log xfs defaults,swalloc,inode64 0 0
LABEL=HANA_DATA /hana/data xfs defaults,largeio,swalloc,inode64 0 0

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 47

4. Finally, a file system needs to be created on top of each volume group and then mounted:
$ [root@vx2d-16x224 ~]# mkfs.xfs -L HANA_SHARED /dev/mapper/hana_vg-hana_shared_lv
[root@vx2d-16x224 ~]# mkfs.xfs -L HANA_LOG /dev/mapper/hana_vg-hana_log_lv
[root@vx2d-16x224 ~]# mkfs.xfs -L HANA_DATA /dev/mapper/hana_vg-hana_data_lv
[root@vx2d-16x224 ~]# mkdir -p /hana/shared
[root@vx2d-16x224 ~]# mkdir -p /hana/log
[root@vx2d-16x224 ~]# mkdir -p /hana/data
[root@vx2d-16x224 ~]# mount -a

vx2d-44x616 and vx2d-88x1232
1. Create the volume group for LVM. Only /hana/log is assigned to the LVM.
$ [root@vx2d-44x616 ~]# pvcreate /dev/vdf /dev/vdg /dev/vdh
[root@vx2d-44x616 ~]# vgcreate hana_log_vg /dev/vdf /dev/vdg /dev/vdh

2. After the volume group is created, the logical volume for /hana/log needs to be defined on top. This logical volume reflects the file system size
requirement for SAP HANA.
$ [root@vx2d-44x616 ~]# lvcreate -i 3 -I 64 -l 100%VG -n hana_log_lv hana_log_vg

3. Now proceed with the same instructions that are listed in steps 3 and 4 profile vx2d-16x224.

vx2d-144x2016 and vx2d-176x2464
1. Create the volume group for LVM. /hana/log and /hana/data are assigned to the LVM.
$ [root@vx2d-144x2016 ~]# pvcreate /dev/vde /dev/vdf /dev/vdg /dev/vdh
[root@vx2d-144x2016 ~]# pvcreate /dev/vdi /dev/vdj /dev/vdk
[root@vx2d-144x2016 ~]# vgcreate hana_data_vg /dev/vde /dev/vdf /dev/vdg /dev/vdh
[root@vx2d-144x2016 ~]# vgcreate hana_log_vg /dev/vdi /dev/vdj /dev/vdk

2. After the volume group is created, two logical volumes need to be defined on top. These logical volumes reflect the file system size requirements for
SAP HANA.
$ [root@vx2d-144x2016 ~]# lvcreate -i 4 -I 64 -l 100%VG -n hana_data_lv hana_data_vg
[root@vx2d-144x2016 ~]# lvcreate -i 3 -I 64 -l 100%VG -n hana_log_lv hana_log_vg

3. Now proceed with the same instructions that are listed in steps 3 and 4 profile vx2d-16x224.

ux2d-* profiles - Storage Layouts
The following table shows the required volumes and related volume groups, if necessary, and their characteristics:
Profile

ux2d-8x224

ux2d-16x448

File

Logical

LV Size

system

Volume

(GB)

/hana/shared

hana_shared_lv

224

/hana/data

hana_data_lv

672

/hana/log

hana_log_lv

224

/hana/shared

hana_shared_lv

448

/hana/data

hana_data_lv

1,344

/hana/log

hana_log_lv

448

Volume Group

Physical

PV Size

Volume

(GB)

hana_vg

vde

1,120

hana_vg

vde

2,240

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 48

ux2d-36x1008

/hana/data

/hana/log

ux2d-48x1344

/hana/log

hana_log_lv

/hana/log

hana_data_lv

hana_log_lv

576

hana_data_vg

hana_log_vg

2,700

576

hana_data_vg

hana_log_vg

n/a
hana_data_lv

hana_log_lv

4,096

576

hana_data_vg

hana_log_vg

n/a

/hana/shared

/hana/data

2,016

n/a

/hana/shared

/hana/data

ux2d-100x2800

hana_data_lv

/hana/shared

/hana/data

ux2d-72x2016

n/a

/hana/shared

hana_data_lv

8,400

hana_data_vg

vdd

1,008

vde

1,008

vdf

1,008

vdg

192

vdh

192

vdi

192

vdd

1,344

vde

1,350

vdf

1,350

vdg

192

vdh

192

vdi

192

vdd

2,016

vde

1,024

vdf

1,024

vdg

1,024

vdh

1,024

vdi

192

vdj

192

vdk

192

vdd

2,800

vde

2,100

vdf

2,100

vdg

2,100

vdh

2,100

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 49

/hana/log

ux2d-200x5600

hana_log_lv

/hana/log

hana_log_vg

n/a

/hana/shared

/hana/data

576

hana_data_lv

hana_log_lv

16,800

576

hana_data_vg

hana_log_vg

vdi

192

vdj

192

vdk

192

vdd

5,600

vde

4,200

vdf

4,200

vdg

4,200

vdh

4,200

vdi

192

vdj

192

vdk

192

Table 7. Storage for ux2* profile based virtual servers

ux2d-* profiles - Setup Instructions
See the step by step instructions for setting up the file systems here. The according volume sizes are captured in the table 7. Read the section

Adding

Block Storage for VPC to see how to attach the volumes to the HANA server. Some disks are governed by the Linux Logical Volume Manager LVM or lvm2.
Note: For each profile, consider the specific volume sizes in table 7 and always make sure that the correct disks are given for the respective
commands. The Linux command fdisk -l shows which disk has been mapped to the volume, for example /dev/vde .

ux2d-8x224 and ux2d-16x448
1. Create the volume group for LVM.
$ [root@ux2d-8x224 ~]# pvcreate /dev/vde
[root@ux2d-8x224 ~]# vgcreate hana_vg /dev/vde

2. After the volume group is created, three logical volumes are defined on top. These logical volumes reflect the file system size requirements for SAP
HANA.
$ [root@ux2d-8x224 ~]# lvcreate -L 224G -n hana_shared_lv hana_vg
## or lvcreate -L 448G -n hana_shared_lv hana_vg
[root@ux2d-8x224 ~]# lvcreate -L 224G -n hana_log_lv hana_vg
## or lvcreate -L 448G -n hana_log_lv hana_vg
[root@ux2d-8x224 ~]# lvcreate -l 100%VG -n hana_data_lv hana_vg

3. Now proceed with the same instructions that are listed in steps 3 and 4 profile vx2d-16x224.

ux2d-36x1008 and ux2d-48x1344
1. Create the volume groups for LVM. /hana/log and /hana/data are assigned to the LVM.
$ [root@ux2d-36x1008 ~]# pvcreate /dev/vde /dev/vdf
[root@ux2d-36x1008 ~]# pvcreate /dev/vdg /dev/vdh /dev/vdi
[root@ux2d-36x1008 ~]# vgcreate hana_data_vg /dev/vdg /dev/vdh /dev/vdi
[root@ux2d-36x1008 ~]# vgcreate hana_log_vg /dev/vdg /dev/vdh /dev/vdi
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 50

2. After the volume groups are created, two logical volumes need to be defined on top. These logical volumes reflect the file system size requirements
for SAP HANA.
$ [root@ux2d-36x1008 ~]# lvcreate -i 2 -I 64 -l 100%VG -n hana_data_lv hana_data_vg
[root@ux2d-36x1008 ~]# lvcreate -i 3 -I 64 -l 100%VG -n hana_log_lv hana_log_vg

3. Now proceed with the same instructions that are listed in steps 3 and 4 profile vx2d-16x224.

ux2d-72x2016, ux2d-100x2800, and ux2d-200x5600
1. Create the volume groups for LVM. /hana/log and /hana/data are assigned to the LVM.
$ [root@ux2d-72x2016 ~]# pvcreate /dev/vde /dev/vdf /dev/vdg /dev/vdh
[root@ux2d-72x2016 ~]# pvcreate /dev/vdi /dev/vdj /dev/vdk
[root@ux2d-72x2016 ~]# vgcreate hana_data_vg /dev/vde /dev/vdf /dev/vdg /dev/vdh
[root@ux2d-72x2016 ~]# vgcreate hana_log_vg /dev/vdi /dev/vdj /dev/vdk

2. After the volume groups are created, two logical volumes need to be defined on top. These logical volumes reflect the file system size requirements
for SAP HANA.
$ [root@ux2d-72x2016 ~]# lvcreate -i 4 -I 64 -l 100%VG -n hana_data_lv hana_data_vg
[root@ux2d-72x2016 ~]# lvcreate -i 3 -I 64 -l 100%VG -n hana_log_lv hana_log_vg

3. Now proceed with the same instructions that are listed in steps 3 and 4 profile vx2d-16x224.

Storage for SAP HANA - multi-node
In an SAP HANA scale-out (multi-node) configuration, storage needs to be accessible from different nodes at the same time, and needs to be able to
failover from one node to the other.
Thus, for SAP HANA scale-out configurations, file shares need to be deployed, and local block storage is out of scope for the SAP HANA installation. Those
file shares require so-called mount targets to be created to allow access to the file shares from dedicated subnets. IBM Cloud recommends using the
primary subnet for storage access because routes will not require any changes to access the storage servers for the file shares, if the mount target is
defined on this subnet. Two additional subnets are required for SAP HANA inter-node (internal) communication, and for client access.
SAP HANA in scale-out configuration requires a shared volume for its

/hana/shared file system, and a /hana/log and /hana/data volume for each

node. Follow the mount option recommendation by NetApp for setting up your target OS' fstab. See the following sample for an SAP HANA system of
system ID 'BHB':
1. /hana/shared
$ fsf-tok0551b-fz.adn.networklayer.com:/903586db_f968_4bf7_bbd5_0926fb7a26ce /hana/shared/BHB nfs
sec=sys,rw,vers=4,minorversion=1,hard,timeo=600,rsize=65536,wsize=65536,intr,noatime,lock 0 0

2. /hana/data
$ fsf-tok0551a-fz.adn.networklayer.com:/2b33d3df_9081_47c2_910a_a29356716d51/BHB/mnt00001 /hana/data/BHB/mnt00001 nfs
sec=sys,rw,vers=4,minorversion=1,hard,timeo=600,rsize=65536,wsize=65536,intr,noatime,lock 0 0
fsf-tok0551b-fz.adn.networklayer.com:/ec39996c_346a_4815_a74f_4048382e6ecc/BHB/mnt00002

/hana/data/BHB/mnt00002 nfs

sec=sys,rw,vers=4,minorversion=1,hard,timeo=600,rsize=65536,wsize=65536,intr,noatime,lock 0 0

3. /hana/log
$ fsf-tok0551b-fz.adn.networklayer.com:/7bdee46e_b95f_4ff7_89b8_5273e8f9199d/BHB/mnt00001

/hana/log/BHB/mnt00001 nfs

sec=sys,rw,vers=4,minorversion=1,hard,timeo=600,rsize=65536,wsize=65536,intr,noatime,lock 0 0
fsf-tok0551b-fz.adn.networklayer.com:/2bca0419_3aef_40ca_b38f_8b9717c93905/BHB/mnt00002

/hana/log/BHB/mnt00002 nfs

sec=sys,rw,vers=4,minorversion=1,hard,timeo=600,rsize=65536,wsize=65536,intr,noatime,lock 0 0

You cannot follow NetApp's recommendation regarding rsize and wsize option, these parameters are limited to 65536 by the file share
implementation.
To fulfill SAP's requirements about storage layout and through-put and latency KPIs, see details here: Persistent Data Storage in the SAP HANA Database ).
In any case, they must comply with the TDI performance KPIs (see SAP Note 2613646) verified by SAP HANA Hardware and Cloud Measurement Tools
and also ensure SAP's support for it. IBM Cloud recommends 10 IOPS per GB or Custom profile file shares for meeting SAP's KPIs.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 51

IBM Power Virtual Server certified profiles for SAP HANA
When you provision IBM Power Virtual Servers, you can select from the following families of profiles: Small, Balanced, Compute Intensive, Ultra Memory,
and High Memory.
Note: Certified profiles for SAP HANA are a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services
A profile is a combination of instance attributes, such as the number of vCPUs, amount of RAM, and network bandwidth. The attributes define the size and
capabilities of the virtual server instance that is provisioned. You can select the most recently used profile or click View All Profiles to choose the profile
that best fits your needs.

Profile families
Note: The published names are subject to change.
The following section provides an overview of the SAP-certified profiles with IBM Power Virtual Servers and available profile families.
Families

Description

Custom

Custom profiles are for nonproduct development for testing or development use only. These profiles are not intended for production
deployments and are not supported or certified for SAP production.

Small

Small profiles are best for balanced workloads that require less CPU and storage consumption.

Balanced

Balanced profiles are best for midsize databases and common cloud applications with moderate traffic.

Compute
Intensive

Compute Intensive profiles are best for moderate to high web traffic workloads. Compute profiles are best for workloads with intensive
CPU demands, such as high web traffic workloads, production batch processing, and front-end web servers.

Ultra
Memory

Ultra High Memory profiles offer the highest vCPU to memory ratios to serve in-memory OLTP databases, such as SAP.

High
Memory

Very High Memory profiles are best for server OLAP databases, such as SAP NetWeaver.

Custom
IBM Power Virtual Servers are available with fully adjustable CPU Cores and Memory (RAM GiB). When you create a virtual server instance, you can define a
custom size of the IBM Power Virtual Server profile to use for nonproduction SAP HANA instances, in accordance with existing SAP HANA for IBM Power
Systems best practices and guidance from SAP.
Custom profiles are for nonproduct development for testing or development use only. These profiles aren't intended for production deployments and aren't
supported or certified for SAP production. You cannot use this profile to go from a nonproduction environment to a production environment.
Each profile must have at least two dedicated cores. For required storage performance you should follow Storage Guidelines for SAP HANA . For more
information about storage, see the What is a Power Systems Virtual Server? storage tiers section.

Small
Profile

CPU

CPU Threads (also known as vCPU that uses

GiB

Minimum Storage

SAPS

SAP HANA

Cores

SMT-8)

RAM

(GiB)

ush14x128

4

32

128

500

24,000

OLAP/OLTP

ush14x256

4

32

256

910

24,000

OLAP/OLTP

ush14x384

4

32

384

1,240

24,000

OLAP/OLTP

Processing Type

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 52

ush14x512

4

32

512

1,650

24,000

OLAP/OLTP

ush14x768

4

32

768

2,140

24,000

OLAP/OLTP

SAPS

SAP HANA

Table 1. SAP HANA servers Small profile family

Balanced
Profile

CPU

CPU Threads (also known as vCPU that

GiB

Minimum Storage

Cores

uses SMT-8)

RAM

(GiB)

bh116x1600

16

128

1,600

3,170

96,000

OLAP/OLTP

bh120x2000

20

160

2,000

3,570

120,000

OLAP *

bh122x2200

22

178

2,200

3,810

132,000

OLAP *

bh125x2500

25

200

2,500

4,130

150,000

OLAP *

bh130x3000

30

240

3,000

4,610

180,000

OLAP *

bh135x3500

35

280

3,500

5,090

210,000

OLAP *

bh140x4000

40

320

4,000

5,570

240,000

OLAP *

bh150x5000

50

400

5,000

6,610

300,000

OLAP *

bh160x6000

60

480

6,000

7,570

360,000

OLAP/OLTP

bh170x7000

70

560

7,000

8,610

420,000

OLAP *

bh180x8000

80

640

8,000

9,570

480,000

OLAP *

bh1100x10000

100

800

10,000

11,970

600,000

OLAP *

bh1120x12000

120

900

12,000

13,570

720,000

OLAP *

bh1140x14000

140

1,120

14,000

15,970

840,000

OLAP

SAPS

SAP HANA

Processing Type

Table 2. SAP HANA servers Balanced profile family

Compute Intensive
Profile

CPU

CPU Threads (also known as vCPU that uses

GiB

Minimum Storage

Cores

SMT-8)

RAM

(GiB)

Processing Type

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 53

ch160x3000

60

480

3,000

4,610

360,000

OLAP

ch170x3500

70

560

3,500

5,090

420,000

OLAP *

ch180x4000

80

640

4,000

5,570

480,000

OLAP *

ch1100x5000

100

800

5,000

6,610

600,000

OLAP *

ch1120x6000

120

900

6,000

7,570

720,000

OLAP *

ch1140x7000

140

1,120

7,000

8,610

840,000

OLAP

SAPS

SAP HANA

Table 3. SAP HANA servers Compute Intensive profile family

High Memory
Profile

CPU

CPU Threads (also known as vCPU that

GiB

Minimum Storage

Cores

uses SMT-8)

RAM

(GiB)

mh18x1440

8

64

1,440

3,010

48,000

OLAP

mh110x1800

10

80

1,800

3,410

60,000

OLAP

mh112x2160

12

96

2,160

3,730

72,000

OLAP *

mh116x2880

16

128

2,880

4,450

96,000

OLAP *

mh120x3600

20

160

3,600

5,170

120,000

OLAP *

mh122x3960

22

176

3,960

5,570

132,000

OLAP *

mh125x4500

25

200

4,500

6,130

150,000

OLAP *

mh130x5400

30

240

5,400

7,010

180,000

OLAP *

mh135x6300

35

280

6,300

7,890

210,000

OLAP *

mh140x7200

40

320

7,200

8,770

240,000

OLAP *

mh150x9000

50

400

9,000

11,170

300,000

OLAP *

mh160x10800

60

460

10,800

12,770

360,000

OLAP *

Processing Type

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 54

mh170x12600

70

560

12,600

14,370

420,000

OLAP *

mh180x14400

80

640

14,400

15,970

480,000

OLAP

SAPS

SAP HANA

Table 4. SAP HANA servers High Memory profile family

Ultra Memory
Profile

CPU

CPU Threads (also known as vCPU that

GiB

Minimum Storage

Cores

uses SMT-8)

RAM

(GiB)

umh-4x960

4

32

960

2,490

24,000

OLTP

umh6x1440

6

48

1,440

3,010

36,000

OLTP *

umh8x1920

8

64

1,920

3,490

48,000

OLTP *

umh10x2400

10

80

2,400

3,970

60,000

OLTP *

umh12x2880

12

96

2,880

4,450

72,000

OLTP *

umh16x3840

16

128

3,840

5,410

96,000

OLTP

umh20x4800

20

160

4,800

6,370

120,000

OLTP *

umh22x5280

22

176

5,280

6,850

132,000

OLTP *

umh25x6000

25

200

6,000

7,570

150,000

OLTP *

umh30x7200

30

240

7,200

8,770

180,000

OLTP *

umh35x8400

35

280

8,400

10,370

210,000

OLTP *

umh40x9600

40

320

9,600

11,170

240,000

OLTP *

umh50x12000

50

400

12,000

13,570

300,000

OLTP *

umh60x14400

60

480

14,400

15,970

360,000

OLTP

Processing Type

Table 5. SAP HANA servers Ultra Memory profile family

Note: Profile types that are marked with an * asterisk, are not listed on the SAP HANA Hardware Directory by SAP but are certified for running
SAP HANA production systems. The directory lists the smallest, median, and largest within each profile family. This action was taken by SAP to
avoid too many records, as the scalability of IBM POWER hardware enables significantly more granular sizing. For more information, see SAP Note
2947579 - SAP HANA on IBM Power Virtual Servers.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 55

Understanding IBM Power Virtual Server profile names
The IBM Power Virtual Server for SAP HANA have profile names that are contextual and sequential. SAP HANA has multiple families of profiles, each
associated with the required Service Level Agreements (SLAs):
cnp1 = Nonproduct development for testing or development use only. Not intended for production deployments; not supported or certified for SAP

production.
ush1 = Small for OLAP/OLTP workloads that don't require as much CPU and storage consumption
umh = Ultra Memory HANA for OLTP that use 1:240 as the cpu:memory ratio
mh1 = High Memory for OLAP that use 1:180 as the cpu:memory ratio
bh1 = Balanced for OLAP that use 1:100 as the cpu:memory ratio
ch1 = Compute Intensive for OLAP that use 1:50 as the cpu:memory ratio

The Virtual Server profile names are contextual and sequential. The following table uses an SAP HANA certified server as an example:
Profile name

Naming convention component

What it means

umh-16x3840

umh

Ultra Memory SAP HANA for OLTP (higher on the CPU to Memory ratio), 1:240 ratio
spacer

16

16 CPU Cores

x

spacer

3840

3840 GiB RAM
Table 6. Profile naming scheme for SAP HANA

Directory

Purpose

root volume

100 GiB fixed

/usr/sap

52 GiB required in the test system

/hana/data

Matches the GiB RAM value

/hana/log

Matches the GiB RAM value up to a maximum of 512 GiB

/hana/shared

Matches the GiB RAM value up to a maximum of 1 TB

/export

Local storage for exported images

/backup

A preliminary backup on disk
Table 7. Directory information for profiles

Profiles available on Hourly Consumption Billing
All IBM Power Virtual Server are available with Hourly pro-rata on Monthly Billing.

VMware SDDC certified profiles for SAP HANA
Profiles list
Note: The published names are subject to change.
The following table is an overview of the SAP-certified profiles with either:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 56

Intel Bare Metal and VMware vSphere (ESXi), manual VMware setup and configuration
IBM Cloud for VMware Solutions Dedicated, automated VMware SDDC setup and configuration
Profile

CPU

CPU Threads (also known

Memory (RAM

SAPS (after VMware

SAP HANA Processing

Cores

as. vCPU)

GB)

hypervisor 10%)

Type

BI.S3.H2.192
(VMware)

36

72

192 GB

70,965

OLAP/OLTP

BI.S3.H2.384
(VMware)

36

72

384 GB

71,487

OLAP/OLTP

BI.S3.H2.768
(VMware)

36

72

768 GB

71,667

OLAP/OLTP

BI.S4.H2.192
(VMware)

32

64

192 GB

74,223

OLAP/OLTP

BI.S4.H2.384
(VMware)

32

64

384 GB

76,617

OLAP/OLTP

BI.S4.H2.768
(VMware)

40

80

768 GB

101,547

OLAP/OLTP

BI.S4.H2.1500
(VMware)

56

112

1536 GB

132,498

OLAP/OLTP

BI.S4.H2.3000
(VMware)

56

112

3072 GB

121,614

OLAP/OLTP

BI.S4.H4.3000
(VMware)

112

224

3072 GB

257,373

OLAP/OLTP

BI.S4.H4.6000
(VMware)

112

224

6144 GB

257,373

OLAP/OLTP

BI.S4.H8.6000
(VMware)

224

448

6144 GB

495,603

OLAP/OLTP

Table 1. SAP HANA servers

Understanding Bare Metal profile names
The Bare Metal profile names are contextual and sequential, below uses an SAP HANA certified server as an example:
Profile name

Naming convention component

What it means

BI.S3.H8401

BI

IBM Cloud) Infrastructure

S2

Series 2 (processor generation) \n
S2 is Intel Broadwell
S3 is Intel Skylake/Kaby Lake
S4 is Intel Cascade Lake

H

HANA-certified server

8

8-socket server

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 57

4

4 TB RAM

01

Revision number (00 is launch, 01 is first revision, and so on)

A or B

Available as appliances with preconfigured built-in disks (A) or as boot servers only (B)
Table 2. Profile naming for SAP HANA

Bare Metal Server certified profiles on VPC infrastructure for SAP HANA
Profiles list
The following table gives you an overview of the SAP-certified profiles with bare metal servers for VPC. The vCPUs in this list are CPU cores and their
secondary threads. The term vCPU is kept for comparison with their virtual counterparts.
Profile

vCPU

Memory (RAM GiB)

SAPS

SAP HANA
Processing Type

Compute Optimized
cx2d-metal-96x192

96

192

107,400

SAP Business One (**)

96

384

124,130

OLTP/OLAP (*)
SAP Business One (**)

96

768

127,620

OLTP/OLAP (*)
SAP Business One (**)

ux2d-metal-112x3072

112

3,072

140,730

OLTP/OLAP (*)

ux2d-metal-224x6144

224

6,144

294,730

OLTP/OLAP (*)

Balanced
bx2d-metal-96x384

Memory Optimized
mx2d-metal-96x768

Ultra High Memory Optimized

Table 1. IBM Cloud Bare Metal Servers for VPC certified for SAP HANA

(*): RHEL 8.4 for SAP Solutions, RHEL 8.6 for SAP Solutions, RHEL 8.8 for SAP Solutions, RHEL 9.0 for SAP Solutions, RHEL 9.2 for SAP Solutions
SLES 12 SP5, SLES 15 SP2, SLES 15 SP3, SLES 15 SP4, SLES 15 SP5
(**): SLES 15 SP2, SLES 15 SP3, SLES 15 SP4, SLES 15 SP5
For more information, see SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment .
Important: For SAP HANA deployments that use IBM Cloud Bare Metal Servers for VPC, only single-node deployments are supported. Multi-node /
scale-out is not currently supported.

Understanding Bare Metal Server profile names
With IBM Cloud Bare Metal Servers for VPC, the profile families that are certified for SAP are: Compute Optimized, Balanced, Memory Optimized, and Ultra
High Memory Optimized.
Compute Optimized family profiles provide more compute power, and they have more cores with less memory.
Balanced family profiles provide a good mix of performance and scalability for more common workloads.
Memory Optimized and Ultra High Memory Optimized family profiles cater to memory intensive workloads, such as demanding database applications
and in-memory analytics workloads, and are especially designed for SAP HANA workloads.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 58

For more information, see x86-64 bare metal server profiles .
The first letter of the profile name indicates the profile family:
First letter

Characteristics of the related profile family

c

Compute Optimized family, vCPU to memory ratio 1:2

b

Balanced family, vCPU to memory ratio 1:4

m

Memory Optimized family, higher vCPU to memory ratio 1:8

u

Ultra High Memory Optimized family, even higher vCPU to memory ratio 1:27.43
Table 2. IBM Cloud Bare Metal Servers for VPC Profile Families

The bare metal server profile names are contextual and sequential. See the following example:

Profile name

Naming convention

What it means

component
mx2d-metal96x768

m

Memory Optimized family

x

Intel x86_64 CPU Architecture

2

The generation for the underlying hardware

d

the optional 'd' in the name indicates that the server is equipped with one or more SSD
storage devices

—

spacer

metal

metal in the name indicates that this is a bare metal server

—

spacer

96

96 vCPU

x

spacer

768

768 GiB RAM
Table 2. Profile naming for SAP HANA

Profiles available on Hourly Consumption Billing
All IBM Cloud Bare Metal Servers for VPC are available with Hourly Consumption Billing, which includes Suspend Discounts and Sustained Usage
Discounts. With Suspend Discounts, storage charges occur only if the server is in shutdown state. With Sustained Usage Discount, the more a server is
used, the less the cost per hour.

Storage specifications
When the bare metal server profiles for SAP HANA are initially provisioned, the servers all have one pre-configured disk (sda) and provide the root partition
/ with about 890 GB and the partition /boot/efi with 100 MB or less. Depending on storage volume type, the specific OS release and version the

storage layout and partition sizes are differing a little.
In addition to these partitions, Bare Metal Servers for VPC have up to 8 NVMEs – depending on their RAM size – which need to be configured after the
server deployment.
To fulfill the KPIs defined for SAP HANA, each profile needs different storage volumes that are listed in detail in the following sections. These storage
configurations are recommended. They are certified storage layouts that comply with SAP HANA Tailored Data Center Integration (TDI) Phase 5.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 59

Important: If a specific memory sizing needs to be performed, customers are advised to follow the instructions here and if it turns out that
different logic volume sizes are required then in addition the SAP HANA TDI Overview and SAP HANA TDI FAQ must be considered. In that case,
users must run SAP's performance measurement tool HCMT - see SAP Note 2493172 - SAP HANA Hardware and Cloud Measurement Tools and
follow the instructions of the HCMT guide to check compliance with SAP’s KPIs.

Note: This holds true especially, if file shares are used for SAP HANA installations. They can be deployed and mounted in arbitrary ways to provide
additional storage, for example for backups, as needed. For SAP HANA data and log files, however, they have to be evaluated.
In any case, SAP's recommended file system layout must be available for SAP HANA deployment.

Bare Metal Servers for VPC - Storage Layouts
The following table shows the required physical volumes, related volume groups, logical volumes, and their characteristics:
Profile

cx2d-metal-96x192

File

Logical

LV Size

system

Volume

(GiB)

/hana/shared

hana_shared_lv

192

Volume Group

Physical
Volume

vg0

nvme0n1nvme3n1-

/hana/log

hana_log_lv

192

vg0

/hana/data

hana_data_lv

min. 576

vg1

nvme4n1nvme7n1-

bx2d-metal-96x384

/hana/shared

hana_shared_lv

384

vg0

nvme0n1nvme3n1-

/hana/log

hana_log_lv

384

vg0

/hana/data

hana_data_lv

min. 1,152

vg1

nvme4n1nvme7n1-

mx2d-metal-96x768

/hana/shared

hana_shared_lv

768

vg0

nvme0n1nvme3n1-

/hana/log

hana_log_lv

512

vg0

/hana/data

hana_data_lv

min. 2,304

vg1

nvme4n1nvme7n1-

ux2d-metal-112x3072

/hana/shared

hana_shared_lv

3,072

vg0

nvme0n1nvme3n1-

/hana/log

hana_log_lv

512

vg0

/hana/data

hana_data_lv

min. 9,216

vg1

nvme4n1nvme7n1-

ux2d-metal-224x6144

/hana/shared

hana_shared_lv

6,144

vg0

nvme0n1nvme1n1-

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 60

/hana/log

hana_log_lv

512

vg0

/hana/data

hana_data_lv

the remaining space ~17,190

vg0

Table 3. Storage layout for Bare Metal Servers for VPC

Note: Profile ux2d-metal-224x6144 is equipped with different set of disks, so jump directly to "Steps for setting up storage for the ux2d-metal224x6144 profile".

Steps for setting up storage for the profiles up to 3,072 GiB
Note, that both volume groups vg0 and vg1 are not fully used. Remaining space can be used to extend the listed sizes, which are only minimum sizes, or
can be used for other purposes. However, do not point I/O load at the remaining space since that impacts SAP HANA’s performance.
To ensure a higher level of availability and failure resilience, RAID10 logical volumes are built on-top the under-laying NVMEs, based on Linux’s logical
volume manager.
These steps show a step-by-step guide for setting up the volume groups, logical volumes, and file systems. Size information differs and can be retrieved
from the storage layout table.
1. Log in to the OS and install the lvm2 package, if not installed already.
$ [root@mx2d-metal-96x768 ~]# yum install lvm2

This command applies to RHEL, on SLES use ‘zypper install’ instead.
2. Create the volume groups.
$ [root@mx2d-metal-96x768 ~]# vgcreate vg0 /dev/nvme0n1 /dev/nvme1n1 /dev/nvme2n1 /dev/nvme3n1
[root@mx2d-metal-96x768 ~]# vgcreate vg1 /dev/nvme4n1 /dev/nvme5n1 /dev/nvme6n1 /dev/nvme7n1

3. Create logical volumes on top of the volume groups.
$ [root@mx2d-metal-96x768 ~]# lvcreate --type raid10 -i 2 -m 1 -L 768G -I 64 -n hana_shared_lv vg0

Note: 768G needs to be adapted to the hana_shared volume size specific to your memory size in the sizing table. Sizes for hana_log can be
found there, too, and can be used in the lvcreate command as well.

$ [root@mx2d-metal-96x768 ~]# lvcreate --type raid10 -i 2 -m 1 -L 512G -I 64 -n hana_log_lv vg0

4. Create hana_data. Either modify the size with the -L option according to the sizing table, or the use the entire volume group with

-l 100%FREE :

$ [root@mx2d-metal-96x768 ~]# lvcreate --type raid10 -i 2 -m 1 -l 100%FREE -I 64 -n hana_data_lv vg1

5. Create file systems on the logical volumes. In this example, XFS is used and is mounted by label. Mount by label is not a requirement and can be
adapted according to your needs:
$ [root@mx2d-metal-96x768 ~]# mkfs.xfs -L HANA_SHARED -K /dev/mapper/vg0-hana_shared_lv
[root@mx2d-metal-96x768 ~]# mkfs.xfs -L HANA_LOG -K /dev/mapper/vg0-hana_log_lv
[root@mx2d-metal-96x768 ~]# mkfs.xfs -L HANA_DATA -K /dev/mapper/vg1-hana_data_lv

6. Add the following lines to /etc/fstab and create the required directory paths with mkdir.
$ LABEL=HANA_SHARED /hana/shared xfs defaults 0 0
LABEL=HANA_LOG /hana/log xfs defaults,swalloc,inode64 0 0
LABEL=HANA_DATA /hana/data xfs defaults,largeio,swalloc,inode64 0 0

7. You can now mount the file systems.

Steps for setting up storage for the ux2d-metal-224x6144 profile
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 61

To ensure a higher level of availability and failure resilience, RAID1 logical volumes are built on-top the under-laying NVMEs, based on Linux’s logical
volume manager.
These steps show a step-by-step guide for setting up the volume groups, logical volumes, and file systems.
1. Log in to the OS and install the lvm2 package, if not installed already.
$ [root@ux2d-metal-224x6144 ~]# yum install lvm2

This command applies to RHEL, on SLES use ‘zypper install’ instead.
2. Create the volume group.
$ [root@ux2d-metal-224x6144 ~]# vgcreate vg0 /dev/nvme0n1 /dev/nvme1n1

3. Create logical volumes hana_shared_lv and hana_log_lv on top of the volume group.
$ [root@ux2d-metal-224x6144 ~]# lvcreate --type raid1 -L 6144G -n hana_shared_lv vg0
[root@ux2d-metal-224x6144 ~]# lvcreate --type raid1 -L 512G -n hana_log_lv vg0

4. Create logical volume hana_data_lv.
$ [root@ux2d-metal-224x6144 ~]# lvcreate --type raid1 -l 100%FREE -n hana_data_lv vg0

5. Create file systems on the logical volumes. In this example, XFS is used and is mounted by label. Mount by label is not a requirement and can be
adapted according to your needs:
$ [root@ux2d-metal-224x6144 ~]# mkfs.xfs -L HANA_SHARED -K /dev/mapper/vg0-hana_shared_lv
[root@ux2d-metal-224x6144 ~]# mkfs.xfs -L HANA_LOG -K /dev/mapper/vg0-hana_log_lv
[root@ux2d-metal-224x6144 ~]# mkfs.xfs -L HANA_DATA -K /dev/mapper/vg0-hana_data_lv

6. Add the following lines to /etc/fstab and create the required directory paths with mkdir.
$ LABEL=HANA_SHARED /hana/shared xfs defaults 0 0
LABEL=HANA_LOG /hana/log xfs defaults,swalloc,inode64 0 0
LABEL=HANA_DATA /hana/data xfs defaults,largeio,swalloc,inode64 0 0

7. You can now mount the file systems.
Check SAP Note 2777782 for RHEL and SAP Note 2684254 for SLES to adapt your OS configuration settings according to the requirements for SAP
HANA.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 62

Infrastructure profiles for SAP NetWeaver Application Servers
Intel Bare Metal server certified profiles on Classic infrastructure for SAP NetWeaver
Profiles list
Note: The published names are subject to change.
The following is an overview of the SAP-certified profiles with Intel Bare Metal:
Profile

CPU Cores

CPU Threads (aka. vCPU)

Memory (RAM GB)

SAPS

BI.S3.NW32

4

8

32 GB

11,970

BI.S3.NW64

4

8

64 GB

12,750

BI.S3.NW192

36

72

192 GB

78,850

BI.S3.NW384

36

72

384 GB

79,430

BI.S3.NW768

36

72

768 GB

79,630

BI.S4.NW192

32

64

192 GB

82,470

BI.S4.NW384

32

64

384 GB

85,130

BI.S4.NW384_v3

16

32

384 GB

60,420

BI.S4.NW768

40

80

768 GB

112,830

BI.S4.NW768_v2

48

96

768 GB

124,620

BI.S4.NW768_v3

16

32

768 GB

60,420

BI.S4.NW1500

56

112

1.5 TB

147,220

BI.S4.NW3000

56

112

3 TB

135,127

Table 1. SAP NetWeaver servers

See also SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment .

Understanding Bare Metal profile names
The Bare Metal profile names are contextual and sequential, below uses an SAP NetWeaver certified server as an example:
Profile name

Naming convention component

What it means

BI.S3.NW384

BI

IBM Cloud Infrastructure

S3

Series 3 (processor generation)
S3 is Intel Skylake/Kaby Lake
S4 is Intel Cascade Lake

NW

NetWeaver-certified server

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 63

384

384 GB RAM
Table 2. Profile naming for SAP NetWeaver

Profiles available on Hourly Consumption Billing
The following Bare Metal servers are available on Hourly Consumption Billing:
BI.S3.NW32
BI.S4.NW192
BI.S4.NW384
BI.S4.NW768

AMD Bare Metal server certified profiles on Classic infrastructure for SAP NetWeaver
Profiles list
Note: The published names are subject to change.
The following is an overview of the SAP-certified profiles with AMD Bare Metal:
Profile

CPU Cores

CPU Threads (aka. vCPU)

Memory (RAM GB)

SAPS

BI.S4A.NW2000

96

192

2 TB

265,650

BI.S4A.NW4000

96

192

4 TB

267,450

Table 1. SAP NetWeaver servers AMD

See also SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment .

Understanding Bare Metal profile names
The Bare Metal profile names are contextual and sequential, below uses an SAP NetWeaver certified server as an example:
Profile name

Naming convention component

What it means

BI.S4A.NW2000

BI

IBM Cloud Infrastructure

S4A

Series 3 (processor generation)
S3 is Intel Skylake/Kaby Lake
S4 is Intel Cascade Lake
S4A is AMD 2nd Gen EPYC

NW

NetWeaver-certified server

2000

2000 GB RAM
Table 2. Profile naming for SAP NetWeaver AMD

Intel Virtual Server certified profiles on VPC infrastructure for SAP NetWeaver
Profiles list
Note: The published names are subject to change.
The following tables provide an overview of the SAP-certified profiles for Virtual Servers for VPC:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 64

SAP-certified profiles hosted on Intel Cascade Lake CPUs
Profile

vCPU

Memory (RAM GiB)

SAPS

cx2-2x4
cx2d-2x4

2

4

2,238

cx2-4x8
cx2d-4x8

4

8

4,475

cx2-8x16
cx2d-8x16

8

16

8,950

cx2-16x32
cx2d-16x32

16

32

17,900

cx2-32x64
cx2d-32x64

32

64

35,800

cx2-48x96
cx2d-48x96

48

96

53,700

cx2-64x128
cx2d-64x128

64

128

71,600

cx2-96x192
cx2d-96x192

96

192

107,400

cx2-128x256
cx2d-128x256

128

256

143,200

bx2-2x8
bx2d-2x8

2

8

2,306

bx2-4x16
bx2d-4x16

4

16

4,613

bx2-8x32
bx2d-8x32

8

32

9,225

bx2-16x64
bx2d-16x64

16

64

18,450

bx2-32x128
bx2d-32x128

32

128

36,900

bx2-48x192
bx2d-48x192

48

192

55,350

bx2-64x256
bx2d-64x256

64

256

81,685

bx2-96x384
bx2d-96x384

96

384

122,528

bx2-128x512
bx2d-128x512

128

512

163,370

Compute Optimized

Balanced

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 65

Memory Optimized
mx2-2x16
mx2d-2x16

2

16

2,571

mx2-4x32
mx2d-4x32

4

32

5,141

mx2-8x64
mx2d-8x64

8

64

10,283

mx2-16x128
mx2d-16x128

16

128

20,565

mx2-32x256
mx2d-32x256

32

256

41,130

mx2-48x384
mx2d-48x384

48

384

56,970

mx2-64x512
mx2d-64x512

64

512

81,015

mx2-96x768
mx2d-96x768

96

768

121,523

mx2-128x1024
mx2d-128x1024

128

1,024

162,030

vx2d-2x28

2

28

2,131

vx2d-4x56

4

56

4,262

vx2d-8x112

8

112

8,523

vx2d-16x224

16

224

17,046

vx2d-44x616

44

616

46,875

vx2d-88x1232

88

1,232

93,750

vx2d-144x2016

144

2,016

153,410

vx2d-176x2464

176

2,464

187,500

ux2d-2x56

2

56

2,156

ux2d-4x112

4

112

4,312

ux2d-8x224

8

224

8,623

ux2d-16x448

16

448

17,246

ux2d-36x1008

36

1,008

38,803

Very High Memory Optimized

Ultra High Memory Optimized

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 66

ux2d-48x1344

48

1,344

51,737

ux2d-72x2016

72

2,016

77,606

ux2d-100x2800

100

2,800

107,785

ux2d-200x5600

200

5,600

215,570

Table 1. IBM Cloud Virtual Servers for VPC hosted on Intel Cascade Lake CPUs

SAP-certified profiles hosted on Intel Sapphire Rapids CPUs
Profile

vCPU

Memory (RAM GiB)

SAPS

cx3d-2x5

2

5

2,661

cx3d-4x10

4

10

5,321

cx3d-8x20

8

20

10,642

cx3d-16x40

16

40

21,284

cx3d-24x60

24

60

31,926

cx3d-32x80

32

80

42,568

cx3d-48x120

48

120

63,852

cx3d-64x160

64

160

85,136

cx3d-96x240

96

240

127,703

cx3d-128x320

128

320

170,270

cx3d-176x440

176

440

234,120

bx3d-2x10

2

10

2,616

bx3d-4x20

4

20

5,232

bx3d-8x40

8

40

10,463

bx3d-16x80

16

80

20,926

bx3d-24x120

24

120

31,388

bx3d-32x160

32

160

41,850

bx3d-48x240

48

240

62,775

bx3d-64x320

64

320

83,699

bx3d-96x480

96

480

125,548

Compute Optimized

Balanced

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 67

bx3d-128x640

128

640

167,397

bx3d-176x880

176

880

230,170

mx3d-2x20

2

20

2,590

mx3d-4x40

4

40

5,180

mx3d-8x80

8

80

10,359

mx3d-16x160

16

160

20,718

mx3d-24x240

24

240

31,076

mx3d-32x320

32

320

41,434

mx3d-48x480

48

480

62,150

mx3d-64x640

64

640

82,866

mx3d-96x960

96

960

124,299

mx3d-128x1280

128

1,280

165,731

mx3d-176x1760

176

1,760

227,880

Memory Optimized

Table 2. IBM Cloud Virtual Servers for VPC hosted on Intel Sapphire Rapids CPUs

For more information, see SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment .

Understanding Virtual Server profile names
With IBM Cloud® Virtual Servers for Virtual Private Cloud, the profile families that are certified for SAP are: Compute Optimized, Balanced, Memory
Optimized, Very High Memory Optimized , and Ultra High Memory Optimized.
Compute Optimized family profiles provide more compute power, and they have more cores with less memory.
Balanced family profiles provide a good mix of performance and scalability for more common workloads.
All the memory family profiles cater to memory intensive workloads, such as demanding database applications and in-memory analytics workloads,
and are especially designed for SAP HANA workloads.
For more information, see chapter x86-64 instance profiles.
The first letter of the profile name indicates the profile family mentioned above:
First letter

Characteristics of the related profile family

c

Compute Optimized family, vCPU to memory ratio 1:2 or 1:2.5

b

Balanced family, vCPU to memory ratio 1:4 or 1:5

m

Memory Optimized family, higher vCPU to memory ratio 1:8 or 1:10

v

Very High Memory Optimized family, very high vCPU to memory ratio 1:14

u

Ultra High Memory Optimized family, ultra high vCPU to memory ratio 1:28
Table 3. IBM Cloud® Virtual Servers for Virtual Private Cloud Profile Families

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 68

For SAP HANA, only the memory profile families are used, for NetWeaver also the Compute Optimized and the Balanced families may be considered. The
Virtual Server profile names are contextual and sequential. See here one example:
Profile

Naming convention

What it means

name

component

mx?16x128

m

Memory Optimized family

x

Intel x86_64 CPU Architecture

?
2
3

The Intel generation for the underlying hardware
Cascade Lake
Sapphire Rapids

d

the optional 'd' in the name indicates that the server is equipped with one or more internal SSD or NVMe
storage devices (*)

—

spacer

16

16 vCPU

x

spacer

128

128 GiB RAM
Table 4. Profile naming for SAP HANA

Note: (*) Note for Virtual Server Instances using temporary local SSD or NVMe storage: you must not place any SAP workload related data on such
instance storage, because data loss may occur in certain situations - see more information here: About instance storage.

Profiles available on Hourly Consumption Billing
All IBM Cloud Virtual Servers for VPC are available with Hourly Consumption Billing, which includes Suspend Discounts and Sustained Usage Discounts.
With Suspend Discounts, storage charges occur only if the server is in Shutdown state. With Sustained Usage Discount, the more a server is used, the less
the cost per hour.

Storage specifications
When the virtual server profiles for SAP HANA are initially provisioned, the servers all have one pre-configured volume (vda) attached with the following
basic layout:
File system

Partition

Storage type

size (GB)

Nr. of
IOPS

/

vda1

Pre-configured boot volume

100

3,000

/boot

vda2

Pre-configured boot volume

0.25

3,000

Table 5. Storage configuration of the default virtual server deployment (boot volume)

To fulfill the size and I/O requirements for SAP NetWeaver or SAP AnyDB, more

IBM® Cloud Block Storage for Virtual Private Cloud volumes need to be

added as data volumes to the virtual server configuration.
Block Storage Volumes for Virtual Servers can be created based on different volume profiles that provide different levels of IOPS per gigabyte (IOPS/GB).
For more information, see IOPS tiers for details.
You must consider the total IOPS required for your installation and the performance characteristics of your database. One option is to colocate multiple
directories into a single large volume with high IOPS, versus isolating directories into individual small volumes with an insufficient number of IOPS for the
workload characteristics.
For an overview of all available storage profiles, see VPC Block Storage Profiles.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 69

For SAP NetWeaver and SAP AnyDB, a minimum of 5 IOPS/GB is recommended.
Samples of storage configurations that use Intel Virtual Server (Gen2) profiles are available under Storage design considerations.

IBM Power Virtual Server certified profiles for SAP NetWeaver
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services

Understanding IBM Power Virtual Server profile names
The IBM Power Virtual Servers are available with fully adjustable CPU Cores and Memory (RAM GB). It is permitted to define a custom size of the IBM
Power Virtual Server to use for SAP NetWeaver, in accordance with existing SAP NetWeaver or SAP AnyDB for IBM Power Systems best practices and
guidance from SAP.
Therefore, no profile names are used to define running SAP NetWeaver or SAP AnyDB that uses IBM Power Virtual Servers.
For SAP applications the following virtual server configurations are supported. Given SAP NetWeaver instance sizing is flexible, it must follow the standard
SAP sizing guidelines by using the following SAPS benchmark calculation:
Power System type

SAPS per CPU Core

SAPS per CPU Thread (using SMT-8)

S922

5,570

696.25

E980

6,000

750

Table 1. IBM Power Virtual Servers certified for SAP NetWeaver

For more information, see SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers

Profiles available on Hourly Consumption Billing
All IBM Power Virtual Servers are available with Hourly pro-rata on Monthly Billing.

VMware SDDC certified profiles for SAP NetWeaver
Profiles list
Note: The published names are subject to change.
The following table is an overview of the SAP-certified profiles with either:
Intel Bare Metal and VMware vSphere (ESXi), manual VMware setup and configuration
IBM Cloud for VMware Solutions Dedicated, automated VMware SDDC setup and configuration
Profile

CPU Cores

CPU Threads (also known as. vCPU)

Memory (RAM GB)

SAPS (after VMware hypervisor 10%)

BI.S3.NW192 (VMware)

36

72

192 GB

70,965

BI.S3.NW384 (VMware)

36

72

384 GB

71,487

BI.S3.NW768 (VMware)

36

72

768 GB

71,667

BI.S4.NW192 (VMware)

32

64

192 GB

74,223

BI.S4.NW384 (VMware)

32

64

384 GB

76,617

BI.S4.NW768 (VMware)

40

80

768 GB

101,547

BI.S4.NW1500 (VMware)

56

112

1536 GB

132,498

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 70

BI.S4.NW3000 (VMware)

56

112

3072 GB

121,614

Table 1. SAP NetWeaver servers

Understanding Bare Metal profile names
The Bare Metal profile names are contextual and sequential, below uses an SAP HANA certified server as an example:
Profile name

Naming convention component

What it means

BI.S3.H8401

BI

IBM Cloud Infrastructure

S2

Series 2 (processor generation) \n
S2 is Intel Broadwell
S3 is Intel Skylake/Kaby Lake
S4 is Intel Cascade Lake

H

HANA-certified server

8

8-socket server

4

4 TB RAM

01

Revision number (00 is launch, 01 is first revision, and so on)

A or B

Available as appliances with preconfigured built-in disks (A) or as boot servers only (B)
Table 2. Profile naming for SAP NetWeaver

Bare Metal Server certified profiles on VPC Infrastructure for SAP NetWeaver
Profiles list
Note: The published names are subject to change.
This table gives you an overview of the SAP-certified profiles with bare metal servers for VPC. The vCPUs in this list are CPU cores and their secondary
threads. The term vCPU is kept for comparison with their virtual counterparts.
Profile

vCPU

Memory (RAM GiB)

SAPS

96

192

101,070

96

384

124,130

96

768

127,620

112

3,072

140,730

Compute Optimized
cx2d-metal-96x192
Balanced
bx2d-metal-96x384
Memory Optimized
mx2d-metal-96x768
Ultra High Memory Optimized
ux2d-metal-112x3072

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 71

ux2d-metal-224x6144

224

6,144

294,730

Table 1. IBM Cloud Bare Metal Servers for VPC certified for SAP NetWeaver

For more information, see SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment .

Understanding Bare Metal Server profile names
With IBM Cloud Bare Metal Servers for VPC, the profile families that are certified for SAP are: Compute Optimized, Balanced, Memory Optimized, and Ultra
High Memory Optimized.
Compute Optimized family profiles provide more compute power, and they have more cores with less memory.
Balanced family profiles provide a good mix of performance and scalability for more common workloads.
Memory Optimized and Ultra High Memory Optimized family profiles cater to memory intensive workloads, such as demanding database applications
and in-memory analytics workloads, and are especially designed for SAP HANA workloads.
For more information, see x86-64 bare metal server profiles .
The first letter of the profile name indicates the profile family:
First letter

Characteristics of the related profile family

c

Compute Optimized family, vCPU to memory ratio 1:2

b

Balanced family, vCPU to memory ratio 1:4

m

Memory Optimized family, higher vCPU to memory ratio 1:8

u

Ultra High Memory Optimized family, even higher CPU to memory ratio 1:27.43
Table 2. IBM Cloud Bare Metal Servers for VPC Profile Families

The Bare Metal Server profile names are contextual and sequential. See the following example:

Profile name

Naming convention

What it means

component
mx2d-metal96x768

m

Memory Optimized family

x

Intel x86_64 CPU Architecture

2

The generation for the underlying hardware

d

the optional 'd' in the name indicates that the server is equipped with one or more SSD
storage devices

—

spacer

metal

metal in the name indicates that this is a bare metal server

—

spacer

96

96 vCPU

x

spacer

768

768 GiB RAM
Table 3. Profile naming for SAP NetWeaver

Profiles available on Hourly Consumption Billing
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 72

All IBM Cloud Bare Metal Servers for VPC are available with Hourly Consumption Billing, which includes Suspend Discounts and Sustained Usage
Discounts. With Suspend Discounts, storage charges occur only if the server is in Shutdown state. With Sustained Usage Discount, the more a server is
used, the less the cost per hour.

Storage specifications
When the bare metal server profiles for SAP NetWeaver are initially provisioned, the servers all have one pre-configured disk (sda) attached with the
following basic layout:
File system

Partition

Storage type

Size

sda1

Pre-configured BIOS volume

1 MB

/boot/efi

sda2

Pre-configured boot volume

100 MB

/

sda3

Pre-configured root volume

9.9 GB

Table 4. Storage configuration of the default bare metal server deployment (boot volume)

Internal Storage
Your bare metal server on VPC comes with a number of internal NVMEs, depending on its size. For SAP NetWeaver based deployment, you can use the
NVMEs that are listed as block devices to the operating system. The NVMEs are under “/dev/nvmeXn1” (X from 0 to the number of NVMEs in total, minus
1). Use the NVMEs according to your requirements and needs. However, to increase failure resilience, you might have to install Linux Logical Volume
Manager (LVM) to add RAID configuration, like RAID1 or RAID5. Since NVMEs are provisioned, performance considerations are mostly not an issue.

External Storage
If more storage needs are to be added to your bare metal server on VPC, for example, for backup purposes, NFS-based

file shares can be created and

mounted. Learn more details in the corresponding chapter Creating file shares and mount targets .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 73

Plan your SAP workloads
Sizing process for SAP Systems
After you decide which SAP solutions you want to use, you need to determine the number of hosts that are required to support your SAP landscape and
make sure that the host servers are correctly sized.
SAP sizing is a detailed activity (and often a project in itself) to map business requirements into Infrastructure/Hardware requirements.

Understanding SAP sizing
The SAP sizing methodology for SAP HANA or SAP NetWeaver technical applications is based on SAP benchmarks, such as information from SAP and actual
customer experiences.
The base SAP workload unit is an SAP Application Performance Standard (SAPS).
The SAPS is a definition of throughput that is coined by SAP capacity planning and performance testing personnel. For example, 100 SAPs is defined as
2,000 fully business processed order-line items per hour in the standard SAP Sales and Distribution (SAP SD) application benchmark. This example is
equivalent to 2,400 SAP SD transactions per hour with the SAP Enterprise Resource Planning (SAP ERP) solution.
The benchmarking test determines and rates the infrastructure processing power based on its capability to run and process transactions at close to 100%
CPU load with a response time of less than 1 second.
The capability of processors is measured during the standard (SAP SD) benchmark test that is certified by SAP. For more information about the benchmark
test that is certified by SAP, see SAP Standard Application Benchmarks and Practical Guidelines and Techniques for Sizing your SAP Landscape for
Optimal Performance and Scalability.
SAP sizing is primarily based on:
Business throughput (Throughput based sizing); includes database table size increase from new objects, CPU time to complete processing
transactions or batch job runs within a time limit (decided by the business)
Business concurrent users (User based sizing); includes usage patterns and categorization of user’s based upon their daily transactions
Business need for High Availability and Disaster Recovery
Business need for multiple SAP applications and add-ons, which are integrated into one landscape
SAP sizing is used to determine:
Support for design of the Application Server structure and configurations:
SAP Systems
SAP Tiering/Tracks
SAP Instances
SAP Clients
Support for design of the Database Server structure and configurations:
System Type e.g. Distributed
Deployment Type e.g. MDC
Processing Type e.g. OLAP
Sizing Type and Deployment Method e.g. Expert Sizing with TDIv5/6
High Availability and Disaster Recovery
Processor and Memory requirements
Storage requirements
Network requirements and topology
Backup strategy
SAP sizing inaccuracies can cause risks to SAP implementation projects:
Project risk from

Mitigations of SAP Sizing inaccuracy

inaccurate SAP Sizing

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 74

Incomplete/Insufficient
input data

Information discovery requires support from business departments and the IT organization /n - Communication
issues are a common cause of invalid data therefore assignment of a project manager to run workshops is
recommended /n - Any unknown data will become an assumption

Assumptions are not
verified

/n - Assumptions must be documented and need a verification process included in the project plan

Custom code and
special data structures

/n - Hard to predict scenarios, that are solved by custom code and special data structures, require a verification process to
determine whether there is an impact to infrastructure (commonly processing and storage)
Table 1. SAP Sizing inaccuracies can cause risks to SAP implementation projects

SAP logical structure and SAP Sizing impacts for infrastructure
There are multiple ways in which the SAP logical structure and SAP sizing activities can impact infrastructure-related requirements, three key ways are
highlighted below:
1. Business Requirements
Business requirements, such as 99.99% uptime or 3 downtime windows per year, effect logical design and structure of the SAP Landscape. The logical
structure is made up of:
SAP Systems
SAP Tiering
SAP Tracks
SAP Instances
SAP Clients
2. SAP sizing results
Each decision in the logical structure is reflected by the SAP Sizing project/exercise outcome:
SAPS benchmark threshold required
Size of database (memory and disk storage)
etc.
3. Infrastructure requirements
SAP sizing results will heavily impact Infrastructure needs:
Number of hosts required
Performance/Size of hosts required
Storage capacity for hosts
Networking performance and isolation between hosts
etc.

Migrating an existing SAP System
If you plan to migrate an existing SAP system (from any source) to your IBM Cloud environment, you can determine the SAPS numbers from the SAPS
numbers of your current environment.
Use the information about your current workload (the CPUs and RAM used) and get the SAPS equivalents for your CPU from the

SAP SD Benchmarks

results of your existing hardware.

Using the SAP Quick Sizer
The SAP Quick Sizer is a web-based tool that is provided by SAP; it is available to all customers and business partners of SAP. Sizing information is input
directly into the tool. The tool sizes SAP HANA or SAP NetWeaver servers.
Note: You need an SAP S-user ID to use the Quick Sizer.
The Quick Sizer calculates the workload (in a measurement unit called SAPS) and adjusts the workload to allow for suitable processor use. So, if a workload
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 75

of 4,800 SAP SD benchmark transactions per hour is required, the tool calculates this workload as 200 SAPS. For example, an IT department determined
that to avoid system overloads during high-usage periods, a target processor load of 33% is allowed. A processor that can provide 200 SAPS at 33% load
means that the processor is capable of 600 SAPS at 100% load. Therefore, a system capable of 600 SAPS becomes the benchmark to which any new
infrastructure must adhere.
While the sizing method might be considered conservative, consider that all SAPS calculations for your servers are based on highly tuned SAP systems that
run only specific SAP SD workloads. Depending on the type of SAP application, any custom configuration or custom coding in your system, your results can
vary. Also, requirements for your project, such as proof-of-concept (PoC) or regarding performance and response time, might be different.
After you determine your SAP applications and the SAPS numbers are calculated through the SAP Quick Sizer, or based on your current landscape, you can
choose from the IBM Cloud® for SAP portfolio and the various infrastructure sizes available (as profiles or customizable/flexible in some cases).

Assessment of SAP HANA with the SAP Quick Sizer
SAP HANA is supported in production on single-node and multi-node SAP HANA-certified servers. The SAP HANA database uses column storage for some
tables and fields, reducing the storage below row storage in traditional Relation Database Management System (RDMS); data can be highly compressed
and compression ratios can range from 3:1 to over 10:1 based on the source data and database.
Sizing SAP HANA correctly is key to the success of your project. It is a best practive to complete the sizing before you order any SAP HANA certified server
from IBM Cloud® for SAP. Improperly sized memory or storage requirements can lead to an upgrade and migration to a larger server.
Main memory is one of the most important resources to consider when you size an SAP HANA-certified appliance.
The SAP HANA Master Guide provides a starting point for sizing-related topics.
The Sizing SAP HANA - SAP HANA Master Guide information within the guide provides guidance on how to size your SAP HANA system. It points to the
different installation and migration scenarios for both greenfield installations and existing systems.
This information includes a link to the SAP HANA version of the SAP Quick Sizer tool (an SAP S-user ID is required to access the tool). The page also lists the
SAP Notes that are related to sizing your SAP HANA server.

For more information on SAP Sizing
For more information about sizing, see the following resources:
Sizing SAP HANA - SAP HANA Master Guide
SAP Quick Sizer
SAP Note 1736976 - Sizing Report for BW-on-HANA
SAP Note 1872170 - Suite on HANA memory sizes
SAP Note 1793345 - Sizing for SAP Suite on HANA
SAP Note 1514966 - SAP HANA: Sizing SAP HANA
SAP Certified and Supported SAP HANA Hardware
SAP Note 2055470 - SAP HANA on Power Planning and Installation Specifics - Central Note
SAP HANA TDI - Storage Requirements
SAP Certified Enterprise Storage Hardware for SAP HANA

SAP applications effect on sizing
Primarily, when sizing SAP applications there are design considerations related to the Infrastructure, OS, Database Server and Application Server. These
are covered in this topic group "Sizing and Planning SAP Workloads":
Networking design considerations
Storage design considerations
Compute and OS design considerations
SAP HANA Database design considerations
SAP NetWeaver design considerations
However, for each SAP Business Application and SAP Technical Application there are different implementation design considerations - which will change
for each business and the scenario.
Beyond the topic group "Sizing and Planning SAP Workloads", there are individual topic groups with additional information and considerations for your SAP
implementation:
SAP Business Applications

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 76

SAP S/4HANA
SAP BW/4HANA
SAP Commerce
SAP Business One (B1)
SAP Data Hub 2.x
SAP Technical Applications
SAP Content Server
SAP AnyDB databases
AnyDB - IBM Db2
AnyDB - SAP MaxDB
AnyDB - SAP ASE
AnyDB - SAP IQ

Define your SAP system landscape
Your business and functional requirements determine the SAP solutions that are powered by the SAP HANA Database Server or SAP NetWeaver Application
Server, and therefore determine how your applications are run the infrastructure available.
Your requirements have an influence on how you size your server. You have a wide selection of SAP NetWeaver-based applications (which may use SAP
HANA) to choose from, including SAP S/4HANA, SAP ERP Central Component (ECC), SAP BW/4HANA, SAP BW and many more solutions for different
business operations.
For a complete list of solutions, see SAP NetWeaver installation guidance . For information about supported operating systems and database platforms,
see SAP Product Availability Matrix (PAM). Search for Product Availability Matrix. An SAP S-User ID is required.

Determining your SAP applications
An SAP landscape is a group of two or more SAP systems that usually include development, quality and test, and production.
One SAP system consists of one or more SAP instances, which are a group of processes that are started and stopped at the same time. These SAP instances
are grouped to form a specified SAP system for a defined use for a region or business unit. Then, the instances are grouped in a landscape as development,
test, or production SAP systems with one or multiple tracks (such as "project" and "business"). This landscape design is up to each business, dependent on
business requirements.
Landscapes have several possible configurations, such as server (CPU, RAM) size and storage size, for all SAP solutions in the market. These solutions
include SAP NetWeaver-based products. SAP NetWeaver-based products range from older solutions, such as SAP ECC and SAP BW (that use "AnyDB"
vendors that are approved by SAP), to the new range of SAP solutions, such as SAP S/4HANA and SAP BW/4HANA (that use SAP HANA database). Beyond
the enterprise resource planning (ERP) and enterprise data warehouse (EDW) examples, there are many available SAP products or add-ons for different
industries and business types or operating geographies.
SAP NetWeaver-based products are designed to run on SAP NetWeaver-certified hosts, and SAP HANA-based products are designed to run on SAP HANAcertified hosts. The certified operating systems and supported database systems for IBM Cloud are listed in SAP Note 2927211.
More solutions are available from SAP that are not SAP NetWeaver-based and many third-party software options that might integrate with SAP can affect
the planning of your system landscape. For example, SAP HANA can run as a database for an SAP NetWeaver stack-based solution or as a stand-alone
entity depending on your usage scenario.
Note: Contact SAP Support if you plan to deploy and integrate non-SAP NetWeaver-based or third-party software into your SAP landscape on IBM
Cloud.
You want to be as detailed as possible when you determine the size of your server based on the applications that you plan to run, potential growth, and
performance. Additionally, keep in mind your storage and memory requirements for your applications. SAP systems in a landscape have specific
requirements for connectivity, either among each other or to external systems.
Questions during your determination of the SAP landscape:
How do you intend to use the applications? Is the intended use for development and testing, or production?
How do you intend to connect your SAP workloads in Cloud to your existing network and systems?
How will the database be used? Transactional (OLTP) or Analytical (OLAP)? Serving only the SAP Business Applications, or as part of your wider IT
strategy extracting value from the advanced SAP HANA Components, which are available (such as predictive analytics or Cloud Foundry via XSA)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 77

How do you intend to deploy the applications and databases? And to what level of resiliency (that is, HA/DR strategy)?
If you plan to migrate an on-premises SAP installation into the IBM Power Virtual Servers environment, make sure that you don't carry over existing
performance issues. Run an up-to-date sizing report, and review a recent SAP Early Watch report of your SAP system. For more information, see SAP
EarlyWatch Alert and SAP Note 207223 - SAP EarlyWatch Alert Processed at SAP .
Each deployment of SAP HANA Database Server or SAP NetWeaver Application Server will have items to consider. These are included under each relevant
section of this documentation.
For further information regarding SAP Landscapes, guidance has been released by IBM Power Systems, which provide excellent detailed agnostic
information and guidance regarding SAP Landscapes components and setup (which applies to running SAP on any infrastructure, on-premises data centers
or Cloud IaaS):
SAP on IBM Power Systems Best Practices Guide (click the link in the middle of the page)
IBM Power Systems Virtualization Operation Management for SAP Applications
SAP HANA on IBM Power Systems and IBM System Storage - Guides

Reviewing any relevant SAP and IBM Cloud documentation
Review the following documentation to help you determine any prerequisites for the SAP products that you plan to install.
If your organization is new to IBM Cloud, read the following SAP documentation to help with your planning phase and implementation:
SAP workloads on IBM Cloud®
Get started with IBM Cloud®
Creating an IBM Cloud® account
How to create an SAP S-user ID Note that only super administrators or S-users with the required authorization are allowed to create S-user IDs for
your company's SAP Customer Number (SCN)
The Guide Finder for SAP NetWeaver and ABAP Platform to search for SAP NetWeaver-related documentation, including installation guides.
Applicable installation guides; requires an SAP S-user ID.
SAP release notes, which can be found in the application help of the relevant SAP product documentation on the

SAP Help Portal; requires an SAP S-

user ID.
SAP HANA Help
SAP NetWeaver Help
SAP HANA Installation Guide
SAP Product Availability Matrix (PAM); requires an SAP S-user ID.
SAP Notes; requires an SAP S-user ID.
Third-party documentation

Selecting your SAP-certified infrastructure
This expands on the introduction Comparing the different SAP-certified IaaS offerings , which summarises the benefits of each different Infrastructure
option.
You are ready to define the number of host servers and size of those hosts after:
the business has defined their requirements
decided which SAP applications to use
read the SAP installation documentation
understood the various design considerations
Often your first filter of the infrastructure options is minimum SAPS, which has been calculated using the SAP Quick Sizer, and this will primarily define the
CPU performance requirements. For the official certification documents, see the SAP Standard Application Benchmarks which helps to confirm the IaaS
you are choosing from IBM Cloud is the correct IaaS for your needs.
Full details of the Profiles available for each Infrastructure option available through IBM Cloud, were provided in the previous topic group, which lists all the
IaaS Offerings available for either SAP HANA or SAP NetWeaver (and SAP AnyDB):
SAP HANA profiles
Intel Bare Metal server certified profiles for SAP HANA
Intel Virtual Server certified profiles for SAP HANA
IBM Power Virtual Server certified profiles for SAP HANA

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 78

VMware SDDC certified profiles for SAP HANA
SAP NetWeaver profiles
Intel Bare Metal server certified profiles for SAP NetWeaver
Intel Virtual Server certified profiles for SAP NetWeaver
IBM Power Virtual Server certified profiles for SAP NetWeaver
VMware SDDC certified profiles for SAP NetWeaver

Distributing your SAP Landscape on IBM Cloud Bare Metal and Virtual Servers
Generally, the entire infrastructure for the operation of all closely coupled runtime components of an SAP software solution must be installed on either Intel
Virtual Servers (Gen2) or on Bare Metal Servers from IBM Cloud.
To assist customers looking to combine performance for the database and flexibility for the application solution/s, testing has been performed when
combining environments and networks.
Intel Bare Metal Servers from IBM Cloud in the IBM Cloud Classic Infrastructure environment may offer greater performance capabilities. Notably, this
includes larger memory, local SSD storage in RAID arrays, access to IPMI, and more. Intel Virtual Servers (Gen2), on the other hand provide more
flexibility.
RDBMs on Intel Bare Metal Servers in the older IBM Cloud Classic Infrastructure environment that comply to SAP Note 2414097, are supported when
connected to the SAP AS on Intel Virtual Server (Gen2) in the IBM Cloud VPC Infrastructure environment - when placed in the same location (that is,
Datacenter / Availability Zone) and using an IBM Cloud Transit Gateway local routing.

Mapping CPUs derived from SAPS to an IBM Power Virtual Server
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services
When you create a IBM Power Virtual Server by using the IBM Cloud console:
For SAP NetWeaver, you select the number of CPUs of your server
For SAP HANA, you select an instance profile with a predefined number of CPUs and memory size that suits your workload
While your data must fit into the instance memory with space for data growth defined by the business and SAP Sizing process, choosing an instance profile
with more CPUs improves performance.
To find SAP certified profiles for Cloud IaaS, see SAP Certified and Supported SAP HANA Hardware Directory - Certified IaaS Platforms - IBM Cloud ; this
includes IBM Power Virtual Servers, which can be found by using filter "CPU Architecture" and selecting IBM Power9.
To find SAP certified IBM Power Systems Hardware, see SAP Certified and Supported SAP HANA Hardware Directory - IBM Power Systems .
For more information, see Creating a IBM Power Virtual Server . For information about the pricing difference between CPU types, see Pricing for IBM
Power Systems Virtual Servers on IBM Cloud®. For a description of the technical differences between dedicated, shared capped, and shared uncapped
CPUs, see this FAQ.

Monitoring your system with SAP tools
SAP system monitoring is available through the SAP Host Agent, which provides monitoring functions that are similar to on-premises installations.

Monitoring for IBM Cloud Intel Virtual Servers (Gen2), on VPC Infrastructure
The operating system metrics that the SAP Host Agent provides require the use of IBM Cloud Metrics Collector for SAP and the correct SAP Host Agent
patch level.

Monitoring for IBM Power Virtual Servers
For Infrastructure as a Service (IaaS) environments such as IBM Power Virtual Servers, the operating system metrics that the SAP Host Agent provides
were enhanced. Make sure that you have the prerequisite SAP Host Agent patch level installed. For a description of the new metrics and required SAP Host
Agent patch level, see SAP Note 2932766 - SAP on IBM Power Virtual Servers: Key Monitoring Metrics .

Support from IBM Cloud or SAP
For full information regarding support from IBM Cloud or SAP, please read Getting help and support from IBM Cloud or SAP .

Sizing the server
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 79

After you decide which SAP solutions you plan to use, your next step is to determine the number of IBM® Power® Virtual Servers that you need to support
your SAP landscape, and ensure that the servers are correctly sized.

Understanding the SAP sizing methodology
The SAP sizing methodology for SAP software is based on SAP benchmarks, such as information from SAP and actual customer experiences. The base SAP
workload unit is an SAP Application Performance Standard (SAPS). The SAPS is a definition of throughput that is coined by SAP capacity planning and
performance testing personnel. For example, 100 SAPS are defined as 2,000 fully business processed order-line items per hour in the standard SAP Sales
and Distribution (SAP SD) application benchmark. This is equivalent to 2,400 SAP transactions per hour with the SAP Enterprise Resource Planning (SAP
ERP) solution. The capability of processors is measured during the standard (SAP SD) benchmark test that is certified by SAP. For more information about
the benchmark methodology, see SAP Standard Application Benchmarks.

Using the SAP Quick Sizer
The SAP Quick Sizer is a web-based tool that is provided by SAP for all partners and customers. Sizing information is input directly into the tool, where it
sizes SAP NetWeaver-based applications and SAP HANA databases. Be sure to select the classic version of the tool for sizing SAP NetWeaver-based
applications, and the HANA version of the tool to size SAP HANA databases. SAP Quick Sizer requires an SAP S-user ID.
It calculates the workload (in SAPS) and adjusts it to allow for suitable processor use. So, if a workload of 4,800 SAP SD benchmark transactions per hour
was required, the tool calculates this as 200 SAPS. If a target processor load of 33% is allowed, adjust this to find a processor capable of 600 SAPS at
100% (=200 at 33%).
While the sizing method might be considered conservative, consider the fact that the SAPS numbers for your servers were calculated based on highly tuned
SAP systems running only specific SAP SD workloads. Depending on the type of SAP application, any custom configuration or custom coding in your
system, your results might vary. Also, requirements for your project, such as proof-of-concept (PoC) or regarding performance and response time, might
be different.

Choosing a Power Systems Virtual Server
After you determine your SAP applications and the SAPS numbers are calculated through the SAP Quick Sizer, or based on your current landscape, you are
ready to choose a server. Currently, e980 is the only supported server type. The list of supported server types will be extended in SAP Note 2855850.

Mapping CPUs derived from SAPS to instance profiles in a Power Systems Virtual Servers environment
The SAPS results from the sizing, and the choice of the server results in the number of CPUs and memory size that are required to support your workload.
The number of CPUs and memory are grouped into instance profiles that are certified for the SAP HANA workload. To find certified profiles, see Find
Certified IaaS Platforms.
Click here to find certified profiles for IBM Cloud®.
Click here to find certified profiles for IBM® Power Virtual Servers.
When you create a Power Virtual Server by using the IBM Cloud® console, you select an instance profile with a predefined number of CPUs and memory
size that suits your workload. While your data must fit into the instance memory, choosing an instance profile with more CPUs improves performance.
Instances are structured with a standardized naming convention as follows: AAA-BBxCCCC
Where:
AAA = One of the following profile types that are associated with the required Service Level Agreements (SLAs):
np1 = Non-product development for testing or development use only. Not intended for production deployments; not supported or certified by SAP

production.
umh = Ultra Memory HANA for OLTP using 240:1 memory:core ratios
mh1 = High Memory for OLAP using 180:1 memory:core ratios
bh1 = Balanced for OLAP using 100:1 memory:core ratios
ch1 = Compute Intensive for OLAP using 50:1 memory:core ratios
BB = The number of CPU cores
CCCC = The amount of available reserved RAM memory in GB

Migrating an existing SAP system
If you are planning to migrate an existing SAP system from any source to your Power Virtual Servers environment, you can determine the SAPS numbers
from the SAPS numbers of your current environment. Use the information on your current workload (the CPUs and RAM used) and get the SAPS
equivalents for your CPU from the SAP SD benchmark results .
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 80

For more information
For more information about sizing, see the following resources:
Sizing SAP HANA Portal
SAP Quick Sizer
SAP Note 1736976 - Sizing Report for BW-on-HANA
SAP Note 1872170 - Suite on HANA memory sizing
SAP Note 1793345 - Sizing for SAP Suite on HANA
SAP Note 1514966 - SAP HANA: Sizing SAP HANA
SAP Certified and Supported SAP HANA Hardware
SAP Note 2055470 - SAP HANA on POWER Planning and Installation Specifics - Central Note
SAP HANA TDI - Storage Requirements
SAP Certified Enterprise Storage Hardware for SAP HANA

Next Steps
Configuring high availability
Determining your configuration

Connectivity to your SAP system landscape
IBM Cloud has many connectivity options, including low latency worldwide connections between your private internal network and IBM Cloud's private
network backbone.
You can securely connect to your infrastructure in multiple ways by using various protocols and ports, based on the infrastructure chosen and the different
network types:
Classic Infrastructure network (formerly Softlayer network)
Intel Bare Metal
Classic Intel Virtual Servers
VMware solutions
VPC Infrastructure network
Intel Virtual Servers (Generation 1), formerly known as VPC on Classic no longer available, not SAP certified
Intel Virtual Servers (Generation 2)
IBM Power Virtual Server network, connection through IBM Cloud®
IBM Power Virtual Servers, connection through IBM Cloud®. This is a complementary offering from IBM Power Systems

Interconnectivity between IBM Cloud network
Transit Gateway, handling interconnectivity across the IBM Cloud private backbone between the networks with defined and controlled
communication between resources worldwide across the IBM Cloud network or across multiple IBM Cloud accounts (useful for Managed Service
Providers of SAP). Transit Gateways are used to support hybrid workloads, frequent data transfers, and private workloads by providing dynamic
scalability, high availability, and private, in-transit data between hosts on IBM Cloud.
Local routing, connect VPCs in same region
Global routing, connect VPCs across regions
Classic Infrastructure routing, connect to VLANs on Classic Infrastructure network
Cross-account connection (also known as account-to-account routing), connect VPCs across multiple IBM Cloud accounts. See Adding a
cross-account connection (VPC only)

Connectivity options within the IBM Cloud Classic Infrastructure network
Classic SSL VPN, basic SSL Tunnel with user/password to various PoP or Data centers, which is built in to IBM Cloud® Classic Infrastructure, enabled
per user account and is a good option for administrators during initial stages of deployments to IBM Cloud. It is not for bulk users due to bandwidth
caps.
Classic IPSecVPN, service from the IBM Cloud catalog, which can be provisioned and has advanced configuration options available for the IPsec

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 81

Tunnel
IBM Cloud® Direct Link for Classic Infrastructure , the most robust connection available in varying types from your internal network to IBM Cloud's
Availability Zones (also known as data centers) that use Network Service Providers, Point of Presence (PoP), or directly between the data center
colocation Room (also called a Meet Me Room). This option is available up to 10 Gbps network throughput as a Routed OSI Layer-2/3 connection,
and is designed for enterprise workload connections. Note: If you are using VPC Infrastructure, this option is not necessary as IBM
Cloud&reg; Direct Link 2.0 can also connect to Classic Infrastructure

More information on Direct Link 1.0. To find from a specified site location to IBM Cloud and which network service providers are available, use
Cloud Pathfinder for IBM Cloud (powered by Cloudscene)
IBM Cloud® Classic Infrastructure offers firewalls that can provide your Bare Metal Servers with a layer of security that is provisioned on demand and
designed to eliminate service interruptions.
Within the Classic Infrastructure network, there are many Gateway Appliance and Firewalls to help prevent unwanted traffic from hitting your server, help
reduce your attack vulnerability, and let your server resource be dedicated for its use. Based on your specific performance and feature requirements, you
can choose one of the following options:
Shared firewall (multiple options, see Getting Started Hardware Shared Firewall ),
Dedicated firewall (multiple options, see Getting Started Hardware Dedicated Firewall),
Fortinet FortiGate security appliance .

Connectivity options within the IBM Cloud VPC Infrastructure network
Floating IP, a public internet IPv4 address, which can be configured with Security Groups to allow only certain network connection access on defined
protocols and ports from specified source/target addresses. For initial tests option is often used, with more detail in the short guide on Connecting to
your Linux Virtual Server instance.
VPC IPSecVPN, service from the IBM Cloud catalog and deploys a VPN Gateway to a VPC and creating a VPN Connection with advanced
configuration options available for the IPsec Tunnel; including integration with authentication strategies such as Microsoft Active Directory.
IBM Cloud® Direct Link 2.0 , the latest enhancement and the most robust connection available, now with access to both Classic Infrastructure
network and VPC Infrastructure network simultaneously from your internal network to IBM Cloud's Availability Zones (Data centers) that use
Network Service Providers, Point of Presence (PoP), or directly between the data center colocation Room (also called a Meet Me Room). This is
available up to 10 Gbps network throughput as a Routed OSI Layer-2/3 connection, and is designed for enterprise workload connections.
More information on "Use a VPC/VPN gateway for secure and private on-premises access to cloud resources" .

IBM Cloud Direct Link 2.0
Network back-bone infrastructure of a customer site can be directly connected to IBM Cloud, by using IBM Cloud Direct Link. On-premises
resources can be connected to multiple VPCs, and VPC can provide Bring-your-own-IP or other custom IP ranges.
Note: Technical requirements and restrictions exist in the availability of IBM Cloud Direct Link in different regions. A detailed
description of IBM Cloud Direct Link can be found in Getting started with IBM Cloud® Direct Link .

Accessing the classic infrastructure
Note: Optional setup.
IBM Cloud VPC infrastructure can access other resources on IBM Cloud Classic Infrastructure, such as high-performance IBM Cloud® Bare
Metal Servers designed for SAP HANA.
You have multiple options to achieve this access, notably a one-to-one association, or IBM Cloud® Transit Gateway with increased flexibility.
This is described in the above section Interconnectivity between IBM Cloud network .
Important: All options require upgrading the IBM Cloud account to be VRF-enabled.
For more information on VPC access to Classic Infrastructure, see Setting up access to classic infrastructure . For more information on Transit
Gateway, see Getting started with IBM Cloud Transit Gateway .

Connectivity options within the IBM Power Virtual Server network, connection through IBM Cloud
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 82

To arrange connection through to IBM Cloud or an on-premises network, a private subnet (and the allocated Private VLAN) must exist for the
IBM Power Virtual Server; which is then connected to the subnet in the target network using IBM Cloud Direct Link.
On the target side (IBM Cloud networks or the on-premises network), it is required to perform the necessary configuration of the network
security and permit connections to be established to/from IBM Power Virtual Servers. For example:
With a connection to IBM Cloud Classic Infrastructure, the Gateway Appliance firewall for the Classic Private VLAN (and Primary Subnet,
or any other Subnets) must permit the ports where traffic will flow to/from IBM Power Virtual Servers
With a connection to an on-premises network, the outbound Firewall and DMZ should be configured to permit the ports where traffic will
flow to/from IBM Power Virtual Servers
Depending on the subnet range used for the IBM Power Virtual Server private subnet and the default OS routing configuration, manual routes
on both sides may be required (e.g. a route added to the NAT Gateway of the target in the on-premises network).

Download and install SAP software and applications
SAP software installation media must be obtained from SAP directly, and requires valid license agreements with SAP in order to access these
files.
All downloads of SAP software installation media are handled through the SAP Support Portal and the SAP ONE Support Launchpad . This was
formerly called the SAP Marketplace (SMP) and may still be referred as this in some SAP documentation.
Downloads can be performed directly to a target server (when outbound internet connectivity is permitted), or could be downloaded to an
administrator laptop and uploaded to an IBM Cloud storage option (such as IBM Cloud® Object Storage).
To perform a specific SAP installation, there are many different SAP software components and different installation media compressed archive
files. The software might potentially use:
SAP's own compression format called "SAP Archive (SAR)" which can only be decompressed with the SAPCAR program
SAP's own compression format for Java called "Software Component Archive (SCA)"
Provided in ZIP or RAR (self-extracting EXE) compression formats
The many various SAP software components to download can be downloaded individually by using a web browser, or these download items
can be added to the SAP Download Basket to make it easier for downloading all files by using the SAP Download Manager (a Java GUI
application).
After the SAP software installation media downloads, follow the standard SAP installation procedure that is documented in the applicable

SAP

installation guide for your SAP version and components and the corresponding SAP Notes. The installation guide and SAP Notes require an
SAP S-user ID to view.
It is important to remember that any SAP software installation will require some OS configuration; some of this information is available under
the Compute and OS Design Considerations section. This OS configuration can be done before or after the SAP software installation media
downloads have completed.
For IBM Power, you may want to install AIX Toolbox for Linux Applications for easier handling of SAP software.
For more help with SAP Download Manager, see:
SAP Note 2272824 - How to Download SAP Solution Manager - SAP ONE Support Launchpad
SAP Note 1371839 - How to install SAP Download Manager - SAP ONE Support Launchpad
SAP Note 2624390 - What is the current version of SAP Download Manager?

Bring your own SAP product license
The IBM Cloud® SAP-Certified infrastructure is "bring your own license" (BYOL) capable for your SAP products. You need to apply the
corresponding license for your SAP products after installation. If you are new to SAP, start exploring under SAP All Products. You can also
contact SAP Sales or SAP Support for details on how to obtain the required licenses.

Database licenses for SAP general information
It is recommended to check the license type of your Database Server for your SAP installation scenario onto IBM Cloud to avoid unsupported
scenarios. Typically the license types are:
Full-use database license. Supports both SAP and non-SAP software, unrestricted usage of all functions
Runtime database license. Solely to support software licensed from SAP, restricted usage of functions required by the SAP Business

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 83

Application. This usage can include databases from other vendors if those databases were purchases as OEM products through SAP.

SAP AnyDB - Bring your own IBM Db2 license
If you purchased your SAP and IBM Db2 (for Linux, UNIX, Windows also known as LUW) licenses as part of an original equipment manufacturer
(OEM) application-specific licensing (ASL) agreement, you can download and apply license files from the SAP Support Portal); click Download
Software. For more information, see SAP Note 816773 - DB6: Installing the Application-Specific Db2 License from SAP .
However, if you purchased IBM Db2 from IBM or an IBM Business Partner, you must use the license files that are provided by your vendor
instead.

SAP HANA licenses
SAP HANA licenses are handled by the SAP HANA Cockpit.

SAP NetWeaver and SAP Business Application licenses
Both the SAP NetWeaver application server license and the SAP Business Application license are handled by SAPGUI (or variation thereof).

Creating an SAP license key
The SAP license key, saplikey or SLICENSE , displays a "hardware key" based on the hardware ID.
Use the following steps to create your SAP license key.
1. Run the saplikey -get command on the server that you're using as the SAP message server. As an alternative to the

saplikey

command and if your SAP system is already installed, you can use the SLICENSE transaction to retrieve the HARDWARE KEY .
2. Use the HARDWARE KEY output value to generate a valid SAP software license from SAP Support. Select Request Keys and enter you
SAP S-user ID.
3. Use the SAP system data to create a valid license key.
4. Use the SAP transaction SLICENSE or the saplikey command to install the license on your SAP system.

SAP license key with IBM Power Virtual Servers
This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services
SAP changed the mechanism for licensing when an IBM Power Virtual Server is running on the IBM Cloud®. In the IBM Cloud, the product
license is not dependent on the underlying hardware that's running the server. The license is associated with the virtual server.
The hardware key is no longer based on the hardware ID, but on the partition UUID of the logical partition (LPAR). The partition UUID is
persisted by the platform across restarts, reconfigurations, OS reinstalls, and partition migrations, making it independent of the hardware that
is running the virtual servers.
When you request an SAP software license, be sure to use the

HARDWARE KEY that was generated with an SAP kernel that has the minimum

level that is required for running on IBM Cloud. The minimum SAP Kernel patch level of the kernel is found in SAP Note 2879336. Otherwise,
your SAP software license becomes invalid as soon as your virtual server is moved to different hardware in the IBM Cloud®.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 84

Infrastructure for SAP design considerations
Networking design considerations
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
In some regards, SAP workloads that use a Cloud Service Provider (such as IBM Cloud® for SAP) Infrastructure-as-a-Service is similar to
existing practices (over many decades) for running SAP workloads that use an external data center or a data center provider. An SAP landscape
has specific requirements for connectivity, between hosts within Cloud IaaS and to external systems, IBM Cloud® for SAP provides a rich set of
functions beyond hosting of SAP systems to improve your SAP landscape.
To assist your project's planning phase, the below sections provide IBM Cloud® for SAP portfolio design considerations for Networking.

Preface: units of measure for data/information
Often the throughput Network Storage is shown in Mbps or Gbps.
It is important to note, that Mb (Megabits) is a decimal prefix and MiB (Mebibyte) is a binary prefix so they are on different scales. More
confusion arises because MiB (Mebibyte) was commonly known in Microsoft Windows as Megabyte .
For future reference throughout the networking documentation, Mb (Megabits) and MiB (Mebibyte) is used based on the system of units (SI)
defined by IEC and adopted by IEEE, ISO, and NIST.
For example,:
100 Mbps (Megabits per second), would be 12 MiB/s (Mebibyte per second)
1000 Mbps (Megabits per second) also known as 1 Gbps (Gigabits per second), would be 120 MiB/s (Mebibyte per second)
10 Gbps (Gigabits per second), would be 1200 MiB/s (Mebibyte per second)

Networking connectivity considerations
For an overview of the connectivity options available, see Determining access to your SAP system landscape .
SAP Systems are often the focal point of business operations, with a great number of integrated applications (including legacy applications).
In most circumstances for SAP workloads, a connection to the existing internal network is required, and it is recommended to use IBM Cloud®
Direct Link 2.0 to operate the secure, low-latency, high-throughput (available up to 10 Gbps) as a Routed OSI Layer-2/3 connection.
These connectivity options are dependent on business requirements, for example, whether the business wants to use Cloud and also decrease
security risk by isolating network flows through their existing networking structure and security. In these "disconnected" or "private-only"
connectivity designs, it is best to request IBM Cloud® for additional information and discuss your use cases.
In addition, it is strongly not recommended by SAP to split the SAP System tiering across On-Premises location/s and Cloud locations and it is
up to the business to evaluate this; for example, it is not recommended by SAP to retain SAP AnyDB run from infrastructure in an On-Premises
location and connect to SAP NetWeaver run from infrastructure in a Cloud location. For IBM Power Virtual Servers this split of SAP System
tiering is not supported.

Bring-your-own network (Subnet/CIDR/IP address range)
It is often a business preference to Bring-your-own Subnet/CIDR/IP address range (BYOIP) to your IBM Cloud account; this is available
depending on the Infrastructure selection and environment.

VPC Infrastructure
When using VPC Infrastructure, it is possible to define and use your own subnet. See VPC - Bring your own subnet .
This changes depending on whether RFC 1918 IANA reserved IPv4 private network address spaces are in use, because any IP Address within
these ranges is considered non-routable. These addresses are not unique on the Internet as they could be used by any private network without
any coordination with IANA or an Internet registry, so these addresses are only unique within a private network. These IPv4 private network
address spaces are:
Class A - 10.0.0.0/8
Class B - 172.16.0.0/12
Class C - 192.168.0.0/16

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 85

If you use a bring-your-own subnet range which is defined under RFC 1918 IANA reserved IPv4 private network address spaces, then
connectivity to an existing internal network is possible when using any VPC functions (for example, Public Gateway or Floating IPs).
It is not supported to use a bring-your-own subnet range not defined under RFC 1918 IANA reserved IPv4 private network address spaces
because this would not permit connectivity to an existing internal network when used with a Public Gateway (PGW) and Floating IPs.

Classic Infrastructure with VMware
If the existing business operates SAP on VMware, it is possible to use IBM Cloud for VMware along with VMware HCX and IBM Cloud® Direct
Link to create a bridged bidirectional network between existing Datacenter with VMware and IBM Cloud for VMware. This uses the existing
VMware service mesh routing into VMware HCX and into overlay from VMWare NSX on IBM Cloud for VMware, which creates:
An encrypted Migration Tunnel that uses HCX Cloud Gateway (CGW) + HCX WAN Optimizer (WAN-OPT)
An encrypted Application Tunnel that uses HCX High Throughput Layer 2 Concentrator (HT L2C)
More information and is described on IBM Cloud for VMware Solutions - VMware HCX overview .

Network Topology considerations
Dependent on the count and configuration of SAP Systems that are combined with the arrangement of the network flows between these
systems for security or performance reasons, the Network Topology will be significantly different. The design of this topology reflects the
requirements from the business for security, performance, cost, flexibility, and connectivity.
Using the Enterprise Resource Planning (ERP) business application, for example, an SAP System hosting the Production instance that uses the
SAP System Tiering approach using High Availability of SAP NetWeaver and SAP HANA:
SAP NetWeaver, there are at least four hosts instead of 1:
Central Services (ASCS)
Primary Application Server (PAS), also known as Central Instance (CI)
Enqueue Replication Server Instance (ERS)
Additional Application Server (AAS)
SAP HANA, there are at least 2 hosts (possibly 3) instead of 1:
SAP HANA primary node (using SAP HANA System Replication)
SAP HANA secondary failover node (using SAP HANA System Replication)
SAP HANA tertiary disaster recovery failover node (using SAP HANA System Replication)
This describes 1 SAP System within the SAP Landscape. An SAP Landscape might use:
One Track, 5 SAP Systems (Sandbox > Development > Testing > Staging > Production)
Dual Track, 5 SAP Systems (Sandbox > New Feature Development + Maintenance Development > New feature testing +
Maintenance testing > Staging > Production)
Therefore for an SAP Landscape potentially 30 to 50 instances of SAP, spread across 10-50 host servers (physical or virtualized) might be
required. This is before more business applications are added for specific business operations, industry, or geographic functions.
The size of the SAP Landscapes have a direct impact on the Network Topology.
Typically, although this varies from case to case, the following networks are required to meet the scenarios and performance that is required
by the business that uses SAP Business Applications:
Internal network for communication between multiple instances in an SAP Landscape with different SAP System Tiering approaches
Network for the management and storage transfers of database systems
Network that is used in production
However, in the simplest scenario there might be one private network for all purposes. It depends on business requirements.

Additional management systems to enable SAP systems
Depending on your operating system, SAP workload, and network connectivity, you might need to configure access to many more SAP and
non-SAP systems. The following is a list of various management systems that your SAP workloads might require to operate:
OS packages update server, with the different subscription channels of the OS packages for SAP HANA and SAP NetWeaver.
For IBM Power Virtual Servers, you can use publicly available AIX SUMA or SUSE update repositories, or use your own AIX NIM or
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 86

SUSE RMT servers. To avoid a common issue that occurs when you use the AIX NIM service handler, see Using the NIM service
handler.
Software and patches download server. When the software is downloaded onto the server, you can use various protocols to transfer the
files such as SCP or SFTP to transfer the software to the target server for installation.
Time server (NTP), using NTP on IBM Cloud private backbone, public internet NTP or private NTP host.
For IBM Power Virtual Servers, see Configuring the NTP client (Linux) or Configuring the NTP client (AIX).
Gateway (and Proxy) and Firewall hosts
Bastion/Jump host. Enables secured pass-through to your Cloud resources from public internet or other network access; often this uses
tightly secured SSH on a non-default port.
Jump host that is enabled with VNC or RDP. Enables GUI access to a target machine (if GUI and VNC or RDP is installed on the target).
VPN hosts. Enables secured connection to your existing internal network.
Network Routing hosts, via TelCo or Network Service Provider. Enables secured private high-throughput connection to your existing
internal network.
Backup management service hosts
Network file storage, via Network File System (for example, NFSv3 or NFSv4.1). Runs file system commands encapsulated by TCP/IP
packets.
Network block storage, using iSCSI protocol controlled by MPIO. Runs SCSI commands encapsulated by TCP/IP packets.
Network block storage, using Fibre Channel (FC) protocol. Runs SCSI commands encapsulated by FC frames.
Note: Fibre Channel is only required for IBM Power Virtual Servers, and is handled for you during provisioning.

Hybrid Cloud setup for SAP
The following are specific configuration items that you need consideration when planning your SAP landscape, by using your existing onpremises SAP support systems in combination with IBM Cloud® for SAP portfolio to create a Hybrid Cloud setup:
SAP Transport Management System (STMS also known as. TMS) . Configure STMS based on Transport Groups to prevent file sharing
across data centers.
SAProuter. Provides access to SAP Online Service System (OSS). Use your on-premises SAProuter to access the OSS. This SAProuter can
be used through further SAProuter hops if IP-based routing is not allowed between your IBM Cloud-based systems and your onpremises SAProuter. Alternatively, you might consider setting up another SAProuter that is based on one IBM Cloud-based server with a
public IP and connect it to the SAP OSS system through the internet.
SAP Solution Manager . Access to the SAP Solution Manager has different connectivity requirements between an SAP Solution Manager
and its managed systems. The differences depend on your usage scenario. These scenarios require an understanding of the required
network connectivity.
If you are deploying public gateways or floating IPs, you need to look into the details of Network Address Translation (NAT) and the
behavior of SAP applications. Refer to the SAP document on NAT to consider potential issues on the application layer, especially in the
SAP Remote Function Calls (RFCs).

Networking consumption considerations
Traditional SAP workload network communication is relatively small with under 100 MiB network traffic per day possible, such as:
User transactions from SAPGUI; for Windows, for Java (used with macOS or Linux)
User transactions from SAP WebGUI
User transactions with SAP web Dynpro apps from SAP NetWeaver Business Client (NWBC)
SAP Remote Function Call (SAP RFC) between SAP and non-SAP systems
SAP iDOC Inbound/Outbound between SAP and non-SAP systems with third-parties (for example, banks, suppliers)
However, there are much larger SAP workload network communications too consuming significantly more network traffic, such as:
SAPUI5 preinstall libraries and themes for SAP Fiori Launchpad and Apps
10 MiB - 25 MiB (estimate) per new session that is loaded from SAP web Assistant (also known as. XRay), these preinstall libraries

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 87

are then cached by the browser. Once cached the libraries are available for use in any new browser tab, even after browser restart or
SAP Fiori logout; until browser cache cleared
20 KiB - 500 KiB (estimate) per each new Fiori app that is loaded within the session
SAP HANA System Replication (HSR) Sync or Async, streaming Gigabyte's of data per month from primary to secondary (or tertiary)
nodes
With increased traffic of new design SAP software, it is possible to heavily exceed the amount of network traffic seen in past SAP usage.
Designing your SAP applications to use the IBM Cloud private backbone for these data transfers is important, as there are no ingress/egress
charges; whereas usage over public internet incurs egress charges.
You should estimate the amount of data that is transferred. During initial project implementation stages, this can be difficult. However at least
by an order of magnitude estimate should be performed.

Networking Throughput performance considerations
SAP generally recommends 10 Gbps (redundant) network throughput for traffic between its application servers and SAP HANA databases, and
for other SAP HANA clients, such as SAP Business Intelligence.
For deployments of SAP NetWeaver using SAP AnyDB with local storage, even for three-tier setups, 1 Gbps networks are usually sufficient.

Networking Latency performance considerations
For your business operations and non-SAP dependent systems, you may required certain latency key performance indicators (KPIs) to be met.
This should consider the site location of your hosts, and testing the latency by using the IBM Cloud private backbone network.
The testing of latency by using the Round Trip Time (RTT) metric is necessary when designing High Availability (HA) and Disaster Recovery (DR)
for SAP HANA.
If a HA failover is being designed within one site location, in almost all cases this will be achievable for SAP HANA System Replication
requirements.
However, if designing High Availability for SAP HANA across multiple sites within a Region, or if designing Disaster Recovery across multiple
Regions then the latency that uses the Round Trip Time (RTT) metric must be carefully tested and considered.
This is because IBM Cloud seeks to ensure high availability of the platform, by using geographically dispersed site locations with fault tolerance
(for example, different risk assessments). More information available on How IBM Cloud ensures high availability and disaster recovery .
In particular, for VPC Infrastructure the Availability Zones are geographically dispersed locations within the Region. For most workloads, this
design provides more redundancy across the Region. However, SAP HANA System Replication requires low network latency, which can become
difficult to meet the necessary Round Trip Time (RTT) metric due to current technology physical data transfer limitations of cabling from a
physics perspective (that is, speed of light over fiber Optic cable).

Networking Ports security considerations
The following information is a brief summary of SAP Help Portal - TCP/IP Ports of All SAP Products , which provides an example of the
considerations that are required for the security of your SAP Systems and entire IT infrastructure landscape on IBM Cloud.
Depending on the SAP Technical Applications used and the business scenarios being addressed, different hosts will need ports to be opened.
Typically, to meet this requirement, the Firewall Port Groups are combined with Firewall Rules. You can also use individual Firewall Rules per
host, although is often becomes unmanageable.
The below table includes some of the key Ports to use with SAP Systems that use SAP NetWeaver and SAP HANA, which need correction,
depending on the SAP Technical Application’s instance number; the instance numbers 00, 01, 02 are the defaults across the various SAP
Technical Applications and will be in different patterns (these patterns are shown with code blocks highlighting):
SAP

Component

Port

SAP Router

3200

Technical
Application
SAP Router

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 88

SAP Router

3299

SAP NetWeaver AS Primary App Server (PAS Dialog) Instance 01

3201

SAP NetWeaver AS PAS Gateway Instance 01

3301

SAP NetWeaver AS Central Services Messenger Server (ASCS MS) Instance 01

3602

SAP NetWeaver AS PAS Gateway (with SNC Enabled) Instance 01

4801

SAP NetWeaver AS ICM HTTP (Port 80 prefix)

8001

SAP NetWeaver AS ICM HTTPS (Secure, Port 443 prefix)

44301

SAP NetWeaver sapctrl HTTP (Dual Host install)

50113

SAP NetWeaver sapctrl HTTPS (Dual Host install)

50114

SAP HANA sapctrl HTTP (One Host install)

50013

SAP HANA sapctrl HTTPS (One Host install)

50014

SAP HANA Internal Web Dispatcher

30006

SAP HANA MDC System Tenant SYSDB Index Server

30013

SAP HANA MDC Tenant 1 Index Server

30015

SAP HANA ICM HTTP Internal Web Dispatcher

8000

SAP HANA ICM HTTPS (Secure) Internal Web Dispatcher

4300

SAP Web Dispatcher ICM HTTP (Port 80 prefix) Instance Number 90

8090

SAP Web Dispatcher ICM HTTPS (Secure, Port 443 prefix) Instance Number 90

44390

SAP HANA XSA Instance 00 Client HTTPS for the connection to the xscontroller-managed Web Dispatcher
(platform router) for purposes of user authentication.

30032

SAP HANA XSA Instance 00 Internal HTTPS for the connection from the xscontroller-managed Web
Dispatcher (platform router) to xsuaaserver for purposes of user authentication.

30031

SAP HANA XSA Instance 00 Client HTTPS for the connection to the xscontroller-managed Web Dispatcher
for purposes of data access.

30030

SAP
NetWeaver

SAP HANA

SAP Web
Dispatcher

SAP HANA
XSA

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 89

SAP HANA XSA Instance 00 Dynamic Range Internal HTTPS for the connection from the client to the
xscontroller-managed Web Dispatcher (Platform Router) for access to the application instance.

5100051500

SAP HANA XSA Instance 00 Internal HTTPS xsexecagent to xscontroller

30029

SAP HANA XSA Instance 00 Web Dispatcher HTTP(S) routing

30033

SAP NetWeaver AS Java P4 Port

50304

SAP NetWeaver AS Java P4 Port

50404

SAP
NetWeaver
Java

Table 1. Common Ports used with SAP Technical Applications

Networking Traffic Segregation security considerations
You can separate different network traffic types in your landscape, either because of security restrictions or because of throughput
considerations.
Segregation of networks is useful for the following SAP workload use cases:
Multiple servers that exchange data
SAP Systems in a three-tier logical architecture, where the SAP database and SAP application instances are on different hosts.
Multiple SAP Systems that exchange large amounts of data
Database servers, which need to have low network latency and high network throughput to network block/file storage therefore
need to avoid firewalls. However the database still needs protection for other systems and networks access.
To use segregation of networks effectively, interconnectivity must be allowed under specific conditions.

VPC Infrastructure separation of subnets
To separate traffic, use multiple subnets.
Each VPC for a region can contain multiple subnets. These subnets within the VPC are enabled to communicate with each other, unless
blocked by a Network ACL or Security Group. Therefore, two virtual servers in VPC infrastructure can have a virtual network interfaces (vNIC) on
different subnets from each other.
The Network ACL or Security Group would allow specific network interconnectivity flows across these separate subnets.
Note: However, a virtual server in VPC infrastructure cannot have multiple virtual network interfaces (vNICs) assigned to multiple
subnets.

Classic infrastructure separation of subnets
To separate traffic, use multiple VLAN and subnets therein.
Each VLAN is either public or private and is specific to the data center and the data center Pod. The VLAN can contain multiple subnets. These
subnets within the VLAN are enabled to communicate with each other, unless blocked by a Gateway Appliance.
Therefore, two bare metal hosts in classic infrastructure might have physical network interface cards that are assigned to different VLAN and
subnets from each other.
The Gateway Appliance would allow specific network interconnectivity flows across these separate subnets.
A bare metal server by default (can change depending on the hardware specifications) use physical network interface cards (NICs) and
consume four ethernet ports:
eth0 NIC / eth2 redundant NIC

Public VLAN, as DMZ trunked to Gateway Appliance
Public primary subnet
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 90

Public IP behind DMZ
eth1 NIC / eth3 redundant NIC

Private VLAN, as DMZ trunked to Gateway Appliance
Private primary subnet
Private IP behind DMZ
mgmt0 --- IPMI (Admin Network Zone)

Bare metals can be reconfigured from default specific if the hardware specifications allow for it, with more subnets. This allows for maximum
separation of traffic and can increase performance by using different network interface cards (NICs) to handle more network throughput in
parallel. An example of this reconfiguration might be:
eth0 NIC / eth2 redundant NIC

Public VLAN, as DMZ trunked to Gateway Appliance
Public primary subnet
Public IP behind DMZ
eth1 NIC / altered to eth4 redundant NIC

Private VLAN, as DMZ trunked to Gateway Appliance
Private primary subnet
Private IP behind DMZ
eth3 additional NIC / eth5 additional redundant NIC

Private VLAN
Private secondary portable subnet A
Private IP behind DMZ
Private secondary portable subnet B
Private IP behind DMZ
mgmt0 --- IPMI (Admin Network Zone)

Note: Such reconfiguration, as the example, will not be available in all scenarios.
For SAP HANA and the high network performance and security that is required, additional VLANs can assist. Read the recommendations by SAP
for on-premises environments on SAP HANA Network Requirements and identify the suitable network configuration for meeting your business
needs.

VMware on classic infrastructure separation of subnets
To separate traffic with IBM Cloud for VMware Solutions Dedicated, use multiple subnets within the VMware Overlay VXLAN (powered by
VMware NSX).
In IBM Cloud for VMware Solutions Dedicated, the VMware Overlay VXLAN (powered by VMware NSX) is connected back to public VLAN and
private VLAN on the classic infrastructure network as the underlay; the VMware NSX management utilizes the private secondary portable
subnets to achieve the VXLAN. This provides full control of the network design when running on VMware, and allows assigning VMware VM's an
IP from any defined range.
If instead using a manual deployment of VMware to a bare metal, the VMware vSwitch would directly use the private VLAN's secondary
portable subnet to assign VMware VM's an IP address from the classic infrastructure network.
Traffic segregation needs to be considered carefully within VMware deployments, because elaborate VMware-based deployments, where
different kinds of network traffic might need to be more strictly separated for security reasons.

Storage design considerations
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
For SAP workloads that use a Cloud Service Provider, Infrastructure-as-a-Service is similar to existing practices used to run SAP workloads in
external data centers or by a data center provider. An SAP landscape has specific requirements for connectivity, between hosts within Cloud
IaaS and to external systems. IBM Cloud® for SAP provides a rich set of functions to improve your SAP landscape, beyond hosting SAP systems.
To assist your project's planning phase, the below sections provide IBM Cloud® for SAP portfolio design considerations for Storage.

Preface: units of measure for data/information
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 91

Storage performance refers to the read/write performance from storage file system. Often the throughput Network Storage is shown in Mbps or
Gbps, whereas for Local Disk storage is shown in MiB/s.
It is important to note, that Mb (Megabits) is a decimal prefix and MiB (Mebibyte) is a binary prefix so they are on different scales. More
confusion arises because MiB (Mebibyte) was commonly known in Microsoft Windows as Megabyte .
For future reference throughout the storage documentation, Mb (Megabits) and MiB (Mebibyte) is used based on the system of units (SI)
defined by IEC and adopted by IEEE, ISO, and NIST.
For example:
100 Mbps (Megabits per second), would be 12 MiB/s (Mebibyte per second)
1000 Mbps (Megabits per second) also known as 1 Gbps (Gigabits per second), would be 120 MiB/s (Mebibyte per second)
10 Gbps (Gigabits per second), would be 1200 MiB/s (Mebibyte per second)

Storage configuration for SAP HANA
With any SAP HANA certified profile that is listed as Appliance, storage is already provided or must be attached precisely as described.
When you provision more storage for an SAP HANA instance, you must adhere to mandatory TDI storage requirements. For more information,
see SAP TDI (SAP HANA Tailored Data Center Integration) & IBM Power .
The requirements include multiple volumes that are assigned to the DATA and LOG LVMs, with the striping and multipath enhancements
increase I/O performance. For more information, see the following documents:
SAP TDI Advisory
SAP HANA Tailored Data Center Integration FAQ (Updated May 2020)
For file system sizes, see SAP HANA Storage Requirements

Storage performance considerations
It is important to calculate your project requirements before you decide on a storage solution. This calculation is critical for selecting network
storage because of storage variations and performance considerations.

Storage impacts on Recovery Time Objective (RTO) of SAP HANA backups
If you need to restore an SAP HANA system, then the IOPS of your storage has a significant influence on your restore window. Backup windows
are not as critical with SAP HANA since all backups are online backups no matter how you configure SAP HANA.
For example, by using IBM Cloud Block Storage for Classic, you can calculate for an approximate 12 TB restore of SAP HANA at a maximum
speed. You must create three physical storage devices (block storage iSCSI LUNs) because the maximum size per device is 4 TB. You can
create a stripe over these three devices with the Linux® Logical Volume Manager and create one logical device of 12 TB.
The 12 TB provides 3x10 IOPS/GB, which is a total of 122,880 IOPS/GB at 16 KB. This amount gives you a restore time of 1.875 GB per
second, or a total restore time of under 2 hours. Since the measurement for the IOPS is taken at a 50/50 distribution of read and write, you can
consider the numbers as a lower boundary of restore performance. It is advisable to do backup and restore tests if you rely on a certain restore
window.

Network Block Storage considerations
The following sections describe the storage considerations that use network block storage for SAP workload scenarios that use various IBM
Cloud infrastructure options.

Network Block or File storage for VMware on Classic Infrastructure
Using VMware for SAP workloads on IBM Cloud is certified. However it requires choice of the storage and would use the "TDI" delivery model
for which you would need to run validation checks to gain SAP Support. Therefore, it is important to consider the correct storage for your
VMware hosts when they are running SAP workloads.
For VMware clusters, where SAP workloads are run across multiple VMware vSphere hypervisor nodes, storage must be shared across these
hypervisor nodes.
VMware is available to work with Block storage or File storage from IBM Cloud. To help you select Block storage or File storage for running SAP
on VMware, see VMware Technical Paper on Storage Protocol Comparison .
When you are using Network Block or File storage, do not expect that certification performance benchmarks to remain the same. Particularly
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 92

after factoring in the hypervisor overheads as described in Compute Profiles of SAP-certified VMware on Classic Infrastructure .
For VMware datastores (where the virtual machine .VMDK virtual disks are located), the recommendations are:
For SAP HANA, use Local SDD disks for the datastore in a RAID10 configuration
For SAP HANA, with network storage, use 10 IOPS/GB with each vSphere node that hosts SAP that uses a network interface card with 10
Gbps connection
For SAP NetWeaver or SAP AnyDB, with network storage, use at least 4 IOPS/GB with each vSphere node that hosts SAP that uses a
network interface card with 10 Gbps connection
To achieve maximum IOPS on a volume, adequate network resources need to be in place. Other considerations include private network usage
outside of storage and host side, and application-specific tunings (for example, IP stacks and queue depths). For more information, see
Getting started with Block Storage and Getting started with File Storage for more information on storage tiers and performance.
The storage to use with either the VMware manual setup (Bare Metal with VMware OS Image) or VMware automated setup (IBM Cloud for
VMware Solutions Dedicated), is described in:
Storage to use with VMware vSphere on IBM Cloud Bare Metals provides further direction on how to integrate storage in an ESX
environment.
Storage to use with IBM Cloud for VMware Solutions Dedicated

Block Storage for Virtual Servers on VPC Infrastructure
For network storage, IOPS per GB is limited and performance depends on the workload. For relational database management systems
(RDBMS), it might be advisable to use the same volume for both the database's log and data storage. This setup depends on the behavior of
your application.
In general, for typical RDBMS-based applications, a 5 IOPS/GB profile is reasonable.
If your application uses dedicated key performance indicators (KPIs) on storage performance, test the storage throughput before you begin
software deployment. By using volume manager-based software RAID (like LVM), you meet almost every KPI.

Network Block Storage for IBM Power Virtual Servers
For SAP HANA, Tier 1 (NVMe) high performance is required.
For SAP NetWeaver and SAP AnyDB databases (such as IBM Db2 or Oracle DB), Tier 1 (NVMe) is recommended but Tier 3 (SSD) can be used.
Given IBM Power Virtual Servers are configured to enterprise-grade standards using Fibre Channel, there are no additional performance
considerations.

Sample storage configurations on Classic Infrastructure
The following sections demonstrate storage configurations in various different SAP workload scenarios, which are using Classic
Infrastructure.

Sample storage configuration for IBM Db2 that use Intel Bare Metal
Table 1 is a sample storage configuration for a 256 GB server with 50,000 SAPS, 1.5 TB at 6,000 IOPS for a central system with SAP. The
system uses an IBM Db2 database with external IBM Cloud Block Storage for Classic or IBM Cloud File Storage for Classic (4 IOPS/GB). The
calculation for the IOPS is:
6,000 IOPS/1,500 GB = 4 IOPS/GB needed for external storage. It is assumed that 3,000 GB is for backup at 2 IOPS/GB (medium
performance.
File system

number of volumes

Storage type

IOPS/GB

GB

IOPS

/

1

Internal

N/A

150 GB

N/A

/boot

1

Internal

N/A

0.25 GB

N/A

swap

1

Internal

N/A

256 GB

N/A

/db2 (including logs)

1

Internal

N/A

250 GB

N/A

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 93

sapdata

1

External

4 IOPS/GB

1,500 GB

6,000

backup/log and backup

1

External

2 IOPS/GB

3,000 GB

6,000

Table 1. Sample storage layout based on IOPS calculation

Sample storage configurations on VPC Infrastructure
The following sections demonstrate storage configurations in various different SAP workload scenarios, when you are using VPC
Infrastructure.

Sample storage configuration for SAP AnyDB with IBM Db2 that uses Intel Virtual Server
For SAP AnyDB that uses IBM Db2 on mx2-32x256 profile the volumes that are needed are:
1x 500 GB volumes; one block storage volume of 500 GB size, with a custom volume profile that supports up to 10,000 Max IOPS
attached to the Virtual Server
1x 2,000 GB volume; one block storage volume of 2,000 GB size, with a lower 4,000 IOPS (medium performance) attached to the Virtual
Server for backups

Disk mount points and volumes for IBM Db2
After you attach the two data volumes, two new virtual disks will appear in the Virtual Server, see the following table. In this example, those
disks are vdd , vde , and vdf .
File system

Volume

Storage type

IOPS/GB

GB

IOPS

/

vdal

Pre-configured boot volume

N/A

100 GB

3,000

/boot

vda2

Pre-configured boot volume

N/A

0.25 GB

3,000

/db2

vdd (can vary)

Data volume

20 IOPS/GB

500 GB

10,000

backup/log and backup

vde (can vary)

Data volume

5 IOPS/GB

2,000 GB

4,000

Table 2. Sample storage configuration

Table 1 shows a basic layout of the file system to support an IBM Db2 installation. Generally, an IBM Db2 installation uses subdirectories that
can be segmented into independent volumes.
For example, "/db2/<DBSID>" , "/db2/<DBSID>/log_dir" , and several "sapdata<n>" , where the folder "log_dir" contains the online
logs files of the database and the "sapdata<n>" contains the data itself. For example, see the Db2 documentation here: Required File
Systems for IBM Db2 for Linux, UNIX, and Windows.

Sample storage configurations for SAP HANA
Further information about storage specifications for Virtual Server are available, the below shows only the configuration steps required.

mx2-8x64, mx2-16x128 and mx2-32x256 profiles
Note: The mx2-8x64 profile is certified for SAP Business One on HANA only.
For Virtual Server created based on the mx2-8x64, mx2-16x128 and mx2-32x256 profiles, there are:
3x 500 GB volumes; three block storage volumes of 500 GB size, with a custom volume profile that supports up to 10,000 Max IOPS
attached to the Virtual Server
1x 2,000 GB volume; one block storage volume of 2,000 GB size, with a lower 4,000 IOPS (medium performance) attached to the Virtual
Server for backups
After attaching the three data volumes, three new virtual disks will appear in the virtual server, see the table that follows. In this example,
those disks are vdd , vde and vdf .
The disks are visible in the operating system of the virtual server as follows:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 94

$ [root@hana256-vsi ~]# fdisk -l
Disk /dev/vdd: 536.9 GB, 536870912000 bytes, 1048576000 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes

Disk /dev/vde: 536.9 GB, 536870912000 bytes, 1048576000 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes

Disk /dev/vdf: 536.9 GB, 536870912000 bytes, 1048576000 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes

These three disks must be managed under the Linux® Logical Volume Manager (LVM), and deployed as logical volumes. In order to achieve
that, first put the three devices under LVM control. For example, make them physical volumes:
$ [root@hana256-vsi ~]# pvcreate /dev/vdd /dev/vde /dev/vdf

Then, create a volume group from the physical volumes. The name of the volume group can be chosen according to your preferences, in our
sample it is hana_vg :
$ [root@hana256-vsi ~]# vgcreate hana_vg /dev/vdd /dev/vde /dev/vdf

After creating the volume group, three logical volumes need to be defined on top. These logical volumes reflect the file system size
requirements for SAP HANA. The following commands are for a 256 GB virtual server:
$ [root@hana256-vsi ~]# lvcreate -i 3 -I 64K -L 256GB -n hana_log_lv hana_vg
[root@hana256-vsi ~]# lvcreate -i 3 -I 64K -L 256GB -n hana_shared_lv hana_vg
[root@hana256-vsi ~]# lvcreate -i 3 -I 64K -l 100%FREE -n hana_data_lv hana_vg

For a 128 GB virtual server, in the example above -L 256GB must be replaced by -L 128GB and for 64 GB by -L 64GB accordingly. These
commands will not result in the smallest possible file system size, but they create the smallest configuration, which will fulfill the SAP HANA
KPIs. Finally, a file system needs to be created on top of each volume group:
$ [root@hana256-vsi ~]# mkfs.xfs /dev/mapper/hana_vg-hana_log_lv
[root@hana256-vsi ~]# mkfs.xfs /dev/mapper/hana_vg-hana_data_lv
[root@hana256-vsi ~]# mkfs.xfs /dev/mapper/hana_vg-hana_shared_lv

The following entries to /etc/fstab will mount the file systems after their mount points ( /hana/data , /hana/log and /hana/shared )
have been created:
$ /dev/mapper/hana_vg-hana_log_lv

/hana/log xfs defaults,swalloc,nobarrier,inode64

/dev/mapper/hana_vg-hana_shared_lv /hana/shared xfs defaults,inode64 0 0
/dev/mapper/hana_vg-hana_data_lv

/hana/data xfs defaults,largeio,swalloc,inode64 0 0

mx2-48x384 profile
For Virtual Server created based on the mx2-48x384 profile there are:
3x 500 GB volumes; three block storage volumes of 500 GB size, with a custom volume profile that supports up to 10,000 Max IOPS
attached to the Virtual Server is required
4x 100 GB volumes; four block storage volumes of 100 GB size, with a custom volume profile that supports up to 6,000 Max IOPS
attached to the Virtual Server is required
Optional: 1x 2,000 GB volume; one block storage volume of 2,000 GB size, with a lower 4,000 IOPS (medium performance) attached to
the Virtual Server for backups
After attaching the seven data volumes, seven new virtual disks will appear in the Virtual Server, see the table that follows. In this example,
those disks are vdd , vde , vdf , vdg , vdh , vdi , vdj .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 95

These three disks must be managed under the Linux® Logical Volume Manager (LVM), and deployed as logical volumes. In order to achieve
that, first put the three devices under LVM control. For example, make them physical volumes:
$ [root@hana384-vsi ~]# pvcreate /dev/vd[d,e,f,g,h,i,j]

Then, two different volume groups need to be created:
$ [root@hana384-vsi ~]# vgcreate hana_vg /dev/vdh /dev/vdi /dev/vdj
[root@hana384-vsi ~]# vgcreate hana_log_vg /dev/vdd /dev/vde /dev/vdf /dev/vdg

Next, three logical volumes need to be defined on top. These logical volumes reflect the file system size requirements for SAP HANA. The
following commands are for a 384 GB virtual server:
$ [root@hana384-vsi ~]# lvcreate -l 100%VG -i 4 -I 64K

-n hana_log_lv hana_log_vg

[root@hana384-vsi ~]# lvcreate -i 3 -L 384G -I 64K -n hana_shared_lv hana_vg
[root@hana384-vsi ~]# lvcreate -i 3 -l 100%FREE

-I 64K -n hana_data_lv hana_vg

Finally, a file system needs to be created on top of each volume group:
$ [root@hana384-vsi ~]# mkfs.xfs /dev/mapper/hana_log_vg-hana_log_lv
[root@hana384-vsi ~]# mkfs.xfs /dev/mapper/hana_vg-hana_data_lv
[root@hana384-vsi ~]# mkfs.xfs /dev/mapper/hana_vg-hana_shared_lv

The following entries to /etc/fstab mount the file systems after their mount points ( /hana/data , /hana/log and /hana/shared ) have
been created:
$ /dev/mapper/hana_log_vg-hana_log_lv

/hana/log xfs defaults,swalloc,nobarrier,inode64

/dev/mapper/hana_vg-hana_shared_lv /hana/shared xfs defaults,inode64 0 0
/dev/mapper/hana_vg-hana_data_lv

/hana/data xfs defaults,largeio,swalloc,inode64 0 0

Sample storage configurations on IBM Power Infrastructure
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services
The following sections demonstrate storage configurations in various different SAP workload scenarios.
When you create new storage volumes, keep the following points in mind:
After you provision the storage with Affinity, you cannot change it. Carefully plan your storage layer and make sure that your configuration
is correct. Affinity prevents issues with new volume discovery on existing virtual servers.
When you finish provisioning new volumes, you can toggle bootable and sharing switches.
Make volumes that belong to different OS file systems unique sizes. Otherwise, it is difficult to identify the storage volumes within the
operating system.

Storage Guidelines for SAP HANA based on Flexible IOPS
Note: See Storage tiers to learn more about flexible IOPS.
The storage tier and capacity that is recommended for deployment of SAP S/4HANA on Power Virtual Server is described in this topic. These
recommendations are based on the best practices and to meet the minimum performance criteria defined by HCMT.
Recommendation for SAP HANA DB size 128 GB - 768 GB
Use 4 volumes of Fixed 5,000 IOPS storage for storing log files. Log files are usually up to 512 GB and need the high performance
Use 4 volumes of Tier 0 storage for data file system
Use 1 volume of Tier 3 storage for shared file system.
Recommendations for SAP HANA DB size 960 GB - 22.5 TB
Use 4 volumes of Tier 0 storage for storing log files. Log files are usually up to 512 GB and need the high performance
Use 4 volumes of Tier 3 storage for data file system
Use 1 volume of Tier 3 storage for shared file system.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 96

Important: An additional Capacity of 150 GB per compute instance for the Operating System + /usr/sap on Tier 3 Storage profile is
recommended. For boot volume Tier 3 is sufficient.

Note: There are no defined IOPS requirements for shared file system

Sample storage tier and IOPS mapping
The tables below shows the mapping of minimum IOPS and its storage tier mapping based on the different SAP profiles.
Certified profile

Volume (GB)

Minimum IOPS

Log-storage tier

ush1-4x128

4 x 16 GB

20,000

Fixed 5,000 IOPS

ush1-4x256

4 x 32 GB

20,000

Fixed 5,000 IOPS

ush1-4x384

4 x 48 GB

20,000

Fixed 5,000 IOPS

ush1-4x512

4 x 64 GB

20,000

Fixed 5,000 IOPS

ush1-4x768

4 x 96 GB

20,000

Fixed 5,000 IOPS

umh-4x960

4 x 128 GB

12,800

Tier 0

umh-6x1440

4 x 128 GB

12,800

Tier 0

umh-8x1920

4 x 128 GB

12,800

Tier 0

umh-10x2400

4 x 128 GB

12,800

Tier 0

umh-12x2880

4 x 128 GB

12,800

Tier 0

umh-16x3840

4 x 128 GB

12,800

Tier 0

umh-20x4800

4 x 128 GB

12,800

Tier 0

umh-22x5280

4 x 128 GB

12,800

Tier 0

umh-25x6000

4 x 128 GB

12,800

Tier 0

umh-30x7200

4 x 128 GB

12,800

Tier 0

umh-35x8400

4 x 128 GB

12,800

Tier 0

umh-40x9600

4 x 128 GB

12,800

Tier 0

umh-50x12000

4 x 128 GB

12,800

Tier 0

umh-60x14400

4 x 128 GB

12,800

Tier 0

mh1-8x1440

4 x 128 GB

12,800

Tier 0

mh1-10x1800

4 x 128 GB

12,800

Tier 0

mh1-12x2160

4 x 128 GB

12,800

Tier 0

mh1-16x2880

4 x 128 GB

12,800

Tier 0

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 97

mh1-20x3600

4 x 128 GB

12,800

Tier 0

mh1-22x3960

4 x 128 GB

12,800

Tier 0

mh1-25x4500

4 x 128 GB

12,800

Tier 0

mh1-30x5400

4 x 128 GB

12,800

Tier 0

mh1-35x6300

4 x 128 GB

12,800

Tier 0

mh1-40x7200

4 x 128 GB

12,800

Tier 0

mh1-50x9000

4 x 128 GB

12,800

Tier 0

mh1-60x10800

4 x 128 GB

12,800

Tier 0

mh1-70x12600

4 x 128 GB

12,800

Tier 0

mh1-80x14400

4 x 128 GB

12,800

Tier 0

mh1-90x16200

4 x 128 GB

12,800

Tier 0

mh1-100x18000

4 x 128 GB

12,800

Tier 0

mh1-125x22500

4 x 128 GB

12,800

Tier 0

ch1-60x3000

4 x 128 GB

12,800

Tier 0

ch1-70x3500

4 x 128 GB

12,800

Tier 0

ch1-80x4000

4 x 128 GB

12,800

Tier 0

ch1-100x5000

4 x 128 GB

12,800

Tier 0

ch1-120x6000

4 x 128 GB

12,800

Tier 0

ch1-140x7000

4 x 128 GB

12,800

Tier 0

bh1-16x1600

4 x 128 GB

12,800

Tier 0

bh1-20x2000

4 x 128 GB

12,800

Tier 0

bh1-22x2200

4 x 128 GB

12,800

Tier 0

bh1-25x2500

4 x 128 GB

12,800

Tier 0

bh1-30x3000

4 x 128 GB

12,800

Tier 0

bh1-35x3500

4 x 128 GB

12,800

Tier 0

bh1-40x4000

4 x 128 GB

12,800

Tier 0

bh1-50x5000

4 x 128 GB

12,800

Tier 0

bh1-60x6000

4 x 128 GB

12,800

Tier 0

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 98

bh1-70x7000

4 x 128 GB

12,800

Tier 0

bh1-80x8000

4 x 128 GB

12,800

Tier 0

bh1-100x10000

4 x 128 GB

12,800

Tier 0

bh1-120x12000

4 x 128 GB

12,800

Tier 0

bh1-140x14000

4 x 128 GB

12,800

Tier 0

Table 1. Recommended storage tier and capacity for log data

Certified profile

Volume (GB)

Minimum IOPS

Data-storage tier

ush1-4x128

4 x 77 GB

7,500

Tier 0

ush1-4x256

4 x 77 GB

7,500

Tier 0

ush1-4x384

4 x 115 GB

7,500

Tier 0

ush1-4x512

4 x 154 GB

7,500

Tier 0

ush1-4x768

4 x 230 GB

7,500

Tier 0

umh-4x960

4 x 722 GB

7,500

Tier 3

umh-6x1440

4 x 720 GB

7,500

Tier 3

umh-8x1920

4 x 720 GB

7,500

Tier 3

umh-10x2400

4 x 720 GB

7,500

Tier 3

umh-12x2880

4 x 864 GB

7,500

Tier 3

umh-16x3840

4 x 1,152 GB

7,500

Tier 3

umh-20x4800

4 x 1,440 GB

7,500

Tier 3

umh-22x5280

4 x 1,584 GB

7,500

Tier 3

umh-25x6000

4 x 1,800 GB

7,500

Tier 3

umh-30x7200

4 x 2,160 GB

7,500

Tier 3

umh-35x8400

4 x 2,520 GB

7,500

Tier 3

umh-40x9600

4 x 2,880 GB

7,500

Tier 3

umh-50x12000

4 x 3,600 GB

7,500

Tier 3

umh-60x14400

4 x 4,320 GB

7,500

Tier 3

mh1-8x1440

4 x 648 GB

7,500

Tier 3

mh1-10x1800

4 x 648 GB

7,500

Tier 3

mh1-12x2160

4 x 648 GB

7,500

Tier 3

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 99

mh1-16x2880

4 x 864 GB

7,500

Tier 3

mh1-20x3600

4 x 1,080 GB

7,500

Tier 3

mh1-22x3960

4 x 1,188 GB

7,500

Tier 3

mh1-25x4500

4 x 1,350 GB

7,500

Tier 3

mh1-30x5400

4 x 1,620 GB

7,500

Tier 3

mh1-35x6300

4 x 1,890 GB

7,500

Tier 3

mh1-40x7200

4 x 2,160 GB

7,500

Tier 3

mh1-50x9000

4 x 2,700 GB

7,500

Tier 3

mh1-60x10800

4 x 3,240 GB

7,500

Tier 3

mh1-70x12600

4 x 3,780 GB

7,500

Tier 3

mh1-80x14400

4 x 4,320 GB

7,500

Tier 3

mh1-90x16200

4 x 4,860 GB

7,500

Tier 3

mh1-100x18000

4 x 5,400 GB

7,500

Tier 3

mh1-125x22500

4 x 6,750 GB

7,500

Tier 3

ch1-60x3000

4 x 900 GB

7,500

Tier 3

ch1-70x3500

4 x 1,050 GB

7,500

Tier 3

ch1-80x4000

4 x 1,200 GB

7,500

Tier 3

ch1-100x5000

4 x 1,500 GB

7,500

Tier 3

ch1-120x6000

4 x 1,800 GB

7,500

Tier 3

ch1-140x7000

4 x 2,100 GB

7,500

Tier 3

bh1-16x1600

4 x 660 GB

7,500

Tier 3

bh1-20x2000

4 x 660 GB

7,500

Tier 3

bh1-22x2200

4 x 660 GB

7,500

Tier 3

bh1-25x2500

4 x 750 GB

7,500

Tier 3

bh1-30x3000

4 x 900 GB

7,500

Tier 3

bh1-35x3500

4 x 1,050 GB

7,500

Tier 3

bh1-40x4000

4 x 1,200 GB

7,500

Tier 3

bh1-50x5000

4 x 1,500 GB

7,500

Tier 3

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 100

bh1-60x6000

4 x 1,800 GB

7,500

Tier 3

bh1-70x7000

4 x 2,100 GB

7,500

Tier 3

bh1-80x8000

4 x 2,400 GB

7,500

Tier 3

bh1-100x10000

4 x 3,000 GB

7,500

Tier 3

bh1-120x12000

4 x 3,600 GB

7,500

Tier 3

bh1-140x14000

4 x 4,200 GB

7,500

Tier 3

Table 2. Recommended storage tier and capacity for data

Certified profile

Volume (GB)

Shared-storage tier

ush1-4x128

1 x 128 GB

Tier 3

ush1-4x256

1 x 256 GB

Tier 3

ush1-4x384

1 x 384 GB

Tier 3

ush1-4x512

1 x 512 GB

Tier 3

ush1-4x768

1 x 768 GB

Tier 3

umh-4x960

1 x 1,000 GB

Tier 3

umh-6x1440

1 x 1,000 GB

Tier 3

mh1-8x1440

1 x 1,000 GB

Tier 3

bh1-16x1600

1 x 1,000 GB

Tier 3

umh-8x1920

1 x 1,000 GB

Tier 3

mh1-10x1800

1 x 1,000 GB

Tier 3

bh1-20x2000

1 x 1,000 GB

Tier 3

umh-10x2400

1 x 1,000 GB

Tier 3

mh1-12x2160

1 x 1,000 GB

Tier 3

bh1-22x2200

1 x 1,000 GB

Tier 3

bh1-25x2500

1 x 1,000 GB

Tier 3

umh-12x2880

1 x 1,000 GB

Tier 3

mh1-16x2880

1 x 1,000 GB

Tier 3

bh1-30x3000

1 x 1,000 GB

Tier 3

ch1-60x3000

1 x 1,000 GB

Tier 3

umh-16x3840

1 x 1,000 GB

Tier 3

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 101

mh1-20x3600

1 x 1,000 GB

Tier 3

mh1-22x3960

1 x 1,000 GB

Tier 3

bh1-35x3500

1 x 1,000 GB

Tier 3

ch1-70x3500

1 x 1,000 GB

Tier 3

umh-20x4800

1 x 1,000 GB

Tier 3

mh1-25x4500

1 x 1,000 GB

Tier 3

bh1-40x4000

1 x 1,000 GB

Tier 3

ch1-80x4000

1 x 1,000 GB

Tier 3

umh-22x5280

1 x 1,000 GB

Tier 3

mh1-30x5400

1 x 1,000 GB

Tier 3

bh1-50x5000

1 x 1,000 GB

Tier 3

ch1-100x5000

1 x 1,000 GB

Tier 3

umh-25x6000

1 x 1,000 GB

Tier 3

mh1-35x6300

1 x 1,000 GB

Tier 3

bh1-60x6000

1 x 1,000 GB

Tier 3

ch1-120x6000

1 x 1,000 GB

Tier 3

umh-30x7200

1 x 1,000 GB

Tier 3

mh1-40x7200

1 x 1,000 GB

Tier 3

bh1-70x7000

1 x 1,000 GB

Tier 3

ch1-140x7000

1 x 1,000 GB

Tier 3

umh-35x8400

1 x 1,000 GB

Tier 3

bh1-80x8000

1 x 1,000 GB

Tier 3

umh-40x9600

1 x 1,000 GB

Tier 3

mh1-50x9000

1 x 1,000 GB

Tier 3

bh1-100x10000

1 x 1,000 GB

Tier 3

mh1-60x10800

1 x 1,000 GB

Tier 3

umh-50x12000

1 x 1,000 GB

Tier 3

mh1-70x12600

1 x 1,000 GB

Tier 3

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 102

bh1-120x12000

1 x 1,000 GB

Tier 3

umh-60x14400

1 x 1,000 GB

Tier 3

mh1-80x14400

1 x 1,000 GB

Tier 3

bh1-140x14000

1 x 1,000 GB

Tier 3

mh1-90x16200

1 x 1,000 GB

Tier 3

mh1-100x18000

1 x 1,000 GB

Tier 3

mh1-125x22500

1 x 1,000 GB

Tier 3

Table 3. Recommended storage tier and capacity for shared data

Pricing
See the table 4 and table 5 for sample pricing calculation based on the storage requirement defined. The prices indicated are for reference and
subject to change. Use the cost estimator to get an estimate based on your business need.
Note: Fixed 5000 IOPS is limited to 200 GB of storage.
Sample pricing calculation when you need a storage of 1 GB
Storage Required = 1 GB

Calculation

$Price/Month

IOPS Performance

Tier 0

1 GB x $.24

$0.240

25 IOPS

Fixed 5,000 IOPS

1 GB x $.288

$0.288

5,000 IOPS

Table 4. Sample pricing when the storage required is 1 GB

Sample pricing calculation when you need a storage of 100 GB
Storage Required = 100 GB

Calculation

$Price/Month

IOPS Performance

Tier 0

100 GB x $.24

$24

2,500 IOPS

Fixed 5,000 IOPS

100 GB x $.288

$29

5,000 IOPS

Table 5. Sample pricing when the storage required is 100 GB

Sample storage configuration for SAP NetWeaver that use the IBM Power Virtual Server
Table 1 is a sample storage configuration for a IBM Power Virtual Server for SAP NetWeaver on Linux.
The storage can't be combined within one IBM Power Virtual Server; it must be either Tier 1 or Tier 3. When you provision the Linux server, you
automatically get the standard LVM configuration for the root volume group. These file systems are included in table 1. Disk sizes depend on
whether the installation is Greenfield, or whether the server is a copy of an on-premises AIX server that you decided to use as a sizing
reference.
The naming convention for the LVM entries is optional, but the advice is to include the SID of your SAP NetWeaver system especially if you plan
to install one or more instances.
Storage

Volume group

Logical volume

Mount point

OS disk

Default configuration

Default configuration

Default configuration

Application disk

app<sid>vg

lvusrsap

/usr/sap

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 103

lvusrsap<SID>

/usr/sap/<SID

lvusrsapmnt

/sapmnt/<SID>

lvusrsaptrans

/usr/sap/trans

lvsapDAH

/usr/sap/DAH

Table 3. Sample storage layout for Linux

Sample storage configuration for Oracle DB on IBM AIX that use the IBM Power Virtual Server
Table 2 is a sample configuration for an AIX IBM Power Virtual Server for an SAP NetWeaver application server that uses Oracle as the
example.
The storage cannot be combined within the same IBM Power Virtual Server, and can be either Tier 1 or Tier 3. The recommendation is to
provision three more disks to enable separation between the OS, database, and application layer. Disk size depends on if the installation is
Greenfield or if the server is a copy of an "on-premises" AIX server you decided to use as a sizing reference.
The naming convention for the LVM entries is optional, but the advice is to include the SID of your SAP NetWeaver system, especially if you plan
to install one or more instances.
Storage

Volume group

Logical volume

Mount point

OS disk

Default configuration

Default configuration

Default configuration

Application disk

app<sid>vg

lvusrsap

/usr/sap

lvusrsap<SID>

/usr/sap/<SID>

lvusrsapmnt

/sapmnt/<SID>

lvusrsaptrans

/usr/sap/trans

lvsapDAH

/usr/sap/DAH

lv<SID>arch

/oracle/<SID>/oraarch

lv<SID>reorg

/oracle/<SID>/sapreorg

lv<SID>origlogA

/oracle/<SID>/origlogA

lv<SID>origlogB

/oracle/<SID>/origlogA

lv<SID>ora

/oracle/<SID>

lv<SID>sapdata1

/oracle/<SID>/sapdata1

lv<SID>sapdata2

/oracle/<SID>/sapdata2

lvorastage

/oracle/stage

lv<SID>sapdata3

/oracle/<SID>/sapdata3

lv<SID>sapdata4

/oracle/<SID>/sapdata4

lv<SID>oraclient

/oracle/client

Database storage

db<sid>vg

Table 4. Sample storage layout for Oracle

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 104

For more information, see SAP Note 2172935.

Sample storage configuration for Db2 on Cloud on IBM AIX that use the IBM Power Virtual Server
Table 3 is a sample storage configuration for an AIX IBM Power Virtual Server for a Db2 on Cloud server.
The storage cannot be combined within the same IBM Power Virtual Server, and can be either Tier 1 or Tier 3. The recommendations are to
provision three more disks to enable separation between the OS, database, and application layer. Disk size depends on whether the installation
is Greenfield or the server is a copy of an "on-premises" AIX server that you decided to use as a sizing reference.
The naming convention for the LVM entries is optional, but the advice is to include the SID of your SAP NetWeaver system especially if you plan
to install one or more instances.
Storage

Volume group

Logical volume

Mount point

OS disk

Default configuration

Default configuration

Default configuration

Application disk

app<sid>vg

lvusrsap

/usr/sap

lvusrsap<SID>

/usr/sap/<SID>

lvusrsapmnt

/sapmnt/<SID>

lvusrsaptrans

/usr/sap/trans

lvsapDAH

/usr/sap/DAH

loglv<SID>

NA

lv<SID>db2

/db2/<SID>

lvhome<SID>

/db2/db2<SID>

lv<SID>db2dump

/db2/<SID>/db2dump

lv<SID>logdir

/db2/<SID>/log_dir

lv<SID>log_archive

/db2/<SID>/log_archive

lv<SID>saptmp

/db2/<SID>/saptemp1

lv<SID>db2sw

/db2/db2/<DBSID>/db2_sw

lv<SID>sapdata1

/db2/<SID>/sapdata1

``lv sapdata2`

/db2/<SID>/sapdata2

``lv sapdata3`

/db2/<SID>/sapdata3

``lv sapdata4`

/db2/<SID>/sapdata4

Db2 database storage I

Db2 database storage II

<sid>db2vg

<sid>db2datvg

Table 5. Sample storage layout for Db2 on Cloud

For more information, see Required File Systems for IBM Db2 for Linux, UNIX, and Windows and SAP Note 1707361.

Compute and OS design considerations
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
In some regards, SAP workloads that use a Cloud Service Provider (such as IBM Cloud® for SAP) Infrastructure-as-a-Service is similar to
existing practices (over many decades) for running SAP workloads by using an external data center or data center provider. An SAP landscape
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 105

has specific requirements for connectivity, between hosts within Cloud IaaS and to external systems, IBM Cloud® for SAP provides a rich set of
functions beyond hosting of SAP systems to improve your SAP landscape.
To assist your project's planning phase, the following sections provide IBM Cloud® for SAP portfolio design considerations for Compute and
OS.

Compute Performance considerations
The IBM Cloud® for SAP portfolio is ideal for practically all SAP use case scenarios. You can use your servers for mission-critical workloads, as
your test environment, or your business continuity disaster recovery (BCDR) site.

SAP NetWeaver work processes scheduling and scaling
CPU thread consumption affects the following processes:
Dialog Work Process
Update Work Process
Background Work Process
Enqueue Work Process
Spool Work Process

Compute Profiles of SAP-certified Bare Metal on Classic and on VPC Infrastructure
You are offered an array of RAM and CPU combinations as the SAP-certified servers, which have a pre-configured amount of RAM and number
of CPUs.
These combinations are "Appliance" delivery model of hardware certification. Therefore, the combination that you select cannot be changed
during the ordering process or through a support ticket after servers are deployed.
Some IBM Cloud® for SAP Bare Metal profiles do allow alterations, and therefore - as far as HANA deployments are concerned - would use the
"TDI" delivery model for which you would need to run validation checks to gain SAP Support.

Compute Profiles of SAP-certified Virtual Servers on VPC Infrastructure
IBM Cloud® for SAP provides SAP-certified infrastructure by using the latest Virtual Servers. These virtual servers are available with
instantaneous provisioning, and are offered in different profiles that define CPU and RAM combinations.

Compute Profiles of SAP-certified IBM Power Virtual Servers
Note: This offering is complementary from IBM Power Systems, with low latency access to IBM Cloud services
You have two compute options for SAP workloads: Power System E980 and Power System S922. Both can run SAP NetWeaver application
servers on AIX or Linux®, or SAP database servers with IBM Db2 or Oracle on AIX. SAP HANA runs E980 on Linux.
Currently, Power System E980 is supported for SAP HANA.
Currently, SAP Workloads on IBM Power Virtual Servers are available in Washington, D.C., Dallas, London, and Frankfurt. The number of
supported locations is planned to be extended.
All SAP NetWeaver Application Server ABAP-based products and SAP NetWeaver Application Server Java-based products are supported on
IBM Power Virtual Servers. For SAP NetWeaver-based SAP products, see SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers .
All SAP HANA-based products are supported on IBM Power Virtual Servers. For support requirements, see SAP Note 2923984 - SAP on IBM
Power Virtual Servers: Support prerequisites.
For all other software components or third-party products, contact SAP Support.

Compute Profiles of SAP-certified VMware on Classic Infrastructure
Note: VMware runs on the same SAP-certified Bare Metals. Therefore, the VMware vSphere (ESXi) installation on the certified hardware
enables the VMware-SAP certification and agreements to be valid. Therefore, all VMware-SAP certification guidance must be followed
(as described in SAP Notes for VMware-SAP).

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 106

VMware SDDC is available as a customer-controlled root-access hypervisor, which is certified to run SAP workloads. Providing VMware SDDC
does not automatically provide a pre-sized virtual machine for SAP HANA or SAP NetWeaver upon provisioning either the OS image with
VMware vSphere (ESXi) for the Bare Metal or the fully automated setup from IBM Cloud for VMware Solutions Dedicated. You choose how to
size and configure your SAP Workloads (for SAP HANA, size and configuration is under the SAP HANA TDI delivery model)
When you run SAP workloads on VMware, you have significant flexibility and the full capabilities which VMware built to run SAP workloads over
decades is available to use.
Using VMware for SAP workloads on IBM Cloud is certified, by using the "TDI" delivery model for which you would need to run validation
checks to gain SAP Support.
However, VMware SDDC is a Type 2 hypervisor and therefore does have a small overhead of CPU/RAM that is used for running ESXi on the Bare
Metal server. This CPU/RAM overhead is then available for virtual machines to use. On average this overhead is 10%, and is expected by
VMware-SAP in virtualized environments. Therefore, customers are encouraged to size correctly and test performance before you go live SAP
Note 2393917 - SAP HANA on VMware vSphere 6.5 and 6.7 in production.
Also, both VMware and SAP agree to the physical to virtual overhead of <10% on average, and provide:
The estimation of <10% average overhead with equation "physical SAPS - 10%" for virtualized SAPS to use when you size virtual
machines
The estimation of "between 0.5% and 3%" subtracted from total available physical RAM. Although, "the actual RAM overhead can be
defined only after the VMs are configured"
Sources:
Page 120-121, Architecture Guidelines and Best Practices for Deployments of SAP HANA on VMware vSphere Architecture and
Technical Considerations Guide
Page 19, The Winding Road to Virtual SAP HANA Application Workload Guidance Design for SAP S/4HANA on VMware vSphere 6.5
Only for half-socket VMs and sharing of NUMA Node between two VMs. Keep in mind that

"additional performance impact" and a

"sizing buffer of at least 15%" of the CPU (SAPS) is recommended. SAP Community Wiki - SAP HANA on VMware vSphere

Several other SAP-defined rules must be followed to deploy SAP HANA in a VMware SDDC environment. For more information, see the
following documentation:
SAP Note 2161991 - VMware vSphere configuration guidelines
SAP Note 2393917 - SAP HANA on VMware vSphere 6.5 and 6.7 in production
SAP Note 2779240 - Workload-based sizing for virtualized environments
SAP HANA Tailored Data Center Integration Frequently Asked Questions)

Operating Systems considerations
The IBM Cloud® for SAP portfolio provides various Operating Systems for the Enterprise IT organization to select from.

Operating Systems supported
You need to consult SAP Note 2414097 for a list of guest operating systems (OS) to deploy SAP HANA and SAP NetWeaver-based systems. An
SAP S-user ID is required to access the SAP Note.
For the Operating System, the SAP HANA certified servers are available with the following operating systems:
Red Hat Enterprise Linux for SAP HANA
SUSE Linux Enterprise Server for SAP HANA
VMware vSphere hypervisor (ESXi) + created Guest OS with RHEL/SLES
For the Operating System, the SAP NetWeaver certified servers are available with the following operating systems:
IBM AIX
Red Hat Enterprise Linux for SAP Applications
SUSE Linux Enterprise Server for SAP Applications
VMware vSphere hypervisor (ESXi) + created Guest OS with RHEL/SLES/WinS
Windows Server
For SAP HANA release versions (including SPS and Revision and Patch numbers), support is only available for pre-defined and specific
major.minor releases of an Operating System (for example, RHEL 7.6). This information is shown in SAP 2235581 - SAP HANA: Supported
Operating Systems. An example is available in the SAP Note attachment SAP_HANA_OS_Release_Support_Matrix.pdf .
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 107

For SAP NetWeaver release versions, support is available for each major release of an Operating System (for example, SLES 12) meaning each
subsequent release is available for use (example: SLES 12 SPS4, SLES 12 SP5, and so on). This information is shown in the SAP Product
Availability Matrix (PAM).

OS configuration for SAP
Each infrastructure has various operating systems with various images for those operating systems available on-demand.
Each of these on-demand OS images (for example, RHEL 7.6 for SAP HANA) is provided as shipped (also known as the "general availability" /
"stock image" release) by each of the vendors (for example, Red Hat). These OS images are provided with access from the OS Package
Manager (for example, RHEL4SAP, which is yum ) to the OS package update channels specific to the OS Packages for SAP. The OS package
update channels permit updates to the OS according to the latest SAP Notes for the relevant Operating System with the specified OS kernel
versions, OS package versions, and OS package for SAP versions that are required.
Therefore, for OS images, you need to perform the following actions.
OS configuration according to SAP guidance.
OS package updates according to SAP guidance, which includes updates to specified OS kernel versions (for example, RHEL4SAP 7.6
ships with 3.10.0-957.el7.x86_64 . However, SAP requires the 1.3 version 3.10.0-957.1.3.el7.x86_64 ).

OS for Virtual Servers on VPC Infrastructure
For a list of operating systems and databases available for SAP NetWeaver-based system deployments, see SAP Note 2927211.
Note: An SAP S-user ID is required to access the SAP Note.

OS for IBM Power Virtual Servers
For the Linux® versions to deploy for SAP HANA, see SAP Note 2947579 - SAP HANA on IBM Power Virtual Servers . An SAP S-user ID is
required to access the SAP Note. The OS image is provided by IBM Power Virtual Servers, and the licensing for Linux is covered through a "bring
your own license" (BYOL) model.
For the version of IBM AIX or Linux on Power to deploy for SAP NetWeaver-based systems, see SAP Note 2855850 - SAP Applications on IBM
Power Virtual Servers. An SAP S-user ID is required to access the SAP Note. License fees for AIX are covered by your monthly billing rate.
OS Packages update server with IBM Power Power Virtual Servers:
For SAP NetWeaver you can use publicly available AIX SUMA or SUSE update repositories, or use your own AIX NIM or SUSE RMT
servers.
For SAP HANA you can use publicly available SUSE update repositories, or use your own private SUSE RMT servers.
Operating system for SAP HANA

Operating system image (Bring your own

Operating system image (IBM

license)

subscription)

Red Hat Enterprise Linux (RHEL) 8.1

Linux-RHEL-SAP-8-1

Red Hat Enterprise Linux (RHEL) 8.2

Linux-RHEL-SAP-8-2

Red Hat Enterprise Linux (RHEL) 8.4

Linux-RHEL-SAP-8-4

RHEL8-SP4-SAP

Red Hat Enterprise Linux (RHEL) 8.6

Linux-RHEL-SAP-8-6

RHEL8-SP6-SAP

SUSE Linux Enterprise Server (SLES) for SAP
12 SP4

Linux-SUSE-SAP-12-4

SUSE Linux Enterprise Server (SLES) for SAP
15 SP2

Linux-SUSE-SAP-15-2

SLES15-SP2-SAP

SUSE Linux Enterprise Server (SLES) for SAP
15 SP3

Linux-SUSE-SAP-15-3

SLES15-SP3-SAP

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 108

SUSE Linux Enterprise Server (SLES) for SAP
15 SP4

Linux-SUSE-SAP-15-4

SLES15-SP4-SAP

Table 1. Operating systems for IBM Power virtual servers on SAP HANA

Operating system for SAP NetWeaver

Operating system image (Bring your own

Operating system image (IBM

license)

subscription)

Red Hat Enterprise Linux (RHEL) 8.1

Linux-RHEL-SAP-8-1

Red Hat Enterprise Linux (RHEL) 8.2

Linux-RHEL-SAP-8-2

Red Hat Enterprise Linux (RHEL) 8.4

Linux-RHEL-SAP-8-4

RHEL8-SP4-SAP-NETWEAVER

Red Hat Enterprise Linux (RHEL) 8.6

Linux-RHEL-SAP-8-6

RHEL8-SP6-SAP-NETWEAVER

SUSE Linux Enterprise Server (SLES) for SAP
12 SP4

Linux-SUSE-SAP-12-4

SUSE Linux Enterprise Server (SLES) for SAP
15 SP2

Linux-SUSE-SAP-15-2

SLES15-SP2-SAP-NETWEAVER

SUSE Linux Enterprise Server (SLES) for SAP
15 SP3

Linux-SUSE-SAP-15-3

SLES15-SP3-SAP-NETWEAVER

SUSE Linux Enterprise Server (SLES) for SAP
15 SP4

Linux-SUSE-SAP-15-4

SLES15-SP4-SAP-NETWEAVER

AIX 7.1

7100-05-05 or later

AIX 7.2

7200-04-01 or later
Table 2. Operating systems for IBM Power virtual servers on SAP NetWeaver

Note: Update on new SAP HANA large t-shirt profiles feature IBM supports SLES15 SP4 for SAP and RHEL8.6 for SAP OS images with
all other features on all t-shirt profiles with fewer than 64 cores. These SLES15 SP4 for SAP and RHEL8.6 for SAP OS images while they
are updating to support the larger t-shirt profiles. Until further notice, use the larger t-shirt profiles with the SLES15 SP3 for SAP OS
image or the RHEL8.4 for SAP OS image.

OS when you use VMware SDDC
VMware SDDC is available as a customer-controlled root-access hypervisor, which is available as an OS image for the Bare Metal or available
with fully automated setup from IBM Cloud for VMware Solutions Dedicated. The VMware licensing can be included or BYOL.
However, when you run a VMware SDDC, the Virtual Machine's Guest OS licensing and subscriptions (to the relevant package update channels,
including OS Packages for SAP) is covered by you.
Only the following operating systems are supported as guest Operating Systems for VMware SDDC and SAP workloads.
Red Hat Enterprise Linux (RHEL) for SAP
SUSE Linux Enterprise Server for SAP
Microsoft Windows Server
Note: You need to make sure that the SAP HANA Tailored Data Center Integration (TDI) Key Performance Indicators (KPIs) are met for
every virtual machine on which SAP HANA is deployed.
See SAP Note 2414097) for version details.
Refer to Installing VMware vSphere ESXi by using Remote Console and Virtual Media and other VMware.com documentation to install a Guest
OS.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 109

Bring-your-own-OS (custom OS image and BYOL License)
When you have your own operating system image and license, it can be used with IBM Cloud and the OS install based on the vendor's
instructions.
Infrastructure

BYOS

SAP workloads support

Intel Bare Metal Servers on
Classic Infrastructure

OS BYOL and custom image (BYOS) by using the "no OS"
option during provisioning

SAP HANA by using TDI deployment
SAP NetWeaver AS

Intel Virtual Servers (Gen2) on
VPC Infrastructure

OS BYOL and Custom image (BYOS) by using Importing
and managing custom images

SAP HANA by using TDI deployment
SAP NetWeaver AS

IBM Power Virtual Server in
the IBM Power Infrastructure
environment

Linux OS BYOL and Custom Image (BYOS) by using Linux
within the Power Virtual Server - Capturing and importing
a SLES image

Not supported for SAP HANA or SAP
NetWeaver workloads, available for nonSAP workloads

IBM Power Virtual Server in
the IBM Power Infrastructure
environment

Unix OS BYOL and Custom Image (BYOS) by using
Importing a boot image for IBM AIX or IBM i

SAP NetWeaver AS

VMware SDDC on IBM Cloud

OS BYOL and custom image (BYOS) by using standard
Virtual Machine Guest OS guidance from VMware
documentation

Supported according to SAP-VMware
guidance

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 110

SAP HANA database design considerations
It is important to consider the design of your SAP HANA configuration and deployment to ensure the SAP Business Applications use the full
capabilities available with SAP HANA database server.
There are many decisions for SAP HANA design, which are taken to support the business requirements for the SAP Business Application. These
design decisions for SAP HANA influence your infrastructure decisions. In the table, some of the sample decisions for these SAP HANA design
considerations in the high-level overview are explained in detail.
High-level overview breakdown of SAP HANA design considerations and example decisions:
Design item

Example decision

Sizing Type

Standard sizing

Deployment Method

Appliance deployment

Deployment Type

MDC

System Type

Distributed, scale-out

Processing Type

OLAP, scale-out

Storage Type

Network File Storage (NFS)

Storage Filesystem

NFS mount points

High Availability fencing
mechanism

STONITH

High Availability replication mode

SAP HANA System Replication, Full Synchronous replication within same Availability Zone or Data
center

Disaster Recovery fencing
mechanism

STONITH

Disaster Recovery replication
mode

SAP HANA System Replication, Asynchronous replication to different Region

Backups

Backint native, daily complete backup + incremental backup every 30 minutes

SAP HANA Components

Live Cache Apps (LCAPPS), Extended Application Services Advanced (XSA - Cloud Foundry)

Table 1. High-level overview breakdown of SAP HANA design considerations and example decisions

SAP HANA performance indicators and sizing
You have various performance indicators which guide the design decisions for sizing and planning an SAP HANA deployment onto Cloud IaaS.
Each of these performance indicators defined with consideration to meeting the business requirements, determine whether the infrastructure
is suitable. These considerations include compute capacity, storage capacity and latency, network throughput and latency in addition to the
design decisions for SAP HANA database server.
Examples of these performance indicators for SAP HANA include:
Indicator
Memory

Description
Leading factors for SAP Sizing (and cost of landscape + licenses)
Determined by data footprint (business and metadata in the column and row store) after compression and by
extra SAP HANA components used (such as cache store)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 111

CPU

Compared to SAP AnyDB options, more CPU power is required to fully benefit from the parallel processing
capabilities of SAP HANA for optimal response times.
The large parallelization in analytical scenarios influence on Response Times. Therefore, CPU requirement is
more important for analytical scenarios.
Mixed transactional and analytic workloads are supported by SAP HANA but compete for shared resources.

Disk capacity
size
Disk
throughput
(I/O)

Disk capacity that is required for data persistence for logging and cache data

Network
Load

Network throughput bandwidth in gigabits per second (Gbps):

Disk capacity size depends on the type of database store usage (such as row and column)
Sufficient I/O performance is required to enable processes to run with acceptable data throughput and storage
system latency (that is, read/write from or to the disk)

Amount of data transferred between SAP Application Servers and Database Servers
Amount of data transferred between SAP Application and End User
Network latency roundtrip in milliseconds (ms):
Time between SAP Application Servers and Database Servers
Time between hosts and any network-attached storage
Time between SAP Application and End User
Table 2. Example performance indicators for SAP HANA

SAP HANA Sizing Type and Deployment Method
Sizing type refers to the exercise of sizing SAP HANA, using either pre-defined or custom configurations.
Whereas the deployment method (sometimes referred as delivery model) refers to running IaaS certified for SAP HANA, which is either predefined or custom configurations.
Here is the summary of the Appliance and TDI deployment methods:
Appliance

TDI

Application

Application

Database

Custom Database sizing (including CPU:DRAM ratios)

Linux Operating System

Select from defined range of supported Linux® Operating System versions

Virtualization (optional)

Virtualization (optional)

Server

Server

Storage

Custom Storage
Table 3. Appliance vs. TDI deployment methods

The following sub-sections describe the appliance deployment method for Standard Sizing type, and the TDI deployment method for Expert
Sizing. Detailed documentation regarding the methods and types are shown in SAP documentation:
SAP HANA Administration Guide for SAP HANA Platform
SAP HANA Server Installation and Update Guide
SAP About Benchmarks - Sizing Types - Expert Sizing
Expert Sizing & Methods of Sizing Validation
Sizing Methods and Tools

Appliance deployment method for Standard sizing type
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 112

Standard sizing type
This term refers to a sizing exercise where pre-defined configuration sizes are defined based on hardware testing and t-shirt sizing for meeting
specific benchmarks to arrive at a sizing result for the hardware requirements of an SAP application (such as network, CPU, Memory, Storage).

Appliance deployment method
Supported hardware for SAP HANA depends on the deployment method. The appliance deployment method uses pre-defined validated SAPoptimized hardware by SAP-certified hardware partners that are running a specific operating system. These hardware options are offered in
various configuration sizes.
Partners (such as Cloud Service Providers) offer appliances with multiple layers of redundant hardware, software and network components,
which do not interrupt SAP HANA operations and defend against system outage. These components include:
Redundant power supplies and fans and uninterrupted power supply (UPS)
Enterprise grade error-correcting memories
Fully redundant network switches and routers
Disk storage systems that use batteries to guarantee writing even in the presence of power failure.
Disk storage systems that use striping and mirroring for redundancy and recovery from disk failures.
In collaboration with SAP, a Cloud Service Provider defines the correct sizing when designing SAP-certified IaaS for SAP HANA with the
appliance deployment method:
Ensures maximum performance with the hardware capable of meeting specified workloads; providing dedicated memory for SAP HANA
after the resident memory of OS and other programs is accounted for and with swapping to disk disabled.
To maximize performance and throughput, SAP recommends that you scale up as far as possible (acquire the configuration with the
highest processor and memory specification for the application workload) before scaling out (for deployments with greater data volume
requirements).
You can copy a database to machines from different SAP HANA appliance vendors with different hardware configurations, if both the
source and target machines are compliant with the SAP HANA appliance specifications.

TDI deployment method for Expert sizing
Expert sizing type
Expert sizing type refers to a sizing exercise where customer-specific data is analyzed and used to put more detail on the sizing result for the
hardware requirements of an SAP application (such as network, CPU, Memory, Storage).
According to SAP, expert sizing typically includes "exploring some business processes in more detail, both on functional and technical level"
(quotation source: Sizing Types - Expert Sizing ).
Therefore, with expert sizing, there are no standardized tools used to conduct the sizing and it will often require significant effort and SAP
expertise. Projects that use expert sizing often use an external consulting and system implementation business partner to assist the internal
SAP team.
For expert sizing, the following steps are likely to be performed (source: Sizing Types - Expert Sizing ):
Identify the most important queries/apps/scenarios
Identify, how they are used, for example, filter criteria, authorizations.
Run these queries/apps/scenarios on representative test data (quality of test data and quantity of test data). Ideally, on a recent copy of
the production data
Measure resource consumption (CPU/memory) and response times
Perform a forecast calculation based on the expected usage of the queries/apps/scenarios

TDI deployment method
Supported hardware for SAP HANA depends on the deployment method. The TDI deployment method uses custom-defined hardware by
SAP-certified hardware partners that use flexible OS or SAP HANA versions; these can be configured to any size (under the maximum
configuration tested by SAP).
Partners (such as Cloud Service Providers) offer TDI with various configuration options and redundancy options. Thes options depend on
whether you select scale-up or scale-out sizing, and must be installed by an appointed SAP HANA certified administrator. These may include:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 113

Redundant power supplies and fans and uninterrupted power supply (UPS)
Enterprise grade error-correcting memories
Fully redundant network switches and routers
Disk storage systems use batteries to guarantee writing even in the presence of power failure
Disk storage systems that use striping and mirroring for redundancy and recovery from disk failures
SAP and a cloud service provider agree to support the customer for a selected scale-up or scale-out sizing by using SAP-certified IaaS for SAP
HANA with the TDI deployment method:
This provides different system design options regarding scale-up and scale-out variations; the SAP HANA database must then be
validated before use in Production systems that use the SAP HANA Hardware Configuration Check Tool for TDI testing when requested
by the SAP Support organization.
To maximize performance and throughput, SAP recommends that you scale up as far as possible (acquire the configuration with the
highest processor and memory specification for the application workload) before scaling out (for deployments with greater data volume
requirements).

SAP HANA Deployment Types
SAP HANA can be deployed in various layouts, with various configurations of abstraction and logical separation of database schemas. Different
deployment types are designed for different use cases, and SAP defines those which are approved (with/without restrictions) for production
SAP Systems and those which are not approved. See detailed information here on SAP HANA Deployment Types - SAP HANA Server
Installation and Update Guide and a summary of this information:
Approved for production
Dedicated also known as. Single Application on One SAP HANA System (SCOS)
Multitenant Database Containers (MDC)
Approved for production (with restrictions)
Virtualized Single Tenant - restrictions to the hypervisor; see SAP Note 1788665 - SAP HANA Support for virtualized / partitioned
(multi-tenant) environments
Multiple Applications on One SAP HANA System (MCOD) - supported only for approved applications; see SAP Note 1661202 Support multiple applications one SAP HANA database / tenant DB
Multiple SAP HANA Systems on One Host (MCOS)
Note: Multi-SID hosted with the same physical host, requires significant attention to detailed tasks related to system administration
and performance management. For more information, see SAP Note 1681092 - Multiple SAP HANA systems (SIDs) on the same
underlying servers

SAP HANA System Type
System Types are listed by SAP on SAP HANA System Types as:
Single-host system - one SAP HANA instance on one host server
Multi-node / distributed / scale-out cluster
A single-host system is the simplest system installation type. It is possible to run an SAP HANA system entirely on one host server and then
scale the system up as needed.
A multi-node / distributed / scale-out cluster is a system installation across multiple host servers with a limit on the CPU/RAM for each host
node and a limit on the number of host nodes that can be used. Information on the maximum scale-out configurations, is listed in the SAP
HANA Hardware Directory - Certified IaaS Platforms.

SAP HANA scale-out cluster
Use of scale-out is primarily designed for SAP BW/4HANA or SAP BW on HANA. The

Scale-up and Scale-out for SAP BW/4HANA considerations

at the application-layer is covered separately. These consideratios are in addition to database-layer considerations described in the following
sections.
Note: It is important to note that if your SAP HANA database server nodes or SAP NetWeaver application server components are
distributed across multiple availability zones and data centers, SAP will not support your SAP HANA scale-out cluster (also known as,
SAP HANA multi-node system).

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 114

Important: IBM Power Virtual Servers does not support scale-out for either OLAP or OLTP processing types.

Networking
SAP HANA multi-node requires certain networks be in place to function. Before you order other components of your system, these networks
must be set up correctly and together with the database nodes. Separation of the network flows/traffic can improve performance (that is,
keeping high storage traffic separate from the user traffic) when more network interfaces are attached to the server.
As a summary of the network separation, you need in SAP HANA scale-out cluster to have:
A client-side network, which connects the SAP Advanced Business Application Programming (SAP ABAP) application servers, SAP HANA
Studio clients, and any other network client to the multi-node system. The network throughput and availability options depend on the
environment and usage scenario of your SAP HANA multi-node system. Consider the amount of data transferred from and to the SAP
HANA database, and the availability key performance indicators (KPIs), required for your application.
A storage network, which connects to the Network Storage (File/NFS or Block/iSCSI dependant on infrastructure selection). The network
throughput and availability options depend on the environment and usage scenario of your SAP HANA multi-node system. Consider the
throughput and latency required to provide 10,000 IOPS is available to each SAP HANA node.
An internode network for SAP HANA internal communication that is set up equivalent to the storage network. The internode network is
only used for communication between nodes and the data transfer that might be required between the nodes during operations.
Within each environment is a separate networking design. The classic infrastructure environment network is the forerunner and is the most
robust option of many traditional and physical networking concepts. The VPC Infrastructure environment network is a software-defined
network. The IBM Power environment network (as a complementary offering from IBM Power Systems) is designed with networking principles
for enterprise-grade performance.
Given these environment networks are different, configuring extra NIC throughput changes for the different infrastructure options:
Bare Metal, on Classic Infrastructure network: To maximize performance and redundancy, the physical network interfaces (NIC) are
provided with 10 Gbps and then provisioned with bonding using Link Aggregation Control Protocol (LACP). The switches are configured
automatically when ordering redundancy on the physical NIC. Additional NIC cards might be added, depending on the physical machine
specificiation and physical switch availability of ports.
Intel Virtual Server, on VPC Infrastructure network: To maximize performance and redundancy, up to 5 network interfaces (vNIC) on
multiple Subnets can be added.
IBM Power Virtual Server, on IBM Power Infrastructure network: To maximize performance redundancy, multiple network interfaces
(vNIC) attached to different VLANs (and their respective Subnets) can be added.
VMware for SAP, on Classic Infrastructure network....
IBM Cloud for VMware Solutions, on Classic Infrastructure network: redundant adapters for VMware are set up by the VMware
vSphere Distributed Switch (VDS) using either VDS on NSX-V or VDS on NSX-T , in accordance with current VMware best practices
for SDDC. While subject to change, redundancy is configured by setting every distributed switch with the Route Based on
Originating Virtual Port load balancing algorithm. All port groups used by the algorithm should be configured to use teamings
across 2 uplinks (Active: 0,1).
IBM Cloud Bare Metal with VMware vSphere (manual configuration) , on Classic Infrastructure network: adapters are suggested
to utilise the best practices, however the vSwitch could use LACP bonding of the physical NIC adapters

Scale-out storage
Data is distributed across the multiple SAP HANA nodes, which are hosting the single database.
Follow the guidelines in Sizing SAP HANA - SAP HANA Master Guide to determine the required total storage capacity size for your target SAP
HANA system.
The SAP HANA shared volume, and each of the data and log volumes, must be accessible to all nodes (which may be easier to allow network
storage access to all nodes within the Subnet used for storage connectivity). There are specific performance criteria that must be met by the
attached Network File System (NFS) volumes:
/hana/data/ and /hana/log volumes, individual volumes are required for each node with a minimum of 10 IOPS/GB
/hana/shared volume, required to be shared across all nodes with a minimum of 10 IOPS/GB and recommended to increment further

to 12 IOPS/GB
For Classic Infrastructure:
Read SAP HANA on NetApp FAS Systems with NFS) to assist configuration of your SAP HANA multi-node system.
Use the following Network File System (NFS) mount options in /etc/fstab for each volume to mount IBM Cloud for SAP | IBM Power Virtual Servers for SAP 115

rw,bg,hard,timeo=600,intr,noatime,vers=4,minorversion=1,lock,rsize=1048576,wsize=1048576 .

After you mount all of your volumes to all the nodes, your multi-node servers are configured and ready to install the SAP HANA multi-node
database. Follow the steps in the SAP HANA Server Installation and Update Guide) to install an SAP HANA database of your required version.

SAP HANA performance
After an SAP HANA database server is operational, it is important to inspect the performance to ensure it will meet your business application
requirements. This is particularly important for any deployments using the TDI deployment method.

SAP HANA performance validation
The SAP HANA Hardware and Cloud Measurement Tools (HCMT) replaces the previous SAP HANA HW Configuration Check Tool (HWCCT) . The
HCMT binary executable is run before an SAP HANA installation (commonly), and performs a series of automated tests which analyses the
system performance.
The output of the HCMT execution, is a result archive file - hcmtresult-[timestamp].zip .
This HCMT result archive file is then uploaded to the SAP HANA Hardware and Cloud Measurement Analysis (HCMA) for detailed analysis.
For information about downloading, installing, and configuring the HCMT tool, see SAP Note 2493172 - SAP HANA Hardware and Cloud
Measurement Tools.

SAP HANA overheads impact on available memory
Every SAP HANA database server reserves a small allocation of memory for the operating system and other services required to operate.
SAP provide a rule of thumb for these overheads:
Reserved for OS = 10% of the first 64 GB + 3% of all remaining memory
Reserved for SAP HANA services and caches = 50 GB
The example demonstrates the net capacity for SAP HANA when using 4TB Memory (DRAM) after the memory reservation overheads have
been taken into consideration:
Physical Memory

4096 GB DRAM

Reserved for OS

127 GB

Available for SAP HANA

3969 GB

Reserved for SAP HANA services and caches

50 GB

Net capacity available for SAP HANA data + temporary disk space

3919 GB

Table 1. Example of SAP HANA net capacity

This is shown in more detail on SAP Note 2296290 - New Sizing Report for SAP BW/4HANA under attachment
SAPBW4HANA_Sizing_V2.6.4.pdf

SAP HANA High Availability and Disaster Recovery (HA/DR)
The first requirement for SAP HANA High Availability (HA) and Disaster Recovery (DR), is to use the correct Operating System (OS) add-ons for
SAP High Availability. Be sure to discuss OS for SAP HA details with IBM Cloud Support before your deployment.
The OS supported and deployed by IBM Cloud for running SAP HANA with HA/DR are:
Red Hat Enterprise Linux (RHEL)
SUSE Enterprise Linux Server (SLES)
The IBM Cloud environment does not support any preconfigured high availability (HA) scenarios. However, it does let you implement HA
solutions for SAP HANA through Red Hat Enterprise Linux HA extensions, in a similar manner to existing deployments using Traditional OnPremises data centers.
SAP HANA System Replication (HSR) is configured with an automated fail-over from one server to a replica, using various replication modes
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 116

designed by SAP to fit:
Different SAP Business Applications
Different business risk acceptance of unplanned downtime
Different infrastructure resiliency cost profiles
Refer to SAP documentation on SAP HANA System Replication (HSR) and OS vendor documentation on SAP HANA HA/DR; or consult SAP for
recommendations on your landscape design for further clarity.
For more information on system replication, and network throughput and latency, see
How To Perform System Replication for SAP HANA - Version 5.4 January 2018
Network Configuration for SAP HANA System Replication
SAP Help - SAP HANA System Replication - SAP HANA Administration Guide for SAP HANA Platform
SAP Help - SAP HANA System Replicatio Guide
Troubleshoot System Replication - SAP HANA Troubleshooting and Performance Analysis Guide
SAP Note 1999880 - FAQ: SAP HANA System Replication
SAP Note 2057595 - FAQ: SAP HANA High Availability
For more information on setting up the HA cluster extensions of the OS, view the Linux vendor documentation.
SUSE Linux Enterprise Server for SAP:
SAP HANA System Replication Scale-Up - Performance Optimized Scenario
SUSE Linux Enterprise High Availability Extension
Red Hat Enterprise Linux for SAP:
Supported HA Scenarios for SAP HANA, SAP S/4HANA, and SAP NetWeaver
Automated SAP HANA System Replication in Scale-Up in pacemaker cluster

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 117

SAP NetWeaver design considerations
It is important to carefully consider the design your SAP stack configuration, deployment, and database.
With an SAP NetWeaver system, you have two deployment options: * Central system, which is a single-host installation (two-tier) * Distributed
system, which is a multi-host installation (three-tier or multitier); this is required to achieve high-availability redundancy
This initial deployment option decision to distribute your workload to different servers or keep the workload on one server for simplicity, has
many other decisions which are taken to support the business requirements for the SAP Business Application.
While the deployment option impacts how SAP NetWeaver application server will operate, there are many other options which influence your
server choice.

SAP System Tiering approaches
The SAP System Tiering approach defines the logical architecture of the SAP System or Systems.
At a high level, SAP System Tiering has numerous different approaches:
A two-tier logical architecture SAP System refers to Client and that uses one host for Application and Database.
A three-tier logical architecture SAP System refers to Client, Application (host 1), and Database (host 2).
A multitier logical architecture SAP System refers to any permeation of Client, Application, and Database where HA and DR create further
separation of components to create redundancy
For SAP NetWeaver (ABAP runtime) that uses two-tier or three-tier, the following components run on a single host:
Central Services (ASCS) = Message (MS), Enqueue (EN)
Primary Application Server (PAS) also known as Central Instance (CI) = ICM, Gateway (GW), ABAP Dispatcher (DI/WP)
Application Servers (AS) = ABAP Dispatcher (DI/WP)
When you create a high-availability environment for SAP Netweaver, spit each of these components out across different hosts:
Central Services (ASCS) = Message (MS), Enqueue (EN)
Primary Application Server (PAS) also known as Central Instance (CI) = ICM, Gateway (GW), ABAP Dispatcher (DI/WP)
Enqueue Replication Server Instance (ERS) = Enqueue (EN) with Replication Table (of the ASCS EN Lock Table)
Additional Application Servers (AAS) = ABAP Dispatcher (DI/WP)

High-availability configuration for SAP NetWeaver
The IBM Cloud environment does not support any preconfigured high-availability (HA) scenarios. However, you can configure HA scenarios
based on the HA extension for the operating system you choose. You add the HA extension by adding the required hardware and the required
software components to your landscapes. If you require additional software licenses, access to different software repositories, or both contact
IBM Cloud Support to help you with setting up any additional requirements.
This configuration information applies to HA software for SAP NetWeaver and to the HA software for the relational database management
system (RDBMS) you choose. For example, the replication portion of your high-availability and disaster-recovery mechanisms for your RDBMS.
Setup procedures do not differ from any setup procedures in an on-premises environment and require the same hardware and software
configuration steps.

Overview of SAP NetWeaver high-availability configurations
Numerous documents provide in-depth help on planning and installing an HA environment for SAP services. The documents include
information on failover, replication, scale-out, and disaster recovery (DR). References to specific documents are provided where appropriate.
All the operating systems and distributions that are supported by IBM Cloud for an SAP deployment (Windows Server, RHEL, and SLES) come
with high-availability software and specific extensions. The supported OS and distributions are described in these documents:
New Failover Clustering Improvements in Windows Server 2012 and Its Benefits for SAP NetWeaver High Availability provides a
description based on Microsoft Windows Server Failover Clustering (WFSC) on the Windows OS with SAP NetWeaver.
Two references for guidance on deploying SAP NetWeaver in a Linux-based HA environment with Linux® Pacemaker are:
SUSE SAP NetWeaver High Availability Cluster 7.40 Setup Guide
Deploying Highly Available SAP NetWeaver-based Servers Using Red Hat Enterprise Linux HA add-on with Pacemaker

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 118

Building High Availability for SAP NetWeaver and SAP HANA on Linux is an SAP best-practice document and provides an in-depth
technical description with a strong focus on SAP HANA.
SAP NetWeaver High Availability and Business Continuity in Virtual Environments with VMware and Hyper-V on Microsoft Windows
covers the virtualization aspects if you’re planning to implement HA on virtualized servers.
For more high-availability products certified by SAP partners for high-availability scenarios, see High Availability Partner Information .
For non-HANA SAP databases, more information on HA fail-over and DR configurations, is available in your database documentation.
Supporting HA system failover usually requires shared access to either:
Network File System (NFS) protocol and filesystem; in on-premises deployments may also use Common Internet File System (CIFS)
storage
iSCSI-based logical unique number storage (LUNS)
Supporting DR system failover usually requires Local storage that is combined with a replication method.
As with on-premises installations, check the performance and latency requirements of the database product when you plan your deployment.

Configure high availability in Classic Infrastructure
The IBM Cloud® environment does not support any pre-configured high-availability (HA) scenarios for SAP. However, you can configure HA
scenarios based on the HA extension for the operating system you choose.
HA and storage fencing considerations and HA and network considerations provide lists of things that you need to consider during your
deployment. Apart from the considerations outlined here, installing SAP NetWeaver and its database system in an HA environment doesn’t
differ from other on-premises installations.

HA and storage fencing (that is, Quorum-based) considerations
Cluster environments typically use IPMI-based components for the “fencing of cluster nodes” to ensure a quorum. Due to enterprise security in
the IBM Cloud Classic Infrastructure environment, network-based access to remote management devices through the Intelligent Platform
Management Interface (IPMI) isn’t available. Although IPMI is still used to manage the physical device if necessary.
In the absence of an IPMI-enabled device, shared storage devices are used.
In an IBM Cloud environment, shared storage devices are implemented by deploying an iSCSI LUN to your servers as a quorum device.
For example, a File Share Witness (FSW) on a Microsoft Cluster, and for storage-based death (SDB) for Linux Pacemaker's Stonith.
Click here for more information on Linux High Availability Cluster Concepts.
Click here for more information on configuring and managing quorum servers for Windows Server 2012 and Windows Server 2012 R2.
IBM Cloud Block Storage has built-in HA capabilities, so a single shared iSCSI LUN does not introduce a Single Point Of Failure (SPOF) because
your network layout is redundant. However, the specifics of your cluster product might require multiple quorum devices.

HA and network considerations
An IBM Cloud Classic Infrastructure environment-based installation comes with one of the following network configurations:
Private network
Public network
Public and private networks
Two private networks (on special request, dependent on the server type and physical hardware components configuration)
Like on-premises installations, extra network adapters can be ordered depending on the physical restrictions of the hardware. The restriction is
the same for on-premises installations, how many NIC cards can fit into the Bare Metal.
Ordering redundant network adapters during hardware deployments helps prevent single point of failures (SPOF) across your network
topology.
Redundant adapters for Bare Metals are set up in a failover configuration with Link Aggregation Control Protocol (LACP). For Linux, the setup
uses bonding interfaces, and teaming adapters are used for Microsoft Windows. This creates a logical interface for redundancy and increased
bandwidth.
When using IBM Cloud for VMware Solutions, redundant adapters for VMware are set up by the VMware vSphere Distributed Switch (VDS)
using either VDS on NSX-V or VDS on NSX-T , in accordance with current VMware best practices for SDDC. While subject to change,
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 119

redundancy is configured by setting every Distributed Switch with the Route Based on Originating Virtual Port load balancing algorithm, with all
contained Port Groups using Teaming across 2 uplinks (Active: 0,1). When using IBM Bare Metal with VMware vSphere for a manual installation
using vSwitch, LACP bonding of the physical NIC adapters could be used. This configuration choice depends on the need for increased
throughput (e.g. bonding) versus redundant stability (e.g. load balancing with teaming).
The NIC adapters are connected to redundant switches on, so no additional SPOFs are introduced. The redundant infrastructure can be used
by the ordered VLANs.
For some network requirements, such as DR setup replication scenarios, you must check the location of the connected devices and any new
network requirements specific to the software/application in question. In some cases, the IBM Cloud Classic Infrastructure's File or Block
Storage with snapshot backups might fulfill your requirements. Check with IBM Cloud Support to determine which solution works best for your
business needs.

Configure high availability for IBM Power Infrastructure
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services.
The IBM Cloud® environment does not support any pre-configured high-availability (HA) scenarios for SAP. However, you can configure HA
scenarios based on the HA extension for the operating system you choose.
You add the HA extension by adding the required hardware and the required software components to your landscapes. If you require more
software licenses, access to different software repositories, or both, contact IBM Cloud Support to help you with setting up any additional
requirements. In general, setup procedures do not differ from any setup procedures in an on-premises environment and require the same
hardware and software configuration steps. For specific instructions on how to set up HA for IBM Power Virtual Server, see High Availability
and Disaster Recover options in IBM Power Virtual Server.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 120

SAP Business Applications additional design considerations
SAP S/4HANA
SAP S/4HANA is the leading Enterprise Resource Planning (ERP) software that is designed for the largest enterprises, in any country worldwide
within any industry, with extensive business processes and customization.
ERP software integrates all business management and operations into one cohesive application to coordinate business execution, such as
accounting and financials, purchasing and inventory, sales and customer relationships. An ERP can be considered a hub of all business
operations. Various applications and all parts of the business can be connected into ERP, from the factory to the headquarters. The ERP
software as a whole can have many add-on components (functional and industry) that provide different business functions for different lines of
businesses and industries.
SAP S/4HANA is a major release of ERP software from SAP designed to run with the SAP HANA database exclusively. Previous major releases
of ERP from SAP, known as SAP ECC and SAP R/3, could use various relational database vendors.
SAP S/4HANA acts as the "Digital Core" for large enterprises with upgraded UX, business workflows, and technology upgrades, to enable as
many extensions as possible using Cloud Native technologies.
For more information, see SAP S/4HANA
IBM Cloud® for SAP infrastructure options are certified to SAP NetWeaver application server and SAP HANA database server, which run the SAP
S/4HANA business application.

Preface: variants of SAP S/4HANA
The SAP S/4HANA business application has multiple variants, each with different functional and customization levels, which are available as
different operational models. The model that you select affects the SAP S/4HANA deployment.
Primarily the software operational models are grouped into two categories:
SAP S/4HANA "AnyPremise" (formerly "On-Premise" Edition), which is the same software installation and hosting by the business or a
business’s subcontractors. This option provides the business full control over the functions and deployment of the software, but with
more deployment effort and management overheads to keep the SAP Systems running.
SAP S/4HANA Cloud SaaS, which is the same software but installed and hosted by SAP along with SAP Partner subcontractors. This
model provides the business with less control over the software functions and deployment, but with less deployment effort and
management overheads to keep the SAP Systems running.
Within each of the software operational models, multiple software deployment options are available:
SAP S/4HANA "AnyPremise” Edition (formerly "On-Premise" Edition)
Deployment to existing Traditional On-Premises data center
Deployment to Cloud IaaS
SAP S/4HANA Cloud SaaS
SAP S/4HANA Public Cloud Extended (EX) Edition, SaaS provided by SAP along with SAP Partner subcontractors
SAP S/4HANA Public Cloud Essentials (ES) Edition, SaaS provided by SAP along with SAP Partner subcontractors
SAP S/4HANA Private Cloud, SaaS extension of SAP HANA Enterprise Cloud (HEC) provided by SAP along with SAP Partner
subcontractors
More information on the variants of SAP S/4HANA software is available from SAP. A concise explanation on the variants of SAP S/4HANA is
available from SAP America, see SAP Community Blogs - Product Information - SAP S/4HANA Cloud Deployment Options (June 17, 2019) .
Note: Regarding SAP S/4HANA, the IBM Cloud® for SAP portfolio documentation refers to SAP HANA and SAP NetWeaver installations
as using SAP-certified Cloud Infrastructure-as-a-Service options for running SAP S/4HANA "AnyPremise" deployment to Cloud IaaS. All
further descriptions in the following sections refer to SAP S/4HANA "AnyPremise".

Additional decisions for implementation and maintenance
In addition to selecting a variant of SAP S/4HANA (the operational model and the deployment model), many SAP-run customers need to make
several other decisions, for example:

SAP S/4HANA adoption strategy
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 121

New SAP customer first-time implementation
ERP Migration (Brownfield)
System Conversion (also known as Brownfield)
Selective Data Transition (that uses Shell Conversion or Mix&Match)
ERP Re-Implementation (Greenfield)

SAP S/4HANA delivery model for the project implementation, from the list of SAP Partners
A Global Systems Integrator (GSI) for SAP
A Managed Services Provider (MSP) for SAP

SAP S/4HANA maintenance model for ongoing support, from the list of SAP Partners
An Application Management Services provider (AMS) for SAP
A Managed Services Provider (MSP) for SAP
A list of all SAP Partners is maintained on the SAP Partner Finder tool. The list has more information about SAP Partners, including:
Partnership category (for example, Consulting & Implementation Services)
Partnership level (for example, Platinum, Gold, Silver)
Awards for these SAP Partners are shown on the SAP Partners information page .
These choices particularly affect how your SAP S/4HANA "AnyPremise" Edition on Cloud IaaS is deployed, operated, and maintained. For
example, a GSI has exceeding depth of experience in implementation, functional configuration and development - with the flexibility to create
a bespoke solution for the business requirements. However, the GSI has less experience in maintenance. Conversely, an MSP has more
restrictions on the implementation to ensure more successful maintenance.
Given the division of skills in traditional on-premises data center implementations of SAP workloads during previous decades, there were
multiple tasks handled by the Data Center Provider. It is suggested to consider the skills of your SAP Partners in the following areas because
the Cloud Service Provider is not responsible for those activities previously fullfilled by the Data Center Provider:
Cloud Account and IAM setup
Networking setup (including security)
Storage setup
Infrastructure Sizing for SAP
OS Configuration (including security)
Further information on Moving SAP Workloads is described in the FAQ.

Compute considerations
Depending on the business requirements and risk acceptance, the primary decision for any Cloud IaaS running SAP workloads which Cloud
Tenancy model to use:
Single-Tenant infrastructure, dedicated compute resources that are accessed with a private logical network within the Cloud provider
network backbone that uses:
Bare Metal
Virtual Servers on Dedicated Hosts
VMware SDDC
Multi-Tenant infrastructure, shared compute resources that are accessed with a private logical network within the Cloud provider
network backbone that uses Virtual Servers
After you decide on the Cloud Tenancy model that meets your business and IT risk needs, the focus is then on sizing and throughput
requirements:
Output of your SAP Sizing activities
Benchmark metric "SAPS", which demonstrates the total transactional throughput of the Infrastructure
More information that compares different Infrastructure types is in Comparing the different SAP-certified IaaS offerings with more detail under
Infrastructure certified for SAP. All SAPS benchmarks are listed for each Profile under each Infrastructure type that is offered in the IBM
Cloud® for SAP portfolio.

SAP HANA considerations
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 122

The SAP S/4HANA business application is affected by multiple SAP HANA Database Server design considerations .
SAP S/4HANA is considered a "Mixed Workload", as the business application primarily does Transactional processing (OLTP), but SAP
S/4HANA also does Analytical processing (OLAP) through SAP S/4HANA Embedded Analytics.
During SAP Sizing, decision making, and Infrastructure selection, SAP S/4HANA is often considered as OLTP only. This representation is not a
fully accurate view of the business application, but serves as the closest representation for use with SAP Benchmarks information. However,
for the SAP HANA infrastructure, the sizing is most often determined by the Memory (DRAM) capacity size.

Scale-up and Scale-out
It is important to note that if you are using SAP HANA in scale-out deployment the transaction throughput of the system might be affected.
SAP Note 2428711 - S/4HANA Scale-Out Sizing limits an SAP HANA scale-out to up to four nodes in total. This limit applies to S/4HANA
deployments on IBM Cloud to prevent our customers from experiencing transactional throughput issues. IBM Cloud® for SAP does not actively
publish those specifications.
Instead, we advise customers who have exceptionally large SAP HANA requirements for running an SAP S/4HANA production instance
(particularly those requirements over 14-18TB of DRAM) to discuss their requirements with IBM-SAP. Discussions with IBM and SAP
worldwide technical experts can provide more accurate advice on the business problem and identify alternative paths forward.
Alternates can include, the creation of a Hybrid Cloud model with the use of the available high-performance scale-up options in traditional
datacenter deployments.
An example of Hybrid Cloud used with SAP S/4HANA when exceeding 14-18TB of DRAM, would be the use of IBM Power9 hardware provided
by IBM Power Systems, deployed into Traditional On-Premises datacenters. The maximum IBM Power9 hardware can support 28TB of
DRAM for SAP HANA 2.0 scale-up. These complementary offerings are already succesfully running many customers SAP workloads at these
largest memory footprints, through a close partnership and engineering discussions with SAP, therefore may suit the business needs for such
exceptional scale-up requirements. For more information regarding SAP HANA on IBM Power Systems, see SAP Note 2188482 - SAP HANA on
IBM Power Systems: Allowed Hardware.

SAP NetWeaver considerations
The SAP S/4HANA business application is impacted by multiple SAP NetWeaver Application Server design considerations .

Versioning and upgrades
SAP S/4HANA no longer has a stand-alone shipment of SAP NetWeaver Application Server (ABAP) which can be used.
The SAP S/4HANA Server component is required to install SAP S/4HANA. This component is briefly titled as SAP ABAP Platform and
historically called SAP NetWeaver AS ABAP.
For SAP S/4HANA "AnyPremise" 20xx (for example, 2020), the SAP S/4HANA Server contains:
SAP ABAP Platform 20xx and SAP Kernel 7.7x (the version number of these components are only shown after the installation is
completed)
ADT for Eclipse
Other additional technology components to run SAP S/4HANA
Important: For this reason, when you are running older SAP S/4HANA versions (such as 1511, 1610, 1709) it is not possible to
upgrade SAP NetWeaver AS ABAP 7.5+ in isolation. All upgrades must be handled by using SAP Maintenance Planner for the entire
stack on a specified OS (for example, Red Hat Linux®, SUSE Linux, IBM AIX, Windows Server).

SAP BW/4HANA
SAP BW/4HANA is the leading enterprise data warehouse (EDW) software, which is designed for analyzing mass amounts of structured and
unstructured data from multiple sources. EDW software deciphers business data into tangible and actionable insights that are used for
reporting business performance against metrics and identifying opportunities or gaps in existing business practices.
SAP BW/4HANA is a major release of EDW software from SAP designed to use the analytical capabilities of the SAP HANA database exclusively.
Previous major releases of EDW from SAP were known as SAP BW, which might use various relational database vendors. SAP BW/4HANA acts
as the insights engine for large enterprises with upgraded UX, data integration, and technologies upgrades to enable real-time decision making
and digital business processes.
For more information, see SAP BW/4HANA.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 123

IBM Cloud® for SAP infrastructure options are certified to SAP NetWeaver application server and SAP HANA database server, which run the SAP
BW/4HANA business application.

Preface: variants of SAP BW/4HANA and other analytics solutions from SAP
For analytics, there are multiple interlocking solutions from SAP and variants for each solution. The primary SAP analytics solutions are:
SAP BW/4HANA, the EDW software using SAP HANA Platform with runtime database license
SAP Data Warehouse Cloud (SaaS), the EDW software available as-a-Service using SAP HANA Cloud Services
SAP HANA Platform Enterprise Edition, the database server and analytical components when leveraging the full-use license and can be
used to construct custom/native EDW.
The analytical SAP HANA components include Self Service Analytics Library (SAL), Smart Data Access (SDA), Smart Data Integration
(SDI), Smart Data Streaming (SDS), Remote Data Sync (RDS), and in addition, for Hadoop integration, the use of SAP HANA Spark
Controller optionally with SAP Vora.
There are additional SAP analytics solutions, each with different software deployment options, some of which are summarised below:
SAP BW/4HANA
Deployment to existing traditional on-premises data center
Deployment to Cloud IaaS
SAP HANA Platform Enterprise Edition
Deployment to existing traditional on-premises data center
Deployment to Cloud IaaS
SAP HANA Enterprise Cloud (HEC), Managed DBaaS
SAP HANA Cloud Services
SAP HANA Cloud, DBaaS (released in 2020 to replace SAP HANA Service, which in 2018 replaced SAP HANA One)
SAP Analytics Cloud, SaaS
SAP Data Warehouse Cloud, SaaS
SAP Business Objects Business Intelligence Suite (BOBJ/BO-BI)
SAP Data Intelligence 3.x, using Kubernetes (released in 2019 to replace SAP Data Hub 2.x)
More information on the variants of SAP analytics solutions is available from SAP:
SAP.com - Business Analytics Tools and Solutions
SAP Community Blogs - Technical Articles - SAP (HANA) Cheat Sheet
Note: Regarding SAP BW/4HANA, the IBM Cloud® for SAP portfolio documentation refers to SAP HANA and SAP NetWeaver
installations as using SAP-certified Cloud Infrastructure-as-a-Service options for running SAP BW/4HANA deployment to Cloud IaaS.

Additional decisions for implementation and maintenance
The project implementation and maintenance/support of SAP BW/4HANA selects from the list of SAP Partners:
Project implementations
A Global Systems Integrator (GSI) for SAP
A Managed Services Provider (MSP) for SAP
Maintenance/support
An Application Management Services provider (AMS) for SAP
A Managed Services Provider (MSP) for SAP
A list of all SAP Partners is maintained on the SAP Partner Finder tool. The list has more information about SAP Partners, including:
Partnership category (for example, Consulting & Implementation Services)
Partnership level (for example, Platinum, Gold, Silver)
Awards for these SAP Partners are shown on the SAP Partners information page .
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 124

These choices particularly affect how your SAP BW/4HANA on Cloud IaaS is deployed, operated, and maintained. For example, a GSI has
exceeding depth of experience in implementation, functional configuration, and development - with the flexibility to create a bespoke solution
for the business requirements. However, the GSI has less experience in maintenance. Conversely, an MSP has more restrictions on the
implementation to ensure more successful maintenance.
Given the division of skills in traditional on-premises data center implementations of SAP workloads during previous decades, there were
multiple tasks handled by the Data Center Provider. It is suggested to consider the skills of your SAP Partners in the following areas because
the Cloud Service Provider is not responsible for those activities previously fullfilled by the Data Center Provider:
Cloud account and IAM setup
Networking setup (including security)
Storage setup
Infrastructure sizing for SAP
OS configuration (including security)
Further information on Moving SAP Workloads is described in the FAQ.

Compute considerations
Depending on the business requirements and risk acceptance, the primary decision for any Cloud IaaS running SAP workloads is which Cloud
Tenancy model to use:
Single-tenant infrastructure, dedicated compute resources that are accessed with a private logical network within the cloud provider
network backbone that uses:
Bare metal
Virtual servers on dedicated hosts
VMware SDDC
Multi-tenant infrastructure, shared compute resources that are accessed with a private logical network within the cloud provider
network backbone that uses virtual servers.
After you decide on the Cloud Tenancy model that meets your business and IT risk needs, the focus is then on sizing and throughput
requirements:
Output of your SAP sizing activities
Benchmark metric "SAPS", which demonstrates the total transactional throughput of the infrastructure
More information that compares different infrastructure types is in Comparing the different SAP-certified IaaS offerings with more detail under
Infrastructure certified for SAP. All SAPS benchmarks are listed for each profile under each infrastructure type that is offered in the IBM Cloud®
for SAP portfolio.

SAP HANA considerations
The SAP BW/4HANA business application is an analytical processing (OLAP) workload and is affected by multiple SAP HANA Database Server
design considerations.
During SAP sizing, decision making, and infrastructure selection for the SAP HANA infrastructure to support OLAP workloads, the sizing is most
often determined by the memory (DRAM) capacity size.

Scale-up and Scale-out
SAP BW/4HANA is built to take advantage of the analytical capabilities of SAP HANA and is regularly used in scale-out scenarios to analyze
huge volumes of data (including data beyond ERP transactional data, such as Hadoop data lakes).
It is important to understand SAP BW/4HANA certifications to ensure your infrastructure selection meets business requirements, particularly
for business decisions on lead times of analytics and reporting or quantity of data to be analyzed.
All SAP-certified infrastructure on Cloud for OLAP (i.e. SAP BW/4HANA) is listed in SAP HANA Directory - Certified IaaS Platforms - OLAP
application type. For performance benchmarks of the SAP-certified infrastructure for SAP BW/4HANA, these are listed in the SAP BW edition
for SAP HANA benchmark directory (BWH).
There are a few considerations to be mindful of when looking at the directories from SAP and comparing infrastructure performance for SAP
BW/4HANA:
The CSV Export file of the SAP BWH benchmark directory will not contain important configuration notes, such as "Segmentation" notes

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 125

where the quoted memory is reduced (for example, 4,048 GB DRAM is only permitted with 3,904 GB DRAM). This often occurs when the
certified infrastructure is a virtual machine. This is also not shown on the main site; it is only viewable on the certification PDF of each
certified infrastructure.
The benchmark certification is for a specific number of scale-out nodes; however, this is multipled by SAP for the IaaS certification so
that the same tested infrastructure configuration might be approved for additional scale-out (reaching larger total memory footprint).
Benchmark certification example: 8 scale-out nodes which includes the 1 Parent + 7 Child nodes; using
infrastructure with 6,144 GB DRAM for total memory of 49,152 GB

IaaS certification based on the same benchmark certification example: 16 scale-out nodes which includes 15 Active nodes
(1 Parent + 14 Child nodes) + 1 Standby node; using infrastructure with 6,144 GB DRAM for total memory of
92,160 GB

The following table provides examples of how these benchmarks could be inferred to help the business perform sizing decisions for SAP
BW/4HANA:
Benchmark data point:

Phase 1: Data load

Phase 2: Query executions

Phase 2:

Phase 3: Runtime of

(by sequence shown in

(seconds)

per hour

Records

complex query phase

selected

(seconds)

Higher is
better

Lower is better

benchmark reports)
Measurement interpretation:

Lower is better

Higher is better

Benchmark impacting
factors:

Impacted by quantity
of initial records to
load

Impacted by number of
records selected in Phase 2

Impacted by number of
records selected in Phase 2

Example comparison
calculation for infrastructure
selections (attempts to
account for the impacting
factors):

Seconds to load 1
billion records might
help comparisons of
read from storage

Total records parsed per hour
during Query Execution might
help comparisons of
calculations performed by
CPU

Total records parsed per
minute during complex
query might help
comparisons of
calculations performed by
CPU

(for example,
divide Phase 1

(for example, multiply

data load in

query executions per hour

(for example, divide

seconds by initial

by records selected)

records selected by

records)

runtime of complex
query seconds, then
multiply by 60)

Table 1. Examples of inferring benchmark results into sizing decisions

Additional SAP Notes regarding SAP BW/4HANA and sizing for scale-out:
SAP Note 2296290 - New Sizing Report for SAP BW/4HANA
SAP Note 2347382 - SAP BW/4HANA – General Information (Installation, SAP HANA, security corrections…)
SAP Note 2561976 - SAPBWNews SAP BW/4HANA 1.0 SP 08
SAP Note 2908965 - SAPBWNews SAP BW/4HANA 2.0 SP 06
SAP Note 2671297 - SAP BW on SAP HANA and SAP BW/4HANA in a SAP HANA, active/active read-enabled option environment

SAP Commerce
SAP Commerce (formerly SAP Hybris Commerce) is part of the Customer Experience (CX) portfolio under the SAP C/4HANA suite.
Due to the design and business purpose and the nature of SAP Commerce, the installation, deployment, and additional development code is
much more suited to a DevOps way of working. Project teams often use agile SDLC/PM methodologies (such as Scrum or SAFe). As an example
of the flexibility, SAP Commerce runs across multiple different Operating Systems that are supported by SapMachine, a downstream OpenJDK
release that is maintained and supported by SAP.
Therefore, deployments of SAP Commerce are available in different variants; we detail the following to assist understanding what IBM Cloud®
for SAP can provide:
SAP Commerce "on-premises edition" variants:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 126

SAP Commerce "on-premises edition" with on-premises data center
SAP Commerce "on-premises edition" on Cloud IaaS
SAP Commerce Cloud (PaaS solution) variants:
SAP Commerce Cloud hosted on SAP Infrastructure (also known as CCv1 using VMs)
SAP Commerce Cloud in the Public Cloud (also known as CCv2 using Kubernetes)
Within the IBM Cloud® for SAP portfolio, infrastructure is supported for SAP Commerce "on-premises edition" on Cloud IaaS .
This solution involves an installation of the SAP Commerce software onto Cloud IaaS, according to SAP installation and best practice guidance:
SAP Commerce (on-premises) Installation and Upgrades
SAP Commerce (on-premises) Architecture options are Single Node, Cluster Node, and Multi-Tenant Node
For a typical development environment of SAP Commerce, it is straightforward (compared to other SAP software) to shut down the
instantiation/s and reduce costs outside of business hours through less Cloud resource consumption; however, depending on the
implementation the time to start again can be significant. This decision is required by the project team, and might not be suitable if a worldwide
development team is in-place.
More information is available on cxwiki.sap.com and sap.com/cxworks.
Note: IBM Power Virtual Servers are not available for SAP Commerce.

SAP ECC
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

SAP HANA considerations
Content

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 127

Scale-up/Scale-out
Content

HA/DR
Content

SAP NetWeaver considerations
Content

AnyDB considerations
Content

Operating Systems supported
Content

SAP BW
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

SAP HANA considerations
Content

Scale-up/Scale-out

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 128

Content

HA/DR
Content

SAP NetWeaver considerations
Content

AnyDB considerations
Content

Operating Systems supported
Content

SAP Business One (B1)
SAP Business One is an enterprise resource planning (ERP) software that is especially designed for small-to-medium enterprises. It integrates
business management - accounting and financials, purchasing and inventory, sales and customer relationships, and project management and
operations - into one application.
The single application eliminates the need for multiple installations and interfaces across separate modules. As your business grows, you can
expand SAP Business One to fit your needs by adding one of over 500 add-on solutions from SAP Partners. It runs on both the SAP HANA and
Microsoft SQL Server platforms and helps with the day-to-day operations of your enterprise. For more information, see SAP Business One
Several IBM Cloud® for SAP infrastructure options are certified to run SAP Business One.
Before you implement SAP Business One, considerations need to be made how are you going to use the application. For example, how many
concurrent users will use the application at one time? Do you need only the Financial Management and Sales and Customer Management
modules to start? Maybe you need all the modules (for more information about modules, see SAP Business One Features ).

SAP Business One installation guides
You have the choice of working with an SAP partner or installing the software yourself onto Cloud IaaS.
The main documentation to read for SAP Business One are:
SAP Help Portal - SAP Business One on SAP HANA
SAP Help Portal - SAP Business One on Microsoft SQL Server
After which, the administrator guides to read for SAP Business One are:
SAP Business One on SAP HANA Administrator Guide
SAP Business One on Microsoft SQL Administrator Guide
Lastly, review the hardware requirements guidance for SAP Business One:
Latest SAP Business One Hardware Requirements Guide
SAP Business One Platform Support Matrix
For a list of Microsoft Windows Server versions supported for the following SAP Business One server platforms, see the

SAP Business One

Platform Support Matrix.
More information on SAP HANA versions can be found in
SAP Note 2058870 - SAP Business One, version for SAP HANA on public Infrastructure-as-a-Service (IaaS) platforms .
SAP Note 2801340 - Overview Note for SAP Business One 9.3 PL11, version for SAP HANA .
SAP Note 3328136 - Overview Note for SAP Business One 10.0 FP 2208 Hotfix 02, version for SAP HANA .
SAP Note 3284687 - Overview Note for SAP Business One 10.0 FP 2305, version for SAP HANA .
The SAP Business One community page has links to blogs where community members share their experiences with implementing and running
SAP Business One.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 129

SAP Business One upgrade guides
SAP Business One offers you several upgrade options when a new release is available.
These options are available if you're using SAP HANA or Microsoft SQL. See the SAP Business One upgrade patches and programs information
for more detail on upgrades, patches, and hot fixes.

SAP Business One training information
Training is available on the integration framework for SAP Business One. The self-paced, online course takes you through scenario design
basics, the integration of SAP Business One, and integrating the SAP Business One database. For more information, see the OpenSAP courses
on SAP Business One.
Training is also available on the different SAP Business One modules. For more information about courses, see

SAP Training for Business One

or the online training available with SAP Learning Hub.

Infrastructure options for SAP Business One
Please check SAP Business One, version for SAP HANA Platform Support Matrix for supported OS versions of your SAP Business One release.
All the listed IBM Cloud servers for SAP Business One on SAP HANA show the certified SLES operating systems versions.
SAP Business One is supported on the following Bare Metal servers:
on Classic
BI.S3.H2.192
BI.S3.H2.384
BI.S3.H2.768
BI.S4.H2.192
BI.S4.H2.384
BI.S4.H2.768
on VPC
cx2d-metal-96x192
bx2d-metal-96x384
mx2d-metal-96x768
SAP Business One is also supported for the following Intel virtual server profiles:
on VPC
mx2-8x64
mx2-16x128
mx2-32x256
mx2-48x384
Note: IBM Power Virtual Servers are not available for SAP Business One

SAP Business Objects (BO-BI)
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
This document describes the considerations for SAP Business Objects Business Intelligence Suite (BOBJ/BO-BI).
SAP BusinessObjects as listed in SAP Note 2279688

Usage considerations
Content

Common Scenarios
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 130

Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

SAP HANA considerations
Content

AnyDB considerations
Content

Operating Systems supported
Content

SAP Data Hub 2.x
SAP Data Hub 2.x is a distributed data orchestration and management software for creation of data-driven business processes. SAP Data Hub
2.x is replaced by SAP Data Intelligence 3.x.
Installation of SAP Data Hub 2.x is available for Red Hat OpenShift on IBM Cloud. The OpenShift platform is managed by IBM Cloud, but you
have full control of the size and number of worker nodes available for deployment worldwide.
Note: This documentation appends to Red Hat's article SAP Data Hub 2 on OpenShift Container Platform 3 (referred as acronym RHA )
Any considerations or guidance that is provided by IBM Cloud® for SAP, does not replace implementation documentation for Red Hat OpenShift
and SAP Data Hub.
Many of the implementation steps are in the SAP Data Hub 2 on OpenShift Container Platform 3 article (RHA) . The How To guidance provides
the additional IBM Cloud-specific steps:
Planning your deployment
Deploying your OpenShift cluster and jump host
Preparation and Installation of SAP Data Hub

Before you begin with SAP Data Hub 2.x and Red Hat OpenShift on IBM Cloud
To get started, you need to be familiar with IBM Cloud, OpenShift, and SAP Data Hub. Depending on your current level of knowledge, read
some or all of the following documentation.
Containers and Kubernetes...
What are Containers?

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 131

What is Kubernetes?
What is Red Hat OpenShift on IBM Cloud?
Red Hat OpenShift on IBM Cloud information...
Getting started with Red Hat OpenShift on IBM Cloud
Tutorial: Creating Red Hat OpenShift on IBM Cloud clusters
SAP Data Hub information...
What is SAP Data Hub?
Review the Requirements for SAP Data Hub 2.7.x on OpenShift Container Platform 3.x

Usage considerations
SAP Data Hub provides a simple, scalable approach to manage, integrate, process, and govern data. It provides data orchestration and
metadata management across heterogeneous data sources.
The SAP Data Hub is a fundamental technology in the SAP strategy. Part of the digital platform, SAP Data Hub is a connector and processing
layer on which to build new applications. By enabling connections across the whole SAP product portfolio, SAP Data Hub helps the business
build their Intelligent Enterprise.

Common Scenarios
Use Case

Details

IOT Sensor Data Ingestion

Integrate and transform data streams from any sensor or device into data that can be used by ERP,
AI/ML, and other Big Data services

Big Data, Machine Learning,
Artificial Intelligence

Move your data science projects from PowerPoint to operational applications, gleaning real insight from
what you’re already collecting

Data Warehousing

Make it possible to add disparate data streams into your data warehouse, and transform it from an
archival reporting system to a core business value

Master Data and Governance

Automate your metadata tagging and discovery, understand what data is coming from where, and
control who can see the data based on security and privacy standards
Table 1. Common scenarios for SAP Data Hub

SAP Data Intelligence 3.x (inc. SAP Data Hub)
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
SAP Data Intelligence 3.x (inc. SAP Data Hub) on IBM Cloud

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 132

Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 133

SAP Technical Applications additional design considerations
SAP Router
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

SAP Web Dispatcher
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content
SAP Note 2740052 - Which paths are necessary to configure Web Dispatcher for Fiori Launchpad scenarios?
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 134

https://launchpad.support.sap.com/#/notes/2740052
SAP Web Dispatcher SSL Trust Configuration How to Configure SAP Web Dispatcher to Trust Backend System SSL Certificate
https://wiki.scn.sap.com/wiki/download/attachments/462038592/WebDispatcherSSLTrustConfiguration.pdf?
version=1&modificationDate=1486589618000&api=v2

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

SAP Fiori Front-end Server
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 135

Content

SAP Gateway
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

SAP Solution Manager
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 136

Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

SAP Content Server
The SAP Content Server is a stand-alone component for storing large quantities of electronic documents in any format and with any content.
This component can cache the content from several locations the business operates in which reduces network load. To use the SAP Content
Server, your SAP applications must support its use.
The SAP Content Server uses the SAP MaxDB database and one of the following operating systems:
Windows Server
SUSE Linux®
Red Hat Linux
For more information about these supported operating systems releases, see the SAP Product Availability Matrix (PAM).
For more information about the SAP Content Server, see SAP Help and documentation on the SAP NetWeaver Knowledge Server components .

Usage considerations
Note: The SAP Content Server is not an alternative for optical storage and other storage media for long-term document archiving.
Follow the SAP Content Server Installation Guide , found on the SAP Help Portal under "Installation of SAP Content Server". The guide is
available for Windows or Linux.

Adobe Document Services (ADS) for SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 137

Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

SAP Process Orchestration (PO) - Process Integration (PI)
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

SAP Landscape Management (LaMa)
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 138

Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

SAP Secure Logon Server (SLS)
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Usage considerations
Content

Common Scenarios
Content

Networking considerations
Content

Performance
Content

Security
Content

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 139

Storage considerations
Content

Performance
Content

Operating Systems supported
Content

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 140

SAP AnyDB and SAP HANA databases additional design considerations
AnyDB - IBM Db2
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
Deploying SAP AnyDB on IBM Cloud is similar to deployments with infrastructure with on-premises data centers. You can use the information
that is provided from SAP and the RDBMS providers.
To assist your project's planning phase, more design considerations are provided for SAP AnyDB - IBM Db2 with IBM Cloud® for SAP.

Overview of IBM Db2 for SAP with IBM Cloud®
Several unique capabilities and features are available with IBM Db2. All supported database features that are mentioned in SAP Note
1555903 - DB6: Supported IBM Db2 Database Features are available with IBM Cloud, except for:
The IBM Db2 pureScale feature.
Support for integrated cluster managers for HADR or shared disk high-availability clusters.
Before you start deploying the IBM Db2 software, ensure that:
Check all relevant IBM Db2 information and prerequisites.
Check all relevant SAP and IBM Db2 information and prerequisites (for example, SAP Notes). Also, check the versions and fix pack levels
of IBM Db2 that are supported.
All required packages are installed for the relevant OS that you are using for IBM Db2.

Documentation of IBM Db2 for SAP
A good place to start is the SAP community page for IBM Db2 .
IBM Db2 support on SAP-certified Cloud IaaS:
IBM Knowledge Center for Db2 - Support for Db2 on public clouds (BYOSL, SAP Notes, Reference blueprints)
IBM Db2 versions and fix pack levels that are supported by SAP:
SAP Note 101809 - DB6: Supported Db2 Versions and Fix Pack Levels
IBM Db2 11.5 on UNIX/Linux prerequisites documentation:
General IBM Db2 prerequisites on UNIX and Linux®
IBM Db2 and SAP NetWeaver on UNIX/Linux:
Installation of SAP Systems based on the Application Server ABAP of SAP NetWeaver 7.1 to 7.52 on UNIX: IBM Db2 LUW
Installation of SAP Systems based on the Application Server Java of SAP NetWeaver 7.1 to 7.5 on UNIX: IBM Db2 LUW
SAP Note 1707361 - Inst. Systems based on NW 7.1 and Higher: UNIX Db2 for LUW
IBM Db2 and SAP NetWeaver on Windows:
Installation of SAP Systems based on the Application Server ABAP of SAP NetWeaver 7.1 to 7.52 on Windows: IBM Db2 LUW
Installation of SAP Systems based on the Application Server Java of SAP NetWeaver 7.1 to 7.5 on Windows: IBM Db2 LUW
SAP Note 1707362 - Inst. Systems based on NW 7.1 and Higher: Windows Db2 LUW
Note: In the IBM Knowledge Center for Db2, the documentation links provided refer to specific pages on an IBM Db2 version. You can
switch to the correct version by clicking the "Change version or product" in the upper left area of the IBM Knowledge Center.

SAP on IBM Db2 using Intel Bare Metal
See SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment for supported IBM Db2 database versions.
A sample configuration is shown in:
Quick Study Tutorial - SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, using RHEL
Quick Study Tutorial - SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, using Windows Server
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 141

SAP on IBM Db2 using Intel Virtual Servers
See SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment for supported IBM Db2
database versions.
A sample configuration is shown in:
Quick Study Tutorial - SAP NetWeaver deployment to Intel Virtual Server on VPC Infrastructure, using RHEL

SAP on IBM Db2 using IBM Power Virtual Servers
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services
See SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers for supported IBM Db2 database versions on AIX running on IBM
Power Virtual Servers.

Infrastructure size considerations
When you use IBM Db2 with SAP applications, follow the general SAP sizing rules as described in the SAP Quick Sizer documentation. However,
certain IBM Db2 functions require special considerations.
When you use IBM Db2 columnar organized tables, also known as IBM Db2 BLU Acceleration, the minimal recommended server configuration
is 64 GB memory and 4 CPU cores exclusively available for the database workload. For more information about sizing and usage of Db2 BLU
Acceleration, see SAP Note 1819734 - DB6: Use of BLU Acceleration .

File Systems for IBM Db2
The following information describes the File Systems that are required for IBM Db2 with SAP NetWeaver:
Recommended file system types for Db2
Required file systems for IBM Db2 with SAP NetWeaver ABAP (example is for Unix/Linux)

SWPM and IBM Db2 port conflict
The default port is 5912 for the TCP/IP communication between the Db2 server and the Db2 client when you are using SWPM to install SAP
software.
However, this port is already defined and reserved by the IANA Service Name and Transport Protocol Port Number Registry .
Choose a different port during the installation with SWPM.
Alternatively, it is possible to remove the entry for this port number from the /etc/services file:
$ ...
cpdlc

5911/sctp

# Controller Pilot Data Link Communication

fis

5912/tcp

# Flight Information Services

fis

5912/udp

# Flight Information Services

fis

5912/sctp

# Flight Information Services

ads-c

5913/tcp

# Automatic Dependent Surveillance

...

SAP application-specific considerations
SAP Business Warehouse with IBM Db2
When Using SAP Business Warehouse with the DB2 Database Partitioning Feature, a stable and fast network connections need to be
established between all hosts in the Db2 DPF cluster. For details, check the following Information: SAP Business Warehouse on IBM Db2 for
Linux, UNIX, and Windows 10.5 and Higher: Administration Tasks.

AnyDB - Microsoft SQL Server
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
Deployment of SAP AnyDB on IBM Cloud is similar to deployments with infrastructure with on-premises data centers. Therefore, use the
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 142

information that is provided from SAP and the RDBMS providers.
To assist your project's planning phase, there are additional design considerations for SAP AnyDB - Microsoft SQL Server with IBM Cloud® for
SAP.

Overview of MS SQL Server for SAP with IBM Cloud
Before you start deploying the MS SQL Server software, ensure that:
Check all relevant SAP and MS SQL Server information and prerequisites (for example, SAP Notes); including versions and fix pack levels
of MS SQL Server that are supported
All required packages are installed for the relevant OS that you are using for MS SQL

Documentation of MS SQL Server for SAP
A good entry point into the documentation is the SAP community page for MS SQL Server For a current overview of the combinations of MS SQL
Server, SAP NetWeaver (or other SAP components), and operating systems - see the Product Availability Matrix (PAM).
MS SQL Server database and SAP NetWeaver on Windows
Installation of SAP Systems Based on the Application Server ABAP of SAP NetWeaver 7.3 EHP1 to 7.52 : MS SQL Server
Installation of SAP Systems Based on the Application Server Java of SAP NetWeaver 7.5 and SAP Solution Manager 7.2 SR2 Java : MS
SQL Server
MS SQL Server licensing supported by SAP
SAP Note 1491158 - Information About the Microsoft SQL Server License Scope
SAP Note 398136 - Support Policy for Microsoft SQL Server
MS SQL Server release/support information
SAP Note 2807743 - Release planning for Microsoft SQL Server 2019
SAP Note 2779625 - Setting up Microsoft SQL Server 2019
SAP Note 2492596 - Release planning for Microsoft SQL Server 2017
SAP Note 2484674 - Setting up Microsoft SQL Server 2017
SAP Note 2201059 - Release planning for Microsoft SQL Server 2016
SAP Note 1177356 - MS SQL Server: End of Support for SAP Releases
SAP Note 62988 - Service packs for MS SQL Server

SAP on MS SQL Server using Intel Bare Metal
See SAP Note 2414097 - SAP Applications on IBM Cloud: Supported DB/OS and IBM Cloud Bare Metal Server Types for supported MSSQL
database versions.
A sample configuration is shown in:
Quick Study Tutorial - SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, using Windows Server

SAP on MS SQL Server using Intel Virtual Servers (Gen2)
See SAP Note 2927211 - SAP Applications on IBM Virtual Private Cloud: Supported DB/OS and IBM Gen 2 Virtual Server Instances for
supported MSSQL database versions.
A sample configuration is shown in:
SAP NetWeaver deployment to Intel Virtual Server (Gen2) on VPC Infrastructure that uses Windows Server

AnyDB - Oracle DB
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 143

To assist your project's planning phase, there are additional design considerations for SAP AnyDB - Oracle DB.
Oracle product deployments are only supportable in two circumstances:
1. Oracle product deployments with IBM Power Virtual Servers , a complementary offering from IBM Power Systems with low latency
access to IBM Cloud services. With Oracle and IBM Power, these deployments are made to the same enterprise infrastructure setup.
More information can be found here.
2. Oracle product deployments with support from an SAP Partner , either Managed Services Provider (MSP) or Application Management
Services (AMS), is contracted for support of Oracle products and is an Oracle Partner with the relevant Oracle Support contracts.
Many customers run Oracle products on IBM Cloud today leveraging these methods.
In any other circumstance, deployments of Oracle products to Infrastructure-as-a-Service offerings from IBM Cloud will not be supported by
Oracle, which results in SAP not supporting Oracle-based workloads on the SAP-certified Infrastructure-as-a-Service from IBM Cloud.

Infrastructure size considerations
Content

Networking performance considerations
Content

Storage performance considerations
Content

Oracle DB RAC
Content

COPIED
SAP on Oracle
See SAP Note 2855850 for supported Oracle Database versions on AIX running on IBM Power Virtual Servers. For the installation procedure,
see the SAP online documentation:
Installation of SAP Systems Based on the Application Server ABAP of SAP NetWeaver 7.1 to 7.52 on UNIX : Oracle
Installation of SAP Systems Based on the Application Server Java of SAP NetWeaver 7.1 to 7.5 on UNIX: Oracle

AnyDB - SAP MaxDB
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
Deploying SAP AnyDB on IBM Cloud is similar to deploying the infrastructure with on-premises data centers. Therefore, use the information
that is provided from SAP and the RDBMS providers.
To assist your project's planning phase, extra design considerations are listed for SAP AnyDB - SAP Max DB with IBM Cloud® for SAP.

Overview of SAP MaxDB with IBM Cloud®
Before you start deploying SAP MaxDB software, be sure to:
Check all relevant SAP MaxDB information and prerequisites (for example, SAP Notes)
Verify that all required packages are installed for the relevant OS that that is used for SAP MaxDB

Documentation of SAP MaxDB
A good entry point into the documentation is the SAP community page for SAP MaxDB .
SAP MaxDB documentation:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 144

SAP Help Portal - SAP MaxDB
SAP Note 767598 - Available SAP MaxDB documentation
SAP Note 1020175 - FAQ: SAP MaxDB installation, upgrade, or applying a patch
For a current overview of the combinations of SAP MaxDB, SAP NetWeaver (or other SAP components), and operating systems, see the

Product

Availability Matrix (PAM).

SAP MaxDB using Intel Bare Metal
See SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment for supported SAP MaxDB versions.

SAP MaxDB using Intel Virtual Servers
See SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment for supported SAP MaxDB
versions.

SAP MaxDB using IBM Power Virtual Servers)
See SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers for supported SAP MaxDB versions.

AnyDB - SAP ASE
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
Deployment of SAP AnyDB on IBM Cloud is similar to deployments with infrastructure with on-premises data centers. Therefore, use the
information that is provided from SAP and the RDBMS providers.
To assist your project's planning phase, more design considerations are provided for SAP AnyDB - SAP ASE with IBM Cloud® for SAP.

Overview of SAP ASE with IBM Cloud®
Before you start the software deployment of SAP ASE, ensure that:
Check all relevant SAP ASE information and prerequisites (for example, SAP Notes)
All required packages are installed for the relevant OS that is used for SAP ASE

Documentation of SAP ASE
A good entry point into the documentation is the SAP Community page for SAP Adaptive Server Enterprise (ASE)
SAP ASE documentation:
SAP Help Portal - SAP Adaptive Server Enterprise (ASE)
SAP Help Portal - SAP Adaptive Server Enterprise (ASE) Installation and Upgrade Guide for Linux®
SAP Help Portal - SAP Adaptive Server Enterprise (ASE) Installation and Upgrade Guide for IBM AIX
SAP Help Portal - SAP Adaptive Server Enterprise (ASE) Installation and Upgrade Guide for Windows
SAP Note 1748888 - Installing Systems Based on NW 7.3 and Higher: SAP ASE
SAP Note 2489781 - SAP ASE 16.0 SP03 Supported Operating Systems and Versions
For a current overview of the combinations of SAP ASE, SAP NetWeaver (or other SAP components), and operating systems - see the

Product

Availability Matrix (PAM)
SAP ASE and SAP NetWeaver on UNIX/Linux:
Installation of SAP Systems Based on the Application Server ABAP of SAP NetWeaver 7.3 to 7.52 on UNIX/Linux: SAP Adaptive Server
Enterprise
Installation of SAP Systems Based on the Application Server Java of SAP NetWeaver 7.3 to 7.5 on UNIX/Linux: SAP Adaptive Server
Enterprise
SAP ASE and SAP NetWeaver on Windows:
Installation of SAP Systems Based on the Application Server ABAP of SAP NetWeaver 7.3 to 7.52 on Windows: SAP Adaptive Server
Enterprise
Installation of SAP Systems Based on the Application Server Java of SAP NetWeaver 7.3 to 7.5 on Windows: SAP Adaptive Server
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 145

Enterprise

SAP ASE using Intel Virtual Servers
See SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment for supported SAP ASE
database versions.

SAP ASE using IBM Power Virtual Servers
Note: This is a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services.
See SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers for supported SAP ASE database versions on AIX running on IBM
Power Virtual Servers.

AnyDB - SAP IQ
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
Deployment of SAP AnyDB on IBM Cloud is similar to deployments with infrastructure with on-premises data centers. Therefore, use the
information that is provided from SAP and the RDBMS providers.
To assist your project's planning phase, more design considerations for SAP AnyDB - SAP IQ with IBM Cloud® for SAP are provided.

Overview of SAP IQ with IBM Cloud
Before you start deploying the SAP IQ software:
Check all relevant SAP IQ information and prerequisites (for example, SAP Notes)
Verify that all required packages are installed for the relevant OS that is used for SAP IQ

Documentation of SAP IQ
A good entry point into the documentation is the SAP Community Wiki for SAP IQ.
SAP IQ documentation:
SAP Help Portal - SAP IQ
For a current overview of the combinations of SAP IQ, SAP NetWeaver (or other SAP components), and operating systems, see the

Product

Availability Matrix (PAM).

SAP HANA Database
The SAP systems in a landscape have specific requirements for servers, operating systems, network setup, and supported storage.
To assist your project's planning phase, more design considerations are provided for SAP HANA Database with IBM Cloud® for SAP.

SAP HANA Database Overview
SAP HANA offers a robust set of capabilities, including database management, database administration, data security, multi-model processing,
application development, and data virtualization.
The SAP HANA database is a hybrid in-memory database that combines row-based, column-based, and object-based database technology. It
allows online transaction processing (OLTP) and online analytical processing (OLAP) on one system, without the need for redundant data
storage or aggregates.
It is optimized to exploit the processing capabilities of multi-core/CPU architectures. With this architecture, SAP applications can benefit from
current bar down technologies.
The SAP HANA database is the heart of SAP’s in-memory technology offering, helping customers to improve their operational efficiency,
agility, and flexibility.

Overview of SAP HANA database for SAP NW with IBM Cloud

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 146

Before you start deploying the SAP HANA database, ensure that:
Only software installed by certified hardware partners, or any person holding certification, is recommended for use on the SAP HANA
system. Do not install any other software on the SAP HANA system. The components of SAP HANA can only be installed by certified
hardware partners, or any person holding certification. Furthermore, it must be installed on validated hardware running an approved
operating system.
An SAP HANA system comprises multiple isolated databases and may consist of one host or a cluster of several hosts.
An SAP HANA system is identified by a single system ID (SID) and contains one or more tenant databases and one system database.
Databases are identified by a SID and a database name. From the administration perspective, there is a distinction between tasks
performed at system level and those performed at database level. Database clients, such as the SAP HANA cockpit, connect to specific
databases.
The SAP HANA XS advanced application server is a layer on top of SAP HANA that provides the platform for running SAP HANA-based
Web applications. It is an integral part of the SAP HANA system.
A system may consist of one host or a cluster of several hosts. This is referred to as a muliple-host, distributed system, or scale-out
system and supports scalability and availability.
The following sections provide overview information about these aspects of system architecture.
Note: You can find a complete list of all SAP HANA components and the corresponding SAP HANA hardware and software requirements
in the Product Availability Matrix (PAM), in the SAP HANA Hardware Directory, and in the SAP Community Network.

Documentation of SAP HANA database
SAP HANA hardware and software requirements are described in the SAP HANA Master Guide at:
SAP HANA Hardware and Software Requirements
SAP HANA support on SAP-certified Cloud IaaS:
Certified and Supported SAP HANA Hardware – Ceritified IaaS Platforms
SAP HANA and SAP NetWeaver on UNIX/Linux:
Installation of SAP Systems Based on the Application Server ABAP of SAP NetWeaver 7.3 EHP1 to 7.52 on UNIX: SAP HANA Database
Installation of SAP Systems Based on the Application Server Java of SAP NetWeaver 7.5 and SAP Solution Manager 7.2 SR2 Java on
UNIX: SAP HANA Database
Installation of SAP ABAP S/4HANA and BW/4HANA Systems on UNIX: SAP HANA 2.0 Database
HANA and SAP NetWeaver on Windows:
Installation of SAP Systems Based on the Application Server ABAP of SAP NetWeaver 7.3 EHP1 to 7.52 on Windows: SAP HANA
Database
Installation of SAP Systems Based on the Application Server Java of SAP NetWeaver 7.5 and SAP Solution Manager 7.2 SR2 Java on
Windows: SAP HANA Database
Installation of SAP ABAP S/4HANA and BW/4HANA Systems on Windows: SAP HANA 2.0 Database

SAP on SAP HANA using Intel Bare Metal
See SAP Note 2414097 - SAP Applications on IBM Cloud: Supported DB/OS and IBM Cloud Bare Metal Server Types for supported SAP HANA
database versions.
A sample configuration is shown in:
Quick Study Tutorial - SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, using RHEL
Quick Study Tutorial - SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, using Windows Server

SAP on SAP HANA using Intel Virtual Servers (Gen2)
See SAP Note 2927211 - SAP Applications on IBM Virtual Private Cloud: Supported DB/OS and IBM Gen 2 Virtual Server Instances for
supported MSSQL database versions.
A sample configuration is shown in:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 147

Quick Study Tutorial - SAP NetWeaver deployment to Intel Virtual Server (Gen2) on VPC Infrastructure, using RHEL
Quick Study Tutorial - SAP NetWeaver deployment to Intel Virtual Server (Gen2) on VPC Infrastructure that uses Windows Server

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 148

SAP Development Applications additional design considerations
SAP Cloud Platform
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Integrating IBM Cloud services into development spaces on SAP Cloud Platform
SAP Cloud Platform account and structure
Content

Bind IBM Cloud services to SCP Cloud Foundry as User-Provided Service Instances
Content

SAP Cloud Platform Single-tenant Edition
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Heading 2
Content

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 149

Operating Systems for SAP additional design considerations
Red Hat Enterprise Linux for SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Red Hat Enterprise Linux for SAP is tailored to the needs of SAP workloads, with capabilities for SAP HANA, SAP NetWeaver, and business
applications such as SAP S/4HANA or SAP BW/4HANA.
The capabilities of Red Hat for SAP include:
Tuning for higher performance,
Clustering for Scale-out,
Clustering for High Availability and Disaster Recovery,
Lifecycle management and proactive optimization leveraging Smart Management and Red Hat Insights,
Extended Update Support - both 2 year (EUS) and 4 year (E4S)
More features available starting with RHEL for SAP 8.x include:
RHEL System Roles for SAP, which can be used to automate the configuration of a RHEL system to run SAP workloads,
Extended capabilities with leveraging Smart Management and Red Hat Insights

Variants of RHEL for SAP
There are two main variants of Red Hat Enterprise Linux for SAP:
RHEL for SAP Applications; designed for SAP NetWeaver only without HA/DR capabilities
RHEL for SAP Solutions; designed for SAP HANA and SAP NetWeaver
Feature

RHEL for SAP Applications

RHEL for SAP Solutions

OS Packages for SAP NetWeaver and other †

Yes

Yes

compat-sap-c++
resource-agents-sap
tuned-profiles-sap
compat-locales-sap
sapconf
OS Packages for SAP HANA †

Yes

compat-sap-c++
resource-agents-sap-hana
tuned-profiles-sap-hana
RHEL High-Availability Add-On

Yes

RHEL System Roles for SAP

Yes

Extended Update Support (EUS, 2 years)

Only in Premium

Yes

Extended Update Services for SAP Solutions (E4S), 4 years

Yes

Red Hat Smart Management Add-On

Yes *

Red Hat Insights usage

Yes *

Yes *

* - Available when using Bring-your-OS (BYOS)
† - There are multiple changes to these OS Packages starting with RHEL 8.x, please see RHEL 8 - Considerations in adopting RHEL 8 -

Appendix A. Changes to packages for changes in package names and repositories
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 150

Additional information is available in the Red Hat documentation:
Red Hat KB - Overview of the Red Hat Enterprise Linux for SAP Solutions subscription
Red Hat KB - Overview of the Red Hat Enterprise Linux for SAP Applications subscription
Other variants of Red Hat Enterprise Linux for SAP include:
RHEL for SAP with High Availability (HA) and Update Services (US), through a Partner's Marketplace

Variant of RHEL for SAP, available on-demand within the IBM Cloud® for SAP portfolio
Environment

IBM Cloud® for SAP portfolio - IaaS

Classic Infrastructure

Intel Bare Metal certified for SAP HANA

Classic Infrastructure

Intel Bare Metal ceritifed for SAP NetWeaver

VPC Infrastructure

Intel Virtual Server (Gen2) certified for SAP HANA

VPC Infrastructure

Intel Virtual Server (Gen2) certified for SAP NetWeaver

IBM Power Infrastructure

IBM Power Virtual Server certified for SAP HANA

IBM Power Infrastructure

IBM Power Virtual Server certified for SAP NetWeaver

Classic Infrastructure

IBM Cloud for VMware certified for SAP

Availability

BYOS only

The Red Hat on-demand provisioning and subscriptions are provided with full support directly from IBM Cloud and triage to Red Hat.

Variant of RHEL for SAP, available Bring-your-OS (BYOS) through the Red Hat Cloud Access
program
Existing RHEL for SAP licenses purchased directly from Red Hat or Red Hat channel partners, can be used with the Red Hat Cloud Access
program.
The Red Hat Cloud Access program enables existing Red Hat subscriptions to be used with certified cloud providers with full support directly
from Red Hat.

OS installation from IBM Cloud® for SAP
Whether the RHEL4SAP installation is available for a specified profile from the IBM Cloud® for SAP portfolio, will always depend on whether it is
listed in the SAP Certified and Supported SAP HANA Hardware Directory - Certified IaaS Platforms - IBM Cloud .

OS Security considerations
OS Preparation for SAP considerations
OS on-demand license, subscriptions and package repositories
Each RHEL OS on-demand license is made of a few concepts:
License
Activation Key: the alphanumerical sequence associated to a specific licence
Entitlement: number of systems where this license can be applied
Service Level: support level for the subscriptions
Subscriptions:
Product:
Product Key:
Package Repositories:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 151

OS support procedure and package updates
Extended Update Support (EUS) provides up to two years of extended update support.
Extended Update Services for SAP Solutions (E4S) provides up to four years of update services; this was first introduced with RHEL for SAP 7.4
with High Availability (HA) and Update Services (US) license.
Red Hat Enterprise Linux (RHEL) Extended Update Support (EUS) Overview
Further information regarding the integrated support process, is shown:
Red Hat KB - Overview of the Red Hat Enterprise Linux for SAP Solutions subscription
Red Hat KB - Overview of the Red Hat Enterprise Linux for SAP Applications subscription

RHEL 8.2 on Intel Virtual Server (Gen2), on IBM Cloud VPC Infrastructure environment
Below is an abbreviated example listing all RHEL 8.x available repos for the system, including disabled repos:
Note: To activate a disabled repository, see documentation for command subscription-manager repos --enable=xxxxxxxxxxxxxxxx

$ [root ~]# subscription-manager repos --list
+----------------------------------------------------------+
Available Repositories in /etc/yum.repos.d/redhat.repo
+----------------------------------------------------------+
Repo ID:

rhel-8-for-x86_64-appstream-rpms

Repo ID:

rhel-8-for-x86_64-appstream-eus-rpms

Repo ID:

rhel-8-for-x86_64-appstream-e4s-rpms

Repo ID:

rhel-8-for-x86_64-baseos-rpms

Repo ID:

rhel-8-for-x86_64-baseos-eus-rpms

Repo ID:

rhel-8-for-x86_64-baseos-e4s-rpms

Repo ID:

rhel-8-for-x86_64-supplementary-rpms

Repo ID:

rhel-8-for-x86_64-supplementary-eus-rpms

Repo ID:

rhel-8-for-x86_64-highavailability-rpms

Repo ID:

rhel-8-for-x86_64-highavailability-eus-rpms

Repo ID:

rhel-8-for-x86_64-highavailability-e4s-rpms

Repo ID:

rhel-8-for-x86_64-sap-netweaver-rpms

Repo ID:

rhel-8-for-x86_64-sap-netweaver-eus-rpms

Repo ID:

rhel-8-for-x86_64-sap-netweaver-e4s-rpms

Repo ID:

rhel-8-for-x86_64-sap-solutions-rpms

Repo ID:

rhel-8-for-x86_64-sap-solutions-eus-rpms

Repo ID:

rhel-8-for-x86_64-sap-solutions-e4s-rpms

Below is an example listing all RHEL 8.x available subscriptions not yet attached to the system (including any that apply for other CPU
Architectures):
$ [root ~]# subscription-manager list --available
+-------------------------------------------+
Available Subscriptions
+-------------------------------------------+
Subscription Name:

Red Hat Satellite - Add-Ons for Providers

Provides:
Red Hat Enterprise Linux for SAP Applications for x86_64
Red Hat Enterprise Linux for SAP HANA for Power, little endian
Red Hat Enterprise Linux for SAP HANA for x86_64
Red Hat Enterprise Linux High Availability - Update Services for SAP Solutions
Red Hat Enterprise Linux High Availability (for IBM Power LE) - Update Services for SAP Solutions
Red Hat Enterprise Linux Server - Update Services for SAP Solutions
Red Hat Enterprise Linux Server (for IBM Power LE) - Update Services for SAP Solutions
RHEL for SAP - Extended Update Support
RHEL for SAP - Update Services for SAP Solutions
RHEL for SAP (for IBM Power LE) - Update Services for SAP Solutions
RHEL for SAP Applications for Power LE EUS
RHEL for SAP HANA - Extended Update Support
RHEL for SAP HANA - Update Services for SAP Solutions
RHEL for SAP HANA (for IBM Power LE) - Update Services for SAP Solutions
RHEL for SAP HANA for Power LE EUS
Red Hat 3scale API Management Platform

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 152

Red Hat Ansible Automation Platform
Red Hat Ansible Engine
Red Hat Beta
Red Hat Build of Jaeger
Red Hat Ceph Storage
Red Hat Ceph Storage Calamari
Red Hat Ceph Storage MON
Red Hat Ceph Storage OSD
Red Hat Certification (for RHEL Server)
Red Hat CloudForms
Red Hat CloudForms Beta
Red Hat CodeReady Linux Builder for ARM 64
Red Hat CodeReady Linux Builder for ARM 64 Beta
Red Hat CodeReady Linux Builder for ARM 64 High Touch Beta
Red Hat CodeReady Linux Builder for IBM z Systems
Red Hat CodeReady Linux Builder for IBM z Systems - Extended Update Support
Red Hat CodeReady Linux Builder for Power, little endian
Red Hat CodeReady Linux Builder for Power, little endian - Extended Update Support
Red Hat CodeReady Linux Builder for x86_64
Red Hat CodeReady Linux Builder for x86_64 - Extended Update Support
Red Hat CodeReady Workspaces for OpenShift
Red Hat Developer Tools (for RHEL Server for ARM 64)
Red Hat Developer Tools (for RHEL Server for ARM)
Red Hat Developer Tools (for RHEL Server for IBM Power LE)
Red Hat Developer Tools (for RHEL Server for IBM Power)
Red Hat Developer Tools (for RHEL Server for System Z)
Red Hat Developer Tools (for RHEL Server)
Red Hat Developer Tools (for RHEL Workstation)
Red Hat Developer Tools Beta (for RHEL Server for ARM 64)
Red Hat Developer Tools Beta (for RHEL Server for ARM)
Red Hat Developer Tools Beta (for RHEL Server for IBM Power LE)
Red Hat Developer Tools Beta (for RHEL Server for IBM Power)
Red Hat Developer Tools Beta (for RHEL Server for System Z)
Red Hat Developer Tools Beta (for RHEL Server)
Red Hat Developer Tools Beta (for RHEL Workstation)
Red Hat Developer Toolset (for RHEL Server)
Red Hat Directory Server
Red Hat Enterprise Linux Advanced Virtualization
Red Hat Enterprise Linux Advanced Virtualization Beta
Red Hat Enterprise Linux Atomic Host
Red Hat Enterprise Linux Fast Datapath
Red Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)
Red Hat Enterprise Linux Fast Datapath Beta for Power, little endian
Red Hat Enterprise Linux for ARM 64
Red Hat Enterprise Linux for ARM 64 Beta
Red Hat Enterprise Linux for ARM 64 High Touch Beta
Red Hat Enterprise Linux for IBM z Systems
Red Hat Enterprise Linux for IBM z Systems - Extended Update Support
Red Hat Enterprise Linux for Power 9
Red Hat Enterprise Linux for Power, big endian
Red Hat Enterprise Linux for Power, big endian - Extended Update Support
Red Hat Enterprise Linux for Power, little endian
Red Hat Enterprise Linux for Power, little endian - Extended Update Support
Red Hat Enterprise Linux for Power, little endian Beta
Red Hat Enterprise Linux for Real Time
Red Hat Enterprise Linux for x86_64
Red Hat Enterprise Linux for x86_64 - Extended Update Support
Red Hat Enterprise Linux High Availability (for IBM Power LE) - Extended Update Support
Red Hat Enterprise Linux High Availability (for IBM z Systems) - Extended Update Support
Red Hat Enterprise Linux High Availability for Power, little endian
Red Hat Enterprise Linux High Availability for x86_64
Red Hat Enterprise Linux High Availability for x86_64 - Extended Update Support
Red Hat Enterprise Linux High Performance Networking (for RHEL Server) - Extended Update Support
Red Hat Enterprise Linux Load Balancer (for RHEL Server)
Red Hat Enterprise Linux Load Balancer (for RHEL Server) - Extended Update Support
Red Hat Enterprise Linux Resilient Storage for IBM z Systems - Extended Update Support
Red Hat Enterprise Linux Resilient Storage for x86_64
Red Hat Enterprise Linux Resilient Storage for x86_64 - Extended Update Support
Red Hat Enterprise Linux Scalable File System (for RHEL Server)
Red Hat Enterprise Linux Scalable File System (for RHEL Server) - Extended Update Support
Red Hat Enterprise Linux Server
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 153

Red Hat Enterprise Linux Server - Extended Life Cycle Support
Red Hat Enterprise Linux Server - Extended Life Cycle Support (for IBM z Systems)
Red Hat Enterprise Linux Server for ARM
Red Hat Enterprise Linux Server for ARM Beta
Red Hat Enterprise MRG Messaging
Red Hat Enterprise Virtualization for Power, little endian
Red Hat Gluster Storage Management Console (for RHEL Server)
Red Hat Gluster Storage Nagios Server
Red Hat Gluster Storage Server for On-premise
Red Hat Gluster Storage Web Administration (for RHEL Server)
Red Hat JBoss Core Services
Red Hat Openshift Application Runtimes for IBM Power LE
Red Hat OpenShift Container Platform
Red Hat OpenShift Pipelines
Red Hat Openshift Serverless
Red Hat OpenShift Service Mesh
Red Hat OpenStack
Red Hat OpenStack - Extended Life Cycle Support
Red Hat OpenStack Beta
Red Hat OpenStack Director Deployment Tools
Red Hat OpenStack Director Deployment Tools Beta
Red Hat OpenStack Director Deployment Tools Beta for IBM Power LE
Red Hat OpenStack Director Deployment Tools for IBM Power LE
Red Hat Satellite Proxy
Red Hat Software Collections (for RHEL Server for ARM 64)
Red Hat Software Collections (for RHEL Server for ARM)
Red Hat Software Collections (for RHEL Server for IBM Power LE)
Red Hat Software Collections (for RHEL Server)
Red Hat Software Collections Beta (for RHEL Server for ARM 64)
Red Hat Software Collections Beta (for RHEL Server for ARM)
Red Hat Software Collections Beta (for RHEL Server for IBM Power LE)
Red Hat Software Collections Beta (for RHEL Server)
Red Hat Software Test Suite 5 (for RHEL Server)
Red Hat Storage Console
Red Hat Storage Console Node
Red Hat Storage for Public Cloud (via RHUI)
Red Hat Virtualization
Red Hat Virtualization - ELS
Red Hat Virtualization - Extended Update Support
Red Hat Virtualization for IBM Power LE
Red Hat Virtualization for IBM Power LE - Extended Update Support
Red Hat Virtualization Host
Red Hat Virtualization Host - Extended Update Support
Red Hat Virtualization Manager
dotNET on RHEL (for RHEL Server)
dotNET on RHEL Beta (for RHEL Server)
JBoss Enterprise Application Platform
OpenJDK Java (for Middleware)
OpenShift Tools and Services
Oracle Java (for RHEL Server)
Oracle Java (for RHEL Server) - Extended Update Support
SKU:

RC0000000

Contract:

00000000

Pool ID:

00000000000000000000000000000000

Provides Management: Yes
Available:

000000

Suggested:

0

Service Type:

L1-L3

Roles:
Service Level:

Premium

Usage:
Add-ons:
Subscription Type:

Stackable

Starts:

01/01/21

Ends:

17/01/22

Entitlement Type:

Physical

RHEL 7.6 on Intel Bare Metal, on IBM Cloud Classic Infrastructure environment
Below is an abbreviated example listing all RHEL 7.x available repos for the system, including disabled repos:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 154

Note: To activate a disabled repository, see documentation for command subscription-manager repos --enable=xxxxxxxxxxxxxxxx

$ [root ~]# subscription-manager repos --list
+----------------------------------------------------------+
Available Repositories in /etc/yum.repos.d/redhat.repo
+----------------------------------------------------------+
Repo ID:

rhel-7-server-rh-common-rpms

Repo ID:

rhel-7-server-rpms

Repo ID:

rhel-7-server-eus-rpms

Repo ID:

rhel-7-server-e4s-rpms

Repo ID:

rhel-7-server-optional-rpms

Repo ID:

rhel-7-server-eus-optional-rpms

Repo ID:

rhel-7-server-supplementary-rpms

Repo ID:

rhel-7-server-eus-supplementary-rpms

Repo ID:

rhel-7-server-extras-rpms

Repo ID:

rhel-ha-for-rhel-7-server-rpms

Repo ID:

rhel-ha-for-rhel-7-server-eus-rpms

Repo ID:

rhel-ha-for-rhel-7-server-e4s-rpms

Repo ID:

rhel-sap-for-rhel-7-server-rpms

Repo ID:

rhel-sap-for-rhel-7-server-eus-rpms

Repo ID:

rhel-sap-for-rhel-7-server-e4s-rpms

Repo ID:

rhel-sap-hana-for-rhel-7-server-rpms

Repo ID:

rhel-sap-hana-for-rhel-7-server-eus-rpms

Repo ID:

rhel-sap-hana-for-rhel-7-server-e4s-rpms

Below is an example listing all RHEL 7.x available subscriptions not yet attached to the system (including any that apply for other CPU
Architectures):
$ [root ~]# subscription-manager list --available
+-------------------------------------------+
Available Subscriptions
+-------------------------------------------+
Subscription Name:

Red Hat Satellite - Add-Ons for Providers

Provides:
Red Hat Enterprise Linux for SAP Applications for x86_64
Red Hat Enterprise Linux for SAP HANA for x86_64
Red Hat Enterprise Linux High Availability - Update Services for SAP Solutions
Red Hat Enterprise Linux High Availability (for IBM Power LE) - Update Services for SAP Solutions
Red Hat Enterprise Linux Server - Update Services for SAP Solutions
Red Hat Enterprise Linux Server (for IBM Power LE) - Update Services for SAP Solutions
RHEL for SAP - Extended Update Support
RHEL for SAP - Update Services for SAP Solutions
RHEL for SAP (for IBM Power LE) - Update Services for SAP Solutions
RHEL for SAP Applications for Power LE EUS
RHEL for SAP HANA - Extended Update Support
RHEL for SAP HANA - Update Services for SAP Solutions
RHEL for SAP HANA (for IBM Power LE) - Update Services for SAP Solutions
RHEL for SAP HANA for Power LE EUS
Red Hat 3scale API Management Platform
Red Hat Ansible Engine
Red Hat Ansible Tower
Red Hat Beta
Red Hat Ceph Storage
Red Hat Ceph Storage Calamari
Red Hat Ceph Storage MON
Red Hat Ceph Storage OSD
Red Hat Certification (for RHEL Server)
Red Hat CloudForms
Red Hat CloudForms Beta
Red Hat CodeReady Linux Builder for ARM 64
Red Hat CodeReady Linux Builder for ARM 64 Beta
Red Hat CodeReady Linux Builder for ARM 64 High Touch Beta
Red Hat CodeReady Linux Builder for IBM z Systems
Red Hat CodeReady Linux Builder for IBM z Systems - Extended Update Support
Red Hat CodeReady Linux Builder for Power, little endian
Red Hat CodeReady Linux Builder for Power, little endian - Extended Update Support
Red Hat CodeReady Linux Builder for x86_64

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 155

Red Hat CodeReady Linux Builder for x86_64 - Extended Update Support
Red Hat CodeReady Workspaces for OpenShift
Red Hat Developer Tools (for RHEL Server for ARM)
Red Hat Developer Tools (for RHEL Server for ARM 64)
Red Hat Developer Tools (for RHEL Server for IBM Power LE)
Red Hat Developer Tools (for RHEL Server for IBM Power)
Red Hat Developer Tools (for RHEL Server for System Z)
Red Hat Developer Tools (for RHEL Server)
Red Hat Developer Tools (for RHEL Workstation)
Red Hat Developer Tools Beta (for RHEL Server for ARM 64)
Red Hat Developer Tools Beta (for RHEL Server for ARM)
Red Hat Developer Tools Beta (for RHEL Server for IBM Power LE)
Red Hat Developer Tools Beta (for RHEL Server for IBM Power)
Red Hat Developer Tools Beta (for RHEL Server for System Z)
Red Hat Developer Tools Beta (for RHEL Server)
Red Hat Developer Tools Beta (for RHEL Workstation)
Red Hat Developer Toolset (for RHEL Server)
Red Hat Directory Server
Red Hat Enterprise Linux Advanced Virtualization
Red Hat Enterprise Linux Advanced Virtualization Beta
Red Hat Enterprise Linux Atomic Host
Red Hat Enterprise Linux Fast Datapath
Red Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)
Red Hat Enterprise Linux Fast Datapath Beta for Power, little endian
Red Hat Enterprise Linux for ARM 64
Red Hat Enterprise Linux for ARM 64 Beta
Red Hat Enterprise Linux for ARM 64 High Touch Beta
Red Hat Enterprise Linux for IBM z Systems
Red Hat Enterprise Linux for IBM z Systems - Extended Update Support
Red Hat Enterprise Linux for Power 9
Red Hat Enterprise Linux for Power, big endian
Red Hat Enterprise Linux for Power, big endian - Extended Update Support
Red Hat Enterprise Linux for Power, little endian
Red Hat Enterprise Linux for Power, little endian - Extended Update Support
Red Hat Enterprise Linux for Power, little endian Beta
Red Hat Enterprise Linux for Real Time
Red Hat Enterprise Linux for x86_64
Red Hat Enterprise Linux for x86_64 - Extended Update Support
Red Hat Enterprise Linux High Availability (for IBM Power LE) - Extended Update Support
Red Hat Enterprise Linux High Availability (for IBM z Systems) - Extended Update Support
Red Hat Enterprise Linux High Availability for x86_64
Red Hat Enterprise Linux High Availability for x86_64 - Extended Update Support
Red Hat Enterprise Linux High Performance Networking (for RHEL Server) - Extended Update Support
Red Hat Enterprise Linux Load Balancer (for RHEL Server)
Red Hat Enterprise Linux Load Balancer (for RHEL Server) - Extended Update Support
Red Hat Enterprise Linux Resilient Storage for IBM z Systems - Extended Update Support
Red Hat Enterprise Linux Resilient Storage for x86_64
Red Hat Enterprise Linux Resilient Storage for x86_64 - Extended Update Support
Red Hat Enterprise Linux Scalable File System (for RHEL Server)
Red Hat Enterprise Linux Scalable File System (for RHEL Server) - Extended Update Support
Red Hat Enterprise Linux Server
Red Hat Enterprise Linux Server - Extended Life Cycle Support
Red Hat Enterprise Linux Server - Extended Life Cycle Support (for IBM z Systems)
Red Hat Enterprise Linux Server for ARM
Red Hat Enterprise Linux Server for ARM Beta
Red Hat Enterprise MRG Messaging
Red Hat Enterprise Virtualization for Power, little endian
Red Hat Gluster Storage Management Console (for RHEL Server)
Red Hat Gluster Storage Nagios Server
Red Hat Gluster Storage Server for On-premise
Red Hat Gluster Storage Web Administration (for RHEL Server)
Red Hat JBoss Core Services
Red Hat Openshift Application Runtimes for IBM Power LE
Red Hat OpenShift Container Platform
Red Hat Openshift Serverless
Red Hat OpenShift Service Mesh
Red Hat OpenStack
Red Hat OpenStack - Extended Life Cycle Support
Red Hat OpenStack Beta
Red Hat OpenStack Director Deployment Tools
Red Hat OpenStack Director Deployment Tools Beta
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 156

Red Hat OpenStack Director Deployment Tools Beta for IBM Power LE
Red Hat OpenStack Director Deployment Tools for IBM Power LE
Red Hat Satellite Proxy
Red Hat Software Collections (for RHEL Server for ARM 64)
Red Hat Software Collections (for RHEL Server for ARM)
Red Hat Software Collections (for RHEL Server for IBM Power LE)
Red Hat Software Collections (for RHEL Server)
Red Hat Software Collections Beta (for RHEL Server for ARM 64)
Red Hat Software Collections Beta (for RHEL Server for ARM)
Red Hat Software Collections Beta (for RHEL Server for IBM Power LE)
Red Hat Software Collections Beta (for RHEL Server)
Red Hat Software Test Suite 5 (for RHEL Server)
Red Hat Storage Console
Red Hat Storage Console Node
Red Hat Storage for Public Cloud (via RHUI)
Red Hat Virtualization
Red Hat Virtualization - ELS
Red Hat Virtualization - Extended Update Support
Red Hat Virtualization for IBM Power LE
Red Hat Virtualization Host
Red Hat Virtualization Host - Extended Update Support
Red Hat Virtualization Manager
dotNET on RHEL (for RHEL Server)
dotNET on RHEL Beta (for RHEL Server)
JBoss Enterprise Application Platform
OpenJDK Java (for Middleware)
Oracle Java (for RHEL Server)
Oracle Java (for RHEL Server) - Extended Update Support
SKU:

RC0000000

Contract:

00000000

Pool ID:

00000000000000000000000000000000

Provides Management: Yes
Available:

000000

Suggested:

0

Service Type:

L1-L3

Roles:
Service Level:

Premium

Usage:
Add-ons:
Subscription Type:

Stackable

Starts:

01/01/2020

Ends:

01/16/2021

Entitlement Type:

Physical

SUSE Linux Enterprise Server for SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
introduction information

OS installation from IBM Cloud® for SAP
Whether the SLES 4 SAP installation is available for a specified profile from the IBM Cloud® for SAP portfolio, will always depend on whether it
is listed in the SAP Certified and Supported SAP HANA Hardware Directory - Certified IaaS Platforms - IBM Cloud .

OS Security considerations
OS Preparation for SAP considerations
IBM Power Infrastructure environment requirements for OS BYOL
In the IBM Power Virtual Server environment, you must bring your own license (BYOL) for the SUSE Enterprise Linux® for SAP. You must apply
the corresponding license after deployment. For information about how to obtain the required licenses, contact SUSE Sales or SUSE Support.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 157

IBM AIX for SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
introduction information

OS installation from IBM Cloud® for SAP
Whether the IBM AIX installation is available for a specified profile from the IBM Cloud® for SAP portfolio, will always depend on whether it is
listed in the SAP Certified and Supported SAP HANA Hardware Directory - Certified IaaS Platforms - IBM Cloud .

OS Security considerations
OS Preparation for SAP considerations

Windows Server
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
introduction information

OS installation from IBM Cloud® for SAP
Whether the Windows Server installation is available for a specified profile from the IBM Cloud® for SAP portfolio, will always depend on
whether it is listed in the SAP Certified and Supported SAP HANA Hardware Directory - Certified IaaS Platforms - IBM Cloud .

OS Security considerations
OS Preparation for SAP considerations

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 158

SAP Partner certified solutions
Veeam for SAP HANA backups
Deprecated: This document is out of date, it is being updated for Veeam 10.x and replaced in November-2020 with new content.
Veeam Backup & Replication can be provisioned and deployed from the IBM Cloud catalog to provide protection for SAP HANA workloads on
certified IBM Cloud® for SAP infrastructure. Veeam performs SAP HANA Backint -based backup and restore of databases and logs, and is
lisited on the SAP Certified Solutions Directory.

Veeam overview and considerations
Below is high-level overview of how an SAP Backint database backup is performed:

Figure 1. SAP HANA Backint database backup overview

Veeam Plug-in, which acts as a go-between for SAP HANA and Veeam Backup repository, is installed on the SAP HANA server. Veeam Backup
& Replication is provisioned on either IBM Cloud Bare Metal Servers or IBM Cloud Classic Virtual Servers.
Note: IBM Cloud Classic Virtual Servers are used for the sample deployment.
Veeam Plug-in connects to the Veeam Backup & Replication server and creates a backup job. Once a backup job is requested, Veeam Plug-in
starts a Veeam Transport Agent on the SAP HANA server and on the backup repository, which transports data to the backup repository. For
more information, see How Veeam Plug-in for SAP HANA Works .
At this time, Veeam is able to provision with IBM Cloud® for VMware Solutions Dedicated only.

System considerations
Veeam Backup & Replication has a very high-performance data mover engine embedded within its components that is used for
Reading VM data from production storage
Applying compression/de-duplication
Writing the resulting data stream to backup storage
The efficiency that it performs these operations is impacted by available resources, including network bandwidth, storage performance, and
server processing capacity.

Systems requirements
vSphere. Veeam supports vSphere (ESXi) and vCenter environments v4.1 and greater. While Veaam is suited for backup of individual
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 159

vSphere (ESXi) hosts, vCenter, if deployed, is the preferred interface into a vSphere environment. vCenter provides added configuration
and ease of management.
Veeam supports all OS types compatible with VMware.
VMs with disks in the SCSI bus-sharing mode are not supported as VMware does not support snapshotting VMs with those types of
disks.
The following disk types are skipped from processing automatically and are not supported:
RDM virtual disks in physical mode,
independent disks,
disks connected via in-guest iSCSI initiator,
and VMs with pass-through virtual disks.
IBM Cloud Classic Virtual Servers. Veeam Backup & Replication components are provisioned on IBM Cloud Classic Virtual Servers.
Minimum requirements are
4-core
8 GB RAM
1 Gb network uplink speed
Veeam supports Windows Server 2012 and later, however, Windows Server 2016 is recommended for the advanced storage
optimization and efficiency presented by the Resilient File System (ReFS).
Storage. IBM Block Storage for Classic Endurance block storage with LUN's from 1 TB to 2 TB, 0.25 IOPS/GB performance level is
recommended for hosting the Veeam backup repository. You are encouraged to thoroughly test other performance levels before
selecting the performance storage level for your production Veeam repository.
The Restore Point Simulator can be used to help estimate your Veeam backup storage needs.
Throughput. For the initial full backup, Veeam ignores empty or deleted VM storage blocks. For example, if a VM has been allocated 1 TB
of storage, thin or thick provisioned, and only consumes 450 G, Veeam only processes 450 G for that VM. For ongoing incremental
backups, Veeam only processes VM data blocks changed since the last backup.
Based on preliminary results, the standard Veeam virtual server processes approximately 220 GB of VM data per hour, which means if
total active VM data to be backed up is 1 TB, the initial backup takes approximately 4.5 hours. Based on a 10% per day VM change rate,
the daily incremental backup takes approximately 45 minutes.

Veeam Reference material
Veeam Backup & Replication Evaluator's Guide for VMware vSphere
Veeam Support Knowledge Base
Veeam Backup & Replication Best Practices

Actifio for SAP HANA backups
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Actifio GO can be provisioned and deployed from the IBM Cloud catalog to provide protection for SAP HANA workloads on certified IBM Cloud®
for SAP infrastructure. Actifio performs SAP HANA database snapshot combined with block change tracking to backup incremental block
changes of disk mount points used by the database, and is lisited on the SAP Certified Solutions Directory.

Actifio GO overview and considerations
Actifio GO on IBM Cloud is the next generation multi-cloud Copy Data Management SaaS solution that allows customers to perform backups to
directly to IBM Cloud® Object Storage (COS); while being able to instantly access the backup images within their on-premises data center.
Actifio GO SaaS is built on Actifio Sky, and uses the patented core Virtual Data Pipeline technology - Actifio VDP. It enables users to provision
multiple clones instantly in the cloud, so tests can be done simultaneously on multiple instances and reduce testing cycles.
The Actifio Sky appliances run on a hardened Linux software stack and user accounts and direct access to the operating system are not used
for normal operations and support.
Actifio GO SaaS uses Actifio Sky to support multiple on-premises workloads for backup to Cloud:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 160

File systems
VMware
SAP HANA
IBM Db2
Microsoft SQL Server
PostgreSQL
MySQL
MongoDB
Progress
Depending on the backup target, a different method of backup will be performed with Actifio technology:
For VMware, Actifio GO leverages the patented OnVault technology to incrementally backup VMware data to IBM Cloud® Object Storage
(COS) while still maintaining instant access
For SAP HANA database server, Actifio GO leverages the native SAP HANA Database Snapshot API backup interfaces combined with
block change tracking to backup incremental block changes of disk mount points used by the database; for SAP's own cutting-edge inmemory database, Actifio leverages backint interface of the SAP HANA Database Server
For SAP AnyDB databases such as IBM Db2, Actifio uses the native database API backup interfaces to perform snapshots combined with
block change tracking to backup incremental block changes of disk mount points used by the database
Note: Actifio GO is able to provision for all IBM Cloud infrastructure. However, at time of writing, the regular pricing plan is only
available to use with IBM Cloud® for VMware Solutions Dedicated. For pricing related to SAP, including for databases (e.g. SAP HANA,
IBM Db2, MS SQL, etc.) and other compute types (e.g. physical servers) please contact info@actifio.com .

Note: When using Actifo GO with IBM Cloud® for VMware Solutions Dedicated, the Virtual machines associated with a VMware host are
discovered through the Application Manager on the Actifio Global Manager (AGM) and can be backed up using either VMware snapshots
or the Actifio Connector. However for SAP Workloads, this is performed at the database-level and there is not an auto-detect for the
databases which could be backed up via Actifio GO to the defined IBM Cloud® Object Storage.

Actifio GO benefits for SAP Workloads
Benefits include:
Incremental Forever Backup - Efficient incremental forever backup which reduces backup window (RPO/RTO), optimizes bandwidth
and cloud storage utilization
Direct to Cloud Object Storage - Incremental forever backups go directly to IBM Cloud® Object Storage, eliminating any on-premises
data center storage needs and the operational burden for capacity management (and zero network bandwidth charges using IBM
Cloud's private network backbone)
Instant testing from Cloud - Instantly begin clone deployments from IBM Cloud® Object Storage to begin isolated testing quickly or
point-in-time data science analysis
Data Encryption - Data is encrypted in transit and at rest in IBM Cloud® Object Storage
Actifio can be used in various SAP project implementations:
for SAP Systems Sandbox and Regression Testing
testing SAP workloads move from on-premises to Cloud environment
testing validation of SAP workload performance in a Cloud environment
running conversion trial projects to the newest SAP software releases (e.g. SAP ECC > SAP S/4HANA)

Solution overview
The diagram below shows the solution overview of Actifio GO:

The solution consists of the following components:
Source host - the on-premises host running an SAP workload, to backup and restore on Cloud
Actifio GO SaaS Cloud - provides the registration, deployment, reporting and enables Enterprises to set up and monitor SLAs
Actifio Global Manager (AGM) - the manager is hosted in the Actifio GO SaaS Cloud and provides centralized management capabilities,
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 161

via web-based UI, to manage multiple Actifio Sky appliances. The AGM can manage up to 40 Actifio Sky appliances and communicates
with each Actifio appliance over the Internet via a bi-directional link set up by the appliance. This requires firewall rule changes and a
outbound internet access e.g. via SNAT or Public Internet Gateway; for example, with IBM Cloud® for VMware Solutions Dedicated
vCenter Server instances this would be achieved using a firewall rule and a SNAT entry on the customer-ESG in a vCenter Server instance
Windows Server host - a Windows server is required to download and run the Actifio GO installer, which is only available as a Windows
executable. When the installer is executed, additional files are downloaded and the Actifio Sky appliance (separate host) is installed. This
requires firewall rule changes and a outbound internet access, including specific ports opened to allow licensing validation, installation
and post-install configuration
Actifio Sky host - the data mover appliance is downloaded and installed via the Actifio GO intaller on Windows Server. The Actifio Sky
host is on both the source (on-premises hosts) and the target (Cloud hosts) environments
DNS Server - the DNS server must be able to resolve external FQDN such as actifiogo.com and resolve internal FQDN within the
landscape on IBM Cloud
Optional: NTP Server - the Actifio Sky appliance can be configured to use a specific NTP server

Process overview
The process is as follows, it assumes you have an on-premises VMware environment and an IBM Cloud® for VMware Solutions Dedicated
vCenter Server instance:

Initial setup
1. Purchase Actifio GO from the IBM Cloud catalog. An account is automatically created for the provisioning user. The Actifio GO service
dashboard on the IBM Cloud Catalog will present the user with temporary credentials to access the service. The temporary credentials
can be accessed at any time from the service dashboard of the IBM Cloud resource listing page.
2. Purchase IBM Cloud® Object Storage (COS) from the IBM Cloud catalog.

On-premises setup
1. Configure the networks to allow the required traffic flow.
2. Provision or use an existing Windows virtual machine as a jump server.
3. Enable the Windows Jump server to allow incoming connections on port 5420.
4. Browse to Actifio GO and using the temporary credentials generated as part of the provisioning process, log into the service.
5. Change credentials.
6. Navigate to the quickstart page.
7. Click on the Get Ahead tile to be presented with a page to download the installer.
8. The installer guides the user through the provisioning steps:
The Actifio ova is downloaded.
Provide the on-premises vCenter credentials to deploy the Actifio Sky appliance.
Provide the required on premises network information.
Provide the IBM Cloud Object Storage credentials, and enter the public endpoint URL.
The installer will provision the Actifio Sky appliance.
9. Using the Actifio Global Manager, select the virtual machines you want to backup and restore to Cloud, which will use IBM Cloud Object
Storage to store the backups. The Actifio GO service includes a default OnVault Policy and Resource Profiles. These can be adjusted as
required. The OnVault policy will run according to its schedule and the selected virtual machines will be written to the OnVault Pool, IBM
Cloud Object Storage bucket, specified in the Resource Profile.

vCenter Server instance setup
1. Configure the networks to allow the required traffic flow.
2. Provision or use an existing Windows virtual machine as a jump server.
3. Enable the Windows Jump server to allow incoming connections on port 5420.
4. Browse to Actifio GO, log into the service.
5. Navigate to the quickstart page.
6. Click on the Get Ahead tile to be presented with a page to download the installer.
7. The installer guides the user through the provisioning steps:
The Actifio ova is downloaded.
Provide the on-premises vCenter credentials to deploy the Actifio Sky appliance.
Provide the required on premises network information.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 162

Provide the IBM Cloud Object Storage credentials, and enter the private endpoint URL.
The installer will provision the Actifio Sky appliance.

Backup and Restore
1. After the first on-premises capture operation has completed, the backup of the virtual machines to backup and restore will be stored as
images in the OnVault Pool's object storage location ready to be accessed by the Actifio Sky appliance in the vCenter Server instance.
2. Using AGM, users can import OnVault images from one managed Actifio appliance to another. An image that has been imported to
another Actifio appliance can be mounted to that appliance's application hosts.
3. Images can be imported from the AGM Domain Manager's Storage Pool page or the AGM Application Manager's Applications page.
Importing images from the Domain Manager's Storage Pool page has the advantage of allowing you to select multiple application images.
To import images from the Domain Manager's Storage Pool page:
Right click on an OnVault Storage Pool and from the drop down menu select Import Images and the Import OnVault Images page
is displayed.
Select the Actifio Sky appliance to which the images will be imported.
Select the images to import.
Click Import and the import operation will begin. A message will be displayed when the operation completes.
4. Actifio GO provides the following options;
Restore - Recovers the image to the existing virtual machine. This option is not suitable for backup and restore to IBM Cloud.
Mount - The image can be mounted to an existing host or a new VM. When mounting as new VM, the VM version, Guest Id, number
of CPUs, memory, hardware details are preserved. The images are presented as either NFS, vRDM or pRDM disks to the new virtual
machines. The Actifio Sky appliance acts as a gateway to the image. The image is not copied to the datastore. This can be useful
for testing the move to Cloud but not for production workload migration to IBM Cloud.
Clone - The image can be used to clone to a source or target VMware environment. Select the vCenter in IBM Cloud, and a clone of
the on-premises VM, the VM version, Guest Id, number of CPUs, memory and Hardware details are cloned and the network left
disconnected and the virtual machine is powered off.
Recover System - This recovers the virtual machine to either AWS, Azure or GCP. This option is not suitable for IBM Cloud.
5. Using the Clone option, clone a virtual machine in the vCenter Server instance, connect to the required network and power on.
6. Carry out the required testing.
7. Upon successful testing, power off the on-premises virtual machine and make the virtual machine in IBM Cloud accessible.
Note, this is an overview of the backup and restore process. To use this process for production workload migration, then use of the native
Database Snapshot API backup interfaces is required instead and a full migration plan with detailed tasks is required, with required testing and
SAP cut-over process (including post-copy processing).
As we are using a clone of a copy of data for testing use case only, multiple tests can be carried out with no impact to production. the cloned
virtual machine can be placed in an isolated network to not impact the production instance of SAP.

Actifio Sky Appliance
Actifio Sky performs only one full backup of the source device. All subsequent backups rely on incremental changes only due to the CBT
feature. Actifio Sky synthesizes a point-in-time virtual full backup from the incremental backups. An OnVault policy defines when data is
captured, the frequency it will be captured, and how long it will be retained and are created via the AGM. Resource Profiles define which Actifio
pools will be used to retain application data and are created via the AGM.

Actifio Connector
In this use case an Actifio Connector was not used. The Actifio connector is a lightweight connector that incorporates change-block tracking
(CBT). The connector automatically provides a list of changed blocks when backups are initiated, minimizing the amount of CPU, storage, and
memory required. The Actifio Connector is deployed on the source device and invokes the appropriate APIs to ensure that all backups are
application consistent. A connector is required to discover applications on the host or VM and to interact with the applications API. VMware
virtual machines can be backed up without an Actifio Connector. This provide crash consistent backups or some level of application
consistency with VM Tools integration. Additionally, vSphere ESXI hosts do not need to be be enabled for iSCSI. Actifio Connector based
protection, provides better application consistency and application aware restore functionality, again if the application is hosted on VMware
virtual machine iSCSI is not required.
The Actifio appliance comes with different connector installer files. Each is of a file type appropriate to its intended host type. You can
download these with a web browser from the Actifio Resource Center; just open a browser to the IP address of the appliance. Traffic between
the Actifio Sky appliance and the connector on the SAP host is encrypted and communicated via SSL. The Actifio Connector uses port 5106 by
default for bidirectional communication from the Actifio SKY appliance. The flow is as follows:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 163

The Actifio connector uses the SAP HANA HDB SQL API to create a snapshot to flush data and memory to disk.
The connector creates a snapshot of the SAP HANA data area disk and deletes the native SAP HANA snapshot, freeing up the HANA
database for new reads and writes.
Actifio Sky mounts a volume to the SAP HANA server and the connector leverages its changed block tracking bitmap to back up the
changed blocks from the data area disk snapshot to the mounted volume.
When the incremental backup is done, Actifio Sky unmounts the volume and deletes the data area disk snapshot.
Actifio Sky issues an internal software snapshot and synthesizes a point in time virtual full backup copy.
Now that we have a replicated copy, the admin invokes the cloning process. To clone an SAP HANA database, the user triggers an Actifio
workflow, that will automatically present a clone on-demand, which can be presented to the target server for instant access. Once the SAP
HANA clone is presented by the connector to the target server, the connector will mount the disc volume containing the clone. The connector
will then bring the database online using native SAP HANA functionality, and the server will have a complete read/write enabled virtual full SAP
HANA database ready for testing.

Actifio GO installer requirements
During the install you are presented with the following requirements:
You have access to a VMware vCenter wherein you are about to deploy an Actifio virtual appliance.
Your VMware vCenter Server User ID has sufficient privileges to perform these required operations.
Your VMware vCenter Server has access to a datastore with at least 250GB of free space.
Your ESXi systems are configured with iSCSI technology for the Actifio appliance to access remote storage using the IP network - This
requirement is only required if using the Actifio Connector and certain uses cases. It is NOT required for this use case.
On this machine where the Actifio Appliance Installer is running, Port 5420 is open for SSL communication with your VMware vCenter
Server.
The network you choose to deploy Actifio Sky on allows outbound communication via TCP port 1194 which is required to ensure that the
vaulting Sky can be securely managed via Actifio cloud.
Based on Windows compatibility, install Microsoft Net Framework of versions 3.5 and above.
You have at least 6 GB of free space on the local disk where this Actifio Appliance Installer application is running.

Network Ports
The following network traffic is required between the various components:

Destination Port

Source IP

Destination IP Address

Description

Protocol(s)

Address

3389 (TCP) MS RDP

User device

Jump-server

MS RDP access from the user's device to the jump-server.

80 (TCP) HTTP

Jump-server

Actifio Appliance

Installation post deployment.

443 (TCP) HTTPS

Jump-server

Actifio Appliance

Download of the Actifio Desktop and Connector software.

53 (UDP) DNS

Jump-server

DNS server

Resolve IP addresses.

443 (TCP) HTTPS

Jump-server

vCenter Server IP

To install the appliance ova.

443 (TCP) HTTPS

Jump-server

AGM server

Web browser access to AGM.

53 (UDP) DNS

Actifio
Appliance

DNS server

Resolve IP addresses.

123 (UDP) NTP

Actifio
Appliance

NTP server

NTP.

443 (TCP) HTTPS

Actifio
Appliance

vCenter Server IP

Snapshot and image management

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 164

443 (TCP) HTTPS

Actifio
Appliance

IBM Cloud Object Storage
Endpoint

Actifio OnVault cloud data transfer

902 (TCP)

Actifio
Appliance

ESX Server VMKernel IPs

Encrypted connectivity to VMware ESXi hosts for data
movement operations.

5420 (TCP)

Actifio
Appliance

vCenter Server IP

Licence server details from the installer.

1194 (TCP)

Actifio
Appliance

AGM Server

Secure communications between Actifio Sky appliance and
the AGM.

If Actifio Connectors are used the following network traffic is required between the various components:
Destination Port

Source IP

Destination IP

Protocol(s)

Address

Address

5106 (TCP) Actifio API

Actifio Appliance

Host Servers

Description

Encrypted control channel for hosts with Actifio
connector.

If iSCSI ise used the following network traffic is required between the various components:
Destination Port Protocol(s)

Source IP Address

Destination IP Address

Description

3205 and 3260 (TCP) iSCSI

Host servers

Actifio Appliance

iSCSI target

On-premises information
Parameter

Notes

Cluster\resource pool

As required, e.g. cluster1.

Datastore

As required, e.g. vsanDatastore.

Network

As required.

Sky Appliance name

As required, e.g. actifiosrc.

Sky Appliance IP

Select a free IP address.

Gateway

The customer edge private interface IP address for the portable subnet for customer workloads.

DNS

The IP address iof the on-premises DNS.

Mask

The network mask of the subnet hSky Appliance IP e.g. 255.255.255.0.

NTP

Optional.

Time Zone

As required.

Bucket Name

The bucket name used in the IBM Cloud Object Storage order e.g. actifio01

Access Key ID

Available from the IBM Cloud Object Storage credentials web page.

Secret Access Key

Available from the IBM Cloud Object Storage credentials web page.

Public Region Endpoint

Available from the IBM Cloud Object Storage service page.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 165

vCenter Credentials
vCenter IP/FQDN

vCenter Server instance information
The following information will need to be collected for use by, the installation of the jump server, Actifio GO installer or for use in configuring
NAT and firewall rules in the customer-esg. It assumes that you will use the default customer VXLAN, DLR and ESG configured by the
automation:
Parameter

Notes

Jump server IP

Select a free IP address from the workload BYOIP range. e.g. 192.168.10.168

Jump server IP
Public

This uses the existing secondary IP address configured from the public portable subnet for customer workload
edge IP range.

Jump server IP
Private

Select a free IP address from the private portable subnet for customer workload edge IP range. e.g.
10.134.217.198

Private subnets

The IBM Cloud private network subnets that you want to allow to connect the jump-server.

Cluster\resource
pool

As required, e.g. cluster1.

Datastore

As required, e.g. vsanDatastore.

Network

The network should be; vxw-dvs-22-virtualwire-3-sid-6002-Workload; if the workload BYOIP subnet is being
used.

Sky Appliance name

As required, e.g. actifiotgt.

Sky Appliance IP

Select a free IP address from the workload BYOIP range, e.g. 192.168.10.169

Gateway

The customer edge private interface IP address for the portable subnet for customer workloads, e.g.
192.168.10.1

DNS

The IP address is published in the IBM Cloud® for VMware Solutions Dedicated console.

Mask

The private portable subnet for customer workloads subnet has a network mask of 255.255.255.0.

NTP

The IBM Cloud time server; 10.0.77.54

Time Zone

As required.

Bucket Name

The bucket name used in the IBM Cloud Object Storage order e.g. actifio01

Access Key ID

Available from the IBM Cloud Object Storage credentials web page.

Secret Access Key

Available from the IBM Cloud Object Storage credentials web page.

Private Region
Endpoint

Available from the IBM Cloud Object Storage service page.

vCenter credentials

Available from the IBM Cloud® for VMware Solutions Dedicated console.

vCenter IP/FQDN

Available from the IBM Cloud® for VMware Solutions Dedicated console.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 166

The diagram below shows a network overview for the vCenter Server instance, the Network Address Translation (NAT) and Firewalls are
described in the sections below.

Network address translation
NAT needs to be configured to allow the following:
The automation configures a SNAT rule, SNAT for customer VMs, that translates customer workload IP addresses to a secondary public
IP address on the customer-esg. This rule may need to be enabled. This NAT will allow the jump server and the Actifio Sky appliance
access to Internet resources such as Actifio GO SaaS.
To make the jump server accessible from the IBM Cloud private network, a DNAT is required to translate a secondary private IP address
on the customer-esg to the BYOIP address used on the jump server. e.g. DNAT, applied on Private Uplink destination IP
10.134.217.198, translated IP 192.168.10.168.
To alow the jump server access to DNS and vCenter, and the Actifio Sky appliance access to DNS, NTP, IBM Cloud Object Storage private
endpoint, vCenter and the vSphere ESXi hosts, a SNAT is required to translate the BYOIP address used on the appliance to a secondary
private IP address on the customer-esg. e.g. SNAT, applied on Private Uplink, source IP 192.168.0.0/16 translated IP 10.134.217.197.

Firewall rules
Firewall rules are required to allow traffic into and out of the subnets protected by the customer-esg. The following rules are required:
The vCenter Server automation configures the, All outgoing customer VMs rule, with a source 192.168.0.0/16, destination any, and
action accept. This will allow the jump server and Actifio Sky appliance access to resources on the public and private networks.
A rule to allow access to the jump server is required. e.g source 10.0.0.0/8, destination 10.134.217.198, and action accept.

Jump-server
Install Microsoft Net Framework of versions 3.5 and above using Windows Server Manager, add roles and features. Using the following
PowerShell command to open the Windows firewall to allow the Actifio Sky appliance to get a licence:
netsh advfirewall firewall add rule name="Open Port 5420 In” dir=in action=allow protocol=TCP localport=5420

Related links
Actifio
About Actifio GO
Actifio Global Manager (AGM)
Installing an Actifio Sky Appliance on a VMware Server
Network Administrator's Guide to Actifio Copy Data Management
Actifio Global Manager getting started
Connecting Hosts to Actifio Appliances
Configuring Actifio OnVault
Accessing and Recovering Copy Data with the Application Manager
Actifio data security

F5 for SAP Networking Load Balancing and User Control
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction, described on SAP Certified Solutions Directory

Heading 2
Content

HyTrust for SAP Workload Access Control

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 167

Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction, described on SAP Certified Solutions Directory

Heading 2
Content

IBM Security Services for SAP
IBM Cloud® Security Services for SAP offer a cybersecurity solution that automates the monitoring and protection of SAP applications on IBM
Cloud, and keeps workloads compliant and secure from inside and outside threats.
IBM Services for SAP, developed in partnership with IBM Security Software and other business partners, implement and configure the SAP
landscape to meet IT environment requirements for continuous workload visibility and protection.
Through continuous monitoring, IBM Security Services are able to deliver near real-time preventive, detective, and corrective solutions for
securing SAP systems and applications with unmatched coverage and protection. This protection includes context-aware insight across SAP
NetWeaver ABAP or Javas and SAP HANA platforms, with network security, security management, and associated workflows.
IBM Security Services for SAP offer the following features:
Comprehensive understanding of vulnerabilities and potential attack vectors
Methods to implement and avoid defects in ABAP code or SAP Transports
Identifying configuration vulnerabilities for ABAP, Java, and HANA environments
Identifying missing or outdated SAP notes and patches
Identifying, monitoring and review of highly privileged SAP accounts
Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution
Key benefits of requesting IBM Security Services for SAP to assist with your IBM Cloud® for SAP deployments:
Consultative engagement methods centered on your business objectives
Experienced end-to-end architectural experts that work jointly with the IBM Cloud team
Accelerated cloud adoption for successful implementation of SAP workloads on the cloud
Prescriptive best practices for solution implementation by using IBM Cloud Services products and features
Rapid learning and risk mitigation through access to IBM Cloud experts
For more information, see IBM.com - IBM Security - SAP Security and GRC Strategy Services

Procedure to request IBM Security Services for SAP
To begin with IBM Security Services for SAP, use either:
Live Chat with IBM Security Sales, by using IBM.com - IBM Security and click Let's talk in the botttom-left
Email with IBM Security Sales

Procedure to request IBM Security Services for SAP, directly from IBM Cloud for VMware
Solutions
Because of the close collaboration between IBM Cloud for VMware with SAP and IBM Security Services for SAP, the quickest way to use IBM
Security Services in combination with SAP workloads on VMware is to:
1. Open the IBM Cloud for VMware Solutions console. Scroll down to the Services section and on the Featured Workload Solutions card
click IBM Security Services for SAP .
2. On the IBM Security Services for SAP page, in the Engage IBM Security Services box, provide the requested details, and click Request
a consultation.
An IBM Cloud for VMware Solutions representative will contact you by using your IBM Cloud contact information to help you with the
solution that you need.

SAP HANA with Intel Optane Persistent Memory (PMEM)
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 168

SAP HANA now has a non-volatile in-memory option on Bare Metal servers. Intel Optane™ persistent memory (PMEM) retains its contents like
traditional storage options but with speeds similar to main memory.

{: caption="Figure 1. SAP HANA Intel
Optane PMem [1] overview" caption-side="bottom"}
Many systems with large data storage and retrieval needs use DRAM for fast data retrieval. DRAM is costly and data does not persist when the
server is rebooted or shutdown. On startup, data must be reloaded from storage.
With Intel Optane PMEM, data is retained in memory during system restarts and power outages, providing faster start times. PMEM provides
near-DRAM performance and is also byte-addressable.
Intel Optane PMEM modules are installed with DRAM in the same dual in-line memory module (DIMM) slot. PMEM modules do not function
without any DRAM DIMMS installed. The current configurations supports DRAM to PMEM ratios of 1:1, 1:2, and 1:4.
SAP HANA uses App Direct mode, in which the application stores data on the persistent memory. HANA2 SP04 release or higher was coengineered by SAP and Intel to use the unique dual memory and storage capability of the PMem modules.
In App Direct mode, the applications directly access the memory and control the direct load and store of the PMem and DRAM DIMMs memory
resources. In this mode, the PMem acts as byte-addressed persistent memory that is mapped to the system physical address space. App Dir
mode uses regions, which are groups of one or more PMem modules that appear to be a single logical virtual address space. Regions are
partitioned into one or more namespaces, similar to hard disk partitions.

Persistent memory is a Bare Metal profile option
You order persistent memory as part of ordering your Bare Metal server.
Bare Metal server profiles for the DRAM:PMEM ratios include:
DRAM:PMEM ratio

Bare Metal Profile

1:1

BI.S4.H2.1.5TB RAM + 1.5TB Persistent Memory

1:1

BI.S4.H4.3TB RAM + 3TB Persistent Memory

1:1

BI.S4.H8.6TB RAM + 6TB Persistent Memory

1:2

BI.S4.H2.768GB RAM + 1.5TB Persistent Memory

1:2

BI.S4.H2.1.5TB RAM + 3TB Persistent Memory

1:2

BI.S4.H2.768GB RAM + 3TB Persistent Memory

1:2

BI.S4.H4.1.5TB RAM + 3TB Persistent Memory

1:2

BI.S4.H4.3TB RAM + 6TB Persistent Memory

1:2

BI.S4.H8.3TB RAM + 6TB Persistent Memory

1:2

BI.S4.H8.6TB RAM + 12TB Persistent Memory

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 169

1:4

BI.S4.H2.384GB RAM + 1.5TB Persistent Memory

1:4

BI.S4.H4.768GB RAM + 3TB Persistent Memory

1:4

BI.S4.H4.1.5TB RAM + 6TB Persistent Memory

1:4

BI.S4.H8.1.5TB RAM + 6TB Persistent Memory

1:4

BI.S4.H8.3TB RAM + 12TB Persistent Memory

Sizing
Standard HANA sizing rules apply to a 1:1 ratio configured server. The PMem size is the maximum HANA database size capacity. For example,
the BI.S4.H4 profile can host a database of up to approximately 3 TB (compressed). If the server is hosting multiple systems or tenants, you
have a total maximum data capacity of 3 TB (for example 3 x 1 TB databases or 2 x 1.5 TB systems). HANA uses both the DRAM and PMem
and manages memory use for both data and application logic.

Post-provisioning
When you order your Bare Metal server with persistent memory, regions are created by the provisioning engine. As part of post-provisioning,
you create the namespaces that you need. For more information, see Deploying your infrastructure.

Backup, recovery, and system replication
Backup, recovery, and system replication are part of standard Bare Metal configuration. You perform the same steps for post provisioning on
the Bare Metal servers as you do for SAP HANA.
1. This diagram originally appeared in the SAP Community blog by Andreas Schuster ↩︎

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 170

IBM certified for SAP solutions
IBM Cloud Paks for Data with SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction
IBM InfoSphere Information Server 11.7, Pack for SAP Applications (Version 8.2.0.4) https://www.ibm.com/docs/en/iis/11.7?
topic=applications-introduction https://www.ibm.com/docs/en/iis/11.7?topic=rn-infosphere-information-server-pack-sap-applicationsversion-8204-release-notes
IBM InfoSphere Information Server 11.7, Pack for SAP BW (Version 4.4.0.2) https://www.ibm.com/docs/en/iis/11.7?topic=bw-introduction
https://www.ibm.com/docs/en/iis/11.7?topic=iispsbrn-infosphere-information-server-pack-sap-bw-version-4402-release-notes
DataStage Cartridge Containers == CP4D?
IBM® InfoSphere® Information Server Pack for SAP Applications enables you to extract data from SAP applications, and enrich the extracted
data by mapping, aggregating, and reformatting it for use in other applications.
IBM InfoSphere Information Server Pack for SAP Applications provides common facilities to manage connection configurations for SAP
systems. IBM InfoSphere Information Server Pack for SAP Applications includes the following stages:
$ BAPI: The BAPI stage exchanges data with SAP systems by using the SAP Business Application Programming Interfaces
(BAPIs).
IDoc (intermediate documents): The IDoc Load and Extract Connector stages use the IDoc (intermediate document)
interface to load or extract SAP data.
ABAP: The ABAP Extract stage allows direct data extraction from internal SAP tables by running a generated ABAP program
directly on the SAP system.
Delta Extract: Allows you to extract data from SAP application systems by using SAP Datasource. Available from Pack for
SAP Applications version 8.0.0.0.
OData: Enables you to extract data from SAP systems (on-prem and cloud) by using the SAP exposed OData services.
Available from Pack for SAP Applications version 8.2.0.0

The InfoSphere® Information Server Pack for SAP BW enable users to schedule and run the ETL jobs. It has a friendly user interface to design
ETL jobs and to set up the data operations to be performed on SAP BI systems.
The Pack includes the following major components:
$ BW Load Stage: Loads data from non-SAP data sources to an SAP BI system. BW Load Stage is an SAP-certified, dataloading integration solution implemented using the SAP Staging BAPI interface.
BW Extract Stage: Extracts data from an SAP BI system. It is an SAP-certified, data-extraction integration solution
based on the SAP Open Hub Service interface.
BW RFC Server: Implements various functions that are invoked by an SAP BI system. It accepts the SAP BI initiated dataloading or data-extraction requests and triggers the DataStage jobs to execute the corresponding data operations.
BW RFC Manager: Manages the BW RFC Server processes. It creates one BW RFC Server process per source system. It also
provides the functions to start or stop BW RFC Server processes. A source system represents a logical or physical
system that is external to an SAP BI system. A source system provides source data to an SAP BI system or accepts
extracted data from an SAP BI system.

IBM Cloud Paks for Integration with SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction
https://www.ibm.com/support/knowledgecenter/SSGT7J

IBM Cloud Paks for Multicloud Management with SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 171

https://www.ibm.com/support/knowledgecenter/en/SSFC4F
Monitoring Agents for SAP:
SAP monitoring (i.e. SAP NetWeaver ABAP) >
https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/sap_config_agent.html
SAP HANA monitoring > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/sap_hana_config.html
SAP NetWeaver Java monitoring >
https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/sap_nw_js_config_agent.html
SAP ASE monitoring > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/sybase_config_agent.html
Monitoring Agents for SAP AnyDB:
IBM Db2 monitoring > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/db2_config.html
Microsoft SQL Server monitoring > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/mssql_config.html
Oracle Database monitoring > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/oracle_config_agent.html
Other applicable Monitoring Agents for SAP workloads:
OS (UNIX, Linux, Windows) monitoring >
https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/osagent_config_intro.html
VMware vCenter and vSphere > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/vmware_config_agent.html
Ports for the Monitoring Agents > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/planning_ports.html
System Requirements for the Monitoring Agents >
https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/planning_requirements.html
Troubleshooting SAP monitoring agents > https://www.ibm.com/support/knowledgecenter/en/SSFC4F_2.1.0/icam/trouble_sap_config.html

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 172

Innovations with IBM Cloud for SAP
ABAP SDK for IBM Watson
The ABAP SDK for IBM Watson, enables developers to easily call and use IBM Watson Developer Services directly from ABAP to create an
Intelligent Enterprise.
ABAP SDK is a community-driven SDK for the ABAP open source community that is written by ABAPers from IBM Cloud, IBM Services, and IBM
Systems. The SDK includes tight collaboration with the SAP Cloud Platform ABAP Environment development team to provide optimal usage of
IBM Watson for side-by-side extensibility development.
The ABAP SDK includes over 40,000 lines of ABAP code so that any ABAP developer needs to use only 10 - 20 lines of ABAP code to call IBM
Watson APIs.

Summary of ABAP SDK capabilities
The ABAP SDK for IBM Watson includes:
Pre-built Classes for each IBM Watson API; use only 10 - 20 lines to call IBM Watson APIs
Pre-built Methods and data types
API responses that are provided in ABAP Structures or Tables
Packaged using abapGit (Git client for ABAP) , for easy use with APACK (package and dependency manager)
SAP-standard-generated documentation (abap-docs)
This IBM first-of-a-kind release of ABAP code to open source (licensed under the Apache 2.0 license), is designed for and released with
variants for both:
SAP NetWeaver Application Server 7.50+
SAP Cloud Platform ABAP Environment 2002+
The ABAP SDK for IBM Watson is available in two variants:
ABAP SDK for IBM Watson, using SAP NetWeaver
ABAP SDK for IBM Watson, using SAP Cloud Platform ABAP Environment
It is tested with:
SAP Business Applications
SAP S/4HANA
SAP ECC
SAP Development Applications
SAP Cloud Platform ABAP Environment
SAP Development methods, frameworks, and tools
ABAP RESTful Application Programming Model
SAP Fiori UX with SAPUI5 side-by-side extensions
And it adheres to SAP coding standards for application development, such as:
HTTP(S) / REST calls
Authentication
IAM token handling
JSON <-> DDIC type conversion
Error handling

Simple Business Example Use Case
This example is an end-to-end simplified business example use case for using the ABAP SDK for IBM Watson in multiple ways.
1. ABAP with SAP Fiori + ABAP SDK for IBM Watson on the SAP Cloud Platform, Mobile Services, and ABAP Environment
Action: Customer uses mobile app to take photo of broken item, identified material by using Visual Recognition
For example, send request to business to fulfill:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 173

Submitted photo of asset
Lookup of material in ERP
Enact RFQ or PO
2. ABAP with SAP Fiori + ABAP SDK for IBM Watson
Action: Visual Recognition to check uploaded file before import of document into ERP
For example, check that uploaded image is:
A contract document
The correct contract required
Has a signature in the required position of the form
3. ABAP with SAP GUI + ABAP SDK for IBM Watson
Action: Visual Recognition and Language Translation of document that is imported into ERP
For example, upload contract document in a different language:
Convert to English
Extract specific data points
Triggers integrated business process (Finance, Planning, and other processes) or RPA flow
Resulting in a vendor comparison by global Category Managers which:
Reduces low-quality data entry
Compares Payment Term Objectives
Investigates payment punctuality of Invoice Payment Days above Term
Starts execution of automated Next Best Action workflow routing

Available IBM Watson APIs with the ABAP SDK
Full documentation for IBM Watson Developer Services is available.
The ABAP SDK for IBM Watson provides for the following IBM Watson Developer Services:
Compare and Comply
Discovery
Language Translator
Natural Language Classifier
Natural Language Understanding
Personality Insights
Speech to Text
Text to Speech
Tone Analyzer
Visual Recognition
Watson Assistant

Getting started with the ABAP SDK for IBM Watson
The four main steps to getting started are:
1. Import the ABAP SDK by using abapGit . Use Online Mode with clone of GitHub Repository or Offline Mode with .zip download from
GitHub, and import into your ABAP runtime
2. Create IBM Cloud account . Start with the free “Lite” IBM Watson Developer Services on cloud.ibm.com, obtain service instance
credentials for use in ABAP SDK
3. Use Sample Code examples . To begin innovation initiatives combined with any SAP Application, while you are following SAP’s ABAP
coding standards
4. Begin developing business-led value . Create your Intelligent Enterprise with SAP, combining SAP business application data with
insights from IBM Watson
Full documentation on using the ABAP SDK for IBM Watson is available in the first page (the README.md file) of the Git repositories on
GitHub.com:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 174

ABAP SDK for IBM Watson, using SAP NetWeaver
ABAP SDK for IBM Watson, using SAP Cloud Platform ABAP Environment

Step-by-Step Tutorial
The following step-by-step tutorial is written by one of the open source ABAP SDK core developers for IBM Watson. The tutorial details how to
go from zero to running your own ABAP Program by using the ABAP SDK for IBM Watson:
ABAP SDK for IBM Watson: Step-by-Step Tutorial

Example code snippets
Several example code snippets are included with the ABAP SDK for IBM Watson, including:
Text to Speech Example
Natural Language Understanding Example
Personality Insights Example
Language Translator Example
Each of these example code snippets is included in the Git repository under the #Usage section of the documentation:
#Usage section with sample code for the ABAP SDK for IBM Watson, using SAP NetWeaver
#Usage section with sample code for the ABAP SDK for IBM Watson, using SAP Cloud Platform ABAP Environment

API Reference
The API Reference is built into the open source Git repository, and is therefore hosted by GitHub Pages:
ABAP Client Library for Watson API Reference.

Release and Support
As the ABAP SDK is a community release, it is not updated with the same schedule as IBM-supported SDKs. It is the choice and responsibility
of application developers how this Community SDK is used.
The ABAP SDK is a Community SDK for IBM Watson, created by the IBM Watson development community and SAP's ABAP development
community - written by ABAPers from IBM Cloud, IBM Services, and IBM Systems.
Therefore, as a community release it is not updated with the same schedule as IBM-supported SDKs, and does not include support by IBM. For
more information about IBM-supported SDKs and the update policy, see Watson SDKs Reference information .
If you have questions about the IBM Watson services or are having difficulties with using the APIs, ask a question on

Stack Overflow under tag

ibm-watson-cognitive.

The Weather Company Data Packages usage with SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

SAP to Cloud Migration Acceleration Program
SAP Business Applications continue to play a critical role for many Enterprises. IBM Cloud believes “The Best Run SAP”, and we empower
those Enterprises; we put smart to work for the Enterprise.
The way that we empower SAP-run businesses, is to merge the functions of SAP business applications with the full capabilities of Cloud for the
Enterprise.
We deliver these capabilities, by providing solutions to accelerate SAP implementations and run Enterprises with worldwide, on-demand, SAPcertified Infrastructure and more.
To accelerate our joint customers' success and maximize return on investment as they move SAP workloads to Cloud, IBM Cloud provides the
SAP to Cloud Migration Acceleration Program with the following promotional benefits:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 175

Price discounts for all SAP-certified Infrastructure within the portfolio (including complementary offerings from IBM Power Systems)
Consumption-based credits of your total spend with IBM Cloud (or complementary offerings from IBM Power Systems)
These benefits are available across all IBM Business Partners and channels. Eligibility requirements for this program are amended for each
local country and details are available from your local IBM Cloud sales team.
This program is our commitment to helping SAP-run Enterprises, and we work with your chosen services partners to make your journey to
Cloud successful.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 176

Billing Considerations for SAP Workloads
Storage
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Heading 2
Content

Networking
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Heading 2
Content

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 177

Quick Study Deployment of SAP
SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, using RHEL
Note: A Quick Study, someone who is able to learn new things quickly.
These Quick Study Tutorials provide a single sample configuration, with less detailed instructions, as an introduction for customers who prefer
hands-on tasks to increase their pace of learning.
The following information provides an introduction for customers who are new to the Classic Infrastructure environment. Two sample
configurations are provided to help you through the ordering process to the start of the SAP installation.
The first configuration sample is a simple, single node 32 GB RAM server with Red Hat Enterprise Linux® (RHEL). The second is an advanced
two node configuration that adds a second virtual server of 192 GB RAM with Red Hat Enterprise Linux (RHEL) to the landscape.
An example of how to set up external storage, which can be applied to either sample configuration, is also provided.
The sample layouts might not be your preferred layout. The purpose of this guidance is to show two possibilities. Your installation should follow
your business requirements and SAP installation documentation.

Step 1: Provisioning a 32 GB server for a single-host environment
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Create > Compute > Infrastructure > Bare Metal Server .
3. Click Continue. If you can't click Continue, you don't have the correct permissions to create a server. Check with your system
administrator about your permissions.
4. Leave 1 in the Quantity field.
5. Enter e2e1270 in the Hostname field. Hostname is a permanent or temporary name for your servers. Click Information for formatting
specifics.
6. Enter mycloud.com in the Domain field. Domain is the identification string that defines administrative control within the internet. Click
Information for formatting specifics.
7. Billing defaults to Monthly. Currently, 1-year contract and 3-year contract are not available for SAP-certified servers.
8. The data centers displayed under Location depend on product availability within a particular data center. Select NA East TOR01-Toronto.
9. Click All servers > SAP certified.

Configuring your server
1. Select CPU Model BI.S3.NW32 (OS Options). For more information about how to decipher the server names, see Provisioning your Bare
Metal Servers using the IBM Cloud console.
2. RAM defaults to a predefined value based on your server selection and cannot be changed.
3. Enter an optional public key for your SSH key, which you can use to log in to your server after the server is provisioned. The default is
None.
4. Select Red Hat as your Image (OS). The default is 7.x (64 bit).
Note: If you're bringing your own license (BYOL) for your OS, select No OS. For more information, see Bring your own license .

Adding storage disks
1. Under Type, select RAID 10.
2. Disks, Hot Spare, and Disk Media have default values. Select a Disk size that covers the total amount of storage you need.
3. Click the Menu icon

> Advanced configuration and leave Controller cleared. Click OK.

Network interface
1. Select 1 Gbps Redundant Public and Private Network Uplinks for Uplink Port Speed.
2. Select the values in Table 1 for the following fields:
Field

Value

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 178

Private VLAN

tor01.bcr01a.1241

Public VLAN

tor01.fcr01a.851

Private Subnet

10.114.63.64/26

Public Subnet

158.85.65.224/28
Table 1. 32 GB network interface values

3. Leave the default values for all other fields.
4. Review your Order Summary.
5. Click I read and agree to the following Third-Party Service Agreements .
Note: You can create your server, save the order as a quote to provision later, or add the order to an estimate, which might
include multiple services.
6. Click Create to be redirected to the Checkout page after your order is verified.
You are redirected to a page with your order number. The page is your order receipt; print a copy for your records. You also receive a
confirmation email with the subject Your IBM Cloud Order ## has been approved . The ## is your order number.
Depending on your order, server is available for use within one to four hours after your order is submitted. You can check the Device Details
from the IBM Cloud console (Menu icon

> Resource List > Devices) for the status of the provisioning steps. Click the Device Name that

matches your device's Hostname and Domain to see its status.

Bring your own license
If you have your own operating system license, you install it on your Bare Metal Servers based on the vendor's instructions. For more
information, see The no OS option .

Access your server
A public IP is used for remote access, so you can connect to your server through an

ssh client (for example, PuTTY on Microsoft Windows).

Use the public IP address displayed in the Device List (under the Devices menu) for your device. The root password for your server is also
displayed. Click Show Password to see it.

Partitioning and file systems
For the single-node example, you ordered a server with one logical disk (on RAID 1). The server has one mirrored disk with the operating
system (OS) and one large root file system equal to the total size of the disk (with some space used for /boot ). The file system layout in this
example is just one possible approach. For production use, follow the sizing information for your system as other layouts might better meet
your needs or SAP requirements.
1. Create the three directories required for the SAP installation, /sapmnt , /usr/sap , and /db2 .
$ [root@e2e1270 ~]# mkdir /sapmnt
[root@e2e1270 ~]# mkdir /usr/sap
[root@e2e1270 ~]# mkdir /db2

Your IBM Cloud® Bare Metal Servers is now ready for external storage and the installation of your SAP applications and software.

Step 2: Provisioning 192 GB and 32 GB servers for a three-tier environment
A three-tier environment is a more complex scenario using a 192 GB server as the database server and a 32 GB server as the SAP NetWeaver
application server.

Ordering your SAP NetWeaver Application Server
Follow the same steps in Provisioning a 32 GB server for a single-host environment to order the SAP NetWeaver Application Server.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 179

Ordering your Database Server
Use the following steps to order an SAP-certified server as your database server.
1. Log in to the IBM Cloud® console) with your unique credentials.
2. Click Create resource > Compute > Bare Metal Server .
3. Click Continue. If you can't click Continue, you don't have the correct permissions to create a server. Check with your system
administrator about your permissions.
4. Leave 1 in the Quantity field.
5. Enter sdb192 in the Hostname field. Hostname is a permanent or temporary name for your servers. Click Information for formatting
specifics.
6. Enter mycloud.com in the Domain field. Domain is the identification string that defines administrative control within the internet. Click
Information for formatting specifics.
7. Billing defaults to Monthly. Currently, 1-year contract and 3-year contract are not available for SAP-certified servers.
8. The data centers displayed under Location depend on product availability within a particular data center. Select NA East, TOR01Toronto.
9. Click All servers > SAP certified.

Configuring your Database Server
Use the following steps to configure your database server and OS.
1. Select CPU Model BI.S3.NW192 (OS Options). For more information about how to decipher the server names, see Provisioning your Bare
Metal Servers using the IBM Cloud console.
2. RAM defaults to a predefined value based on your server selection and cannot be changed.
3. Enter an optional public key for SSH key, which you can use to log in to your server after the server is provisioned. The default is None.
4. Select Red Hat as your Image (OS). The default is 7.x (64 bit).
Note: If you're bringing your own license (BYOL) for your OS, select No OS as your image. For more information, see Bring your
own license.

Adding storage disks
Use the following steps to add a second 2 TB SATA drive to your database server.
1. For Disk 1, click the Menu icon

> Advanced configuration > and verify that Primary disk partition** is set to the default of Windows

Basic. Click OK.
2. Click Add new.
3. Disks, Hot Spare, and Disk Media have default values. Select a Disk Size that covers the total amount of storage you need.

Setting up the network interface
Use the following steps to set up the network interface for your database server.
1. Select 1 Gbps Redundant Public & Private Network Uplinks for Uplink Port Speed.
2. Select the values in Table 1 for the following fields:
Note: Make sure the network interface values for your database server match the values of your application server.

Field

Value

Private VLAN

tor01.bcr01a.1241

Public VLAN

tor01.fcr01a.851

Private Subnet

10.114.63.64/26

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 180

Public Subnet

158.85.65.224/28
Table 2. 192 GB network interface values

3. Leave the default values for all other fields.
4. Review your Order Summary.
5. Select I read and agree to the following Third-Party Service Agreements .
Note: You can create your server, save the order as a quote to provision later, or add the order to an estimate, which might
include multiple services.
6. Click Create to be redirected to the Checkout page after your order is verified.
You are redirected to a page with your order number. The page is your receipt; print the page for your records. You also receive a confirmation
email with the subject Your IBM Cloud Order ## has been approved . The ## is your order number.
Depending on your order, the server is available for use within one to four hours after the order is submitted. You can check Device Details from
the IBM Cloud console (Menu icon

> Resource List > Devices) for the status of the provisioning steps. Click the Device Name that

matches your given Hostname and Domain to see its status.

Bring your own license
If you have your own operating system license, you install it on your Bare Metal Servers based on the vendor's instructions. For more
information, see The no OS option .

Access your server
A public IP is used for remote access, so you can connect to your server through an

ssh client (for example, PuTTY on Microsoft Windows).

Use the public IP address displayed in the Device List (Classic Infrastructure > Devices) for your device. The root password for your server is
also displayed. Click Show Password to see it.

Partitioning and file systems
For the three-tier example, a 192 GB database server with one logical disk (on RAID10) and a 32 GB application server with one logical disk
(on RAID 1) were ordered. Both servers come with one large root file system that is equal to the total size of disk (with some space that is used
for /boot ).
For the 32 GB server, create the /usr/sap/ file system. The file systems sapmnt1 and /usr/sap/trans are created on the database server.
The Network File System (NFS) is exported from the database server, which also hosts the Advanced Business Application Programming
(ABAP) SAP Central Service [(A)SCS] instance.
The following file system layout is one possible approach. For production use, you might follow the sizing information for your system as other
layouts might better meet your needs or SAP requirements, or you might use quotas.
Use the following commands to create the required directories for installing the SAP software,

/sapmnt , /usr/sap , and /db2 :

$ [root@ sdb192 ~]# mkdir /sapmnt
[root@ sdb192 ~]# mkdir /usr/sap
[root@ sdb192 ~]# mkdir /db2

Preparing your network for a three-tier setup
If you are planning to install a three-tier setup, the network needs to be set up correctly. In the example, a 192 GB database server (named
"sdb192") and a 32 GB application server (named "e2e1270") are deployed. The database server also hosts the (A)SCS instance. Adding the
IP addresses on the private network to your /etc/hosts helps with the upcoming steps and ensures that SAP internal network traffic goes
through the right network.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 181

Figure 1. Sample of three-tier setup

Use the following steps to establish your network.
1. Log in to the servers and find their private network configuration.
$ [root@sdb192 ~]# ifconfig bond0
bond0

Link encap:Ethernet

HWaddr 0C:C4:7A:66:2D:A8

inet addr:10.17.139.35

Bcast:10.17.139.63 Mask:255.255.255.192

inet6 addr: fe80::ec4:7aff:fe66:2da8/64 Scope:Link
UP BROADCAST RUNNING MASTER MULTICAST

MTU:1500

Metric:1

RX packets:128080 errors:0 dropped:0 overruns:0 frame:0
TX packets:25491 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:0
RX bytes:19137850 (18.2 MiB)

TX bytes:3426015 (3.2 MiB)

$ [root@sdb192 ~]# ifconfig bond1
bond1

Link encap:Ethernet

HWaddr 0C:C4:7A:66:2D:A9

inet addr:208.43.211.118

Bcast:208.43.211.127 Mask:255.255.255.224

inet6 addr: fe80::ec4:7aff:fe66:2da9/64 Scope:Link
UP BROADCAST RUNNING MASTER MULTICAST

MTU:1500

Metric:1

RX packets:289610 errors:0 dropped:0 overruns:0 frame:0
TX packets:109371 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:0
RX bytes:31216160 (29.7 MiB)

TX bytes:18591947 (17.7 MiB)

In the three-tier example, 10.17.139.35 is the private IP address of the database server; it is from one of the IP address ranges from RFC
1597. You can determine the IP address of the application server, too, and add both IP addresses to both servers’ /etc/hosts .
$ [root@sdb192 ~]# cat /etc/hosts
127.0.0.1 localhost.localdomain localhost
208.43.211.118 e2e2690.saptest.com e2e2690
10.17.139.35

sdb192-priv

10.17.139.46

e2e1270-priv

Add the last two lines on e2e1270 , too.

Installing NFS software
1. Install NFS software nfs-utils on both servers.
$ [root@sdb192 ~]# yum install nfs-utils

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 182

Make sure you start and register the rpcbind and NFS service on the database server.
$ [root@sdb192 ~]# service rpcbind start
[root@sdb192 ~]# chkconfig nfs on
[root@sdb192 ~]# service nfs start

Using NFS to export
1. Use NFS to export /sapmnt and /usr/sap/trans from the database server to the application server by adding the required entry to
/etc/exports of the database server.
$ /sapmnt/C10

10.17.139.46(rw,no_root_squash,sync,no_subtree_check)

/usr/sap/trans 10.17.139.46(rw,no_root_squash,sync,no_subtree_check)

The sample value C10 needs to be replaced with the SAP System ID for your SAP system. You must create the directory before you export it.
Run the following commands from the command line of the database server:
$ [root@sdb192 ~]# mkdir /sapmnt/C10
[root@sdb192 ~]# mkdir -p /usr/sap/trans
[root@sdb192 ~]# exportfs -a

Mounting the NFS share
1. Mount the NFS share on the application server by adding the following entry to its

/etc/fstab and mount it from the command line.

$ sdb192-priv:/sapmnt/C10 /sapmnt/C10 nfs defaults 0 0
sdb192-priv:/usr/sap/trans /usr/sap/trans nfs defaults 0 0

2. Create the target directories on the application server and mount them.
$ [root@e2e1270 ~]# mkdir -p /sapmnt/C10
[root@e2e1270 ~]# mkdir /usr/sap/trans
[root@e2e1270 ~]# mount /sapmnt/C10
[root@e2e1270 ~]# mount /usr/sap/trans

Your servers are now prepared to host the components of a distributed SAP installation.

Step 3: Adding external storage to your server
External storage can be added to your provisioned server or servers. You can use the external storage as a backup device, or use as a snapshot
to quickly restore your database in a test environment. For the three-tier example, block storage is used for both archiving database log files
and online and offline database backups. The fastest block storage (10 IOPS per GB) was selected to help assure a minimum backup time.
Slower block storage might be sufficient for your needs. For more information about IBM Cloud® Block Storage for Classic, see Getting started
with Block Storage.
IBM Cloud storage LUNS can be provisioned with two options - Endurance and Performance. Endurance tiers feature pre-defined performance
levels and other features, such as snapshot and replication. A custom Performance environment is built with allocated input/output operations
per second (IOPS) in the range 100 - 1,000.

Setting up external storage
1. Log in to the IBM Cloud console with your unique credentials.
2. Expand the Menu icon

and select Classic Infrastructure.

3. Select Storage > Block Storage > Order Block Storage.
4. Select the specifics for your storage needs. Table 1 contains recommended values, including 10 IOPS/GB for a demanding database
workload.
Field

Value

Location

US South, DAL10

Billing Method

Monthly (default)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 183

Size

1000 GB

Endurance (IOPS tiers)

10 IOPS/GB

Snapshot space

0 GB

OS Type

Linux (default)
Table 3. Recommended values for block storage

5. Review the Order Summary.
6. Select I have read and agree to the terms and conditions listed below .
7. Click Create.

Authorizing host
1. Select Storage > Block Storage.
2. Highlight your LUN and expand the Action menu

and select Authorize Host.

3. Select Bare Metal Server for Device Type.
4. Click Hardware to load available devices and select the hostname of your database server.
5. Click Save.
6. Check the status of your provisioned storage under Devices > (select your device) > Storage tab.
7. Note the Target Address and iSCSI Qualified Name ( IQN) for your server (iSCSI initiator), and the username and password for
authorization with the iSCSI server. You need that information in the following steps.
Tip: More provisioning information can be found under Ordering Block Storage through the Console .
Follow the steps in Connecting to MPIO iSCSCI LUNS on Microsoft Windows to make your storage accessible from your provisioned server.

Making storage multipath
In the sample deployment, you retrieved the following data from the Storage tab: * Target IP: 10.2.62.78 * IQN: iqn.200505.com.softlayer:SL01SU276540-H896345 * User: SL01SU276540-H896345 * Password: EtJ79F4RA33dXm2q
1. Enter the following based on the retrieved information:
$ [root@sdb192 ~]# cat /etc/iscsi/initiatorname.iscsi
InitiatorName=iqn.2005-05.come.softlayer:SL01SU276540-H986345

An existing entry might have to be replaced in /etc/iscsi/initiatorname.iscsi .
2. Add the following lines to the end of /etc/iscsi/iscsid.conf :
$ [root@sdb192 ~]# tail /etc/iscsi/iscsid.conf
# it continue to respond to R2Ts. To enable this, uncomment this line
# node.session.iscsi.FastAbort = No
node.session.auth.authmethod = CHAP
node.session.auth.username = SL01SU276540-H896345
node.session.auth.password = EtJ79F4RA33dXm2q
discovery.sendtargets.auth.authmethod = CHAP
discovery.sendtargets.auth.username = SL01SU276540-H896345
discovery.sendtargets.auth.password = EtJ79F4RA33dXm2q

3. Replace the username and password values in step 2 with th values that you noted during step 5 of Authorizing hosts.
4. Discover the iSCSI target by entering the following lines.
$ [root@sdb192 ~]# iscsiadm -m discovery -t sendtargets -p "10.2.62.78"
10.2.62.78:3260,1031 iqn.1992-08.com.netapp:tor0101
10.2.62.87:3260,1032 iqn.1992-08.com.netapp:tor0101
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 184

5. Set the host to automatically log in to the iSCSI array.
$ [root@sdb192 ~]# iscsiadm -m node -L automatic

6. Install and start the multipath daemon.
$ [root@sdb192 ~]# yum install device-mapper-multipath
…
[root@sdb192 ~]# chkconfig multipathd on
[root@sdb192 ~]# service multipathd start

7. Complete all the commands in Connecting to iSCSI LUNS on Linux so another LUN appears in the multipath output.
$ [root@sdb192 ~]# multipath -ll
…
3600a098038303452543f464142755a42 dm-9 NETAPP,LUN C-Mode
size=500G features='3 queue_if_no_path pg_init_retries 50' hwhandler='1 alua' wp=rw
|-+- policy='round-robin 0' prio=50 status=active
| `- 10:0:0:169 sde 8:64 active ready running
`-+- policy='round-robin 0' prio=10 status=enabled
`- 9:0:0:169

sdf 8:80 active ready running

…`

You can now use the multipath device as you would use any disk device. A device path appears under
/dev/mapper/3600a098038303452543f464142755a42 .

Take the sample /etc/multipath.conf from the example multipath.conf and create it on your server. Any copied special characters, DOSlike carriage returns, line-feed entries might lead to unexpected behavior. Make sure that you have an ASCII Unix file after you copy the
contents.
Adapt the multipath block from /etc/multipath.conf to create an alias of the path to access the device under

1/dev/mapper/mpath1 .

$ multipaths {
multipath {
wwid 3600a098038303452543f464142755a42
alias mpath1
}
}

1. Restart multipathd . You can now create the /backup file system and mount on the block device.
$ [root@sdb192 ~]# service multipathd restart
[root@sdb192 ~]# mkfs.ext4 /dev/mapper/mpath1
[root@sdb192 ~]# mkdir

/backup

1. Check the file systems on both servers. Your output should be similar to the following output.
$ [root@e2e1270 ~]# df -h
Filesystem

Size

Used Avail Use% Mounted on

/dev/sda3

879G

1,5G

833G

1% /

tmpfs

16G

0

16G

0% /dev/shm

/dev/sda1

248M

63M

173M

27% /boot

/dev/sdb2

849G

201M

805G

1% /usr/sap

db192-priv:/usr/sap/trans
165G

59M

157G

1% /usr/sap/trans

db192-priv:/sapmnt/C10
165G

59M

157G

1% /sapmnt/C10

$ [root@sdb192 ~]# df -h
Filesystem

Size

Used Avail Use% Mounted on

/dev/sda3

549G

2,3G

519G

1% /

tmpfs

127G

0

127G

0% /dev/shm

/dev/sda1

248M

63M

173M

27% /boot

/dev/mapper/mpath1

493G

70M

468G

1% /backup

/dev/mapper/datavg-datalv
1,2T

71M

1,1T

1% /db2

/dev/mapper/datavg-saplv
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 185

165G

60M

157G

1% /usr/sap

/dev/mapper/datavg-sapmntlv
165G

60M

157G

1% /sapmnt

If you install an SAP NetWeaver-based SAP application on IBM Db2, you must create subdirectories under

/backup owned by the database

admin user (db2SID) for full backups and archived log files. To automatically archive the log files, set LOGMETH1 in your Db2 on Cloud
database. Refer to the Db2 on Cloud documentation) for details.

Step 4: Installing your SAP landscape
Prerequisite: Installing RPM packages
An SAP installation requires certain prerequisites for the packages that are installed on the OS and the OS daemons that are running. Refer to
the latest installation guides). Click Access downloads under Installations & Upgrades (requires an SAP S-user ID. Also, refer to the latest
support notes) (requires an SAP S-user ID) from SAP for an up-to-date list of these prerequisites.
Two more packages need to be installed:
compat-sap-c++: Generally achieves compatibility of the C++ runtime with the compilers that are used by SAP. Because Red Hat
Enterprise Linux for SAP Business Application 7.X was selected as the OS for both the 32 GB application server and the 192 GB database
server, you use compat-sap-c++-7.
uuidd: Maintains OS support for the creation of UUIDs.

Checking if uuidd is installed
1. Check whether uuid daemon (uuidd) is installed. If it is not, install and start it.
$ [root@sdb192 ~]# rpm -qa | grep uuidd
[root@sdb192 ~]# yum install uuidd
[root@sdb192 ~]# chkconfig uuidd on
[root@sdb192 ~]# service uuidd start

Installing package compat-sap-c++-7
1. Follow SAP Note 2195019) and install package compat-sap-c++-7 and create a specific soft-link, which is required by the SAP binaries.
Check the release-specific SAP Notes for the product you are installing to determine whether the library is required.
$ [root@sdb192 ~]# yum install compat-sap-c++-7-7.2.1-2.e17_4.x86_64.rpm
....
[root@sdb192 ~]# mkdir -p /usr/sap/lib
[root@sdb192 ~]# ln -s /opt/rh/SAP/lib64/compat-sap-c++.so /usr/sap/lib/libstdc++.so.6

Downloading your SAP software
Log in to the SAP Support Portal), click Download Software, and download the required DVDs to a local share drive. Transfer the files to your
provisioned server. Another option is to download the SAP Software Download Manager) , install it on your target server and directly download
the DVD images to the server.

Preparing for SAP's SWPM GUI
Depending on your network bandwidth and latency, you might want to run the SAP Software Provisioning Manager (SWPM) graphical user
interface (GUI) remotely in a virtual network computing (VNC) session. Another option is to have the GUI running locally and connect to SWPM
on the target machine. Use the SWPM documentation) if you decide to run the GUI locally.
The following steps outline running the SWPM GUI remotely in a virtual network computing (VNC) session. This option installs a VNC server,
which might not be inline with hardening your operating system; ensure that you are meeting your security measures. Refer to VNC
documentation for an overview on its functions if you are not familiar with it.
1. Use the following commands to install a VNC server.
$ [root@sdb192 ~]# yum install tigervnc-server

2. Use the following command to install the X11 window manager, twm , which is included in the Linux distribution.
$ [root@sdb192 ~]# yum install twm

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 186

3. Install a terminal emulator, for example, xterm .
$ [root@sdb192 ~]# yum install xterm

4. Start the VNC server from the command line.
$ [root@sdb192 ~]# vncserver

You now require a VNC client program. Multiple implementations are available for all operating systems at no cost. Typically, you need port
590X (where X is the number of the servers that are running, starting at 1) to be accessible from your client.
You might have to start an xterm from the background menu of twm. You can start SWPM (sapinst) from the xterm.

Installing SAP software
After you download the installation media, follow the standard SAP installation procedure that is documented in the SAP installation guide for
your SAP version and components, and the corresponding SAP Notes.
You can start SAP SWPM from the xterm, and run the installation steps.

Installing the SAP software in a three-tier environment
Follow the steps in SAP's SWPM for a three-tier setup.
1. Select Distributed System and install the ASCS and the database on the database server.
2. Install the Application Server ABAP on the application server. Be sure to use the private addresses for the ASCS and the database
hostnames during installation of the application server.
The use of the private addresses and hostnames assures that network traffic between the application server and ASCS, or database, passes
through the private network and not through the public network.

Step 5: Sample multipath.conf
The following sample multipath.conf is for Red Hat 7.X and NetApp-based iSCSI LUNs.
$ defaults {
user_friendly_names no
max_fds max
flush_on_last_del yes
queue_without_daemon no
dev_loss_tmo infinity
fast_io_fail_tmo 5
}

All data under blacklist must be specific to your system.
$ blacklist {
wwid "SAdaptec*"
devnode "^hd[a-z]"
devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"
devnode "^cciss.*"
}
devices {
device {
vendor "NETAPP"
product "LUN"
path_grouping_policy group_by_prio
features "3 queue_if_no_path pg_init_retries 50"
prio "alua"
path_checker tur
failback immediate
path_selector "round-robin 0"
hardware_handler "1 alua"
rr_weight uniform
rr_min_io 128
}
}
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 187

Sample multipath.conf multipaths extension for ‘human readable’ device paths:
$ multipaths {
multipath {
wwid XXXXYYYZZZ
alias pathname
}
}

SAP NetWeaver deployment to Bare Metal on Classic Infrastructure, when you are
using Windows Server
Note: A Quick Study, someone who is able to learn new things quickly.
These Quick Study Tutorials provide a single sample configuration, with less detailed instructions, as an introduction for customers who prefer
hands-on tasks to increase their pace of learning.
The following information provides an introduction for customers who are new to the Classic Infrastructure environment. Two sample
configurations are provided to help you through the ordering process to the start of the SAP installation.
The first configuration sample is a simple, single node 32 GB RAM server with Windows Server. The second is an advanced two-node
configuration that adds a second virtual server of 192 GB RAM with Windows Server to the landscape.
The third sample is an example of how to set up external storage, which can be applied to either sample configuration.
The sample layouts might match your preferred layout. The purpose of the tutorial is to show two possibilities. Your installation should follow
your business requirements and SAP installation documentation.

Step 1: Provisioning a 32 GB server for a single-host environment
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Create resource > Compute > Infrastructure > Bare Metal Server .
3. Click Continue. If you can't click Continue, you don't have the correct permissions to create a server. Check with your system
administrator about your permissions.
4. Leave 1 in the Quantity field.
5. Enter e2e1270 in the Hostname field. Hostname is a permanent or temporary name for your servers. Click Information for formatting
specifics.
6. Enter mycloud.com in the Domain field. Domain is the identification string that defines administrative control within the internet. Click
Information for formatting specifics.
7. Billing defaults to Monthly. Currently, 1-year contract and 3-year contract are not available for SAP-certified servers.
8. The data centers displayed under Location depend on product availability within a particular data center. Leave the default Location of
NA South DAL10-Dallas.
9. Click All servers > SAP certified.

Configuring your server
Select your SAP-certified server and OS.
1. Select CPU Model BI.S3.NW32 (OS Options) . For more information about deciphering the server names, see Provisioning your Bare
Metal Servers using the IBM Cloud console.
2. RAM defaults to a predefined value based on your server selection and cannot be changed.
3. Enter an optional public key for your SSH key, which you can use to log in to your server after provisioning is done. The default is None.
4. Choose Microsoft as your Image (OS) and select 2016 Standard (64 bit)-HVM .
Note: If you're bringing your own license (BYOL) for your OS, select No OS. For more information, see Bring your own license .

Adding storage disks
1. Under Type, select RAID 10.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 188

2. Disks, Hot Spare, and Disk Media have default values that are based on your selection. Select a Disk Size that covers the total amount
of storage you need.
3. Click the Menu icon

> Advanced configuration and leave Controller cleared. Click OK.

Network interface
1. Select 1 Gbps Redundant Public and Private Network Uplinks for Uplink Port Speed.
2. Select the values in Table 1 for the following fields:
Field

Value

Private VLAN

dal10.bcr01a.981

Public VLAN

dal10.fcr01a.926

Private Subnet

10.177.119.192/26

Public Subnet

169.46.15.96/27
Table 1. 32 GB network interface values

3. Leave the default values for all other fields.
4. Review your Order Summary.
5. Select I read and agree to the following Third-Party Service Agreements .
Note: You can create your server, save the order as a quote to provision later, or add the order an estimate, which might include
multiple services.
6. Click Create to be redirected to the Checkout page after your order is verified.
You are redirected to a page with your order number. Print the page because it is your receipt. You also receive a confirmation email with the
subject Your IBM Cloud Order ## has been approved . The ## is your order number.
Depending on your order, the server is available for use within one to four hours after the order is submitted. You can check Device Details from
the IBM Cloud console (Menu icon

> Resource List > Devices) for the status of the provisioning steps. Click the Device Name that matches

your device's hostname and domain to see its status.

Bring your own license
If you have your own operating system license, you install it on your Bare Metal Servers based on the vendor's instructions. For more
information, see The no OS option .

Access your server
Use a public IP for remote access so that you can connect to your server through a Remote Desktop (RDP) client (for example, Microsoft
Windows’ MSTSC). The public IP address is displayed in the Device List for your device. The administrator password for your server is also
displayed. Click Show Password to see the password.

Partitioning and file systems
For the single-node example, a server with one logical disk (on RAID 1) was ordered. The operating system (OS) has one mirrored disk, with
one large file system equal to the total size of the ordered disk.
The server does not require any further installation steps for storage.

Step 2: Provisioning 192 GB and 32 GB servers for a three-tier environment
A three-tier environment is a more complex scenario that uses a 192 GB server as the database server and a 32 GB server as the SAP
NetWeaver application server.

Ordering your SAP NetWeaver Application Server
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 189

Follow the steps in the Provisioning a 32 GB server for a single-host environment to order the SAP NetWeaver Application Server.

Ordering your Database Server
Use the following steps to order an SAP-certified server as your database server.
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Create resource > Compute > Infrastructure > Bare Metal Server .
3. Click Continue. If you can't click Continue, you don't have the correct permissions to create a server. Check with your system
administrator about your permissions.
4. Leave 1 in the Quantity field.
5. Enter sdb192 in the Hostname field. Hostname is a permanent or temporary name for your servers. Click Information for formatting
specifics.
6. Enter mycloud.com in the Domain field. Domain is the identification string that defines administrative control within the internet. Click
Information for formatting specifics.
7. Billing defaults to Monthly. Currently, 1-year contract and 3-year contract are not available for SAP-certified servers.
8. The data centers displayed under Location depend on product availability within a particular data center. Leave the default Location of
NA South DAL10-Dallas.
9. Click All servers > SAP certified.

Configuring your Database Server
Use the following steps to configure your database server and its OS.
1. Select CPU Model BI.S3.NW192 (OS Options). For more information about deciphering the server names, see Provisioning your Bare
Metal Servers using the IBM Cloud console.
2. RAM defaults to a predefined value based on your server selection and cannot be changed.
3. Enter an optional public key for your SSH key, which you can use to log in to your server after provisioning is done. The default is None.
4. Choose Microsoft as your Image (OS), and select 2016 Standard (64 bit)-HVM .
Note: If you're bringing your own license (BYOL) for your OS, select No OS. For more information, see Bring your own license .

Adding storage disks
Use the following steps to add a 2 TB SATA drive for your database server.
1. For Disk 1, click the Menu icon

> Advanced configuration and verify that Primary disk partition is set to the default of Windows

Basic. Click OK.
2. Click Add new.
3. Disks, Hot Spare, and Disk Media have default values. Select a Disk Size that covers the total amount of storage you need.

Setting up the network interface
Use the following steps to set up the network interface for your database server.
1. Select 1 Gbps Redundant Public and Private Network Uplinks for Uplink Port Speed.
2. Select the values in Table 1 for the following fields:
Note: Make sure the network interface values for your database server match the values for your application server.

Field

Value

Private VLAN

dal10.bcr01a.981

Public VLAN

dal10.fcr01a.926

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 190

Private Subnet

10.177.119.192/26

Public Subnet

169.46.15.96/27
Table 2. 192 GB network interface values

3. Leave the default values for all other fields.
4. Review your Order Summary.
5. Select I read and agree to the following Third-Party Service Agreements .
Note: You can create your server, save the order as a quote to provision later, or add the order to an estimate, which might
include multiple services.
6. Click Create to be redirected to the Checkout page after your order is verified.
You are redirected to a page with your order number. Print the page because it is your receipt. You also receive a confirmation email with the
subject Your IBM Cloud Order ## has been approved . The ## is your order number.
Depending on your order, the server is available for use within one to four hours after the order is submitted. You can check Device Details from
the IBM Cloud console (Menu icon

> Resource List > Devices) for the status of the provisioning steps. Click the Device Name that matches

your given hostname and Domain to see its status.

Bring your own license
If you have your own operating system license, you install it on your Bare Metal Servers based on the vendor's instructions. For more
information, see The no OS option .

Access your server
Use a public IP for remote access so that you can connect to your servers through a Remote Desktop (RDP) client (for example, Windows’
MSTSC). The public IP addresses are displayed in the Device List (under the Device menu) for your device. The root passwords for your servers
are also displayed. Click Show Password to see the passwords.

Partitioning and file systems
For the three-tier example, a 192 GB database server with one logical disk (on RAID10) and a 32 GB application server with one logical disk
(on RAID 1) were ordered. Both servers come with one large file system equal to the total size of disks.
The server does not require any further installation steps for storage.

Preparing your network for a three-tier setup
If you are installing a three-tier setup, you need to prepare the network setup. For the sample setup, a 192 GB database server (named
"sdb192") and a 32 GB application server (named "e2e1270") are deployed. The database server also hosts the ABAP SAP Central Services
(ASCS) instance. Adding the IPs on the private network to your hosts file helps with the upcoming steps and ensures that SAP internal network
traffic goes through the right network.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 191

Figure 1. Sample of three-tier setup

Figure 1. Sample of three-tier setup
The network setup of the deployed servers that are outlined in Figure 1 is found under Network Connections in Microsoft Windows. In the
sample setup, 10.17.139.35 is the private IP of the database server that is found under Network Connections - Private Network-Teamed,
and is one of the IP ranges from RFC 1597. You can determine the IP of the application server, too, and add both IPs to both servers' host
files under C:\Windows\System32\drivers\etc .

In the IBM Cloud® console, you can find the private IP of the database server under Menu icon

> Resource List > Devices. Select the

applicable device and the IP address is displayed in the respective column.

Step 3: Adding external storage to your server
External storage can be added to your provisioned server, or servers. You can use the external storage as a backup device, or as a snapshot to
quickly restore your database in a test environment. In the example, block storage is used for both archiving log files of the database and
online and offline backups for the database. The fastest block storage (10 IOPS per GB) was selected to help assure a minimum backup time.
Slower block storage might be sufficient for your needs. For more information about IBM Cloud® Block Storage for Classic, see Getting started
with Block Storage.
IBM Cloud storage LUNS can be provisioned with two options - Endurance and Performance. Endurance tiers feature pre-defined performance
levels and other features, such as snapshot and replication. A custom Performance environment is built with allocated input/output operations
per second (IOPS) in the range 100 - 1,000.

Setting up external storage
1. Log in to the IBM Cloud console with your unique credentials.
2. Expand the Menu icon

and select Classic Infrastructure.

3. Select Storage > Block Storage > Order Block Storage.
4. Select the specifics for your storage needs. Table 1 contains recommended values, including 10 IOPS/GB for a demanding database
workload.
Field

Value

Location

US South, DAL10

Billing Method

Monthly (default)

Size

1000 GB

Endurance (IOPS tiers)

10 IOPS/GB

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 192

Snapshot space

0 GB

OS Type

Windows 2008+
Table 3. Recommended values for block storage

5. Review the Order Summary.
6. Select I have read and agree to the terms and conditions listed below .

Authorizing host
1. Select Storage > Block Storage.
2. Highlight your LUN and expand the Action menu

and select Authorize Host.

3. Select a Device Type of Bare Metal Server.
4. Click Hardware to load available devices and select the hostname of your database server.
5. Click Save.
Tip: More provisioning information can be found under Ordering Block Storage through the Console .
Follow the steps in Connecting to MPIO iSCSCI LUNS on Microsoft Windows to connect your block storage to your database server by using
the data from the example. Follow the steps carefully; they lead to a new “offline” disk available for your Windows server.
You can now bring the disk online and initialize it.

Step 4: Installing your SAP landscape
Downloading your SAP software
You need an SAP S-user ID and Download Authorization to download the DVDs. For more information about the SAP S-user ID, see

How to set

up an S-user ID.
1. Log in to the SAP Support Portal, click Download Software, and download the required DVDs to a local share drive.
2. Transfer the files to your provisioned server.
Another option is to download the SAP Software Download Manager , install it on your target server, and directly download the DVD images to
the server.

Installing SAP software
Note: This example is for downloading the applicable SAP NetWeaver software. You may or might not be using SAP Netweaver 7.5.
After you download the installation media, follow the standard SAP installation procedure that is documented in the SAP installation guide for
your SAP version and components, and the corresponding SAP Notes. For more information, see SAP Installation Guide (search for the guides
based on the Windows OS) and SAP Notes. SAP Notes requires an SAP S-user ID.
1. Open the root folder of your SWPM-DVD or of your installation DVD as Administrator, and run

sapinst . The Welcome to SAP Installation

page is displayed.
2. Select SAP NetWeaver 7.5 > IBM DB2 for Linux, Unix, and Windows > SAP Systems > Application Server ABAP.
3. Open Distributed System and run ASCS Instance and Database Instance on the database server.
4. Verify that sapinst successfully shared folders \\usr\sap\trans and \\sapmnt after the ASCS Instance is installed for the next step
to work.
5. Run Primary Application Server Instance on the application server. Be sure to use the private addresses for the ASCS and the database
hostnames during installation of the application server. Using private addresses ensures that network traffic between the application
server and ASCS, or database, path through the private network and not through the public network.
You can now run your SAP installation according to the SAP installation instructions.

SAP NetWeaver deployment to Intel Virtual Server on VPC Infrastructure that uses
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 193

RHEL
Note: A Quick Study, someone who is able to learn new things quickly.
These Quick Study Tutorials provide a single sample configuration, with less detailed instructions, as an introduction for customers who prefer
hands-on tasks to increase their pace of learning.
The following information provides an introduction for customers who are new to IBM Cloud® Virtual Private Cloud (VPC) Gen 2 environment.
Two sample configurations are provided to help you through the ordering process to the start of the SAP installation.
The first configuration sample is simple, a single node 128 GB, 32 vCPU server. The second is an advanced configuration of two nodes by
adding a second virtual server to the landscape. The sample layouts might not be your preferred layout. The purpose of this guidance is to
show you two possibilities if you are not experienced with the Linux® operating system or with VPC Gen 2.

Figure 1. IBM Cloud VPC

Step 1: Securing Access
Security is one of the biggest concerns when you run your business-critical applications in a cloud environment. To secure your connection to
your IBM® Virtual Servers, a public SSH key can be uploaded to your account, per region. These public keys are deployed to your virtual servers
instances to allow access to the servers.
Tip: Before you continue, create an SSH public key that you can upload later to the region of your choice when you are creating the
virtual server instance. Follow the steps that are documented here.
You use security groups to restrict access to and from IP ranges, protocols, and ports. Security groups aren't within the scope of this guidance,
and the default security group that is deployed with your sample VPC can suffice. However, you might have to add extra ports for exceptions to
the access restrictions, such as, the SAP Software Provisioning Manager and for the ports that are being used by your SAP NetWeaver based
application.

Step 2: Creating an IBM Cloud VPC and subnet
IBM Cloud® compute resources are kept in a global region within a VPC. Use the following steps to create a VPC and its subnet.
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Menu icon

> VPC Infrastructure > Network > VPCs and click New virtual private cloud > Create VPC for Gen 2 .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 194

Figure 2. Creating a VPC

1. Enter a unique Name for the VPC, for example, sap-test-inst.
2. Keep the default Resource group. Use resource groups to organize your account resources for access control and billing purposes. For
more information, see Best practices for organizing resources in a resource group . For this example, you can use the default value.
3. Optional: Tags. Enter tags to help you organize and find your resources. You can add more tags later. For more information, see

Working

with tags.
4. Keep the Default security group settings, which allow inbound SSH and ping traffic to virtual server instances in this VPC.
5. Optional: Classic access. Select whether you want to enable your VPC to access classic infrastructure resources. For more information,
see Setting up access to classic infrastructure .
Important: You can enable a VPC for classic access only while you are creating it. In addition, you can have only one classic
access VPC in your account at any time.
6. Optional: Default address prefixes. Disable this option if you don't want to assign default subnet address prefixes to each zone in your
VPC. After you create your VPC, you can go to its details page and set your own subnet address prefixes. If you do disable this option, the
New subnet for VPC section will be hidden, and will require manual definition after the VPC is created. Leave the default value.
Note: If you want to create the subnet and your own subnet address prefixes later, become familiar with important details of VPC
networking. For more information, see About networking for VPC and Designing an addressing plan for a VPC .

New subnet for VPC
1. Enter a unique Name for the VPC subnet, for example, sap-subnet1.
2. Select a Resource group for the subnet. For this example, keep the value default.
3. Select a Location for the subnet, for example, LON, London 3. The location consists of a region and a zone.
Tip: The region that you select is used as the region of the VPC. All additional resources that you create in this VPC are created in
the selected region.
4. Enter an Address prefix, Number of addresses , and an IP range for the subnet. The IP range is entered in CIDR notation, for example:
10.240.0.0/24. In most cases, you can use the default IP range. If you want to specify a custom IP range, you can use the IP range
calculator to select a different address prefix or change the number of addresses.
Important: A subnet cannot be resized after it is created.
5. Keep the default value for Subnet access control list . A new default ACL is created that you can configure later following these steps in:
Configuring the ACL .
6. Attach a public gateway to the subnet if you want to allow all attached resources to communicate with resources on the public internet.
However, keep in mind, that public gateways are for 'outbound traffic', 'inbound traffic' would require a Floating IP. See Preparing the
virtual server instance for your workload.
Tip: You can also attach the public gateway after you create the subnet.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 195

7. Click Create virtual private cloud . The VPC appears in the Virtual Private Clouds page immediately.

Step 3: Creating a Virtual Server Instance
Use the following steps to create a virtual server instance.
1. Click Virtual server instances > New instance.
2. Enter a unique Name for the virtual server, for example, sap-app-vsi . The name that you enter becomes the hostname.
Important: SAP hostnames must consist of a maximum of 13 alpha-numeric characters. See SAP Note 611361 for further
details.
3. Select the Virtual private cloud in which to attach the virtual server instance, for example, sap-test-inst .
4. Keep the Resource group default.
5. Optional: Tags. Enter tags to help you organize and find your resources. You can add more tags later. For more information, see

Working

with tags.
6. The Location in which you created your subnets is already selected. The location consists of a region and a zone.
7. Select Catalog image > ibm-redhat-7-6-amd64-sap-applications-1 as the OS image.

Figure 3. Catalog image for SAP NetWeaver
$ For every SUSE Linux&reg; Enterprise and Red Hat&reg; Enterprise Linux&reg; version there are two different Catalog
Images available each: one for SAP HANA and one for SAP NetWeaver (Applications). In these images, the specific
repositories are enabled, so you can install the OS packages that are required to install SAP HANA or SAP NetWeaver.
{: note}

1. Click All profiles > Balanced and select bx2-32x128. For more information about SAP-certified profiles, see Intel Virtual Server certified
profiles for SAP NetWeaver.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 196

Figure 4. Balanced profiles for SAP NetWeaver

Setting an SSH key
If you uploaded your public key for the VPC's region, select it and skip to the next section (Attaching storage). Otherwise, follow these steps.
1. Click New key.
2. Enter a unique Name, for example, sap-ssh-key.
3. Keep the default Resource group.
4. The Region in which you created your subnets is already selected.
5. Optional: Tags. Enter tags to help you organize and find your resources. You can add more tags later. For more information, see

Working

with tags.
6. Paste the Public key, that you created according to the guidelines mentioned in Securing Access .
7. Click Add SSH key.
8. Optional: User data, leave blank.

Attaching a block storage volume
To have file system space available beyond what is required by the operating system, you need to attach a block storage volume to your virtual
server instance. This storage volume is used by the application that you're installing. In this example, the application is the Relational Database
Management System (RDBMS) required for an SAP NetWeaver stack.
1. Click New volume.
2. Enter sap-app-vol1 for Name.
3. Select Custom for Profile.
4. Enter 500 for Size.
5. Enter 10000 for IOPS. Throughput defaults to 156.25 MiBps.
6. Keep the Encryption and Auto Delete defaults.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 197

Figure 5. Attaching a block storage volume

1. Click Attach.
2. Keep the Network interfaces default.
3. Click Create virtual server instance. After the Virtual Servers for VPC is provisioned and ready for SSH logon, you can begin installing the
SAP NetWeaver applications.

Step 4: Preparing the virtual server instance for your workload
IBM® Virtual Servers are accessed through IPsec connections into your VPC. Configuring IPsec-based access to virtual server instances is
beyond the scope of this guidance. For simplicity, and to quickly access the deployed instance, you can assign a Floating IP to your virtual
server instance. This IP is assigned to a gateway that forwards ports and protocols according to the defined security groups.

Figure 6. Floating IP

By assigning the IP, you can directly ssh into your virtual server instance - in our example, the command is
$ ssh -i ~/.ssh/sap-ssh-key root@158.176.180.39

To update the operating system for your virtual server instance to the latest level, run yum update and restart the virtual server instance.
The SAP NetWeaver Software Provisioning Manager (SWPM) doesn't allow products to install to hostnames that don't resolve to an external IP
on the server instance. Because of this restriction, the default settings in the virtual server instance need to be adapted. Edit /etc/hosts and
comment out the lines that resolve the hostname to the IPv4 AND IPv6 localhost addresses. Instead, the hostname must resolve to the
external IP address of your virtual server (see the example). In our example, the hostname resolves to 10.242.128.8 , the private IP
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 198

displayed in Figure 6. In this example, we append a sample default domain. Adapt this example to your specific environment.
These lines are an example of an /etc/hosts file. Take care that both references of localhost to the hostname, IPv4 and IPv6 are in comments
(or deleted).
$

# The following lines are desirable for IPv4 capable hosts
#127.0.0.1 sap-app-vsi sap-app-vsi
127.0.0.1 localhost.localdomain localhost
127.0.0.1 localhost4.localdomain4 localhost4
# The following lines are desirable for IPv6 capable hosts
#::1 sap-app-vsi sap-app-vsi
::1 localhost.localdomain localhost
::1 localhost6.localdomain6 localhost6
10.242.128.8 sap-app-vsi.saptest.com sap-app-vsi

To prevent the IBM Cloud cloudinit process from reverting the content of /etc/hosts to the previous values on the next restart, change the
configuration in /etc/cloud/cloud.cfg . Change manage_etc_host from True to False .
Finally, you need to adapt your storage by creating a file system on the attached storage volume. You can identify the newly attached volume
by its size by entering /sbin/fdisk -l and checking the sizes. To safely identify it, find the device ID by clicking Device on the Virtual server
instances for VPC page.

Figure 7. Data volumes

1. On the Overview page, check the first 20 digits in Device, and find the same ID under /dev/disk/by-id . Our example device is 07a7184b... .
$

[root@sap-app-vsi ~]# ls -als /dev/disk/by-id/ | grep 07a7-184b4a2f-d768-4 0 lrwxrwxrwx 1 root root 11 May 3 08:30 virtio-07a7-184b4a2fd786-4 -> ../../vdb
$ In our example, it's `virtio-07a7-184b4a2f-d786-4`, which is linked to `/dev/vdb`.
1. Create a file system on this path:
```
[root@sap-app-vsi ~]# mkfs.xfs /dev/vdb

1. Find the related UUID in /dev/disk/by-uuid :
$

[root@sap-app-vsi ~]# ls -als /dev/disk/by-uuid/ | grep vdb 0 lrwxrwxrwx 1 root root 11 May 10 08:31 1350230e-8058-4fe5-bbc0cc27253ff778 -> ../../vdb
$
1. Add the UUID to `/etc/fstab`, in our example:
```
UUID=1350230e-8058-4fe5-bbc0-cc27253ff778 /db2 xfs defaults 0 0

1. Create a file system to use for the greater part of your installation, since we are using IBM Db2, we choose:
$

[root@sap-app-vsi ~]# mkdir /db2 [root@sap-app-vsi ~]# mount /db2
$
1. Add swap space for SWPM. We are adding a minimum swap space to the system.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 199

```
[root@sap-app-vsi ~]# dd if=/dev/zero of=/swapfile bs=1M count=8192
8192+0 records in
8192+0 records out
8589934592 bytes (8.6 GB) copied, 24.701 s, 348 MB/s
[root@sap-app-vsi ~]# chmod 0600 /swapfile
[root@sap-app-vsi ~]# mkswap /swapfile
Setting up swapspace version 1, size = 8388604 KiB
no label, UUID=e7a63777-521a-44a7-abcc-0d17e1876a78

1. Add the following line to your /etc/fstab .
$

/swapfile none swap sw 0 0
$
1. Activate the swap space:
```
[root@sap-app-vsi ~]# swapon -a

You're now ready to install the SAP product of your choice. Your next step is to download and install your SAP software and applications if a
single virtual server sample is sufficient for your needs.

Step 5: Installing two virtual server instances in a 3-tier setup
A more complex scenario involves installing two virtual servers. One server is the SAP NetWeaver Application Server ( sap-app-vsi ) and the
other server is the database server for SAP NetWeaver. Given that we have two virtual servers of the same layout, per the example, Figures 8
and 9 are an overview of the virtual servers.

Figure 8. Virtual server instances

Figure 9. Block storage volumes for VPC

Both virtual servers have one extra attached volume and a Floating IP. A smaller volume is attached to sap-app-vsi , which is the application

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 200

server. sap-app2-vsi has a slightly larger volume to host the RDBMS and the SAP Central Services (ASCS) instance. A second volume is
needed on sap-app2-vsi to host the SAP NetWeaver stack. Create another volume from the Block storage volumes for VPC page and name it
sap-app2-vol2 . Attach sap-app2-vol2 to our virtual server by selecting its details screen.

Figure 10. Block storage volumes for VPC

Step 6: Preparing your network
To segregate network traffic, as SAP recommends, deploy a second subnet. One network is used for client access, the other for
communication between the SAP ABAP stack and the RDBMS.
Use Figure 11 as your guide to create a new subnet named sap-test-net2 .
Click Menu icon

> VPC Infrastructure > Network > Subnets and click New subnet.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 201

Figure 11. Create a subnet

After the new subnet is created, it is displayed on the Subnets for VPC page.

Figure 12. Subnets for VPC page

The two virtual servers need to connect to the new network. Go back to the virtual server overview and click New interface.

Figure 13. Data volumes

Maintain your /etc/hosts files according to the targeted setup. The following example is for sap-app2-vsi .
$

# The following lines are desirable for IPv4 capable hosts
#127.0.0.1 sap-app2-vsi sap-app2-vsi
127.0.0.1 localhost.localdomain localhost
127.0.0.1 localhost4.localdomain4 localhost4
# The following lines are desirable for IPv6 capable hosts
#::1 sap-app2-vsi sap-app2-vsi
::1 localhost.localdomain localhost
::1 localhost6.localdomain6 localhost6
10.243.128.9 sap-app2-vsi.saptest.com sap-app2-vsi
10.243.129.6 sap-app2-vsi-priv.saptest.com sap-app2-vsi-priv
10.243.128.7 sap-app-vsi.saptest.com sap-app-vsi
10.243.129.4 sap-app-vsi-priv.saptest.com sap-app-vsi-priv

Step 7: Preparing your storage
You need to provision two volumes on the database virtual server with a file system for the database and for the SAP installation. In addition,
/sapmnt needs to be Network File System (NFS) exported to the application server virtual server.

The application server virtual server has only one attached 20 GB volume. You can identify the volume without looking at the resource ID.
$ Disk /dev/vdd: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 202

I/O size (minimum/optimal): 512 bytes / 512 bytes

We create a file system on the volume and mount it after you determine its

/dev/disk/by-uuid path.

$ ls -als /dev/disk/by-uuid/ | grep vdd
0 lrwxrwxrwx 1 root root 9 May 13 03:23 cf5d6692-4176-47c4-b799-039c11103fd4 -> ../../vdd

The resulting /etc/fstab entry is in the following example.
$ UUID=cf5d6692-4176-47c4-b799-039c11103fd4 /usr/sap xfs defaults 0 0

You need to create the mount point and mount it.
$ [root@sap-app-vsi ~]# mkdir /usr/sap
[root@sap-app-vsi ~]# mount -a

On the database virtual server, you need to create three file systems. One for the RDBMS installation and two for

/usr/sap and /sapmnt .

Both attached volumes are created the same way and display as /dev/vdb and /dev/vde . In our example, we split the first file system in
two partitions.
$ [root@sap-app2-vsi ~]# /sbin/fdisk /dev/vdb
Welcome to fdisk (util-linux 2.23.2).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.
Device does not contain a recognized partition table
Building a new DOS disklabel with disk identifier 0x8f5f8b5e.
Command (m for help): n
Partition type:
p primary (0 primary, 0 extended, 4 free)
e extended
Select (default p): p
Partition number (1-4, default 1): 1
First sector (2048-419430399, default 2048):
Using default value 2048
Last sector, +sectors or +size{K,M,G} (2048-419430399, default 419430399): +100G
Partition 1 of type Linux and of size 100 GiB is set
Command (m for help): n
Partition type:
p primary (1 primary, 0 extended, 3 free)
e extended
Select (default p): p
Partition number (2-4, default 2):
First sector (209717248-419430399, default 209717248):
Using default value 209717248
Last sector, +sectors or +size{K,M,G} (209717248-419430399, default 419430399):
Using default value 419430399
Partition 2 of type Linux and of size 100 GiB is set
Command (m for help): w
The partition table has been altered!
Calling ioctl() to re-read partition table.
Syncing disks.

Create the three file systems (output isn't shown in this example).
$ [root@sap-app2-vsi ~]# mkfs.xfs /dev/vdb1
[root@sap-app2-vsi ~]# mkfs.xfs /dev/vdb2
[root@sap-app2-vsi ~]# mkfs.xfs /dev/vde
[root@sap-app2-vsi ~]# mkdir /usr/sap /sapmnt /db2

Again, you need to determine the /dev/disk/by-uuid paths, as previously shown, and maintain /etc/fstab entries. As a final step, you
need to set up the NFS to install SAP.
1. Install the NFS utilities on both virtual servers.
$ [root@sap-app-vsi ~]# yum install nfs-utils

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 203

$ [root@sap-app2-vsi ~]# yum install nfs-utils

2. Start the NFS server on the database virtual server.
$ [root@sap-app2-vsi ~]# systemctl enable nfs-server
[root@sap-app2-vsi ~]# systemctl start nfs-server

3. Use NFS to export /sapmnt and /usr/sap/trans from the database server to the application server by adding the required entry to
/etc/exports of the database server:
$ /sapmnt/C10 10.243.129.0/24(rw,no_root_squash,sync,no_subtree_check)
/usr/sap/trans 10.17.139.0/24(rw,no_root_squash,sync,no_subtree_check)

You need to adapt the subnet in the previous example to your actual IP range and subnet mask. Replace the value

C10 with the SAP

System ID for your SAP system. C10 is a sample value. You must create the directory before you export it.
4. Run on the following command from the command line.
$ [root@sap-app2-vsi ~]# mkdir /sapmnt/C10
[root@sap-app2-vsi ~]# mkdir -p /usr/sap/trans
[root@sap-app2-vsi ~]# exportfs -a

5. Mount the NFS share on the application server by adding the following entry to its

/etc/fstab and mount the application server from

the command line by using the following command.
$ [root@sap-app-vsi ~]# vi /etc/fstab
...
sap-app2-vsi-priv:/sapmnt/C10 /sapmnt/C10 nfs defaults 0 0
sap-app2-vsi-priv:/usr/sap/trans /usr/sap/trans nfs defaults 0 0

6. Create and mount the target directory.
$ [root@sap-app-vsi ~]# mkdir /sapmnt/C10
[root@sap-app-vsi ~]# mkdir /usr/sap/trans
[root@sap-app-vsi ~]# mount /sapmnt/C10
[root@sap-app-vsi ~]# mount /usr/sap/trans

Your servers are now prepared to host the components of a distributed SAP installation. For more information about more installation
preparations, see Downloading and installing SAP software and applications .

Step 8: Installing your SAP landscape
RPM package prerequisites
An SAP installation requires that certain prerequisites are met regarding the packages that are installed on the OS and the OS daemons that
are running. See the latest installation guides and support notes from SAP for an up-to-date list of these prerequisites. Currently, the following
extra packages are required for an SAP NetWeaver installation: - compat-sap-c++-7 : Achieves compatibility of the C++ runtime with the
compilers that are used by SAP - uuidd : Maintains OS support for the creation of UUIDs - csh : C shell support for the OS
1. Follow SAP note 2195019 and install package compat-sap-c++-7 . Create a specific soft-link, which is required by the SAP binary files.
$ [root@sap-app-vsi ~]# yum install compat-sap-c++-7
...
[root@sap-app-vsi tmp]# mkdir -p /usr/sap/lib
[root@sap-app-vsi tmp]# ln -s /opt/rh/SAP/lib64/compat-sap-c++-7.so /usr/sap/lib/libstdc++.so.6

2. Check if uuid daemon (uuidd) is installed. If it’s not, install and start it.
$ [root@sap-app-vsi ~]# rpm -qa | grep uuidd
[root@sap-app-vsi ~]# yum install uuidd
[root@sap-app-vsi ~]# systemctl enable uuidd
[root@sap-app-vsi ~]# systemctl start uuidd

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 204

3. Install the tcsh package required for C shell support
$ [root@sap-app-vsi ~]# yum install tcsh

Installing the IBM Cloud Metrics Collector for SAP
SAP requires the installation of the IBM Cloud Metrics Collector for SAP to analyze your infrastructure if a support case is submitted. Install the
collector by using the instructions in IBM Cloud Metrics Collector for SAP .

Downloading your SAP software
Log in to the SAP Service Marketplace ( https://support.sap.com/swdc) and download the required digital versatile discs (DVDs) to a local share
drive and then transfer the DVDs to your provisioned server. Alternative option, download the SAP Software Download Manager, install it on
your target server and directly download the DVD images to the server. For more information about the SAP Software Download Manager, see
http://service.sap.com.
Note: You need an S-User ID and the Download Software authorization when you download the DVDs from the SAP Service
Marketplace. To request an S-USer ID, see the SAP Support Portal.

Preparing for SAP’s Software Provisioning Manager (SWPM)
Depending on your network bandwidth and latency, you might need to run the SAP SWPM GUI remotely in a virtual network computing (VNC)
session. Another option is to run GUI locally and connect it to SWPM on the target machine. For the first option, you must run X11 in your
virtual server and install a VNC server and a browser. You can run the browser locally on your desktop, and connect to SWPM in the virtual
server. To connect to SWPM, check the port that SWPM is listening on. SWPM displays the port during startup when it lists the access URL. The
port, typically 4237, needs to open in the security group of your VPC. You need to add a New Inbound rule for your IP source range (or
0.0.0.0/0) and the port number. Another possibility, and even more secure, is to tunnel the port through ssh .
$ [root@sap-app-vsi ~]# ssh -L 4237:localhost:4237 <your virtual server IP>

-L option for local tunnels and connecting your browser to that localhost port, instead of the remote IP. Remember to add the ports that are
required by your SAP application (example: ports 3200-3299, depending on your SAP NetWeaver instance number) to the security group. For
more information about ports, see SAP ports for details.

Figure 14. All security groups for VPC

Installing SAP software
After you download the installation media, follow the standard SAP installation procedure that is documented in the SAP installation guides for
your SAP version and components. Also, review the corresponding SAP notes. See more detailed information about SAP NetWeaver installation
that uses Db2 as the RDBMS in Considerations about IBM Db2.

Relevant SAP Notes
SAP Note 2002167 - Red Hat Enterprise Linux 7.x: Installation and Upgrade .
SAP Note 2923773 - Linux on IBM Cloud (IaaS): Adaption of your SAP License .

SAP NetWeaver deployment to Intel Virtual Server on VPC Infrastructure that uses
Windows Server
Note: A Quick Study, someone who is able to learn new things quickly.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 205

These Quick Study Tutorials provide a single sample configuration, with less detailed instructions, as an introduction for customers who prefer
hands-on tasks to increase their pace of learning.
The following information provides an introduction for customers who are new to IBM Cloud® Virtual Private Cloud (VPC) environment. Two
sample configurations are provided to help you through the ordering process to the start of the SAP installation.
The first configuration sample is simple, a single node 128 GB, 32 vCPU virtual server instance (VSI). The second is an advanced configuration
of two nodes by adding a second VSI to the landscape. The sample layouts might not be your preferred layout. The purpose of this guidance is
to show you two possibilities if you are not experienced with the Windows® operating system or with VPC.
Although we want to start quickly, you first must be able to log in to IBM Cloud and make sure that you have access to important SAP
resources. Read the Pre-Requisites for SAP Workloads topic group, under Necessary account credentials for SAP and IBM Cloud .
Note: This tutorial contains instructions to complete the deployment - a detailed explanation of the navigation through the IBM Cloud
console and all available options that you can use, you find in the topic Deploying your infrastructure.

Step 1: Securing Access
Security is one of the biggest concerns when you run your business-critical applications in a cloud environment. To secure your connection to
your IBM® Virtual Servers, a public SSH key can be uploaded to your account, per region. These public keys are deployed to your VSIs to allow
access to them.
Tip: Before you continue, create an SSH public key that you can upload later to the region of your choice when you are creating the VSI.
Follow the steps that are documented here. Store your public and private key on your client computer - usually, in Linux® environments
it is located in the ~/.ssh folder.
You use security groups to restrict access to and from IP ranges, protocols, and ports. The default security group that is deployed with your
sample VPC can suffice. However, you might have to add extra ports for exceptions to the access restrictions, such as the SAP Software
Provisioning Manager and for the ports that are being used by your SAP NetWeaver based application.

Step 2: Creating an IBM Cloud VPC and subnet
IBM Cloud® compute resources are kept in a global region within a VPC. Use the following steps to create a VPC and its subnet.
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Menu icon

> VPC Infrastructure > Network > VPCs

3. Click Create.
4. Enter a unique Name for the VPC, for example, sap-test-vpc.
5. Select a Resource group. Use resource groups to organize your account resources for access control and billing purposes. Leave the
value default.
6. Optional: Tags. Enter tags to help you organize and find your resources. For example, sap quick guide.
7. Select whether the Default security group allows inbound SSH and ping traffic to VSIs in this VPC. Leave the value default.
8. Optional: Classic access. Select whether you want to enable your VPC to access classic infrastructure resources. Leave the value
default.
9. Optional: Default address prefixes. If you do disable this option, the New subnet for VPC section will be hidden, and will require manual
definition after the VPC is created. Leave the value default.

New subnet for VPC
1. Enter a unique Name for the VPC subnet, for example, sap-test-net.
2. Select a Resource group for the subnet. Leave the value default.
3. Select a Location for the subnet. The location consists of a region and a zone.
Tip: The region that you select is used as the region of the VPC. All additional resources that you create in this VPC are created in
the selected region.
4. Enter an Address prefix, Number of addresses , and an IP range for the subnet. Leave the value default.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 206

5. Optional: Public gateway. Leave the value default.
6. Click Create virtual private cloud on the right.

Step 3: Creating a Virtual Server Instance
Use the following steps to create a virtual server instance.
1. Click Virtual server instances > New instance.
2. Enter a unique Name for the virtual server, for example, sap-wdb. The name that you enter becomes the hostname.
Important: SAP hostnames must consist of a maximum of 13 alpha-numeric characters. See SAP Note 611361 for further
details.
3. Select the Virtual private cloud in which to attach the VSI, for example, sap-test-vpc.
4. Keep the Resource group default.
5. Optional: Tags. For example, sap quick guide.
6. Leave the selected Location in which you created your subnet
7. Select Windows Server > 2016 Standard Edition as the Operating System.
8. Click All profiles > Balanced and select bx2-32x128.
For more information about SAP-certified profiles, see Intel Virtual Server certified profiles for SAP NetWeaver .

Setting an SSH key
If you uploaded your public key for the VPC's region, select it and skip to the next section (Attaching storage). Otherwise, follow these steps.
1. Click New key.
2. Enter a unique Name, for example, sap-ssh-key.
3. Keep the default Resource group.
4. The Region in which you created your subnets is already selected.
5. Optional: Tags. For example, sap quick guide.
6. Paste the Public key, that you created according to the guidelines mentioned in Securing Access .
7. Click Add SSH key.
8. Optional: User data . Leave blank.

Attaching a block storage volume
To have file system space available beyond what is required by the operating system, you need to attach a block storage volume to your VSI.
This storage volume is used by the application that you're installing. In this example, the application is the Relational Database Management
System (RDBMS) required for an SAP NetWeaver stack.
1. Click New volume.
2. Enter sap-db-vol for Name.
3. Select Custom for Profile.
4. Enter 500 for Size.
5. Enter 10000 for IOPS. Throughput defaults to 156.25 MiBps.
6. Keep the Encryption and Auto Delete defaults.
7. Click Attach.
8. Keep the Networking default.
9. Keep the Network interfaces default.
10. Click Create virtual server instance. After the Windows instance is provisioned and ready, you need to retrieve the Administrator
password and connect to it.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 207

Step 4: Connecting to your Windows VSI
To be able to connect to the Windows VSI from your client, you need the Administrator password and a public IP address. The password is
retrieved by the IBM Cloud command-line interface (CLI) whereas the public IP address - it is called Floating IP - can be created with the IBM
Cloud console.

Install CLI
Before you can use the CLI to retrieve the Administrator password, you must install the IBM Cloud CLI and the VPC CLI plug-in.

Connect to IBM Cloud with the CLI
Log in to IBM Cloud with your IBMid. If you have multiple accounts, you are prompted to select which account to use.
$ ibmcloud login

Tip: If your credentials are rejected, you might be using a federated ID. To log in with a federated ID, use the

--sso flag. See Logging

in with a federated ID for more details.

Set the target region (DC)
Look up your region code in the table that corresponds to the location of your VPC.
Region

Location

au-syd

Sydney

jp-tok

Tokyo

eu-de

Frankfurt

eu-gb

London

us-south

Dallas

us-east

Washington DC

For example:
$ ibmcloud target -r eu-de

Get the instance ID
$ ibmcloud is ins

Find the instance ID that is assigned to your VSI sap-wdb.

Retrieve the Administrator password
$ ibmcloud is instance-initialization-values <instance ID> --private-key @sap-ssh-key

Take note of the password.

Set the floating IP
To quickly access the deployed instance, you can assign a Floating IP to your VSI. To add this IP to your server, complete the following steps:
1. In the IBM Cloud console, go to Menu icon

> VPC Infrastructure > Compute > Virtual server instances .

2. Click the name of the Windows VSI - sap-wdb.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 208

3. On the Instance details page, find the Network interfaces section.
4. By default, the first interface is named eth0.
5. Click the pencil icon to edit the primary network interface.
6. On the Edit network interface page, locate the Floating IP address field. You can select Reserve a new floating IP or you can select an
existing floating IP address.
7. After you make your selection, click Save.
8. You might note the Floating IP address or back in the virtual server instances list you can click it and copy it into the clipboard.
You can now log in to the virtual instance and begin preparing it for the SAP NetWeaver workload installation.

Step 5: Preparing the virtual server instance for your workload
Important: In this tutorial, we simplify the process and use sample VSI profiles, volume and pagefile sizes. In a production-ready
environment, of course, you need to size the servers and the volumes according to the number of concurrent users and the expected
amount of data and further parameters. Find more in the topic Sizing process for SAP Systems .
Depending on the database vendor you should consult their specific documentation, recommendations and best practises how to setup the file
systems. You may start here.
IBM Db2
SAP MaxDB
SAP ASE
We let sapinst , the SAP installation programm, care about the user management, the disk partitioning as well as folder and subfolder
creations that are required for the SAP application and the RDBMS.

Logging in to your Windows VSI
You can access the newly created VSI with Windows Remote Desktop. Enter the Floating IP and the Administrator password that you retrieved
during the steps that are described previously.

Initializing the block storage for Windows disk usage
1. Start the Windows Server Disk Management

Figure 1. Windows Server Disk Manager

2. Find the block storage - usually it is Disk 2 and shows the ordered size and the status offline

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 209

3. Right-click the Disk tile and select online from the menu
4. Again right-click the Disk tile and select Initialize Disk from the menu, check to make sure that the correct disk is selected, select GPT
as the default partition style - see footnote (+) below - and click Ok
5. Now right-click the related tile to the right that shows Unallocated and select New Simple Volume...
6. Click Next twice, which retains the default value for the disk size and then specify your preferred drive letter, or leave the default and
click Next
7. Overwrite the Folder Name, for example, SAP and leave the other default values and click Next - note, that File System FAT32 is NOT
SUPPORTED for SAP applications
8. Check the values and click Finish
9. After the volume has been prepared and formatted, you can find the new disk in the Windows Explorer
(+) About partition styles - GPT and MBR.

Specifying the page file
1. Start the Windows Control Panel
2. Click System and Security then System
3. Click Advanced system settings
4. Click the tab Advanced then in Section Performance the button Settings...
5. Click the tab Advanced then in Section Virtual memory the button Change...
6. Deselect the check mark Automacally manage...
7. Select drive C: and click Custom size
8. Enter Initial size and Maximum size 32768, click Set and Ok
Your next step is to download and install your SAP software and applications if a single virtual server sample is sufficient for your needs.

Step 6: Installing two virtual server instances in a 3-tier setup
A more complex scenario involves installing two virtual servers. One server is the SAP NetWeaver Application Server ( sap-wapp) and the other
server (sap-wdb) is the database server for SAP NetWeaver. You can reuse the server sap-wdb that you provisioned in the previous sections
and create the application server sap-wapp as described in sections Creating a Virtual Server Instance and Attaching a block storage volume
previously, except that you use the Balanced profile bx2-8x32 and 20 as Size for data volume sap-app-vol. Also, follow the steps to retrieve
the Administrator password of the new VSI.
Both VSIs have one extra attached volume and a Floating IP. A smaller volume is attached to sap-wapp, which is the SAP primary application
server (PAS). sap-wdb has a larger volume to host the RDBMS and the SAP Central Services (ASCS) instance.

Figure 4. Virtual server instances

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 210

Figure 5. Block storage volumes for VPC

Step 7: Preparing your network
To segregate network traffic, as recommended by SAP, deploy a second subnet. One network is used for client access, the other for
communication between the SAP ABAP stack and the RDBMS.
Follow the steps in the section New subnet for VPC but use the Name sap-test-net2. After the new subnet is created, it will show on the
Subnets for VPC page.
The two VSIs need to connect to the new network.
1. Go to the VSIs details overview and on each click New interface.
2. Select eth1 as Interface name.
3. Select sap-test-net2 as Subnet.
4. Leave the other vaulues default and click Create.

Figure 13. Data volumes

Maintain your hosts files on both servers according to the targeted setup. Usually you find it in the following path:
C:\Windows\System32\drivers\etc\hosts .

Note: In this tutorial that installs a prototypical SAP System, we do not specify a Windows domain. Usually, if you configure a server for
your company's access, you would specify the domain in the hosts file. During the SAP installation, you turn off the FQDN option and
leave the domain name blank.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 211

The following example is for the server instance sap-wdb.
$ 10.243.128.9 sap-wdb
10.243.129.6 sap-wdb-priv
10.243.128.7 sap-wapp-win
10.243.129.4 sap-wapp-priv

Your VSIs are now prepared to host the components of a distributed SAP installation. For more information about more installation
preparations, see Downloading and installing SAP software and applications .

Step 8: Installing your SAP landscape
Installing the IBM Cloud Metrics Collector for SAP
SAP requires the installation of the IBM Cloud Metrics Collector for SAP to analyze your infrastructure in the event that a support incident has
been submitted. Install the collector by using the instructions in IBM Cloud Metrics Collector for SAP .

Downloading your SAP software
Note: You need an S-User ID and the Download Software authorization when you download the DVD images from the SAP Service
Marketplace. To request an S-USer ID, see the SAP Support Portal.
Depending on your target SAP application that you are going to install you need to gather information, which SAP images you will need to
download. In this tutorial, we are choosing SAP NetWeaver ABAP on Windows using IBM Db2 for the SAP Database. Therefore we find in this
guide SAP NetWeaver Installation Guide all the needed information. SAP recommends to always search for the most recent versions.
Log in to the SAP Service Marketplace and download the required DVD images to a local share drive and then transfer the images to your
provisioned server. Alternative option, download the SAP Software Download Manager, install it on your target server and directly download
the DVD images to the server. You might also consider an extra volume for keeping the SAP DVD images. For more information about the SAP
Software Download Manager, see SAP Software Download Center .

Preparing for SAP’s Software Provisioning Manager (SWPM)
SWPM is the component that guides you through the steps to successfully prepare and complete an SAP installation. Together with the other
required images you may store and unpack SWPM on an extra file share that you then can attach to several VSIs on which you want to install
SAP workloads.

Installing SAP software
Follow the instructions in the SAP NetWeaver Installation Guide. Also, review the corresponding SAP notes. See more detailed information
about SAP NetWeaver installation that uses Db2 as the RDBMS in Considerations about IBM Db2.

Figure 2. SAP Application instances

Figure 2 illustrates the basic SAP instances that will be installed to deploy the SAP NetWeaver ABAP application server onto one host. If you

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 212

now want to complete the single server instance - i.e. just using VSI sap-wdb , you need to launch sapinst only one time on that server. In
this case, you will first install the ABAP Central Services Instance (ASCS), then the Database Instance DB and finally the Primary Application
Server (PAS).
If you go for the more complex implementation, a distributed SAP System, you will need to launch

sapinst on sap-wdb , install the ASCS and

the DB and then run sapinst on sap-wapp to install the PAS. Then, it is necessary that you open specific ports to allow inter-application
communication between the application server and the database server. To accomplish this, you must use Windows Firewall tool.
1. Start Windows Firewall with Advanced Security - enter wf.msc in Windows search field
2. Click Inbound Rules then Action and New rule...
3. Click Rule Type Port and Next
4. Enter the ports that need to be opened (see below)
5. Click Action Allow the connection and Next
6. Click Profile Public to unselect this option and Next
7. Enter a name and optionally a description and click Finish (see below)
Example values are e.g. depending on the instance numbers that you have chosen:
Ports

Name

3000-3999

SAP

5912-5917

Db2

40000-40099

IGS

50000-50099

sapstartsrv

Note: In a production environment you will get more granular on the port numbers. For more information about ports, see

SAP ports

and the respective documentation of your database vendor for details.
If you run SAP GUI on your desktop, remember to add the ports that are required by your SAP application (example: ports 3200-3299,
depending on your SAP NetWeaver instance number) to the security group.

Finding more information
Leaving now the tutorial and finding all information that you need to install your specific SAP components and versions, visit the

SAP Help

Portal as a starting point.

Relevant SAP Notes
SAP Note 2384179 - SAP Systems on Windows Server 2016 .
SAP Note 2979010 - Windows on IBM Cloud (IaaS): Adaption of your SAP License .

Memory Management
SAP Note 88416 - Zero administration memory management for the ABAP server .
SAP Note 1518419 - Page file and virtual memory required by the SAP system .
SAP Note 2488097 - FAQ: Memory usage for the ABAP Server on Windows .

Troubleshooting
SAP Note 100972 - Windows bug check event (blue screen) .
SAP Note 1559353 - How to capture user dumps on Windows .
SAP Note 2015747 - How to generate Windows crash dump files .

SAP NetWeaver deployment to IBM Power Virtual Server using AIX
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 213

Note: A Quick Study, someone who is able to learn new things quickly.
These Quick Study Tutorials provide a single sample configuration, with less detailed instructions, as an introduction for customers who prefer
hands-on tasks to increase their pace of learning.
The following information provides an introduction for customers who are new to IBM Power Infrastructure environment.

Getting started with the jump server
If you are using IBM Cloud® Direct Link, you access your Power Virtual Server instances from Linux® or Windows servers that are located in IBM
Cloud® or on-premises networks. These systems are known as access system jump servers.
You can also use these jump servers as a software installation repository. The jump server has private and public IP addresses for accessing
SAP Software Center or third-party vendor websites to download fixes or updates that can be stored on the jump server.
If you are using the Windows platform, you can install useful tools like WinSCP to transfer the software from the jump server to your AIX or
Linux Power Virtual Server. The following table lists tools for jump servers on Windows:
Tool

Purpose

Link

WinSCP

Upload and download third-party files

WinSCP Download and Install

PuTTY

SSH client

Download PuTTY: latest release

VNC Viewer

Virtual session connections

Download VNC Viewer

WinRAR

File decompression and compression

WinRAR Demo Edition

Java 8

Prerequisite for SAP GUI for Windows

Java SE Runtime Environment 8 Downloads

SAP GUI

SAP GUI for Windows

SAP GUI 7.6 Core Download

Google Chrome

Internet browser

Download Chrome
Table 1. Tools for jump servers on Windows

If you are using Windows as a jump server, you can use Windows PowerShell which includes a built-in SSH server.
For jump servers on Linux, the list of tools is nearly identical. For file uploads and downloads, you can use FileZilla, native SFTP, or SCP
functionality.
Download SAP's SAPCAR utility, so when you download SAP Installation Media that is often bundled into .SAR files, you can extract the files
immediately on the target AIX or Linux Power Virtual Server:
1. Go to the SAP Software Center.
2. In Downloads, search for SAPCAR.
3. Select SAPCAR 7.21.
4. For the operating system, select AIX 64BIT or LINUX ON POWER LE 64BIT .
5. Click the latest entry in the list and download to your jump server.
6. Transfer SAPCAR to your AIX or Linux Power Virtual Server.

Adding routes on your instance for the jump server
After you configure IBM Cloud® Direct Link and your jump server is provisioned with a private and public IP address, update the network route
on your virtual server instance so it can connect to your jump server. The following example shows how to connect a jump server on Windows
to the AIX virtual server instance.

AIX instance
1. Go to the Resource list to find your jump server.
2. In the devices list, click your jump server to display the Devices Overview.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 214

3. In the Network Details, note the private interface information. Click the information icon (" i") next to the private IP address to display the
Gateway and Subnet Mask information. This information is required when you add the route to your AIX virtual server instance.
4. Log on to your AIX virtual server instance and add the route.
For example, given the following information:
Private IP address: 10.123.111.78
Subnet: 255.255.255.192
Default Gateway: 10.123.111.1
You can run the following command:
route add -net 10.123.111.0 255.255.255.192 10.123.111.1

Note that the route is added temporarily; it disappears when you reboot.
To add the route permanently across reboots, run the following command:
$ chdev -l inet0

-a route=net,-hopcount,0,-netmask,255.255.255.192,-if,en0,,,,-static,10.123.111.0,10.123.111.1

5. Run netstat -rn and check that the entry appears in the list. Ping the jump server network, log on to the jump server, and use
Windows Powershell to connect to the AIX instance from the jump server.

Linux
To update the persistent route in Linux, add details to the /etc/sysconfig/network/ifroute-XX file, where XX is the network adapter. In
the file, add details in the following format:
$ [Destination Address]

[Default Gateway]

[Subnet Mask]

[Network Adapter]

For example:
$ cat

/etc/sysconfig/network/ifroute-eth0

10.123.456.0

10.123.456.1 255.255.255.192 eth0

SSH tunneling
This section describes SSH tunneling for specific SAP methods such as SAP GUI and Software Provisioning Manager (formerly known as
SAPINST).

SSH connection
For a stable SSH connection, use the ServerAliveInterval and ServerAliveCountMax SSH options when you connect to Power Virtual
Server by using a public network interface.
$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 <user>@<Public IP Address>

SSH tunneling for SAP GUI
Establish an SSH tunnel from your client machine to the cloud server. For example, if your client machine is running on a Windows operating
system, run the following command:
$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -4 -L 3200:localhost:3200 -N -f -l root <Public IP Address>
-p 22

In this command, 3200 is the port number that is used to connect to an application server with instance number 00. You might have to change
it to connect to a different application server, for example, 3202 for instance number 02.

SSH tunneling for SAP Software Provisioning Manager
Establish an SSH tunnel from your client machine to the cloud server. For example, if your client machine is running on a Windows operating
system, run the following command:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 215

$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -4 -L 4237:localhost:4237 -N -f -l root 149.81.129.28 -p 22

4237 is the default port that is used by Software Provisioning Manager. You might have to change it if the Software Provisioning Manager
execution suggests a different port.

Generic Command
$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -4 -L $localport:localhost:$remoteport -N -f -l root $host
-p 22

For more information about SSH port forwarding and SAP ports, see SSH Port Forwarding with PuTTY .

SSH configuration issues such as missing host keys
For SSH tunnelling, missing SSH host keys must be generated. For more information, see

Setting up an SSH client .

Configuring the NTP client
A newly provisioned Power Virtual Server might not show the correct time when you run the

date command. The initial time setting on the

server often differs by 10 - 15 minutes from the correct time. This time difference can cause problems when you install and run your SAP
system on the server, or when you connect the SAP system to your on-premises landscape.
You can keep the time current by configuring an NTP daemon that receives the correct time from an NTP time server. To set up NTP on AIX,
see How to configure NTP in your Environment and common issues .
To enable the AIX virtual server to synchronize with the NTP server, add the network IP address of your company’s NTP server or a public NTP
server to the NTP configuration file /etc/ntpd.conf .
Be sure to configure NTP to use the SLEWING option -x as recommended in the following SAP Notes:
1972803 - SAP on AIX: Recommendations
2456565 - Set NTP with SLEWING option in AIX
After you complete the configuration, check that the NTP daemon runs with the -x argument as follows:
$ root@ibmdemnw01:/home/root> ps -ef | grep -i xntpd
root 32309530

1

0 00:13:24

-

0:00 /usr/sbin/xntpd -x

Using the NIM service handler
If you plan to run a NIM Service Handler (NIMSH) on your AIX virtual server to connect to a NIM server, make sure that you avoid the following
port conflict.
The NIM client daemon (NIMSH) uses reserved ports 3901 and 3902 (see Using the NIM service handler for client communication ). If you
install an SAP Central Services Instance with instance number 01 or 02 on the same virtual server, a conflict is generated. By default, the SAP
Central Services Instance installation configures port number 39XX for SAP Message Server internal communication, where XX is the two-digit
SAP instance number.
An SAP installation places the port number into the SAP profile file DEFAULT.PFL . For example, the following entry in DEFAULT.PFL is for an
SAP Central Services instance number 01:
$ rdisp/msserv_internal = 3901

To avoid port conflicts, do one of the following actions:
Use instance number 00 for your SAP Central Services instance or another instance number that is not 01 or 02.
Change the value of the rdisp/msserv_internal profile parameter to a port value that does not conflict with the reserved ports of
NIMSH or any other program on your server.
You can check the status of the NIM components on the AIX server as follows:
$ # lssrc -a |grep -i nim
nimsh

nimclient

inoperative

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 216

nimhttp

inoperative

Adding storage for the rootvg during AIX server provisioning
Configure additional space in the rootvg for third-party vendor prerequisite checks. After provisioning the AIX server, the rootvg has
approximately 8 GB of free space. To prevent issues with prerequisite checks when you install database software, add another disk with a
partition size of 30 GB.
1. During virtual server instance provisioning, create a new storage volume that is 30 GB.
2. After the AIX server is provisioned, run the lspv command for an overview of hdisks . The output shows one disk that belongs to the
rootvg and another disk that does not have a physical volume identifier and a volume group assigned:
$ # lspv
hdisk0

none

None

hdisk1

00f6db0af58e9775

rootvg

active

3. To extend the rootvg volume group, run the following command:
$ extendvg rootvg <new hdisk>

Extending /tmp
SAP installations as well as Db2 and Oracle Database software installations use PREINSTALLER checks to make sure that your system is
database-ready. One of the checks is the amount of free space in /tmp . For example, at least 5 GB of available space is expected for Oracle
installations. For Db2, the free space check expects 512 MB.
To extend /tmp :
1. Check the space available in the rootvg . Run the following command:
$ lsvg rootvg | grep "FREE PPs"

If more storage is required, you should have sufficient space to extend /tmp because you already added an extra disk.
2. Run the following command:
$ chfs -a size=5G /tmp

The size of the logical volume on which /tmp resides (typically hd3 ) and the file system capacity is increased to 5 GB.
You can run the same command with +5G /tmp to append the size of the file system and add 5 GB to the existing size.
You can enter a higher value to extend the file system further, for example, if you need more capacity, or if there are issues with free space in
either “ / ” or /tmp during the PREINSTALLER check.

Extending or adding paging space
Prechecks can include a paging space check, which analyzes your system and determines whether your server has sufficient paging space for
the database or application installation.
Some databases require at least 32 GB. Instead of increasing the size of the current paging space

hd6 , create a second paging volume when

you define additional storage for the database or application volume groups.
After you create volume groups for applications and databases, you can create the new paging space to reside on the volumes within the
volume groups.
The lsps -s command shows the total amount of paging space on your system, for example:
$ root@ibmdemnw01:/swrepo/AIX> lsps -s
Total Paging Space

Percent Used

25760MB

0%

The lsps -a command shows the distribution of the paging space that is defined on your system, for example:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 217

$ root@ibmdemnw01:/swrepo/AIX> lsps -a
Page Space

Physical Volume

Volume Group

Size %Used

Active Auto Type Ch

hd6

hdisk4

rootvg

160MB

20

yes

yes

lv

paginglv

hdisk2

fr02swreposvg 25600MB

0

yes

yes

lv

root@ibmdemnw01:/swrepo/AIX> I

This example shows that a paging space was defined in the volume group fr02swreposvg on hdisk2 called paginglv in addition to the
standard paging space hd6 in the rootvg .
If your new AIX server instance doesn't have sufficient paging space when you begin the implementation phase of your database or
application, it can lead to multiple errors, for example, PGSPACE_KILL where the VMM starts to prune system processes. Be sure to follow
third-party software recommendations for their products.

AIX Toolbox for Linux Applications
When you download SAP packages from the SAP Marketplace, sometimes the files are packed into multispanning archives. Tools are required
to decompress the files and rebuild the packages.
For more information, see SAP Note 886535 - Downloading multispanning archives (RAR archive) and SAP Note 960755 - Unpacking ZIP
archives in Unix.
The required tools, unrar and unzip, can be downloaded from the AIX Toolbox For Linux Applications. Download the tools and use RPM to
install them on your AIX system. You might need to install additional filesets as a prerequisite. These files might already be in the limited AIX
repository that is supplied when the AIX server is provisioned.
Additional installation files can be found on the /usr/sys/inst.images mountpoint.
The vnc package is another useful tool in the AIX Toolbox for Linux Applications. After you install the

vnc package into your AIX server, you

will be able to start a VNC server on your AIX server. Then you can use a VNC viewer such as TightVNC on the jump server or another desktop
to connect to your AIX server to start an SAP installation by using Software Provisioning Manager (formerly known as SAPINST) with the web
front end. For more information, see Software Provisioning Manager and Installing by using a jump server .

Required filesets for Oracle, IBM Db2, and SAP MaxDB
Oracle 12 on AIX IBM Power Systems
Oracle 12 is supported on AIX 7.1 and 7.2. For a list of required operating system filesets and APARs, see the

system requirements.

Run the following command to check whether the filesets are available:
$ lslpp -l |egrep -w 'bos.adt.base|bos.perf.libperfstat|bos.adt.lib|
bos.adt.libm|bos.perf.perfstat|bos.perf.proctools|xlC.aix61.rte|xlC.rte'

Oracle 19 on AIX IBM Power Systems
Oracle 19 is supported on AIX 7.1 and 7.2.
For a list of operating system filesets and APARs, see the system requirements.

IBM Db2
Before you install IBM Db2, make sure that the system requirements are met.
For the software requirements for Db2 and SAP, see Installation of SAP Systems Based on the Application Server ABAP and DB2 .
For dependencies and download details for Db2, see System requirements for IBM Db2 for Linux, UNIX, and Windows .
The following additional filesets must be installed for Db2 installations:
bos.adt.* - Base Application Development
bos.perf.* - Performance and diagnostics tools
perfagent.tools - Performance monitoring tools
You can run the following command to check whether the filesets are available:
$ lslpp -l |egrep -w 'bos.adt.base|bos.perf.libperfstat|bos.adt.lib| bos.adt.libm|bos.perf.perfstat|bos.perf.proctools'
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 218

SAP MaxDB
Before you install SAP MaxDB, make sure that the required AIX filesets are installed. Run the following command:
$ lslpp -l | egrep -w 'bos.mp64|bos.rte.libc*|xlC.aix61.rte|xlC.sup.aix50.rte'

bos.mp64 - Base Operating System 64-bit
bos.rte.libc - libc Library
xlC.aix61.rte - IBM XL C++ Runtime for AIX 6.1
xlC.sup.aix50.rte - XL C/C++ Runtime for AIX 5.2
bos.mp64 - Base Operating System 64-bit
bos.rte.libc - libc Library
For more information about the required AIX filesets, see SAP Note 720261 - System prerequisite AIX - liveCache/MaxDB 7.4-7.9 .
Important: I/O usage is intensive during the Software Provisioning Manager installation phase. If there isn't enough paging space to
complete the Software Provisioning Manager MaxDB tasks, the stability of the system can be impacted. Before you install third-party
tools, make sure that sufficient paging space is provisioned according to the third-party software manufacturer's space
recommendations.

Storage and the AIX Logical Volume Manager
Follow these recommendations on creating storage and the AIX Logical Volume Manager (LVM) for the database and application layer.

Storage and volume affinity
When you create storage by using the IBM Cloud® console, specify volume affinity to prevent issues with new volume discovery on existing
virtual server instances. Keep the following points in mind:
You can't mix Tier 1 and Tier 3 storage.
After you provision storage with volume affinity, you can't go back and change it. Carefully plan your storage layer and make sure that
your configuration is correct.
After you provision new volume, you can toggle bootable and sharing switches. Sharing is especially useful for an Oracle RAC
implementation.
For more information about volume affinity, see Adding network block storage .

Logical volumes and mount points
Be sure to follow the recommendations of third-party software vendors about the configuration of logical volumes and mount points for the file
systems. For more information, see the following links:
Installation of SAP Systems Based on the Application Server ABAP of SAP NetWeaver with IBM DB2
SAP Note 2172935 - Installation - SAP Systems based on SAP NetWeaver : Oracle Database
Directory and Filesystem Structure for MaxDB

More recommendations
Create separate volume groups for database and applications. For example, for an Oracle installation, create the

oraclevg . For SAP

products, create the appsvg or sapvg , depending on the products that you choose to install.
Allocate sufficient storage to each of the volume groups and follow a standard naming convention when you create logical volumes. Add
your preferred SID to the logical volume name.

Creating separate storage for an installation repository
SAP Software Provisioning Manager requires additional files that will be used for the installation of SAP products such as exported images, SAP
kernel files, and database clients. The disk space requirements depend on the SAP product and database that you plan to install.
Calculate the sum of SAP packages on the SAP Marketplace that are required for your installation. Before you install SAP products by using
Software Provisioning Manager, provide the required storage. Create a dedicated volume group and logical volume and mount it on
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 219

/swrepo/SAP .

Installing the system
Before you install the system by using Software Provisioning Manager (SWPM), follow these preliminary steps:
1. Create a user in the smitty user menu called swpmuser so you can avoid running the installation as the root user. If you didn't
create a separate rootgrp , keep the primary group as system . Also include this user in the system and root groups so it is basically an
administrative user. You will use this user when you start the Software Provisioning Manager tool as a Remote Access Tool user.
2. Create the following directory structure under your software repository mount point /swrepo/SAP for Software Provisioning Manager
and other required software as recommended here: Creating separate storage for an installation repository .
Directory

Purpose

/swrepo/SAP/SWPM/

Location to unpack the Software Provisioning Manager SAR file

/swrepo/SAP/SWPM/tmp

Temporary storage and cache for Software Provisioning Manager installation

/swrepo/SAP/kernel

Location for the SAP kernel files

/swrepo/SAP/export

Location for the export files needed

/swrepo/SAP/DB

Location for the database product and client software

/swrepo/SAP/others

Location for miscellaneous software such as saphostagent

/swrepo/SAP/prereqcheck

Location for the prerequisite check output
Table 2. Software repository directory structure

Installing by using a client machine
Follow these steps to install the system by using a client machine.
1. Set up SSH tunneling on the client machine. For more information, see SSH tunneling.
2. Set a variable on the server for TMPDIR on the AIX server:
$ export TMPDIR=/swrepo/SAP/SWPM/tmp

Otherwise, Software Provisioning Manager uses the system-wide /tmp directory for sapinstdir logging and quickly runs out of space.
3. Unpack the Software Provisioning Manager SAR file on the server.
4. Unpack the installation into the respective folders.
5. Run the Prerequisites Check to make sure that all requirements are met for the installation.
a. Go to the /swrepo/SAP/prereqcheck directory.
b. Run the Software Provisioning Manager sapinst executable as follows:
$ /swrepo/SAP/SWPM/sapinst SAPINST_REMOTE_ACCESS_USER=swpmuser SAPINST_HTTPS_PORT=443

6. Open a browser on your client machine and go to this URL:
$ https://<Public IP address of your AIX server>:443/sapinst/docs/index.html

7. In login box, enter the swpmuser and the password that you defined.
8. Open the Prerequisites Checker. For example, for Db2: On the Welcome page, select SAP NetWeaver 7.5 > IBM Db2 for Linux, UNIX,
and Windows > Preparations > Prerequisites Check.
9. On the Prerequisite Checker Options page, select the first three options.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 220

10. Click Next to proceed through the wizard until the Prerequisites Checker Results are displayed.
Note: If you see a swap size MEDIUM result, check that you have sufficient swap space on your system.
After you complete the prerequisites check, you can proceed with the SAP NetWeaver installation for the application server, central services,
and database installation.

Installing by using a jump server
Follow these steps to install the system by using the jump server and tools that are installed on your AIX virtual server.

On the AIX server
1. Set a password. The VNC executable can be started multiple times and open multiple channels. Set a password to prevent other people
from working on your channel.
a. Go to the /home/root/.vnc directory.
b. Run the vncpasswd command.
c. Set the password for your connection.
2. In the root directory, run the vncserver command to start a vncserver session.

On your laptop or jump server
Opening a terminal
1. Connect the VNC Viewer software to the AIX server. In the VNC Viewer window, enter the address that was displayed when you started
the vncserver on AIX. To use a hostname, make sure to update the /etc/hosts file so that the hostname resolves to IP.
Important: Your new server must be resolvable in the Windows or operating system of your laptop (for direct connections) and in
your jump server. If an encryption warning is displayed, click Continue. When prompted, enter your password and click OK.
2. Open a terminal. Enter xterm or aixterm on the command line.

Setting variables
When you run SAPINST, set variables to ensure that there are enough resources to start the executable and that it exports the correct details
about you and your system.
1. Echo the $DISPLAY variable. The output should show the same details as the connection.
2. Run the xhost + command to disable access control.
3. Run the xauth command to list the currently assigned keys that are needed to connect.
Tip: Make a copy of the entries. If you need to switch to an SAP ACCOUNT for any reason, you can add the keys, access the
session, and export the $DISPLAY again.
4. Set the following variables for the installation session that are needed for SAPINST:
$ export SAPINST_REMOTE_ACCESS_USER=<Your User ID here, root or swpmuser>
export SAPINST_USE_HOSTNAME=<Hostname or Virtual Address>
export LIBPATH=/sapmnt/<SID>/exe
export CPIC_MAX_CONV=500
export JAVA_HOME=/usr/java8_64
export PATH=$JAVA_HOME/bin:$PATH
export TMP=/swrepo/SAP/SWPM/tmp
export TEMP=/swrepo/SAP/SWPM/tmp
export TMPDIR=/swrepo/SAP/SWPM/tmp
umask 022
ulimit -n 32000
ulimit -d unlimited
ulimit -s unlimited
ulimit -f unlimited
ulimit -m unlimited

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 221

The $LIBPATH variable should point to your /sapmnt/<SID>/exe directory, which should already be on your system.
JAVA_HOME should point to the /usr/javaX_64 version installed on your server.

The exports for the TEMP; , TEMPDIR , and TMP directories ensure that SAPINST doesn't use the /tmp directory on AIX for the
installation.
Make sure that the temp exports are set to a dedicated filesystem where you have unpacked SAPINST.
The umask and ulimit settings are recommended.

Testing SAPINST and installing
1. In the SAPINST directory, run the following command:
$ ./sapinst SAPINST_SLP_MODE=true

2. When prompted to confirm, enter y .
3. In your browser, go to the following URL:
https:// :4237/sapinst/docs/index.html
For example:
https://ibmdemnw01.local.demo:4237/sapinst/docs/index.html

4. When prompted, log in with the Software Provisioning Manager user or root user.
5. Select your preferred product and proceed to install.

Port forwarding
If you're using a Windows operating system and the VNC port isn't working or it's closed, you need to tunnel to make the port for VNC 5901
usable. If you're using a recent version of Windows PowerShell, an SSH server is included so you can use SSH commands on the command line.
For more information, see SSH tunneling.

Common problems and solutions
Here are some common issues that occur with Software Provisioning Manager:
Capacity of the /tmp directory during the pre-flight checks. The recommendation is at least 5 GB.
Make sure that there's at least 32 GB of paging space. This can be adjusted after the AIX server is installed with the required database
and applications. The recommendation is to run the required workload and tune the I/O resources.
Extend hd4 or “ / ” to 150 MB. Otherwise, you get a WARNING during the prerequisite tests for Db2 and Oracle.
Check /etc/security/login.cfg during installation. For more information, see SAP Note 2360008 - 3004-703 Check
"/etc/security/login.cfg" during installation.
Required EXPORT750 (Folder EXP1) missing - If you want to install the system in another language, download the EXP1 compressed

file and associated LANG .zip files. Download them to the jump server or swrepos filesystem and specify them when the Software
Provisioning Manager installer requests them.
R3load TestConnect fails - To resolve this issue, refer to the following SAP Notes:
SAP Note 1875902 - R3load -testconnect fails during using SWPM in step testDatabaseConnection
SAP Note 2805859 - A1EEGEN 000 (DBS) DbSlErrorMsg rc = 28 'no connection info in DBCON found'

Information resources for SAP NetWeaver
The following links will assist you in the installation and configuration of your Power Virtual Server instances and databases with SAP products.
Links with numbers in the title point to the SAP Support Portal.

Cloud-related resources - IBM Power Virtual Servers
Link

Description

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 222

2855850 - SAP Applications on IBM Power Virtual Servers

Supported SAP applications on IBM Power Virtual
Servers

1380654 - SAP support in IaaS environments

IaaS environments

2923984 - SAP on IBM Power Virtual Servers: Support prerequisites

Support prerequisites

2947579 - SAP HANA on IBM Power Virtual Servers

SAP HANA and virtual server instances

2923962 - Check SAP HANA NUMA Layout on IBM Power Systems Virtual
Servers

Checking the NUMA layout

2932766 - SAP on IBM Power Virtual Servers: Key Monitoring Metrics

Key Monitoring Metrics

Table 3. Cloud-related resources - IBM Power Virtual Servers

Operating systems - AIX
Link

Description

1780629 - AIX: Minimal OS Requirements for SAP Kernel

Minimum operating system requirements for AIX

2267287 - Using SAP systems with AIX 7.2

SAP Systems on AIX 7.2

1541935 - Using SAP systems with AIX 7.1

SAP Systems on AIX 7.1

1972803 - SAP on AIX: Recommendations

Guidance on how to optimally configure AIX for SAP

2630086 - Avoid signal 33, out of memory on AIX

Signals paging and memory situations - recommended

AIX Service Strategy and Best Practices

The AIX journey and strategy

IBM Knowledge Center AIX

A central link for AIX information

Troubleshooting AIX 7.2

Useful problem solving

IBM Fix Central

Fix Central for your AIX filesets and operating system upgrade source

Services and Support Best Practices POWER9

Download the PDF and see the command reference

Fix Level Recommendation Tool - FLRT

Cross-compatibility and fix recommendations tool

IBM AIX Developer

AIX developer website

IBM AIX Enhancements and Modernization

The latest updated IBM Redbook for AIX
Table 4. Operating systems - AIX

Operating systems - Linux
Link

Description

2378874 - Install SAP Solutions on Linux on IBM Power Systems (little endian)

Installing SAP Solutions on IBM Power Systems

2369910 - SAP Software on Linux: General information

General information for SAP software on Linux

765424 - Linux: Released IBM Hardware - POWER based servers

Power-based servers

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 223

1002461 - Support of IBM Dynamic LPAR and Micropartitioning

LPAR and micro partitioning

1122387 - Linux: SAP Support in virtualized environments

SAP Support in virtualized environments

1400911 - Linux: SAP NetWeaver on Red Hat KVM - Kernel-based Virtual
Machine

Red Hat KVM - Kernel-based virtual machine

2526952 - Red Hat Enterprise Linux for SAP Solutions

RHEL for SAP Solutions *** Central Note for RHEL

1631106 - Red Hat Enterprise Linux for SAP Applications

RHEL for SAP applications

2002167 - Red Hat Enterprise Linux 7.x: Installation and Upgrade

RHEL 7x installation and upgrading

936887 - End of maintenance for Linux distributions

Maintenance calendar and product maturity

2679703 - Linux on IBM Power Systems -- SAP monitoring recommendations

SAP monitoring recommendations

2578899 - SUSE Linux Enterprise Server 15: Installation Note

SLES 15 installation note

1275776 - Linux: Preparing SLES for SAP environments

Preparing SLES for SAP environments

SUSE Best Practices Library

A useful collection of SUSE documentation

187864 - Linux: Locale Support on Linux

Locale support for Linux

SAP on IBM Power Systems running Linux

News about SAP on IBM Power Systems running
Linux

Technical Resource for SAP Business Applications on Red Hat

A useful collection of links for SAP and Redhat

SUSE Enterprise Server for IBM POWER

IBM and SUSE
Table 5. Operating systems - Linux

Databases - Db2
Link

Description

Installation of SAP Systems Based on the Application Server ABAP and IBM DB2

Downloadable as a PDF File

System requirements for IBM Db2 for Linux, UNIX, and Windows

System requirements DB2

IBM POWER9 and SMT performance for IBM Db2

IBM POWER9 and Db2

Currently supported DB2 software levels and Fixpacks

Db2 software levels + Fixes

Currently supported database features DB2

Db2 feature support

Required File systems for DB2 and SAP Netweaver

Filesystem overview and mountpoints
Table 6. Databases - Db2

Databases - Oracle
Link

Description

2172935 - Installation - SAP Systems based on SAP NetWeaver : Oracle Database

Also includes the Filesystems that should
exist and mountpoints

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 224

2799900 - Central Technical Note for Oracle Database 19c

Oracle 19c

2660020 - Central Technical Note for Oracle Database 18c

Oracle 18c

1496927 - Protection of SAP instances through Oracle Clusterware

Also, pre-reqs for Oracle 18c

527843 - Oracle RAC support in the SAP environment

Oracle RAC support

2470660 - Central Technical Note for Oracle Database 12c Release 2 (12.2)

Oracle 12.2c

Oracle Community on SAP

Oracle Community link

Managing the Stability and Performance of current Oracle Database versions running AIX
on Power Systems including POWER9

Oracle stability and performance

Operating System Checklist for Oracle Database on IBM AIX on POWER Systems (64-Bit)

Oracle, AIX and POWER systems

2540847 - SAP Guides for Oracle Database Upgrade

Oracle guide collection

2086029 - Corrections for SAP Database Upgrade Guides for Oracle

Corrections to the above SAP Note as
reference

Oracle Database 11g and 12c on IBM Power Systems S924, S922 and S914 with
POWER9 processors

Further details on POWER9 and Oracle

Supported AIX versions with Oracle

Fully supported setups with AIX and Oracle

Server Configuration Checklist with Oracle Installations and AIX

Useful for setting up Oracle on AIX

Checking Asynchronous Input Output Processes

Useful for Oracle tuning on AIX OS

Configuring Shell Limits and System Configuration Parameters for IBM AIX

Explanation on User Limits and System
configuration

Central Landing page for Oracle Versions and Products

Useful to bookmark

Oracle Client Installation

Oracle Client Installation

Oracle 18c Installation and Upgrade repository

Useful hints and guidance for 18c
Table 7. Databases - Oracle

Databases - MaxDB
Link

Description

2365014 - Installation of SAP Systems Based on SAP NetWeaver: SAP MaxDB

MaxDB installation guide

1706928 - Inst. SAP Sys. Based on NW 7.1 and higher: SAP Max DB, UNIX

SAP installation note with MaxDB

1020175 - FAQ: SAP MaxDB installation, upgrade or applying a patch

MaxDB FAQ

SAP and MaxDB Community Wiki

MaxDB Community Wiki

Installing MaxDB with SL Tools

Software Logistics Tools landing page

SAP MaxDB Community page

MaxDB Community page

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 225

Problems during installation, upgrade or migration of MaxDB

Another Wiki page (very useful)

The Complete SAP MaxDB Documentation

Collection of Guides for MaxDB

820824 - FAQ: SAP MaxDB/liveCache technology

MaxDB and LiveCache

767598 - Available SAP MaxDB documentation

Available MaxDB documentation

819641 - FAQ: SAP MaxDB performance

MaxDB performance

720261 - System prerequisite AIX - liveCache/MaxDB 7.4-7.9

Important SAP Note

725489 - SAP MaxDB performance analysis tools

Performance tracking
Table 8. Databases - MaxDB

Applications - SAP
Link

Description

SAP Guide Finder

Recommended for all installations

1704753 - Inst.Systems Based on NetWeaver on UNIX - Using Software
Provisioning Manager 1.0

Software Provisioning Manager information for
version 1.0

Installation Guides - Application Server Systems - Software Provisioning Manager
1.0

Additional content

IBM Power Systems Planning and Monitoring Best Practices for SAP Applications

IBM Redbook for planning and monitoring SAP

IBM Power Systems Infrastructure I/O for SAP Applications

IBM Redbook for infrastructure planning and SAP

2158828 - Minimal DB system platform requirements for SAP NetWeaver 7.5

Platform requirements for NW7.5

2329005 - Minimal DB system platform requirements for NW AS ABAP 7.51
INNOVATION PKG

Platform requirements for innovation package
7.51

Table 9. Applications - SAP

SAP HANA deployment to IBM Power Virtual Server using SLES
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

Note: A Quick Study, someone who is able to learn new things quickly.
These Quick Study Tutorials provide a single sample configuration, with less detailed instructions, as an introduction for customers who prefer
hands-on tasks to increase their pace of learning.
The following information provides an introduction for customers who are new to IBM Power Infrastructure environment.

Getting started with the jump server
If you are using IBM Cloud® Direct Link, you access your Power Virtual Server instances from Linux® or Windows servers that are located in IBM
Cloud® or on-premises networks. These systems are known as access system jump servers.
You can also use these jump servers as a software installation repository. The jump server has private and public IP addresses for accessing
SAP Software Center or third-party vendor websites to download fixes or updates that can be stored on the jump server.
If you are using the Windows platform, you can install useful tools like WinSCP to transfer the software from the jump server to your AIX or
Linux Power Virtual Server. The following table lists tools for jump servers on Windows:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 226

Tool

Purpose

Link

WinSCP

Upload and download third-party files

WinSCP Download and Install

PuTTY

SSH client

Download PuTTY: latest release

VNC Viewer

Virtual session connections

Download VNC Viewer

WinRAR

File decompression and compression

WinRAR Demo Edition

Java 8

Prerequisite for SAP GUI for Windows

Java SE Runtime Environment 8 Downloads

SAP GUI

SAP GUI for Windows

SAP GUI 7.6 Core Download

Google Chrome

Internet browser

Download Chrome
Table 1. Tools for jump servers on Windows

If you are using Windows as a jump server, you can use Windows PowerShell which includes a built-in SSH server.
For jump servers on Linux, the list of tools is nearly identical. For file uploads and downloads, you can use FileZilla, native SFTP, or SCP
functionality.
Download SAP's SAPCAR utility, so when you download SAP Installation Media that is often bundled into .SAR files, you can extract the files
immediately on the target AIX or Linux Power Virtual Server:
1. Go to the SAP Software Center.
2. In Downloads, search for SAPCAR.
3. Select SAPCAR 7.21.
4. For the operating system, select AIX 64BIT or LINUX ON POWER LE 64BIT .
5. Click the latest entry in the list and download to your jump server.
6. Transfer SAPCAR to your AIX or Linux Power Virtual Server.

Adding routes on your instance for the jump server
After you configure IBM Cloud® Direct Link and your jump server is provisioned with a private and public IP address, update the network route
on your virtual server instance so it can connect to your jump server. The following example shows how to connect a jump server on Windows
to the AIX virtual server instance.

AIX instance
1. Go to the Resource list to find your jump server.
2. In the devices list, click your jump server to display the Devices Overview.
3. In the Network Details, note the private interface information. Click the information icon (" i") next to the private IP address to display the
Gateway and Subnet Mask information. This information is required when you add the route to your AIX virtual server instance.
4. Log on to your AIX virtual server instance and add the route.
For example, given the following information:
Private IP address: 10.123.111.78
Subnet: 255.255.255.192
Default Gateway: 10.123.111.1
You can run the following command:
route add -net 10.123.111.0 255.255.255.192 10.123.111.1

Note that the route is added temporarily; it disappears when you reboot.
To add the route permanently across reboots, run the following command:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 227

$ chdev -l inet0

-a route=net,-hopcount,0,-netmask,255.255.255.192,-if,en0,,,,-static,10.123.111.0,10.123.111.1

5. Run netstat -rn and check that the entry appears in the list. Ping the jump server network, log on to the jump server, and use
Windows Powershell to connect to the AIX instance from the jump server.

Linux
To update the persistent route in Linux, add details to the /etc/sysconfig/network/ifroute-XX file, where XX is the network adapter. In
the file, add details in the following format:
$ [Destination Address]

[Default Gateway]

[Subnet Mask]

[Network Adapter]

For example:
$ cat

/etc/sysconfig/network/ifroute-eth0

10.123.456.0

10.123.456.1 255.255.255.192 eth0

SSH tunneling
This section describes SSH tunneling for specific SAP methods such as SAP GUI and Software Provisioning Manager (formerly known as
SAPINST).

SSH connection
For a stable SSH connection, use the ServerAliveInterval and ServerAliveCountMax SSH options when you connect to Power Virtual
Server by using a public network interface.
$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 <user>@<Public IP Address>

SSH tunneling for SAP GUI
Establish an SSH tunnel from your client machine to the cloud server. For example, if your client machine is running on a Windows operating
system, run the following command:
$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -4 -L 3200:localhost:3200 -N -f -l root <Public IP Address>
-p 22

In this command, 3200 is the port number that is used to connect to an application server with instance number 00. You might have to change
it to connect to a different application server, for example, 3202 for instance number 02.

SSH tunneling for SAP Software Provisioning Manager
Establish an SSH tunnel from your client machine to the cloud server. For example, if your client machine is running on a Windows operating
system, run the following command:
$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -4 -L 4237:localhost:4237 -N -f -l root 149.81.129.28 -p 22

4237 is the default port that is used by Software Provisioning Manager. You might have to change it if the Software Provisioning Manager
execution suggests a different port.

Generic Command
$ ssh -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -4 -L $localport:localhost:$remoteport -N -f -l root $host
-p 22

For more information about SSH port forwarding and SAP ports, see SSH Port Forwarding with PuTTY .

SSH configuration issues such as missing host keys
For SSH tunnelling, missing SSH host keys must be generated. For more information, see

Setting up an SSH client .

Configuring the NTP client
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 228

A newly provisioned Power Virtual Server might not show the correct time when you run the

date command. The initial time setting on the

server often differs by 10 - 15 minutes from the correct time. This time difference can cause problems when you install and run your SAP
system on the server, or when you connect the SAP system to your on-premises landscape.
Ensure that time is synchronized for all Power Virtual Servers in your SAP system by using the same time server. For information about setting
up NTP on Linux, see Time Synchronization with NTP.

Disk provisioning and layout
When you provision a new Linux server, the default size of the boot logical volume is 100 GB. To prepare your Power Virtual Server instance,
see the following resources.
Link

Description

SAP Note 2055470 - HANA on POWER Planning and Installation
Specifics - Central Note

Server and storage setup and configuration

SAP Note 1943937 - Hardware Configuration Check Tool - Central
Note

Required checks to run with the HWCCT (Hardware
Configuration Check Tool)

Best Practices TDI Certified for IBM Storage

How to configure SAP HANA TDI certified IBM storage
Table 1. Information resources

For test systems, follow these guidelines for storage allocation:
52 GB of free disk space for the partition /usr/sap .
Space for three partitions for SAP HANA file storage locations as shown in Table 2:
Directory

Purpose

/usr/sap

52 GB required in the test system

/hana/data

Same size as RAM

/hana/log

Same size as RAM up to a maximum of 512 GB

/hana/shared

Same size as RAM up to a maximum of 1 TB

/export

Local storage for exported images **

/backup

A preliminary backup on disk **
Table 2. SAP HANA file storage locations

** Optional directory for the Linux server
If all disks that you want to use to construct the storage layer for SAP HANA are equal in size, it can be complicated to determine which disks to
include in which volume groups.
Tip: Create an Excel spreadsheet with an overview of the naming convention that you want to use, the size of the disks, and LVM
information.
For example, multiple disks aren't needed for the SAPVG using the /usr/sap directory. The amount of I/O workload is negligible and not
intensive compared to /hana/data and /hana/log ( /hana/log depends on your log archive mode).

Example
Consider a system that requires 400 GB storage. For /usr/sap and hdb_usrsap_vg , you create one 52 GB disk.
For /hana/data and hdb_data_vg , the data is accessed randomly, depending on the disk action or request at the time. For performance
purposes, you create eight physical volumes. When you provision your new virtual server instance, specify the following settings on the storage
provisioning page:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 229

Add storage volumes: New Storage Volume
Provide the name of the new storage volume(s): datavolumes1-8
Size of volumes to be created : 60G
Shareable: Off
Quantity: 8
Disk type is automatically set to Tier 1.
Create and Attach
480 GB of space is allocated for the datavg .
For the /hana/log and the hdb_log_vg , logs are created every 5 minutes, so the I/O activity is intense. Eight physical volumes are created
for performance purposes.

Another example
If log_mode=normal and you are using a backup method such as Spectrum Protect that backs up log files and removes them after saving
them, provision more storage space. If the process is interrupted, the space in /hana/log will be reduced quickly, which can result in a
database crash and possible loss of data. See the following example of provisioning storage for /hana/log when more space is added.
Add Storage Volumes New Storage Volume
Provide the name of the new storage volume(s) logvolumes1-8
Size of Volumes to be created 70G
Shareable Off
Quantity 8
Disk type is automatically set to Tier 1
560 GB of space is allocated for the hdb_log_vg .
For /hana/shared , provision one physical volume by using the following formula:
Size = installation(single - node) = MIN(1x RAM ; 1 TB)
For example, a test HANA server is a scale up sized at 400 GB, thus provisioning a single PD of 400 GB.
Currently, scale out is not supported on Power Virtual Servers.
When custom sizes are assigned to each of the physical volumes, you can use a simple script to create each of the required file systems.

Disk discovery and storage setup
On the Linux operating system, scan for the new storage that was provisioned. Run the following command for storage and disk discovery:
$ /usr/bin/rescan-scsi-bus.sh -a -c -v

Newly discovered disks are listed at the end of the report.
It's easier to check the system when the physical disks have different sizes. If the volumes are the same size, you can use the worldwide name
(WWN) of the volume that is shown in the IBM Cloud® UI. The WWN corresponds to the ID in the output of the multipath -ll command.
For example, a storage volume with the name sapdata_vol has a worldwide name 3600507681081814CE80000000000054D. In the
operating system output of the multipath -ll command, the corresponding device name for this WWN is dm-4. The device name is required
to create the logical volume and the volume group.
$ ibmdmhan01:~ # multipath -ll
3600507681081814ce80000000000054d dm-4 IBM,2145
size=100G features='0' hwhandler='1 alua' wp=rwv

Note: The WWN in the IBM Cloud® UI contains uppercase letters. In the operating system, the same ID contains lowercase letters.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 230

The following example shows how to identify disks by using disk sizes. The eight data volumes are 60 GB each, the eight log volumes are 70
GB each, the single volume for sapdata is 52 GB, and the single volume for the /hana/shared directory is 400 GB.
Run the following command to check how many volumes were created based on size:
$ ibmdmhan01:/usr/sap/DM2/SYS # /sbin/multipath -ll | grep -i 70G
size=70G features='0' hwhandler='1 alua' wp=rw
size=70G features='0' hwhandler='1 alua' wp=rw
size=70G features='0' hwhandler='1 alua' wp=rw
size=70G features='0' hwhandler='1 alua' wp=rw
size=70G features='0' hwhandler='1 alua' wp=rw
size=70G features='0' hwhandler='1 alua' wp=rw
size=70G features='0' hwhandler='1 alua' wp=rw
size=70G features='0' hwhandler='1 alua' wp=rw

Eight 70 GB volumes were created for the log volumes.
Run the following command to see the physical volumes that were created for the data volumes:
$ ibmdmhan01:/usr/sap/DM2/SYS # /sbin/multipath -ll | grep -i 60G
size=60G features='0' hwhandler='1 alua' wp=rw
size=60G features='0' hwhandler='1 alua' wp=rw
size=60G features='0' hwhandler='1 alua' wp=rw
size=60G features='0' hwhandler='1 alua' wp=rw
size=60G features='0' hwhandler='1 alua' wp=rw
size=60G features='0' hwhandler='1 alua' wp=rw
size=60G features='0' hwhandler='1 alua' wp=rw
size=60G features='0' hwhandler='1 alua' wp=rw

To create the volume groups, logical volumes, striping, and the file systems, you can use a simple script as follows. Alternatively, you can use
your own standard of LVM configuration.
$ # Sample script for mkfs.sh
export pv_size=60G
export lv_name=hdb_data_lv
export vg_name=hdb_data_vg
export mount=/hana/data
devices=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$2}' | tr '\n' ' ')
stripes=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$2}' | wc | awk '{print $1}')
pvcreate $devices
vgcreate ${vg_name} ${devices}
lvcreate -i${stripes} -I64 -l100%VG -n ${lv_name} ${vg_name}
mkfs.xfs /dev/mapper/${vg_name}-${lv_name}
mkdir -p ${mount}
mount /dev/mapper/$vg_name-$lv_name ${mount}
echo "/dev/mapper/$vg_name-$lv_name ${mount} xfs defaults 1 2 " >> /etc/fstab

The script creates the /hana/data mount point and puts it in /etc/fstab .
Important: If HANA scale-out or HA node failover is used, do not add the DATA and LOG file system to

/etc/fstab . Mounting is done

by SAP HANA. Always add the /hana/shared file system to fstab .
Repeat the same process and update the pv_size variable to the next LVM entry that you want to create, update the

lv_name , and so on.

When you create entries for /usr/sap and /hana/shared , you might get a system message that says striping can be done on multiple
volumes and not a single volume. Striping isn't necessary if you use one volume only.

Checking the multipathd
Check the status of the multipath daemon after the LVM actions finish. To enable the multipathd at boot time, run the following command as a
root user:
$ systemctl enable multipathd

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 231

To check the status of the multipathd, run the following command:
$ systemctl status multipathd

To stop the service, run the following command. This isn't advisable because it can cause the partition to no longer boot.
$ systemctl stop multipathd

Whenever you enable or disable the multipathd, you must rebuild the

initrd . After enabling the multipath services, run the following

command to force a rebuild of the initrd :
$ dracut --force --add multipath

When you disable the multipath services, run the following command to force a rebuild of the

initrd :

$ dracut --force -o multipath

Verifying network and adapter configurations
Review the following considerations when you set the MTU for the adapter that is used for your private network.
Local connections in the same data center (for example, within SAP HANA scale-out nodes or with a local system replication scenario) can
often take advantage of jumbo frames (MTU = 9000).
Remote connections to other data centers (for example, with smart data access or system replication) have an increased risk that network
components can't efficiently handle jumbo frames. You might need to set MTU = 1500.
If you want to check whether a connection uses jumbo frames, run the following ping command:
$ ping -M do -c 4 -s 8972 <remote_host_or_ip>

The ping command sends 9 KB requests to the remote host. If one component can't handle jumbo frames, the package is broken into smaller
pieces. This fragmentation is not allowed due to the -M do option. A 100% packet loss error is generated if all components aren't able to
handle jumbo frames.
To change the network adapter for the private network, follow the steps in Configuring SUSE for the SAP HANA or SAP NetWeaver workload .

Hostname verification
Make sure that your Power Virtual Server hostname resolves correctly. Check that the DNS server is entered correctly in

/etc/resolv.conf

and that instance hostname resolution is possible (in the simplest case, through an entry in /etc/hosts ).
If you are using virtual hostnames for the SAP HANA database server, make sure that the IP addresses, short name, and fully qualified domain
names are includes in the hosts file on the SAP HANA server and on any application servers that are connected to the database instance.
Issues with hostname or virtual hostname resolution cause problems when you connect the application server to the database backend and
configure the hdbuserstore.

Registering the system
You can register your Power Virtual Servers with SUSE for operating system updates in one of two ways.
Register your system by using a public SUSE repository server. This method isn't recommended for SAP HANA systems because
connectivity to the internet is required through a public network adapter.
To register by using a public SUSE repository server, run the following command:
$ SUSEConnect -r <REGISTRATION_KEY> -e <EMAIL_ADDRESS>

Mirror operating system repositories with the SUSE Repository Mirroring Tool (RMT), and register your systems by using the SUSE RMT
server. Because the mirror is running in the private network, connectivity to the internet through the public network isn't required. For
more information, see Configuring Clients to Use SUSE RMT (versions 12 and 15) .
To register by using the SUSE RMT server, run the following commands:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 232

$ curl http://<RMT_SERVER_IP>/tools/rmt-client-setup --output rmt-client-setup
chmod +x rmt-client-setup
./rmt-client-setup https://<RMT_SERVER_IP>

Using saptune
Use the saptune tool to apply the HANA solution to your server. The HANA solution applies recommended operating system settings for SAP
HANA on SUSE Linux Enterprise Server.
The following sample workflow shows how you can use the saptune tool to apply the HANA solution to your server. For more information
about saptune , see SAP Note 1275776 - Linux: Preparing SLES for SAP environments .
1. Verify that the package status is current.
$ zypper info saptune

2. Verify that the saptune version is at least 2.
$ saptune version

3. List all available solutions. Numbered entries represent integrated SAP Notes for each of the solutions.
$ saptune solution list

4. Get an overview of saptune options.
$ saptune --help

5. List SUSE OS defaults for instance network tunables and THP. Most of the defaults aren't set correctly for SAP HANA.
$ sysctl -a| grep -E

6. Optional: Simulate the changes that will be applied.
$ saptune solution simulate HANA
saptune autotunes parameters based on fixed or calculated values.

saptune indicates which parameters can't be changed

automatically, and provides links to related SAP or IBM documentation to assist with manual steps.
7. Apply the HANA saptune solution.
$ saptune solution apply HANA

8. If you want to automatically activate the solution's tuning options after a reboot, run the following command:
$ saptune daemon start

Tip: To diagnose startup issues, see SAP Note 401162 - Linux: Avoiding TCP/IP port conflicts and start problems .

NUMA layout
Check that the balance of CPU and memory placement is optimized for SAP HANA by running the

chk_numa_lpm.py script. The

chk_numa_lpm.py script does the following actions:

Checks the non-uniform memory access (NUMA) layout according to SAP HANA rules. The script verifies that there are no cores without
memory and that the memory distribution among the cores does not exceed a 50% margin. In the first case, the script generates an
error; in the latter case, the script generates a warning.
Checks whether a Live Partition Mobility (LPM) operation occurred. After LPM, the NUMA layout might differ from the configuration at
boot time. The script scans the system log for the last LPM. A warning is generated if an LPM operation occurred since the last system
boot.
Download the chk_numa_lpm.py script from the following SAP Note: SAP Note 2923962 - Check SAP HANA NUMA Layout on IBM Power
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 233

Systems Virtual Servers
Then, run the chk_numa_lpm.py script on your newly provisioned IBM Cloud® Power Virtual Server.
Run the script as follows:
$ ibmdmhan01:/backup/software/numa # ./chk_numa_lpm.py
WARNING: LPM may have occurred
ibmdmhan01:/backup/software/numa # ls
chk_numa_lpm.log

chk_numa_lpm.py

ibmdmhan01:/backup/software/numa # cat chk_numa_lpm.log
###

Check run on

: 2020-09-10 09:37:21

#####

Hostname

: ibmdmhan01

Partition UUID

: 2e2fb3e5-ef18-48c6-819a-bd85bfefa953

WARNING: A possible Live Partition Migration (LPM) might have happened after boot!
Date of lastest started LPM : 2020-07-16 06:08:38
Date of lastest boot

: 2020-07-02 10:01:00

Numa Node :

0

Number of virt. CPUs :

32

Amount of memory :

255667 MB

Numa Node :

1

Number of virt. CPUs :

32

Amount of memory :

255738 MB

In this example, a warning was generated. There are two NUMA nodes with an equal amount of CPU and memory. For more information, see
SAP Note 2923962.

Installing SAP HANA
Instead of a Windows jump server, you can provision a Linux jump server and a server with a public and private network. You can use this server
as a software repository.
When you provision the jump server, remember to request more disk space so you can create the LVM setup and directory structure. Because
the jump server has public access, it can access SAP Market Place and download the software on to the locations you specify. Then, you can
enable the file system to be shared with NFS across your new cloud landscape.
There are several benefits to this approach:
Your software is centrally located; there's no need to provision more storage on your Power Virtual Server instances. Mount the jump
server on each new server and install the software.
The jump server has a public IP interface. You can create a shadow of the SUSE software repositories.
It's easier for SAP Basis Administrators to manage one location instead of several.
When you use this setup, you can mount remotely through NFS. Remember to activate rpcbind on your Power Virtual Server:
1. Run the following command:
$ systemctl start rpcbind

2. Check that the service is active:
$ systemctl status rpcbind

3. Start the NFS client service:
$ systemctl start nfs

Information resources for SAP HANA
The following links will assist you with the installation and configuration of your Power Virtual Server instances with SAP HANA on Linux. Links
with numbers in the title point to the SAP Support Portal.

Operating systems – General Linux
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 234

Link

Description

2378874 - Install SAP Solutions on Linux on IBM Power Systems
(little endian)

Installing SAP solutions on IBM Power Systems

2235581 - SAP HANA: Supported Operating Systems

Supported operating systems for SAP HANA

2369910 - SAP Software on Linux: General information

General information for SAP software on Linux

765424 - Linux: Released IBM Hardware - POWER based servers

IBM Power-based servers

1122387 - Linux: SAP Support in virtualized environments

SAP support in virtualized environments

SAP on IBM Power Systems running Linux

Useful information about running Linux on Power

936887 - End of maintenance for Linux distributions

Maintenance calendar and product maturity

2679703 - Linux on IBM Power Systems -- SAP monitoring
recommendations

SAP monitoring recommendations

187864 - Linux: Locale Support on Linux

Locale support for Linux

SAP on IBM Power Systems running Linux

SAP on IBM Power Systems library

2382421 - Optimizing the Network Configuration on HANA- and OSLevel

Increasing efficiency on network for operating systems and
SAP HANA

401162 - Linux: Avoiding TCP/IP port conflicts and start problems

Preventive guidance to avoid network-related start issues

Table 3. Operating systems – general Linux

Operating systems – SUSE Linux
Link

Description

2205917 - SAP HANA DB: Recommended OS settings for SLES 12 / SLES for SAP
Applications 12

SLES 12 recommended operating system
settings

1984787 - SUSE LINUX Enterprise Server 12: Installation notes

SLES 12 installation note

2578899 - SUSE Linux Enterprise Server 15: Installation Note

SLES 15 installation note

2684254 - SAP HANA DB: Recommended OS settings for SLES 15 / SLES for SAP
Applications 15

SLES 15 recommended operating system
settings

2790462 - HANA Server connection is not available or timed out after upgrade to SUSE 15
from SUSE 12

Known issue when upgrading from 12 to
15

1275776 - Linux: Preparing SLES for SAP environments

Preparing SLES for SAP environments

SUSE Best Practices Library

A useful collection of SUSE documentation

SUSE Enterprise Server for IBM POWER

IBM and SUSE
Table 4. Operating systems – SUSE Linux

SAP HANA-related information
Link

Description

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 235

2000003 - FAQ: SAP HANA

Extensive overview of SAP HANA

1999880 - FAQ: SAP HANA System Replication

HSR central note

2000002 - FAQ: SAP HANA SQL Optimization

Useful tips to improve SQL processing times

SAP HANA Platform Landing page

Useful for installation guides and upgrade guides

SAP Guide Finder

Useful to locate user guides and information on updates

2380291 - SAP HANA 2.0 Cockpit Central Release Note

SAP HANA Cockpit central note

Table 5. SAP HANA-related information

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 236

SAP Partner solution tutorials
Veeam Backup & Replication for SAP HANA backups
Deprecated: This document is out of date, it is being updated for Veeam 10.x and replaced in November-2020 with new content.
You need to provision an IBM® Virtual Server and Block Storage for Classic to host Veeam Backup & Replication.

Step 1: Provisioning a Virtual Server to host your Veeam instance
Use the following steps to provision the virtual server to host your Veeam Backup & Replication instance. For more information on provisioning
public virtual server instances, see Provisioning public instances.
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Create resource > Compute > Infrastructure > Virtual Server.
3. The default is Public Virtual Server . Change the type to Starting from $25.00 monthly and click Continue.
4. Leave the defaults for Type of virtual server , Quantity, and Billing.
5. Hostname is a permanent or temporary name for your servers, for example virtualserver01 . Hover over Information for formatting
specifics.
6. Domain is the identification string that defines administrative control within the internet, for example,

Customer-145840.cloud . Hover

over Information for formatting specifics.
7. Leave Placement group set to None.
8. Select the Location where your current SAP-certified infrastructure is located.
9. Click All profiles and select B1.4x8. You can select a larger configuration if your needs require it.
10. Click Microsoft Image (OS) and select Windows 2016 Standard (64 bit)-HVM.
11. Click Add-ons (under Image) and select Veeam, and choose your Veeam licensing based on the number of servers or SAP HANA nodes
to be backed up.
12. Leave Attached storage disks as is.
13. Change Uplink port speeds to 1 Gbps Public & Private Network Uplinks .
14. Leave the default values for all other fields.
15. Review your Order Summary.
16. Click I have read and agree to Third-Party Service Agreements .
17. Click Create to be redirected to the Checkout page after your order has been verified.
You are redirected to a page with your order number. You can print the page because it's your receipt. In addition, you receive a confirmation
email with the subject Your IBM Cloud Order ## has been approved with ## being your order number.
After the order is submitted, the server, depending on your order, is available for use within one to four hours. You can check Device Details
from the IBM Cloud console (Menu icon

> Resource List > Devices) for a status of the provisioning steps. Click the Device Name that

matches your given hostname and domain to see its status.

Step 2: Provisioning Block Storage for Classic to host your Veeam backup repository
1. Expand the Menu icon

and select Classic Infrastructure.

2. Select Storage > Block Storage > Order Block Storage.
3. Select the specifics for your storage needs. Table 1 contains the recommended values for your backup repository.
Field

Value

Location

Same as where you provisioned your virtual server instance

Billing Method

Monthly (default)

Size

1,000 GB

Endurance (IOPS tiers)

0.25 IOPS/GB

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 237

Snapshot space

0 GB

OS Type

Windows 2008+
Table 1. Recommended values for block storage

4. Click Create.

Authorizing host
1. Select Storage > Block Storage.
2. Highlight your LUN and expand the Action menu

and select Authorize Host.

3. Select a Device Type of Virtual Server.
4. Click Virtual Guest and select the name of the server you provisioned for Veeam Backup & Replication.
5. Click Save.
Tip: Additional provisioning information can be found under Ordering Block Storage through the Console .

Step 3: Configuring the server for Veeam Backup & Replication
Before you begin
Before you configure your server to host Veeam Backup & Replication, make sure the following prerequisites have been met.
IBM Cloud® Bare Metal Servers or public IBM® Virtual Servers have been provisioned
IBM Cloud Block Storage for Classic has been allocated to the Veeam backup repository
You have credentials to access your hypervisor environment

Attaching Block Storage for Classic to your provisioned servers
Use the following steps to enable IBM Cloud Block Storage for Classic multipath I/O (MPIO) on your provisioned server.
1. Log in to IBM Cloud console and access your server through the Device List. If you need help accessing the Device List, see

Navigating to

devices.
2. Open Windows Server Manager and select Local Server.
3. Under Manage, choose Tasks > Add Roles and Features . Click Next four times.
4. Click Multipath I/O under Features > Next. Select Restart the destination server automatically > Install.
5. A feature installation confirmation should appear to validate the installation of MPIO.

Configure Windows iSCSI Initiator
Note: You are going between the IBM Cloud console and the Windows Server Manager dashboard to configure the Windows iSCSI
Initiator.
1. Click the Menu icon

> Classic Infrastructure > Storage > Block Storage and select your Block Storage for Classic LUN.

2. Under Authorized Hosts, highlight and copy the LUN's HOST IQN.
3. Go back to the Windows Server Manager dashboard and select Tools > iSCSI Initiator.
4. Click the Configuration tab in the iSCSI Initiator Properties window, click Change, paste the Host IQN into New initiator name, and click
OK.
5. Restore the IBM Cloud console and copy a Target Address. Either address works.
6. Restore the iSCSI Initiator Properties, click Discovery > Discover Portal, and paste the Target Address into IP address or DNS name .
Click Advanced.
7. Go back to the IBM Cloud console and copy Username under Authorized Hosts.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 238

8. Restore the iSCSI Initiator Properties, click Enable CHAP log on , and paste the Username in Name under Advanced Settings.
9. Go back to the IBM Cloud console and copy Password under Authorized Hosts.
10. Restore the iSCSI Initiator Properties, paste the Username in Target secret under Advanced Settings.
11. Click OK twice.
12. Select Targets and click the inactive Discovered Storage IQN. Click Connect and click OK.
13. Click Advanced and repeat steps 7 to 11.
14. Minimize the IBM Cloud console. You'll need it when you establish a connection between the Veeam backup repository and
infrastructure.
The storage target is now in a Connected status if all settings were correctly entered.

Enabling operating system visibility to the attached storage
1. Go back to the Windows Server Manager dashboard and select Tools > Computer Management, and click OK to initialize the new disk.
2. Select Storage > Disk Management. The new storage disk will be offline.
3. Right-click on the disk and click Online. You will also need to right-click and initialize any storage not previously in use.
4. Right-click in the volume field and click New Simple Volume. The New Simple Volume Wizard will display. Click Next.
5. Select the following, click Next, and click Finish when you're done.
64K block size is selected because the sample virtual server is running Windows 2016 as its OS. The selected settings help ensure
optimal performance and reliability with your Veeam deployment.
The volume is now online.
Field

Value

Simple volume size in MB

Select the maximum amount

Assign the following drive letter

Accept the default value

Format the volume with the following settings

Select

File system

ReFS

Allocation unit size

64K

Volume name

Enter a name for the volume, for example VBRrepo
Table 2. Summary of input

Step 4: Creating the Veeam backup repository
The next step in implementing Veeam Backup & Replication is to create repository and establishing connections to your infrastructure.

Setting up the backup repository
Use the following steps to set up the Veeam repository.
1. Log in to the Veeam Backup & Replication console.
2. Select Backup Infrastructure > Backup Repository > Add Repository.
3. Click Direct Attached Storage > Microsoft Windows server.
4. Enter your repository's Name, for example, RSL025IOPS , Descirption, and click Next.
5. Click Populate and select the drive that corresponds to the attached IBM Cloud® Block Storage for Classic. For the example, the
corresponding drive is V:\ . Click Next.
6. Click Advanced, select User per-VM backup files , and click OK.
7. Click Next twice and click Apply to apply the settings.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 239

8. Click Finish to create the repository extent, then click No to relocate the Veeam configuration backup location to the new repository.
Important: To be able to store backups on a Veeam backup repository, accounts, including administrative accounts, must have access
permissions on the backup repository. For instructions on setting up permissions, see Granting Permissions on Repositories

Creating a backup repository
You can now begin writing backups to the new repository. However, for maximum economy, flexibility, and scalability, it is strongly advised to
create an optional scale-out backup repository. Why should you create an optional scale-out backup repository? For economy, it enables the
purchase of only the Block Storage for Classic you need for your current deployment. As your IBM Cloud infrastructure grows, additional Block
Storage for Classic extents can be purchased and added to the scale-out backup repository. You lessen your up-front costs for the Veeam
solution without incurring the overhead of reconfiguring backup jobs to point to specific extents within the repository.
Use the following steps to create a scale-out backup repository.
1. From the Veeam Backup & Replication console, select Scale-out Repositories > Add Repository.
2. Enter a Name and Description for the scale-out repository, and click Next.
3. Click Add and select the new backup repository. Click Apply.

Establishing a connection to the IBM Cloud Infrastructure
Now that you've created your backup repository, you need to connect the repository to the IBM Cloud infrastructure. Use the following steps to
establish the connection.
1. From the Veeam Backup & Replication console, select Backup Infrastructure > Managed Servers > Add Server > MICROSOFT
SERVER.
2. Enter a DNS name or IP address and Description for your host VMware vSphere (ESXi) or VMware vCenter. Click Next.
3. Restore the IBM Cloud console and go to [Menu icon

> Resource List > Devices and find the server you set up for Veeam Backup &

Replication.
4. Copy the Username and go back to the Veeam Backup & Replication console. Paste the server username in Credentials Username.
5. Go back to the IBM Cloud console and copy the server's Password.
6. Restore the Veeam Backup & Replication console and paste the server password in Credentials Password. Enter a Description and click
OK.
7. Click Connect to the Security Warning, and click Next.
The server should now appear under Managed Servers.

Step 5: Submitting the initial backup job
Once the infrastructure and repository has been set up, you're ready to create and submit your initial backup job.

Before you begin
Important: Be sure to have set up the correct permissions on the backup repository. For instructions on setting up permissions, see
Granting Permissions on Repositories

Creating the initial backup job
1. From the Veeam Backup & Replication console, select Backup & Replication > Jobs > Backup Job. The New Backup Job wizard
displays.
2. Under Add Objects, select the IP address of the server you provisioned for Veeam Backup & Replication. Click Add,
Note: Add Objects will list options for the VMs to include in the backup job. Individual VMs, VM folders, VM resource pools, or
entire hosts and clusters can be added to the backup job. Adding VM groups simplifies ongoing job maintenance as the Veeam
backup job doesn't need to be modified in the event VMs are added or removed from the grouping entity.
3. Under Storage in the New Backup Job wizard, Backup proxy defaults to Automatic selection. For Backup repository, select the name of
the scale-out proxy and click Next.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 240

Note: You're selecting the scale-out backup repository for the job's backup storage target because by default 14 restore points
(days) are maintained. These default restore points mean that if a job runs daily, two weeks worth of backups are maintained. The
backup chain is constructed using forward incremental backups. The initial full backup is stored and only changed blocks are
stored for the subsequent restore points. For more information, see Backup Chain.
4. Click Next under Guest Processing.
5. Select Daily at this time at 8:00 AM for your schedule.
6. Click Apply.
7. Click Run the job when I click Finish to run the initial backup job immediately. Click Finish.
8. Double-click the running job and select Show Details to see granular status information on the running backup job.
For information on Veeam's application-aware processing for advanced application-specific item level recovery for SQL, Oracle, Exchange,
SharePoint, and others, see Application-Aware Processing.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 241

Proof of Concept (POC) innovation tutorials
Overview of POCs using IBM Cloud® for SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 242

Navigating the IBM Cloud console
The IBM Cloud® console is the user interface that you use to manage all your IBM Cloud resources. You can create a free account, log in,
access documentation, access the catalog, view pricing information, get support, or check the status of IBM Cloud components. After you log
in, the menu bar contains a Navigation Menu icon

and more links.

Using the console
When you log in to IBM Cloud, your dashboard is displayed, which shows widgets that summarize the status of your account. If you're
interested in customizing your dashboard, see Working with scoped dashboards.
You can navigate the console by using the options from the console menu bar. Use the following options to explore the console:
Use the Catalog link to explore over 350 products that offer options for compute, networking, security management, end-to-end
developer solutions, and more.
Click the Help icon

> Docs to access the product documentation.

Click the Help icon

> Support center to go to the Support Center page

From the Manage menu, you can access your account, billing and usage, and Identity and Access Management options.
Click the IBM Cloud Shell icon

to open a browser-based shell environment that you can use to work with your IBM Cloud resources.

Click the Cost estimator icon

to open the cost estimator.

Click the Notifications icon
Click the Avatar icon

to view and control all incidents, maintenance, and announcements that are likely to affect your account.

to access your profile, guided tours, console theme options, and more.

In addition to the console, command-line interfaces (CLIs) , APIs, and SDKs are available for interacting with you cloud account and resources.
Terraform support is also available through use of the IBM Cloud Provider plug-in for managing cloud resources at enterprise scale through
templates and scripting.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 243

Pre-Requisites for SAP Workloads
Necessary account credentials for SAP and IBM Cloud
Use the following steps to obtain account credentials for SAP and IBM Cloud.

SAP credentials and accounts for new users
1. To set up an SAP ID account, follow the instructions on the SAP Support Portal Home.

IBM Cloud credentials and accounts for new users
1. Go to Getting started with IBM Cloud and click Create a free account.
An email is sent from IBM Cloud Support that contains your verification code, from which you can create your initial login ID and
password.
2. Set up your profile to log in as a new user.
For more information, see Signing up for IBM Cloud .
1. After you receive your login credentials and have access to your IBM Cloud account, you can create other accounts and users. See

IAM

Best practices for assigning access to learn more about assigning access to IBM Cloud.

Setting up your IBM Cloud account structure
The IBM Cloud account requires a unique log-in ID, which is an IBMid.
An IBM Cloud account is set up by using the IBM Cloud console where:
Identity and Access Management (IAM) is used for adding new users to the account and controlling the access privileges (API Keys,
Access Groups, Roles, and Authorizations) for those users, for example which users can provision resources
Billing and Usage is used to monitor and forecast consumption costs, review billing invoices, and control payments (including any
discounts or promotions)
Account resources structure, which is used in tandem with IAM to control how your workloads are organized and run (for example,
Resource Groups, custom Dashboards). This includes advanced features that determine how your IBM Cloud account functions such as
EU Support, HIPAA Support, private network Cloud services endpoints, and routing (that is, VRF) and other items
Use the steps within the following sections to set up your IBM Cloud account structure to establish the best functions for your SAP landscape.

Resource Groups
Other than IBM Cloud Classic Infrastructure resources, most IBM Cloud resources require Resource Groups.
Resource groups are used to organize your account resources for access control, affecting how your workloads are organized and run. IBM
Cloud® provides all users with a default resource group.
Before you consider creating new resource groups, become familiar with the contents of this topic by reading

Best practices for organizing

resources in a resource group and What makes a good resource group strategy? .
For more information about resource groups, see Managing resource groups.

Creating Resource Groups
To create new Resource Groups requires few steps:
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Manage > Account > Account Resources > Resource Groups .
3. Click Create, enter a unique Name for the new Resource Group, and click Create.

Define the Cloud Identity and Access Management (IAM)
Note: Optional setup of IAM controls.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 244

Significant granularity of access control is available for all IBM Cloud services for specified Resource Groups through IAM Access policies.
For more information about IAM roles and actions, see IAM access with full details on how IAM policies are structured.
An account owner or administrator is assumed to have performed IAM setup for the account before the creation of an SAP landscape, including
assignment of all authorizations required to provision infrastructure.
Note: If any actions described in this documentation are being performed by another user who is not the account owner/creator, then
you need to check the current IAM authorizations to complete the tasks for deploying and running SAP within IBM Cloud.

Checking current IAM authorizations
Managing your IBM Cloud environment and preparing it to run SAP workloads includes provisioning compute, storage and network, securing
the server, downloading and installing your SAP software and applications, and testing connectivity to your environment by using resources
from IBM Cloud® for SAP.
Confirm with an administrator that you are assigned the permissions that are required to check current all authorizations. For more information
about the required roles and permissions, see Access management in IBM Cloud .
The following example for VPC Infrastructure, shows how to check the current authorizations:
1. Select Manage > Access (IAM).
2. Click Users and select your username. Names are in given name alphabetical order.
3. Click Access Policies and click the number next to the Role to see the currently assigned roles and the allowed actions.
4. Click Roles.
5. Click 'View the roles for' and select Virtual Servers for VPC. This selection shows the available Roles and allowed actions for a Virtual
Servers for VPC. An Administrator can apply these roles to you or alter them to provide authorization for the necessary actions.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 245

Provisioning Intel Bare Metal for SAP HANA and SAP NetWeaver
Planning your deployment
Make sure that you are already familiar with the fundamental components and options that are provided by IBM Cloud Classic Infrastructure
for SAP. Before you start with the deployment of servers, make sure that you also read the Get Started section.
Intel Optane persistent memory (PMem) is available on the Bare Metal servers. You have three memory options for PMem on the Bare Metal
servers, 1.5 TB, 3.0 TB, and 6.0 TB. Which option you choose depends on the:
Application that you want to run, for example BW or BW/4 HANA.
SAP sizing, which determines the amount of memory and CPU that you need.
Network and storage configuration, disaster recovery, high availability, backups, and system replication are all configured and managed as part
of the Bare Metal provisioning and operation.

The 'Must-Reads' before you start deploying
To ensure that your first deployment is a success, review the information in Provisioning SAP HANA and SAP NetWeaver

Planning your

deployment

Other useful documents
See the respective topics in the Get Started section for the following information:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

Deploying your infrastructure
Before you begin
Determine the amount of memory that you need for your application.

Step 1: Provision your server
Order your Bare Metal SAP HANA server using the steps in Deploying your infrastructure. Select the profile for the amount of PMem that you
need for your application.

Step 2: Post-Provisioning Intel Optane PMem
After you order your Bare Metal server and the server is provisioned, you complete the provisioning by creating namespaces for your system.
PMem on Bare Metal supports the App Dir mode. In App Dir mode, PMem and DRAM DIMMs act as independent memory resources that are
directly accessed by the applications.
The App Dir mode uses regions, and namespaces to represent persistent memory devices in an interleaved set. A region represents the
physical persistent memory devices. A region is made up of one or more namespaces. A namespace represents a unit of storage that can be
used for input/output (I/O).
Regions are created as part of the provisioning process. You must create the namespaces, create mount points, and mount the PMem devices.
For more information about regions and namespaces, see Intel Optane Persistent Memory and SAP HANA Platform Configuration .
1. Log in to the Bare Metal server as root.
2. Download the current version of the zypper (for SLES) or yum (for RHEL).
3. Install the ndctl software for your system:
For SLES:
$ zypper in ndctl

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 246

$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...
The following 2 NEW packages are going to be installed:
libndctl6 ndctl

For RHEL:
$ yum install ndctl
$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...

4. List the available regions for your system:
$ ndctl list -R -v
$

[
{
"dev":"region1",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":1,
"target_node":3,
"iset_id":-7847382400914477876,
"persistence_domain":"memory_controller"
},
{
"dev":"region0",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":0,
"target_node":2,
"iset_id":9195364489516887244,
"persistence_domain":"memory_controller"
}

5. Create a namespace for each of your regions.
$ ndctl create-namespace -r region0
$

{
"dev":"namespace0.0",
"mode":"fsdax",
"map":"dev",
"size":"1488.37 GiB (1598.13 GB)",
"uuid":"75af4e28-1b99-4d34-a39a-a342a370232a",
"sector_size":512,
"align":2097152,
"blockdev":"pmem0"
}

Repeat this command for region1
6. Create an xfs on-top of the PMem devices:
$ mkfs -t xfs -f /dev/pmem0
$

meta-data=/dev/pmem0
=

isize=512

agcount=4, agsize=97542016 blks

sectsz=4096

attr=2, projid32bit=1
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 247

=

crc=1

=

reflink=0

=

bsize=4096

blocks=390168064, imaxpct=5

=

sunit=0

swidth=0 blks

=version 2

bsize=4096

ascii-ci=0, ftype=1

data
naming
log

=internal log

finobt=1, sparse=0, rmapbt=0

bsize=4096 blocks=190511, version=2

=
realtime =none

sectsz=4096

sunit=1 blks, lazy-count=1

extsz=4096

blocks=0, rtextents=0

Repeat this command for pmem1.
7. Mount the file system that you created by adding the following lines to /etc/fstab :
/dev/pmem0 /hana/pmem/nvmem0 xfs dax 0 0
/dev/pmem1 /hana/pmem/nvmem1 xfs dax 0 0
8. Create the path to the device.
$ mkdir -p /hana/pmem/nvmem0
$ mkdir -p /hana/pmem/nvmem1
$ mount -a
9. Verify the devices.
$ df -h | grep pmem
$

/dev/pmem0
/dev/pmem1

1.5T
1.5T

1.6G

1.6G

1.5T

1.5T

1% /hana/pmem/nvmem0
1% /hana/pmem/nvmem1

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 248

Provisioning Intel Bare Metal with Intel Optane DC PMEM for SAP HANA and SAP
NetWeaver
Planning your deployment
Make sure that you are already familiar with the fundamental components and options that are provided by IBM Cloud Classic Infrastructure
for SAP. Before you start with the deployment of servers, make sure that you also read the Get Started section.
Intel Optane persistent memory (PMem) is available on the Bare Metal servers. You have three memory options for PMem on the Bare Metal
servers, 1.5 TB, 3.0 TB, and 6.0 TB. Which option you choose depends on the:
Application that you want to run, for example BW or BW/4 HANA.
SAP sizing, which determines the amount of memory and CPU that you need.
Network and storage configuration, disaster recovery, high availability, backups, and system replication are all configured and managed as part
of the Bare Metal provisioning and operation.

The 'Must-Reads' before you start deploying
To ensure that your first deployment is a success, review the information in Provisioning SAP HANA and SAP NetWeaver

Planning your

deployment

Other useful documents
See the respective topics in the Get Started section for the following information:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

Deploying your infrastructure
Before you begin
Determine the amount of memory that you need for your application.

Step 1: Provision your server
Order your Bare Metal SAP HANA server using the steps in Deploying your infrastructure. Select the profile for the amount of PMem that you
need for your application.

Step 2: Post-Provisioning Intel Optane PMem
After you order your Bare Metal server and the server is provisioned, you complete the provisioning by creating namespaces for your system.
PMem on Bare Metal supports the App Dir mode. In App Dir mode, PMem and DRAM DIMMs act as independent memory resources that are
directly accessed by the applications.
The App Dir mode uses regions, and namespaces to represent persistent memory devices in an interleaved set. A region represents the
physical persistent memory devices. A region is made up of one or more namespaces. A namespace represents a unit of storage that can be
used for input/output (I/O).
Regions are created as part of the provisioning process. You must create the namespaces, create mount points, and mount the PMem devices.
For more information about regions and namespaces, see Intel Optane Persistent Memory and SAP HANA Platform Configuration .
1. Log in to the Bare Metal server as root.
2. Download the current version of the zypper (for SLES) or yum (for RHEL).
3. Install the ndctl software for your system:
For SLES:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 249

$ zypper in ndctl
$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...
The following 2 NEW packages are going to be installed:
libndctl6 ndctl

For RHEL:
$ yum install ndctl
$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...

4. List the available regions for your system:
$ ndctl list -R -v
$

[
{
"dev":"region1",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":1,
"target_node":3,
"iset_id":-7847382400914477876,
"persistence_domain":"memory_controller"
},
{
"dev":"region0",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":0,
"target_node":2,
"iset_id":9195364489516887244,
"persistence_domain":"memory_controller"
}

5. Create a namespace for each of your regions.
$ ndctl create-namespace -r region0
$

{
"dev":"namespace0.0",
"mode":"fsdax",
"map":"dev",
"size":"1488.37 GiB (1598.13 GB)",
"uuid":"75af4e28-1b99-4d34-a39a-a342a370232a",
"sector_size":512,
"align":2097152,
"blockdev":"pmem0"
}

Repeat this command for region1
6. Create an xfs on-top of the PMem devices:
$ mkfs -t xfs -f /dev/pmem0

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 250

$

meta-data=/dev/pmem0

isize=512

agcount=4, agsize=97542016 blks

=

sectsz=4096

attr=2, projid32bit=1

=

crc=1

finobt=1, sparse=0, rmapbt=0

=

reflink=0

=

bsize=4096

blocks=390168064, imaxpct=5

=

sunit=0

swidth=0 blks

=version 2

bsize=4096

ascii-ci=0, ftype=1

data
naming
log

=internal log

bsize=4096 blocks=190511, version=2

=
realtime =none

sectsz=4096

sunit=1 blks, lazy-count=1

extsz=4096

blocks=0, rtextents=0

Repeat this command for pmem1.
7. Mount the file system that you created by adding the following lines to /etc/fstab :
/dev/pmem0 /hana/pmem/nvmem0 xfs dax 0 0
/dev/pmem1 /hana/pmem/nvmem1 xfs dax 0 0
8. Create the path to the device.
$ mkdir -p /hana/pmem/nvmem0
$ mkdir -p /hana/pmem/nvmem1
$ mount -a
9. Verify the devices.
$ df -h | grep pmem
$

/dev/pmem0
/dev/pmem1

1.5T
1.5T

1.6G

1.6G

1.5T

1.5T

1% /hana/pmem/nvmem0
1% /hana/pmem/nvmem1

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 251

Provisioning Intel Bare Metal with Virtual Server (Gen2) for SAP HANA and SAP
NetWeaver
Planning your deployment
Make sure that you are already familiar with the fundamental components and options that are provided by IBM Cloud Classic Infrastructure
for SAP. Before you start with the deployment of servers, make sure that you also read the Get Started section.
Intel Optane persistent memory (PMem) is available on the Bare Metal servers. You have three memory options for PMem on the Bare Metal
servers, 1.5 TB, 3.0 TB, and 6.0 TB. Which option you choose depends on the:
Application that you want to run, for example BW or BW/4 HANA.
SAP sizing, which determines the amount of memory and CPU that you need.
Network and storage configuration, disaster recovery, high availability, backups, and system replication are all configured and managed as part
of the Bare Metal provisioning and operation.

The 'Must-Reads' before you start deploying
To ensure that your first deployment is a success, review the information in Provisioning SAP HANA and SAP NetWeaver

Planning your

deployment

Other useful documents
See the respective topics in the Get Started section for the following information:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

Deploying your Infrastructure
Use the following information to deploy and set up SAP HANA and/or SAP NetWeaver on IBM Cloud® Bare Metal Servers for Virtual Private
Cloud (VPC).

Setting up a VPC and subnet
The following steps summarize the setup of VPC and subnets, which is detailed further in the Create an IBM Cloud VPC .
1. Click Menu icon

> VPC Infrastructure > Network > VPCs

2. Click Create.
3. Select a Location for the VPC. The location consists of a Geography and a Region.
4. Enter a unique Name for the VPC.
5. Select a Resource group. Use resource groups to organize your account resources for access control and billing purposes. For more
information, see Best practices for organizing resources in a resource group and What makes a good resource group strategy? .
6. Optional: Enter tags to help you organize and find your resources. You can add more tags later. For more information, see

Working with

tags.
7. Select whether the Default security group allows inbound SSH and ping traffic to bare metal server instances in this VPC. You can
modify the default security group later.
8. Optional: Classic access. Select whether you want to enable your VPC to access classic infrastructure resources. For more information,
see Setting up access to classic infrastructure .
Important: You can enable only a VPC for classic access when it is created. You cannot update a VPC to add or remove classic
access. In addition, you can have only one classic access VPC in your account at any time.
9. Optional: Default address prefixes. Disable this option if you don't want to assign default subnet address prefixes to each zone in your

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 252

VPC. After you create your VPC, you can go to its details page and set your own subnet address prefixes. If you do disable this option, the
Subnets section will be hidden, and will require manual definition after the VPC is created. Leave the option enabled.
10. Subnets. You can keep the default subnets for each zone in the selected location or can delete one or more of them and/or create a new
subnet. Leave the default subnets.
11. Review the configuration Summary and then click Create virtual private cloud .

Manually defining your subnets
If you disabled Default address prefixes, which hid the Subnets section on the VPC ordering page, you need to manually define your subnets
before you provision your bare metal server. Use the following steps to set up your subnets if you didn't do so when you set up your VPC.
1. Click Menu icon

> VPC Infrastructure > Subnets > New Subnet.

2. Select a Location for the subnet. The location consists of a Geography, a Region, and a Zone.
3. Enter a unique Name
4. Select a Resource group.
5. Optional: Enter tags to help you organize and find your resources. You can add more tags later. For more information, see

Working with

tags.
6. Select the Virtual private cloud that the subnet is to be associated with.
7. Leave all other values default.
8. Review the configuration Summary and then click Create virtual private cloud .
Note: If you want to learn more on VPC and subnet creation, read section Creating a VPC and subnet in the VPC product tutorials.

Provisioning your Bare Metal Server
Note: Before you can create a bare metal server, you must create the VPC, and you must create an SSH key that you add to the server
instance during its creation. For more information, see SSH keys with bare metal servers . You can either create the VPC and SSH key
before you follow the steps, or you can click the related links within the Create bare metal server UI to do the same.
Use the following steps to order your bare metal server and necessary components. For more information about creating a bare metal server,
see Creating a bare metal server by using the UI .
1. Log in to the IBM Cloud console with your unique credentials.
2. Click Menu icon

> Compute > Bare metal servers .

3. Select the Region and click Create.
4. Enter the information that is in Table 1.
5. Review the configuration Summary and then click Create bare metal server .
After the bare metal server is provisioned and is ready for SSH logon, you can begin installing SAP HANA or SAP NetWeaver applications.
Table 1 is a summary of the fields and values that are used to provision Bare Metal Servers for Virtual Private Cloud (VPC).
Field

Value

Location

Locations are composed of regions (specific geographic areas) and zones (fault tolerant data centers within a region). Select
the location where you want to create your bare metal server.

Name

Unique name for your bare metal server, which becomes the hostname. SAP hostnames must consist of a maximum of 13
alpha-numeric characters. For more information about SAP hostnames, see SAP Notes 611361 and 129997.

Resource
group

Use resource groups to organize your account resources for access control and billing purposes.

Note: The resource group can't be changed after the bare metal server is created.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 253

Optional:
Tags

You can assign labels to your server so that you can easily filter resources in your resource list.

Operating
System

Linux distribution for SAP HANA workloads, select Catalog image > ...-sap-hana-...
Linux distribution for SAP NetWeaver workloads, select Catalog image > ...-sap-applications...
Windows Server for SAP NetWeaver workloads, select Windows Server
. Choose an operating system version that is supported by SAP as documented in SAP Note 2927211

Profile

Select one of the profiles that are outlined in Bare Metal Server certified profiles for SAP HANA or Bare Metal Server
certified profiles for SAP NetWeaver.

SSH Key

Select an existing public SSH key or click New SSH key to add a new one. You must specify at least one SSH key. SSH keys
are used to securely connect to a running instance.
Note: Alpha-numeric combinations are limited to 100 characters. For more information, see SSH keys.

Optional:
User data

You can add user data to automatically complete common configuration tasks or run scripts. For more information, see
User data.

Virtual
private
cloud

Specify the VPC where you want to create your server. You can use the default VPC, another existing VPC, or you can create
a new VPC.

Network
interfaces

Assign networking options to connect into the IBM Cloud VPC. You can create and assign multiple up to 8 PCI network
interfaces and 128 VLAN interfaces on top of network interfaces.
Table 1. Bare metal server provisioning selections

Creating the network interface
Bare metal servers for VPC can be configured with two different types of network interfaces, up to 8 PCI (that is, physical interfaces) and 128
VLAN interfaces on-top the physical interfaces.
Note: VLAN interfaces are strictly targeting advanced virtualization scenarios on top of the bare metal servers. Read the section
Managing network interfaces for Bare Metal Servers on VPC carefully before you order the network interfaces.
To add a new network interface to your Bare metal server for VPC instance, complete the following steps:
1. In the Network interfaces section of the Instance details page, click Create.
2. On the Create network interface page, the interface name defaults to an incremented number. If this is the first new interface after your
primary interface, the default name is eth1. You can change the name if you want.
3. Select a subnet from the subnets that are assigned to your existing network interfaces.
4. Select the method for choosing an IP address for the new interface. Either select a dedicated or let IBM Cloud® reserve it for you.
5. Select the security group that you want to associate with the network interface.
6. Choose, if you want to create a VLAN or a PCI interface. For a VLAN interface, a VLAN ID needs to be provided. Choose PCI interface in
this case.
7. You can configure IPs as ‘floating’. For more information, see Associating floating IPs with a network interface for more information on
floating IPs.
8. Click Create.
More information is shown on VPC Infrastructure - Managing network interfaces.

Bring your own OS product license
When you have your own operating system license, you can install it on your bare metal server based on the vendor's instructions. For more
information about custom images, see Importing and managing custom images.
The OS chosen must be certified for SAP and have access to the necessary OS Packages for SAP.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 254

Storage layout for Bare Metal Servers on VPC
Internal storage
Your Bare metal server on VPC comes with a number of internal NVMEs, depending on its size. For SAP NetWeaver based deployment, you can
use those NVMEs that are presented as block devices to the operating system. The NVMEs are listed under “/dev/nvmeXn1” (X from 0 to the
number of NVMEs in total, minus 1). Use the NVMEs according to your requirements and needs. For SAP HANA based deployments, refer to
Bare Metal Server certified profiles for SAP HANA to see the details on laying out the storage.

External storage
If more storage needs to be added to your bare metal server on VPC, for example, for backup purposes, NFS-based

file shares can be

created and mounted. Learn more details in the corresponding chapter Creating file shares and mount targets .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 255

Provisioning Intel Virtual Server (Gen2) for SAP HANA and SAP NetWeaver
Planning your deployment
Make sure that you are already familiar with the fundamental components and options that are provided by IBM Cloud Classic Infrastructure
for SAP. Before you start with the deployment of servers, make sure that you also read the Get Started section.
Intel Optane persistent memory (PMem) is available on the Bare Metal servers. You have three memory options for PMem on the Bare Metal
servers, 1.5 TB, 3.0 TB, and 6.0 TB. Which option you choose depends on the:
Application that you want to run, for example BW or BW/4 HANA.
SAP sizing, which determines the amount of memory and CPU that you need.
Network and storage configuration, disaster recovery, high availability, backups, and system replication are all configured and managed as part
of the Bare Metal provisioning and operation.

The 'Must-Reads' before you start deploying
To ensure that your first deployment is a success, review the information in Provisioning SAP HANA and SAP NetWeaver

Planning your

deployment

Other useful documents
See the respective topics in the Get Started section for the following information:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

Deploying your infrastructure
Before you begin
Determine the amount of memory that you need for your application.

Step 1: Provision your server
Order your Bare Metal SAP HANA server using the steps in Deploying your infrastructure. Select the profile for the amount of PMem that you
need for your application.

Step 2: Post-Provisioning Intel Optane PMem
After you order your Bare Metal server and the server is provisioned, you complete the provisioning by creating namespaces for your system.
PMem on Bare Metal supports the App Dir mode. In App Dir mode, PMem and DRAM DIMMs act as independent memory resources that are
directly accessed by the applications.
The App Dir mode uses regions, and namespaces to represent persistent memory devices in an interleaved set. A region represents the
physical persistent memory devices. A region is made up of one or more namespaces. A namespace represents a unit of storage that can be
used for input/output (I/O).
Regions are created as part of the provisioning process. You must create the namespaces, create mount points, and mount the PMem devices.
For more information about regions and namespaces, see Intel Optane Persistent Memory and SAP HANA Platform Configuration .
1. Log in to the Bare Metal server as root.
2. Download the current version of the zypper (for SLES) or yum (for RHEL).
3. Install the ndctl software for your system:
For SLES:
$ zypper in ndctl

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 256

$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...
The following 2 NEW packages are going to be installed:
libndctl6 ndctl

For RHEL:
$ yum install ndctl
$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...

4. List the available regions for your system:
$ ndctl list -R -v
$

[
{
"dev":"region1",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":1,
"target_node":3,
"iset_id":-7847382400914477876,
"persistence_domain":"memory_controller"
},
{
"dev":"region0",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":0,
"target_node":2,
"iset_id":9195364489516887244,
"persistence_domain":"memory_controller"
}

5. Create a namespace for each of your regions.
$ ndctl create-namespace -r region0
$

{
"dev":"namespace0.0",
"mode":"fsdax",
"map":"dev",
"size":"1488.37 GiB (1598.13 GB)",
"uuid":"75af4e28-1b99-4d34-a39a-a342a370232a",
"sector_size":512,
"align":2097152,
"blockdev":"pmem0"
}

Repeat this command for region1
6. Create an xfs on-top of the PMem devices:
$ mkfs -t xfs -f /dev/pmem0
$

meta-data=/dev/pmem0
=

isize=512

agcount=4, agsize=97542016 blks

sectsz=4096

attr=2, projid32bit=1
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 257

=

crc=1

=

reflink=0

=

bsize=4096

blocks=390168064, imaxpct=5

=

sunit=0

swidth=0 blks

=version 2

bsize=4096

ascii-ci=0, ftype=1

data
naming
log

=internal log

finobt=1, sparse=0, rmapbt=0

bsize=4096 blocks=190511, version=2

=
realtime =none

sectsz=4096

sunit=1 blks, lazy-count=1

extsz=4096

blocks=0, rtextents=0

Repeat this command for pmem1.
7. Mount the file system that you created by adding the following lines to /etc/fstab :
/dev/pmem0 /hana/pmem/nvmem0 xfs dax 0 0
/dev/pmem1 /hana/pmem/nvmem1 xfs dax 0 0
8. Create the path to the device.
$ mkdir -p /hana/pmem/nvmem0
$ mkdir -p /hana/pmem/nvmem1
$ mount -a
9. Verify the devices.
$ df -h | grep pmem
$

/dev/pmem0
/dev/pmem1

1.5T
1.5T

1.6G

1.6G

1.5T

1.5T

1% /hana/pmem/nvmem0
1% /hana/pmem/nvmem1

Using IBM Metrics Collector for SAP (IMCS) on Linux
Note: The IBM® Metrics Collector for SAP (IMCS) on Linux® is a requirement by SAP Support for IBM Cloud® Virtual Private Cloud
Infrastructure only when SAP workloads are running on the virtual server instance (VSI).
The IMCS collects performance-related data from IBM Cloud® Virtual Servers for Virtual Private Cloud for SAP. The SAP Support team uses the
collected metric data to monitor, troubleshoot, and improve performance of business transactions. Use the following information to help with
installing, configuring, and troubleshooting the IBM Metrics Collector for SAP on Linux.

Before you begin
You need to successfully create an IBM Cloud® Virtual Private Cloud and Virtual Servers for VPC by using the appropriate catalog image for
SAP. Check SAP Note 2927211 to make sure that the selected operating system is supported by SAP. The Metrics Collector runs specifically
on Virtual Servers for VPC to gather required SAP metrics. Figure 1 outlines the data sources that are used by IBM Metrics Collector for SAP.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 258

Figure 1. Data sources for IBM Metrics Collector for SAP

Getting an IBM Cloud API key
You need an IBM Cloud API key for IMCS to successfully collect all required metrics. The API key grants view access to IBM Cloud
infrastructure services. You can install IMCS without an API key. However, some metrics are missing and the virtual server is not supported by
SAP.
For a list of missing metrics, see Additional Information.
Note: You need to create only one Service ID and one API Key per Account. You can use the same Service ID and API Key for all the
Metric Collectors that are installed in the virtual server that is associated to the Account.

Creating a Service ID
You need to first create a Service ID and then the related API key. Use the following steps to create a Service ID.
1. Sign in to the IBM Cloud console and click Manage > Access (IAM).
Figure 2. Open the Access (IAM page)

Figure 2. Open the Access (IAM) page

2. Click Services IDs > Create.
3. Enter a Name and Description for the Service ID and click Create. You can assign the Access Policy after your Service ID is created.
4. Click Access Policies > Assign Access.
5. Click IAM Services for Assign Service ID additional access .
6. Select VPC Infrastructure service for What type of access do you want to assign?
7. Leave the default Account for in
8. Leave All resource types for Resource type and click Viewer for Platform Access.
9. Click Add > Assign. The VPC Infrastructure Service policy is assigned to your Service ID.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 259

Creating an API Key for the Service ID.
Use the following steps to create an API Key for the new Service ID.
1. Select Service IDs and your newly created Service ID
2. Click the tab Access Policy and verify that the VPC Infrastructure Service is listed as an Access Policy. If not repeat steps 4-9.
3. Click the next tab API keys > Create.
4. Enter a Name and Description for the key and click Create.
5. Click Copy or Download your API key to save it.
Important: This is the only opportunity to access the API Key's data. You cannot view this API key again, so you cannot retrieve it later.

Installing the IBM Metrics Collector for SAP on Linux
The IMCS is a daemon or service that automatically starts as soon as it is installed and requires an API key. It collects metrics from the
metadata of the virtual server, IBM Cloud infrastructure services, runtime data about resources, such as CPU, memory, network, and disk. The
metrics are aggregated and displayed through the web server for SAP customers. SAPOSCOL uses the XML output of this web server.
Important: The IMCS uses port 18181 to display the metrics. Make sure that port 18181 is not used by any other application. For
more information about checking port availability, see Troubleshooting.

Note: The commands that are listed in this section were run on a Red Hat virtual server instance. If you have a SUSE virtual server, you
can follow the same steps but you will see a slightly different user interface.
Use the following steps to download the IMCS.
1. Download the IMCS .
2. Select the appropriate tar.gz file. In most cases, use the current version. Connect as guest.
3. Save the file to your internal Downloads folder and click OK.
4. Move or copy the IMCS tar.gz file to your VPC virtual server instance.
5. Extract the file and open the extracted folder.
$ tar -xvf sap-metrics-collector-v1.3.tar.gz
cd sap

6. Run the install-linux.sh file.
$ ./install-linux.sh

7. Paste your API key when prompted. If you don't have an API key, see Getting an IBM Cloud API key.
8. Check to make sure that the IMCS is running after the installation is complete. The service status displays

active when it is ready.

$ sudo systemctl is-active sap-metrics-collector

Verifying data collection
After the installation completes and the service is started, it can take time for the IMCS begins collecting metrics. Wait at least 2 minutes after
the installation before you expect full and accurate metrics.
1. Run the following curl command for your localhost address to see your metrics:
$ curl http://localhost:18181/sap/metrics

<metrics>
<metric category="config" context="vm" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Data Provider Version</name>
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 260

<value>1.3</value>
</metric>
<metric category="config" context="host" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Cloud Provider</name>
<value>IBM Cloud</value>
</metric>
<metric category="config" context="vm" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Instance Type</name>
<value>bx2-8x32</value>
</metric>
<metric category="config" context="host" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Virtualization Solution</name>
<value>KVM</value>
</metric>
.
.
.
</metrics>

Note: You might experience a delay before your data is available.

Troubleshooting
Use the following troubleshooting tips for IMCS.

Uninstalling the Metrics Collector
1. Run the following command to uninstall IMCS if you have any issues during the installation process. Then, reinstall it.
$ ./uninstall-linux.sh

Removing IBM Metric Collector for SAP...
Successfully removed IBM Metric Collector for SAP.

No metrics reported when you run the curl command
No reported metrics message is often due to the port not assigned to SAP Metrics Collector. It needs port

18181 available for localhost . If

you have any other applications that use the port, you must close the applications.
1. Use the following command to see whether the port is assigned to another application.
$ nmap -sT -O localhost

Starting Nmap 6.40 (http://nmap.org) at (date and time)
Nmap scan report for localhost (your localhost address)
Host is up (0.0s latency).
Other addresses for localhost (not scanned): (localhost addresses)
rDNS record for (localhost): sap-mc-redhat
Not shown: (number of) closed ports
PORT

STATE SERVICE

(port)/tcp open

ssh

(port)/tcp open

smtp

Device type: general purpose
Running: Linux 3.X
OS CPE: cpe:/o:linux:linux_kernel:3
OS details: Linux 3.7 3.9
Network Distance: 0 hops

nmap not found
You can install nmap on your system by using the appropriate package manager like

yum or apt-get .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 261

Command for Red Hat: yum install nmap
Command for SUSE: zypper install nmap

Additional information
If you don't have an IBM Cloud API key, the IMCS can't collect all of the metrics that are required by SAP, which include
Network Adapter Mapping - replaced with local MAC ID.
Network Adapter Bandwidth - Port Speed - defaults to 0.
Disk Volume Mapping - replaced with Volume Attachment ID.
Disk Guaranteed IOPS - defaults to 0.
Important: You must provide an API key so that all metrics can be collected. Otherwise, this virtual server is not fully supported by
SAP.

Using IBM Metrics Collector for SAP (IMCS) on Windows
Note: The IBM® Metrics Collector for SAP (IMCS) on Windows is a requirement by SAP Support for IBM Cloud® Virtual Private Cloud
Infrastructure only when SAP workloads are running on the virtual server instance (VSI).

Getting an IBM Cloud API key
You need an IBM Cloud API key for IMCS to successfully collect all required metrics. The API key grants view access to IBM Cloud
infrastructure services. You can install IMCS without an API key. However, some metrics are missing and the virtual server is not supported by
SAP.
For a list of missing metrics, see Additional Information.
Note: You need to create only one Service ID and one API Key per Account. You can use the same Service ID and API Key for all the
Metric Collectors that are installed in the virtual server that is associated to the Account.

Creating a Service ID
You need to first create a Service ID and then the related API key. Use the following steps to create a Service ID.
1. Sign in to the IBM Cloud console and click Manage > Access (IAM).
2. Click Services IDs > Create.
3. Enter a Name and Description for the Service ID and click Create. You can assign the Access Policy after your Service ID is created.
4. Click Access Policies > Assign Access.
5. Click IAM Services for Assign Service ID additional access .
6. Select VPC Infrastructure service for What type of access do you want to assign?
7. Select All resource groups for in.
8. Leave the default Account for in
9. Leave All resource types for Resource type and click Viewer for Platform Access.
10. Click Add > Assign. The VPC Infrastructure Service policy is assigned to your Service ID.

Creating an API Key for the Service ID.
Use the following steps to create an API Key for the new Service ID.
1. Select Service IDs and your newly created Service ID
2. Click the tab Access Policy and verify that the VPC Infrastructure Service is listed as an Access Policy. If not repeat steps 4-9.
3. Click the next tab API keys > Create.
4. Enter a Name and Description for the key and click Create.
5. Click Copy or Download your API key to save it.
Important: Now is the only opportunity to access the API Key data. You cannot view this API key again, so you cannot retrieve it later.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 262

Installing the IBM Metrics Collector for SAP on Windows
The IMCS is a service that automatically starts after the installation is and requires an API key. It collects metrics from the metadata of the
virtual server, IBM Cloud infrastructure services, runtime data about resources, such as CPU, memory, network, and disk. The metrics are
aggregated and displayed through the web server for SAP customers. SAPOSCOL uses the XML output of this web server.
Important: The IMCS uses port 18181 to show the metrics. Make sure that port 18181 is not used by any other application. For more
information on how to check port availability, see Troubleshooting.

Note: The commands that are listed in this section were run in Windows PowerShell 5.1.
Use the following steps to download the IMCS.
1. Download the IMCS .
2. Select the appropriate .zip. In most cases, use the current version. Connect as guest.
3. Save the file to your internal Downloads folder and click OK.
4. Move or copy the IMCS .zip file to your VPC virtual server instance.
5. Extract the file and open the extracted folder.
6. Run the install-metric-collector.ps1 file. Right-click on the file and select 'Run with Powershell', or run the following command on
the power shell:
$ .\install-metric-collector.ps1

7. Paste your API key when prompted. If you don't have an API key, see Getting an IBM Cloud API key.
8. Check to make sure that the IMCS is running after the installation is complete. The service status displays

Running when it is ready.

$ Get-Service Telegraf
Status

Name

DisplayName

------

----

-----------

Running

Telegraf

Telegraf Data Collector Service

Verifying data collection
After the installation completes and the service is started, it can take time for the IMCS begins collecting metrics. Wait at least 2 minutes after
the installation before you expect full and accurate metrics.
1. Open the browser of your choice.
2. Open the following link: http://localhost:18181/sap/metrics
<metrics>
<metric category="config" context="vm" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Data Provider Version</name>
<value>1.3</value>
</metric>
<metric category="config" context="host" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Cloud Provider</name>
<value>IBM Cloud</value>
</metric>
<metric category="config" context="vm" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Instance Type</name>
<value>bx2-8x32</value>
</metric>
<metric category="config" context="host" device-id="" last-refresh="1607451781" refresh-interval="0"
type="string" unit="none">
<name>Virtualization Solution</name>
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 263

<value>KVM</value>
</metric>
.
.
.
</metrics>

Note: You might experience a delay before your data is available.

Troubleshooting
Use the following troubleshooting tips for IMCS.

Uninstalling the Metrics Collector
1. Run the following command to uninstall IMCS if you have any issues during the installation process. Then, reinstall it.
$ .\uninstall-metric-collector.ps1

Are you sure you want to uninstall Metric Collector for SAP? (Default is No)
( y / n ) : y
Continuing uninstalling metric collector...
Removed scheduled task: IBM Metric Collector for SAP Updator
Successfully Uninstalled Metric Collector

No metrics reported when you open the link
No reported metrics is often due to the port not assigned to SAP Metrics Collector. It needs port

18181 available for localhost . If you have

any other applications using the port, you must close the applications/owning process.
1. Use the following command to see whether the port is assigned to another application.
$ Get-NetTCPConnection -State listen

Figure 1. Ports that are used by applications

Additional information
If you don't have an IBM Cloud API key, the IMCS can't collect all of the metrics that are required by SAP, which include
Network Adapter Mapping - replaced with local MAC ID.
Network Adapter Bandwidth - Port Speed - defaults to 0.
Disk Volume Mapping - replaced with Volume Attachment ID.
Disk Guaranteed IOPS - defaults to 0.
Important: You must provide an API key so that all metrics can be collected. Otherwise, this virtual server is not fully supported by
SAP.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 264

Provisioning IBM Power Virtual Server for SAP HANA and SAP NetWeaver
Planning your deployment
Make sure that you are already familiar with the fundamental components and options that are provided by IBM Cloud Classic Infrastructure
for SAP. Before you start with the deployment of servers, make sure that you also read the Get Started section.
Intel Optane persistent memory (PMem) is available on the Bare Metal servers. You have three memory options for PMem on the Bare Metal
servers, 1.5 TB, 3.0 TB, and 6.0 TB. Which option you choose depends on the:
Application that you want to run, for example BW or BW/4 HANA.
SAP sizing, which determines the amount of memory and CPU that you need.
Network and storage configuration, disaster recovery, high availability, backups, and system replication are all configured and managed as part
of the Bare Metal provisioning and operation.

The 'Must-Reads' before you start deploying
To ensure that your first deployment is a success, review the information in Provisioning SAP HANA and SAP NetWeaver

Planning your

deployment

Other useful documents
See the respective topics in the Get Started section for the following information:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

Deploying IBM Cloud VPC infrastructure for Power Virtual Server SAP workloads
As a best practice for SAP that runs on IBM® Power® Virtual Server, three IBM Cloud VPCs are created and three virtual server instances are
deployed and configured.
Access host that is deployed in management VPC is used for the management access to the landscape.
Host for internet services that are deployed in edge VPC is used to configure the access from Power Virtual Server instances to IBM
Cloud services and to the public internet.
Host for private services that are deployed in workload VPC provides certain management services to the Power Virtual Server
instances, like NFS, DNS, NTP.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 265

Figure 1. VPC landing zone for SAP on PowerVS

Deploying IBM Cloud VPC for management services (management VPC)
IBM Cloud VPC for management services (management VPC) is a mandatory component in the SAP on Power Virtual Server best practices.
This service hosts the access hosts to the environment.
Set up Virtual Private Cloud for management services. For more information, see Creating a VPC and subnet .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 266

Take care about the default network prefix. We recommend reducing the default network prefix, so it does not overlap between all your
IBM Cloud VPC services.
Optionally, attach a public gateway to the subnet. With this option, every VPC in the subnet can communicate with the internet. An
alternative is to use a floating IP address on virtual system instance instead and enable internet for the instances.

Deploying access host in management VPC
Access host is a mandatory component in the SAP on Power Virtual Server best practices. By this virtual server instance, the floating IP
address is activated. You can then log in to the environment by using SSH. You need to set up a VPN access as a separate step and disable the
floating IP address for a more secure environment. Use the following steps to deploy the access host.
1. Create a security group for management services. For more information, see Configuring the security group for the instance . Specify
following rules.
Protocol

Source

Source

Value

Rule's purpose

type
ALL

CIDR
Block

10.0.0.0/8

n/a

Address block of IBM Cloud VPC and Power Virtual Server
management subnets

ALL

CIDR
Block

161.26.0.0/16

n/a

Address block of OS registration servers

TCP

CIDR
Block

0.0.0.0/0

Port 2222

Address block allowed for host administration over SSH

Table 1. Overview of the inbound security group rules for the access host

Protocol

Source type

Source

Value

Rule's purpose

ALL

CIDR Block

0.0.0.0/0

n/a

Allow all connections initiated from the hosts

Table 2. Overview of the outbound security group rules for the access host

2. Create an ACL to restrict the access to the management VPC's subnets.
Rule

Allow

priority

or

Protocol

Source

Destination

Value

Rule's purpose

deny
1

Allow

ALL

161.0.0.0/8

10.0.0.0/8

n/a

address block of OS registration servers

2

Allow

TCP

Any IP, any
port

10.10.10./24,
ports 22-22

n/a

address block for host administration over SSH

3

Allow

ALL

10.0.0.0/8

10.0.0.0/8

n/a

address block that is allowed for IBM Cloud VPC
and Power Virtual Server management subnets

4

Deny

ALL

Any IP

Any IP

n/a

Deny all other inbound traffic

Table 3. Overview of the inbound ACL rules for the access host

Rule

Allow

priority

or

Protocol

Source

Destination

Value

Rule's purpose

deny
1

Allow

ALL

10.0.0.0/8

161.0.0.0/8

n/a

address block of OS registration servers

2

Allow

TCP

10.10.10./24,
ports 22-22

Any IP, any
port

n/a

address block for host administration over SSH

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 267

3

Allow

ALL

10.0.0.0/8

10.0.0.0/8

n/a

address block that is allowed for IBM Cloud VPC
and Power Virtual Server management subnets

4

Deny

ALL

Any IP

Any IP

n/a

Deny all other outbound traffic

Table 4. Overview of the outbound ACL rules for the access host

3. Create a virtual server instance with a Linux operating system. For more information, see Creating a virtual server instance .
You can select any available Linux image, but you need to use the same operating system release for all of the virtual server
instances in the landscape. We verify the setup with newest versions of Red Hat Enterprise Linux (starting with RHEL 8.4) and of
Suse Linux Enterprise Server (starting with SLES 15 SP3).
You don't have limitations as to which Compute profile, SAP certification, or storage and network performance is used. You can use
the smallest profile with 2 virtual CPUs and with 4 GB memory.
4. Attach the security group to the virtual server instance that you created in the previous step. Detach the default security group.
5. Enable the floating IP address on the access host. For more information, see

Reserving a floating IP address .

6. After instance status changes to Running , verify that you can successfully log in on the access host.
Tip: We recommend that you use two extra SSH client parameters to get a more reliable SSH connection:

ServerAliveInterval=60

and ServerAliveCountMax=600 . If you use a nondefault path to your SSH key, you must specify it by following SSH client parameter: i \<path to your SSH private key\> .

SSH command example:
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 root@\<access_host_floating_ip\>

Optional steps on IBM Cloud VPC for management services
To create other VPC resources, such as ACL, load balancer, and other resources, see Using the IBM Cloud console to create VPC resources .

Deploying IBM Cloud VPC for edge services (edge VPC)
IBM Cloud VPC for edge services (edge VPC) is a mandatory component in the SAP on IBM Power Virtual Services best practices. This service
hosts the internet-facing SAP workloads.
Set up IBM Cloud VPC for management services. For more information, see Creating a VPC and subnet .
Take care about the default network prefix. We recommend reducing the default network prefix, so it does not overlap between all your
IBM Cloud VPC services.
Attach a public gateway to the subnet. Every VPC in the subnet can communicate with the internet. An alternative is to use a floating IP
address on the virtual system instance instead and enable internet for the instances.

Deploying host for internet services in edge VPC
Host for internet services is a mandatory component in the SAP on Power Virtual Server best practices. This virtual server instance hosts
mandatory proxy server. Use the following steps to deploy a host for basic management services.
Note: The following example setup uses open ports for standard SQUID proxy server that is provided by Linux distributions. If you use
another proxy software or custom configurations, setup might vary.
1. Create a security group for basic management services as described Configuring the security group for the instance . Specify following
rules:
Protocol

Source

Source

Value

Rule's purpose

10.0.0.0/8

n/a

address block of IBM Cloud VPC and Power Virtual Server
management subnets

type
ALL

CIDR
Block

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 268

TCP

CIDR
Block

0.0.0.0/8

Port 80-80

HTTP

TCP

CIDR
Block

0.0.0.0/8

Port 443443

HTTPS

TCP

CIDR
Block

0.0.0.0/8

Port 84438443

HTTPS (used by OS registration)

ALL

CIDR
Block

161.26.0.0/16

n/a

address block of OS registration servers

UDP

CIDR
Block

0.0.0.0/0

Port 53-53

DNS

Table 5. Overview of inbound security group rules for the internet services host

Protocol

Source type

Source

Value

Rule's purpose

ALL

CIDR Block

0.0.0.0/0

n/a

Allow all connections initiated from the hosts

Table 6. Overview of outbound security group rules for the internet services host

2. Create an ACL to restrict the access to the edge IBM Cloud VPC's subnets.
Rule

Allow

Priority

or

Protocol

Source

Destination

Value

Rule's purpose

deny
1

Allow

ALL

161.0.0.0/8

10.0.0.0/8

n/a

address block of OS registration servers

2

Allow

UDP

Any IP, ports
53-53

10.0.0.0/8,
any port

n/a

DNS

3

Allow

ALL

10.0.0.0/8

10.0.0.0/8

n/a

address block that is allowed for IBM Cloud VPC
and Power Virtual Server management subnets

4

Allow

TCP

Any IP, ports
8443-8443

10.0.0.0/8,
any port

n/a

HTTPS for OS registration

5

Allow

TCP

Any IP, ports
443-443

10.0.0.0/8,
any port

n/a

HTTPS

6

Allow

TCP

Any IP, ports
80-80

10.0.0.0/8,
any port

n/a

HTTP

7

Deny

ALL

Any IP

Any IP

n/a

Deny all other inbound traffic

Table 7. Overview of ACL inbound rules for the internet services host

Rule

Allow

priority

or

Protocol

Source

Destination

value

Rule's purpose

deny
1

Allow

ALL

10.0.0.0/8

161.0.0.0/8,
any port

n/a

address block of OS registration servers

2

Allow

UDP

10.0.0.0/8,
any port

Any IP, ports
53-53

n/a

DNS

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 269

3

Allow

ALL

10.0.0.0/8

10.0.0.0/8

n/a

address block that is allowed for IBM Cloud VPC
and Power Virtual Server management subnets

4

Allow

TCP

10.0.0.0/8,
any port

Any IP, ports
8443-8443

n/a

HTTPS for OS registration

5

Allow

TCP

10.0.0.0/8,
any port

Any IP, ports
443-443

n/a

HTTPS

6

Allow

TCP

10.0.0.0/8,
any port

Any IP, ports
80-80

n/a

HTTP

7

Deny

ALL

Any IP

Any IP

n/a

Deny all other outbound traffic

Table 8. Overview of ACL outbound rules for the internet services host

3. Provision a virtual service instance with Linux. For more information, see Creating a virtual server instance .
You can choose any of available Linux distributions. We recommend that you use the same OS release for all virtual server
instances in the landscape. We verify the setup with the newest versions of Red Hat Enterprise Linux (starting with RHEL 8.4) and
of Suse Linux Enterprise Server (starting with SLES 15 SP3).
One of the profiles with 2 or 4 virtual CPUs and with 4 GB or 8 GB of memory would be sufficient in general. If you have stronger
performance requirements, by using SQUID cache, you can choose a profile with more virtual CPUs or memory.
We recommend that you attach extra storage to the instance, locate SAP installation files on this separate disk, and export them
over NFS. The disk size must be large enough to host all the data from IBM Cloud Object Storage that is relevant for all the
installations and setups.
4. Attach the security group to the virtual server instance that you created in the previous step. Detach the default security group.
5. After some time, instance becomes status 'running'.

Deploying IBM Cloud VPC for workload services (workload VPC)
IBM Cloud VPC for workload services (workload VPC) is a mandatory component in the SAP on IBM Power Virtual Services best practices. This
service hosts the instances with management components that are used by operating systems and workloads that are running in Power®
Virtual Servers.
Set up Virtual Private Cloud for management services. For more information, see Creating a VPC and subnet .
Take care about the default network prefix. We recommend reducing the default network prefix, so it does not overlap between all your
IBM Cloud VPC services.
Do not attach a public gateway to the subnet and do not use floating IP addresses. The hosts are communication with the internet over
SQUID proxy.

Deploying host for workload services in workload VPC
Host for workload services is a mandatory component in the SAP on IBM Power Virtual Services best practices. This virtual server instance
hosts optional NFS server, NTP forwarder, DNS forwarder, and LDAP server. If you have already some of these services in your environment
that are accessible from Power Virtual Server networks, then you can use them and do not need to install here. Execute following steps to
deploy host for private services.
Note: By the using the following setup, we open ports for standard widely used management components: NFS service provided by
Linux distributions, NTP service over 'chrony', DNS service over 'bind' and open LDAP. If you use another software solutions or custom
configurations, set up might vary.
1. Create a security group for private services. For more information, see Configuring the security group for the instance . Specify following
rules:
Protocol

Source

Source

Value

Rule's purpose

type

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 270

ALL

CIDR
Block

10.0.0.0/8

n/a

address block of IBM Cloud VPC and Power Virtual Server
management subnets

ALL

CIDR
Block

161.26.0.0/16

n/a

address block of OS registration servers

UDP

CIDR
Block

0.0.0.0/0

Port 5353

DNS

Table 9. Overview of the inbound security group rules for the workload services host

Protocol

Source type

Source

Value

Rule's purpose

ALL

CIDR Block

0.0.0.0/0

n/a

Allow all connections initiated from the hosts

Table 10. Overview of the outbound security group rules for the workload services host

2. Create an ACL to restrict the access to the Workload VPC's subnets.
Rule

Allow

priority

or

Protocol

Source

Destination

Value

Rule's purpose

deny
1

Allow

ALL

161.0.0.0/8

10.0.0.0/8

n/a

address block of OS registration servers

2

Allow

UDP

Any IP,
ports 53-53

10.0.0.0/8,
any port

n/a

DNS

3

Allow

ALL

10.0.0.0/8

10.0.0.0/8

n/a

address block that is allowed for IBM Cloud VPC
and Power Virtual Server management subnets

4

Deny

ALL

Any IP

Any IP

n/a

Deny all other inbound traffic

Table 11. Overview of the inbound ACL rules for the workload services host

Rule

Allow

priority

or

Protocol

Source

Destination

Value

Rule's purpose

deny
1

Allow

ALL

10.0.0.0/8

161.0.0.0/8,
any port

n/a

address block of OS registration servers

2

Allow

UDP

10.0.0.0/8,
any port

Any IP,
ports 53-53

n/a

DNS

3

Allow

ALL

10.0.0.0/8

10.0.0.0/8

n/a

address block that is allowed for IBM Cloud VPC
and Power Virtual Server management subnets

4

Deny

ALL

Any IP

Any IP

n/a

Deny all other outbound traffic

Table 12. Overview of the outbound ACL rules for the workload services host

3. Create a virtual server instance by using a Linux image. For more information, see Creating a virtual server instance .
You can choose any of available Linux distributions. We recommend that you use the same OS release for all virtual server
instances in the landscape. We verify the setup with newest versions of Red Hat Enterprise Linux (starting with RHEL 8.4) and of
Suse Linux Enterprise Server (starting with SLES 15 SP3).
Analyze your DNS and LDAP performance requirements and ensure you choose an appropriate profile with enough virtual CPUs
and memory.
We recommend attaching an extra storage disk to the instance, locate SAP installation files on this separate disk and export them
over NFS. The disk size must be large enough to host all the data from IBM Cloud Object Storage that is relevant for all the
installations and setups in this landscape.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 271

4. Attach the security group to the virtual server instance that you created previously. Detach the default security group.
5. After some time, instance becomes status 'running'.

Connecting IBM Cloud VPC services over transit gateway
To establish communication between virtual server instances that run in different IBM Cloud VPC services, you must connect the private
networks in the IBM Cloud VPC services with each other.
1. Create transit gateway. For more information, see Creating a transit gateway by using the UI .
2. Connect all IBM Cloud VPCs (management, edge, workload) to the transit gateway. For more information, see Adding a connection. Now
you can connect with SSH over the access host with internet and private services hosts.
3. Verify that you can successfully log in to the host for internet services over the access host and to the host for workload services over
the access host. The floating IP address of the access host is specified as ProxyCommand parameter of your ssh command.
Tip: We recommend that you use two extra SSH client parameters for a more reliable SSH connection:

ServerAliveInterval=60 and

ServerAliveCountMax=600 . If you use a nondefault path to your SSH key, you must specify it by following SSH client parameter: -i \
<path_to_your_SSH_private_key\> .

SSH command example (host for internet services over the access host):
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand=\"ssh -W %h:%p root@\
<access_host_floating_ip\>\" root@\<internet_services_host_private_ip\>

SSH command example (host for workload services over the access host):
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand=\"ssh -W %h:%p root@\
<access_host_floating_ip\>\" root@\<workload_services_host_private_ip\>

Configure the management services on the virtual server instances in IBM Cloud VPC
The following setup example demonstrates usage of SQUID proxy server, NFS server, NTP forwarder, IBM Cloud DNS service, or DNS
forwarder for your private DNS server. Setup of central user management (LDAP) is not covered here.

Setup SQUID proxy server
1. Ensure all required ports in the security group in IBM Cloud VPC for edge services that are used by host for internet services are open.
The needed ports are configured for internet services. Required ports for SQUID proxy are used by Power Virtual Server services. For
more information, see Creating a proxy .
2. Log in to the internet services instance. SSH command example:
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand=\"ssh -W %h:%p root@\
<access_host_floating_ip\>\" root@\<internet_services_host_private_ip\>

3. Ensure that the squid software is available. On SUSE: zypper update -y; zypper install -y squid . On RHEL: yum update -y;
yum install epel-release; yum install -y squid .

4. Modify the SQUID configuration and add the rules relevant for OS update registration of virtual instances that run in Power Virtual Server.
For more information, see proxy configuration documentation.
5. Enable and restart SQUID service: systemctl stop squid; systemctl start squid; systemctl enable squid .

Setup SQUID proxy server -- Ansible
To perform the previous steps through ansible automation, download ansible-galaxy collection ibm.power_linux_sap .
$ ansible-galaxy collection install ibm.power_linux_sap

After the ansible collection is installed, to set up proxy, update the variable file

playbook/vars/sample_services_variable_file.yml

$ server_config: {
squid: { enable: true }

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 272

}

After the file is updated, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_services_variable_file.yml

This ansible execution ensures that the squid proxy server is configured on host for workload services.

Setting up NFS server for SAP installation files
1. Ensure all required ports in the security group in IBM Cloud VPC for workload services that are used by host for private services are open.
The needed ports are configured for private services. Required ports for NFS server are: 111 (TCP and UDP) and 2049 (TCP and UDP).
2. Log in to the workload services instance. SSH command example:
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand=\"ssh -W %h:%p root@\
<access_host_floating_ip\>\" root@\<workload_services_host_private_ip\>

3. Make sure that the required NFS software is available. On SUSE: zypper update -y; zypper install -y nfs-utils . On RHEL: yum
update -y; yum install epel-release; yum install -y nfs-utils .

4. Create a directory where NFS is mounted and export it.
5. Start NFS service and verify that the directory is exported. Use command showmount -e .
6. Make sure that the awscli software is available. This software is used later to download the software from S3 storage (IBM Cloud Object
Storage). On SUSE: zypper update -y; zypper install -y aws-cli . On RHEL: yum update -y; yum install epel-release; yum
install -y awscli .

Setting up NFS server for SAP installation files -- Ansible
To perform the previous steps through ansible automation, download ansible-galaxy collection ibm.power_linux_sap .
$ ansible-galaxy collection install ibm.power_linux_sap

After the ansible collection is installed, update the variable file

playbook/vars/sample_services_variable_file.yml to set up proxy.

$ server_config: {
nfs: { enable: true, nfs_directory: "/NFS;/hana/software" }
}

If you also want to install awscli, by using ansible, add update variable file

playbook/vars/sample_services_variable_file.yml as

$ server_config: {
nfs: { enable: true, nfs_directory: "/NFS;/hana/software" },
awscli: { enable: true }
}

After file is updated, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_services_variable_file.yml

This ansible execution makes sure that the host for workload services acts as an NFS server and awscli package is installed.

Setting up NTP proxy and forwarder
1. Ensure all required ports in the security group in IBM Cloud VPC for workload services that are used by host for private services are open.
The needed ports are configured for private services. Required port for NTP forwarder is: 123 (TCP).
2. Log in to the workload services instance. SSH command example:
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand=\"ssh -W %h:%p root@\
<access_host_floating_ip\>\" root@\<workload_services_host_private_ip\>

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 273

3. Make sure that the required NTP software is available. On SUSE: zypper update -y; zypper install -y chrony . On RHEL: yum
update -y; yum install epel-release; yum install -y chrony .

4. Modify file '/etc/chrony.conf' and add following lines. Replace \<pvs_mgmt_cidr\> with Power Virtual Server management CIDR block
(network segment)
$ local stratum 10
manual
allow \<pvs_mgmt_cidr \>

5. Enable and start chrony service: systemctl stop chronyd; systemctl start chronyd; systemctl enable chronyd; .

Setup NTP proxy or forwarder -- Ansible
To perform previous steps through ansible automation, download ansible-galaxy collection ibm.power_linux_sap .
$ ansible-galaxy collection install ibm.power_linux_sap

After the ansible collection is installed, to set up proxy, update the variable file

playbook/vars/sample_services_variable_file.yml .

$ server_config: {
ntp: { enable: true }
}

After the file is updated, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_services_variable_file.yml

This ansible execution ensures that the NTP proxy is configured on the host for workload services.

Setting up IBM Cloud-native DNS service (DNS option 1)
You can use IBM Cloud DNS service that is directly reachable from IBM Power Virtual Servers over custom resolver. For more information, see
the following links.
Setting up an instance
Managing DNS zones
Managing permitted networks
Managing DNS records
Configuring custom resolver. Specify VPE subnet of IBM Cloud VPC for workload services as location in the resolver.
Make sure that all required ports in the security group in IBM Cloud VPC for workload services that are used by host for private services are
open. The needed ports are configured for private services. Required port for DNS is: 53 (TCP and UDP). As result, you get a private IP address
that you can specify in Power® Virtual Server instances as DNS endpoints by private subnet configuration. These IP addresses are entered into
/etc/resolf.conf in the operating system.

Setting up DNS forwarder (DNS option 2)
If you use your own DNS service, its IP must be reachable from VPC for workload services. If the IP is not directly reachable from IBM Power
Systems Virtual Servers, a DNS forwarder on the host for critical management services is required. Use the following steps to complete the
configuration:
1. Make sure that all required ports in the security group in IBM Cloud VPC for workload services that are used by host for private services
are open. The needed ports are configured for private services. Required port for DNS is: 53 (TCP and UDP).
2. Log in to the private services instance. You can use the following SSH command example:
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand=\"ssh -W %h:%p root@\
<access_host_floating_ip\>\" root@\<workload_services_host_private_ip\>

3. Make sure that the required DNS software is available. On SUSE: zypper update -y; zypper install -y bind . On RHEL: yum
update -y; yum install epel-release; yum install -y bind .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 274

4. Modify file /etc/named.conf :
Add the following lines at the beginning of the file direct after the starting comment (before the

options section starts). Replace

<pvs_mgmt_cidr> with Power Virtual Server management CIDR block (network segment)
$ acl allowed_clients {
localhost;
10.10.0.0/16;
};

Add the following lines at the beginning of the options section. Both 161.26.0.x IPs are the IBM Cloud DNS servers. 9.9.9.9 IP is
the IBM public DNS server IP. Replace or extend this IP list with DNS servers of your choice.
$ forwarders {
161.26.0.7;
161.26.0.8;
9.9.9.9;
};
recursion yes;
allow-query { allowed_clients; };
forward only;

5. Enable and start DNS service: systemctl stop named; systemctl start named; systemctl enable named; .

Setup DNS forwarder (DNS option 2) -- Ansible
To perform the previous steps through ansible automation, download ansible-galaxy collection ibm.power_linux_sap .
$ ansible-galaxy collection install ibm.power_linux_sap

After the ansible collection is installed, to set up proxy, update the variable file

playbook/vars/sample_services_variable_file.yml

$ server_config: {
dns: { enable: false, dns_servers: "161.26.0.7; 161.26.0.8; 9.9.9.9;" }
}

After the file is updated, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_services_variable_file.yml

This ansible execution ensures that the DNS forwarder services are configured on Power Virtual Server.

Deploying SAP Power Virtual Server workloads
For SAP workloads that run on IBM® Power® Virtual Server, one workspace for Power Virtual Server is deployed. When the workspace is
deployed, you see the following results.
One workspace for Power Virtual Server
Public SSH key is imported
Two private networks are created and connected through redundant IBM Cloud Connections that pair with all your VPC services.
The following diagram shows deployed components.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 275

Figure 1. Power Virtual Server infrastructure for SAP

Deploying a Power Virtual Server
Workspaces for Power Virtual Server host all the SAP instances that don't require direct internet access. All SAP NetWeaver and SAP HANA
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 276

instances are deployed in the workspace for Power Virtual Server. To create and configure this service, use the following steps.
1. Deploy a new workspace for Power Virtual Server in the same region where your IBM Cloud edge VPC is. For more information, see
Creating a Power Systems Virtual Server workspace .
2. Optionally, you can upload your SSH public key to the workspace. SSH keys are distributed across all the workspaces that are in your
account, so you generate the SSH key one time.
Go to SSH keys, click Create SSH key , provide a unique name, and press Add SSH key.
3. In the workspace, create a management and backup private networks. For more information, see Configuring and adding a private
network subnet.
4. Create two IBM Cloud Connections as described here. Make sure that you select to enable IBM Transit Gateway. Attach the
management and backup networks to both IBM Cloud Connections.
5. Connect Direct Links (named exactly as IBM Cloud Connections that you created) to the transit gateway as described here. You can now
ping gateway IBM PowerVS private networks IP addresses from the access host.

Deploying SAP Power Virtual Server
When architecture for SAP that runs on IBM® Power® Virtual Server is deployed, you get the following features.
Separate private network for SAP system.
A Power Virtual Server instance for shared file systems.
A Power Virtual Server instance for SAP HANA.
A Power Virtual Server instance for SAP NetWeaver (on Linux).
Operating system that is configured to use management services that are configured on IBM Cloud® Virtual Private Cloud (SQUID proxy,
NFS, NTP, DNS).
Operating system that is registered to use IBM-provided OS subscription.
Operating systems on Power Virtual Server instances are prepared for SAP installation, which includes SAP-specific network
performance tuning, file system setup, and OS tuning.
The following diagram shows deployed SAP on PowerVS infrastructure components.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 277

Figure 1. SAP on PowerVS infrastructure

Deploying a separate private network for SAP systems
For each SAP system that you create, a separate private network that is used to communicate between virtual server instances is needed. This
network is tuned for maximum performance. To create separate private network for the SAP system, use the following steps.
1. In the workspace for Power Virtual Server, create a private network for SAP system as described

here.

2. Attach created network to both IBM Cloud Connections.

Deploying optional Power Virtual Server instance for SAP shared file systems
Each SAP system deployment based on SAP NetWeaver as application server contains file systems that are shared between multiple
application server instances. It is a good practice to set up a separate virtual service instance for the shared file systems. One single Power
Virtual Server instance for shared file systems can be used by multiple SAP systems. Your security requirements determine how many Power
Virtual Server instances for shared file systems that you need.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 278

To deploy Power Virtual Server instance for shared file systems, go to your workspace for Power Virtual Server and create Power Virtual Server
instance as described here. Specify following selections:
1. In the General section, make the following selections:
Field

Details

Instance name

Enter a unique name for the instance.

Number of instances

Enter '1'.

Server placement group (optional)

You can skip this selection if you don't use placement groups.

VM pinning (optional)

Keeping this selection is recommended.

SSH key

Select the key that you created previously.
Table 1. General shared file systems selections

2. In the Boot image section, make the following selections:
Field

Details

Operating system

Select Linux for SAP (NetWeaver).

Image

Select operating system and version. Make sure that you use the same operating system and version for all
deployments.

Tier

Select the tier that best fits your needs.

Storage pool
variations

Select the variation that best fits your needs.

Table 2. Shared file systems boot image selections

3. In the Profile section, make the following selections:
Field

Details

Machine type

Select the type that best fits your needs.

Core type

Select the core type that best fits your needs.

Cores and Memory (GiB)

Select based on your performance requirements.
Table 3. Share file system profile selections

4. In the Storage volumes section, make the following selection:
Attach one or more storage volumes to make sure that you have enough capacity for your shared file system.
5. In the Networking section, make the following selections:
Keep 'Public networks' deactivated
Attach both your private networks (management and backup). Make sure that you specify the IP addresses as entered in DNS
configuration for the corresponding hostnames. If IP addresses are assigned dynamically, you need to adapt the DNS entries for
the system hostnames.
It takes some time until the Power Virtual Server instance for shared file systems becomes available. The deployment is finished when you can
log in to the instance over the VPC access host by using the SSH command:
$ >ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand="ssh -W %h:%p root@\
<access_host_floating_ip\>" root@\<shared_fs_pvs_mgmt_ip\>*'

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 279

Where shared_fs_pvs_mgmt_ip is the virtual server instance IP address in the management subnet.

Deploying an SAP NetWeaver Power Virtual Server on Linux
To deploy Power Virtual Server instance for SAP NetWeaver, go to your workspace for Power Virtual Server and create Power Virtual Server
instance as described here. Specify the following selections:
1. In the General section, make the following selections:
Field

Details

Instance name

Enter a unique name for the instance.

Number of instances

Enter '1'.

Server placement group (optional)

You can skip this selection if you don't use placement groups.

VM pinning (optional)

Keeping this selection is recommended.

SSH key

Select the key that you created previously.
Table 4. SAP NetWeaver Linux general selections

2. In the Boot image section, make the following selections:
Field

Details

Operating system

Select 'Linux for SAP (NetWeaver)'.

Image

Select operating system and version. Make sure that you use the same operating system and version for all
deployments.

Tier

Select the tier that best fits your needs.

Storage pool
variations

Select the variation that best fits your needs.

Table 5. Shared file systems boot image selections

3. In the Profile section, make the following selections:
Field

Details

Machine type

Select the type that best fits your needs.

Core type

Select the core type that best fits your needs.

Cores and Memory
(GiB)

Select based on your performance requirements. For more information, see Power virtual server
profiles.
Table 6. Shared file systems profile selections

4. In the Storage volumes section, make the following selection:
Attach one or more volumes to make sure that you have enough capacity for the file system for SAP NetWeaver (/usr/sap)
5. In the Networking section, make the following selections:
Keep 'Public networks' deactivated
Attach both private networks (management and backup) and any separate private networks for the SAP system. Enter the IP
addresses as entered in the DNS configuration for the corresponding hostnames. If the IP addresses are assigned dynamically,
you need to adapt the DNS entries for the hostnames of this system.
It takes some time until the Power Virtual Server instance for SAP NetWeaver becomes available. The deployment is finished when you can log
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 280

in to the instance over the VPC access host by using the SSH command:
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand="ssh -W %h:%p root@\
<access_host_floating_ip\>" root@\<netweaver_pvs_mgmt_ip\>*'

Where netweaver_pvs_mgmt_ip is the virtual server instance IP address in the management subnet.

Deploying an SAP HANA Power Virtual Server
To deploy Power Virtual Server instance for SAP HANA, go to your workspace for Power Virtual Server .
1. In the General section, make the following selections:
Field

Details

Instance name

Enter a unique name for the instance.

Number of instances

Enter '1'.

Server placement group (optional)

You can skip this selection if you don't use placement groups.

VM pinning (optional)

"Soft" is the recommended selection.

SSH key

Select the key that you created previously.
Table 7. SAP HANA general selections

2. In the Boot image section, make the following selections:
Field

Details

Operating
system

Select 'Linux for SAP (NetWeaver)'.

Image

Select operating system and version. Make sure that you use the same operating system and version for all
deployments.

Tier

Select the tier that best fits your needs.

Storage pool

Select the tier that best fits your needs.
Table 8. SAP HANA boot image selections

3. In the Profile section, make the following selection:
Select profile that fits your needs. For more information, see SAP HANA profiles .
4. In the Storage volumes section, make the following selection:
For SAP HANA the attached volumes are on different storage tiers 'Tier 1' and 'Tier 3'. You can't mix storage tiers in the instance
creation process, so you need to attach storage volumes later. Keep this list empty.
5. In the Networking section, make the following selections:
Keep Public networks deactivated.
Attach both private networks (management and backup) and any separate private networks. Enter the IP addresses as entered in
the DNS configuration for the corresponding host names. If the IP addresses are assigned dynamically, you need to adapt the DNS
entries for the host names of this system.
It takes some time until the Power Virtual Server instance for SAP HANA becomes available. The deployment is finished when you can log in to
the instance over the VPC access host by using the SSH command:
$ ssh -A -o ServerAliveInterval=60 -o ServerAliveCountMax=600 -o ProxyCommand="ssh -W %h:%p root@\
<access_host_floating_ip\>" root@\<hana_pvs_mgmt_ip\>*'

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 281

where hana_pvs_mgmt_ip is the virtual server instance IP address in the management subnet.topic=sap-power-vs-set-up-powerinfrastructure) and create Power Virtual Server instance as described here. Specify following parameters:

Creating an SAP HANA Power Virtual Server storage volume
Modify the created Power Virtual Server instance for SAP HANA and attach extra storage volumes as described in

Modifying volume network.

Attach the following volumes:
A storage volume for SAP HANA shared file system. Volume size must be MIN (1 x RAM; 1 TB). Storage tier "Tier 3" is sufficient.
'Shareable' switch can stay 'off'.
Four or eight storage volumes of the same size for SAP HANA log file system. File system size must be MIN (1/2xRAM; 512 GB). Divide
file system size through Four or eight to determine the size for each storage volume. Select "Tier 1" as storage tier. 'Shareable' switch can
stay 'off'.
Four or eight storage volumes of the same size for SAP HANA data file system. File system size must be at minimum equal to the amount
of RAM. Divide file system size through Four or eight to determine size for each storage volume. Select "Tier 1" as storage tier.
'Shareable' switch can stay 'off'.
An extra storage volume of chosen size for extra data (such as '/usr/sap' file system). Storage tier "Tier 3" is sufficient. 'Shareable' switch
can stay 'off'.
You can attach extra volumes for backup or export.

Configuring a Power Virtual Server instance
Complete following configurations on your Power Virtual Server instances.

Configuring a proxy endpoint
To provide proxy and cache services for HTTP, FTP, and other popular network protocols, you need to export a proxy server endpoint. Run the
following commands to export a proxy endpoint.
$ export http_proxy=http://\<SQUID_PROXY_SERVER\>:3128
export https_proxy= http://\<SQUID_PROXY_SERVER\>:3128
export HTTP_proxy= http://\<SQUID_PROXY_SERVER\>:3128
export HTTPS_proxy =http://\<SQUID_PROXY_SERVER\>:3128

To keep these exported variables persistent across multiple sessions, /etc/bash.bashrc (on SLES) or /etc/bashrc (on RHEL) files must be
updated with these entries. These files help make sure that new sessions use these exported variables as environment variables.

Configuring the proxy by using ansible automation`
To configure the proxy by using ansible automation, download the

ibm.power_linux_sap ansible-galaxy collection.

$ ansible-galaxy collection install ibm.power_linux_sap

After the ansible collection is installed, you need to configure the proxy by updating the variable file
playbook/vars/sample_client_services_variable_file.yml .
$ client_config: {
proxy: { enable: true, squid_server_ip_port: \"SQUID_PROXY_SERVER\", no_proxy_hosts: '161.0.0.0/8' }
}

After you update the file, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_client_services_variable_file.yml

This ansible execution helps make sure that the proxy client service is configured.

Registering the operating system
To register the operating system with IBM Full Linux Subscription, follow the steps in Set full Linux.
After registration, perform a system update

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 282

On SUSE:
$ zypper update

On RHEL:
$ yum -y update

Registering the operating system by using ansible automation
To register the operating system by using ansible automation, download the

ibm.power_linux_sap ansible-galaxy collection.

$ ansible-galaxy collection install ibm.power_linux_sap

After the ansible collection installs, register the operating system by running the following ansible-playbook command.
For RHEL:
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-rhel.yml

For SLES:
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-sles.yml

This ansible execution helps make sure that the operating system is registered on Power Virtual Server instance. For more information, see

Set

full Linux.

Manually configuring the NTP client
If NTP server is already configured, you need to install the chrony package by using the following command.
On SLES:
$ zypper install -y chrony

On RHEL:
$ yum install -y chrony

After the package is installed, the file /etc/chrony.conf is available. You need to update this file with the NTP server details. Comment out
! pool pool.ntp.org iburst and add server \<NTP_SERVER_IP\> iburst . Then, start the chrony service with systemctl start
chronyd . To check the status of chrony service, run

systemctl status chronyd .

Configuring NTP client by using ansible automation
Configuring NTP client by using ansible automation, download the ibm.power_linux_sap ansible-galaxy collection.
$ ansible-galaxy collection install ibm.power_linux_sap

After the ansible collection is installed, configure NTP by updating the variable file
playbook/vars/sample_client_services_variable_file.yml .
$ client_config: {
ntp: { enable: true, ntp_server_ip: \"NTP_SERVER_IP\" }
}

After the file is updated, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_client_services_variable_file.yml

This ansible execution helps make sure that the NTP service is configured.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 283

Manually configuring the DNS client
To configure DNS server, you need to create the /etc/resolv.conf file, and enter the DNS server detail as nameserver \
<DNS_SERVER_NAME_or_IP\>

Configuring the DNS client by using ansible automation
1. To enable DNS service through ansible automation, download the ibm.power_linux_sap ansible-galaxy collection.
$ ansible-galaxy collection install ibm.power_linux_sap*

2. After the ansible collection is installed, configure DNS by updating the variable file
playbook/vars/sample_client_services_variable_file.yml .
$ client_config: {
dns: { enable: true, dns_server_ip: \"DNS_SERVER_IP\" }
}

3. After the file is updated, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_client_services_variable_file.yml

This ansible execution helps make sure that the DNS service is configured.

Manually configuring an NFS client
Use to following steps to manually create an NFS client.
1. Export shared NFS directories. To make these exported NFS directories available, mount them by using NFS protocol. Then, install the
nfs-client package and enable NFS client by using the systemctl command.

On SLES:
$ zypper install -y nfs-utils

On RHEL:
$ yum install -y nfs-utils

2. To enable NFS client service, use the following command.
$ systemctl start nfs-client

3. After the NFS client service starts, you can mount the shared NFS directory by using the mount command.
$ mount \<NFS_SERVER\>:\<REMOTE_NFS_DIRECTORY\> \<LOCAL_MOUNT_DIRICTORY\>

Configuring an NFS client by using ansible automation
1. This NFS enablement and mounting of shared NFS directories can also be performed by using ansible automation. Download the
ibm.power_linux_sap ansible-galaxy collection.
$ ansible-galaxy collection install ibm.power_linux_sap

2. After the ansible collection is installed, configure DNS by updating the variable file
playbook/vars/sample_client_services_variable_file.yml .
$ client_config: {
nfs: { enable: true, nfs_server_path: \"172.23.0.12:/NFS;172.23.0.12:/hana/software\", nfs_client_path:
\"/mnt;/hana\" }
}

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 284

3. After the file is updated, run the following ansible-playbook command.
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-services.yml -e
\@vars/sample_client_services_variable_file.yml

This ansible execution helps make sure that the NFS service is configured and that the proper directories are mounted. To check a mounted
directory, run the mount command.

Manually creating file systems
For shared SAP file systems, you need to create a file system to store SAP data and distribute them to all SAP instances. You can use extra file
systems for other purposes.
For an SAP NetWeaver instance, you need create a file system to store instance-specific data. You can use extra file systems for other
purposes.
To install SAP HANA, three file systems are created: data, log, and shared. According to the default installation catalog, these file systems are
/hana/data , /hana/log and /hana/shared , but you can customize these file system names. You might also need file systems for other

purposes ( /usr/sap directory). /hana/data and /hana/log file systems are striped across four or eight disks according to the number of
volumes that you created. /hana/shared and all other file systems are nonstripped 1-disk file systems.
To create a file system, use the following steps. As example, /hana/data is used. The same procedure is repeated for /hana/log and
/hana/shared and all other file systems.

1. Scan for the new storage that was provisioned. Run the following command for storage and disk discovery. Newly discovered disks are
listed at the end of the report.
$ /usr/bin/rescan-scsi-bus.sh -a -c -v

Tip: It is easier to check the system when the physical disks have different sizes. If the volumes are the same size, you can use the
worldwide name (WWN) of the volume that is shown in the IBM Cloud® UI. The WWN corresponds to the ID in the output of
the multipath -ll command.
For example, a storage volume with the name sapdata_vol has a WWN 3600507681081814CE80000000000054D . In the operating system
output of the multipath -ll command, the corresponding device name for this WWN is dm-4 . The device name is needed to create the
logical volume and the volume group.
$ multipath -ll
3600507681081814ce80000000000054d dm-4 IBM,2145
size=100G features=\'0\' hwhandler=\'1 alua\' wp=rwv

Note: The WWN in the IBM Cloud® UI contains uppercase letters. In the operating system, the same ID contains lowercase letters.
2. Use the following to identify disks by using disk sizes. The four storage volumes for SAP HANA data are 60 GB each. Multipath aliases are
used. Run the following command to create file system for /hana/data .
$ export pv_size=60G
export lv_name=hana_data_lv
export vg_name=hana_data_vg
export mount=/hana/data
# use following command if you USE multipath aliases
devices=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$3}' | tr '\n' ' ')
stripes=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$2}' | wc | awk '{print $1}')
pvcreate $devices
vgcreate ${vg_name} ${devices}
lvcreate -i${stripes} -I64 -l100%VG -n ${lv_name} ${vg_name}
mkfs.xfs /dev/mapper/${vg_name}-${lv_name}
mkdir -p ${mount}

3. The four storage volumes for SAP HANA log are 110 GB each. Multipath aliases are used. Run the following command to create
filesystem for /hana/log .
$ export pv_size=110G
export lv_name=hana_log_lv
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 285

export vg_name=hana_log_vg
export mount=/hana/log
# use following command if you USE multipath aliases
devices=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$3}' | tr '\n' ' ')
stripes=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$2}' | wc | awk '{print $1}')
pvcreate $devices
vgcreate ${vg_name} ${devices}
lvcreate -i${stripes} -I64 -l100%VG -n ${lv_name} ${vg_name}
mkfs.xfs /dev/mapper/${vg_name}-${lv_name}
mkdir -p ${mount}

4. One storage volume for SAP HANA shared is 400 GB. Multipath aliases are used. Run the following command to create file system for
/hana/shared .
$ export pv_size=400G
export lv_name=hana_shared_lv
export vg_name=hana_shared_vg
export mount=/hana/shared
# use following command if you USE multipath aliases
devices=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$3}' | tr '\n' ' ')
stripes=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$2}' | wc | awk '{print $1}')
pvcreate $devices
vgcreate ${vg_name} ${devices}
lvcreate -i${stripes} -I64 -l100%VG -n ${lv_name} ${vg_name}
mkfs.xfs /dev/mapper/${vg_name}-${lv_name}
mkdir -p ${mount}

If you don't use multipath aliases, replace the line (starting with devices=$( ) that is used to identify devices. Instead, use following line:
devices=$(multipath -ll | grep -B 1 $pv_size | grep dm- | awk '{print "/dev/"$2}' | tr '\n' ' ')

Creating file systems by using ansible automation
1. To create file systems by using ansible automation, download the ibm.power_linux_sap ansible-galaxy collection.
$ ansible-galaxy collection install ibm.power_linux_sap

Ansible role, powervs_fs_creation is used to create filesystem for SAP HANA, SAP NetWeaver or for SAP shared file systems instance. This
role performs the following tasks:
Creates file systems with user-defined stripe size by using ansible built-in LVM logical volumes modules.
Mounts the file systems on provided mount points
Adds an entry to /etc/fstab for automount on reboot.
2. To run this role, you can pass two types of variables. The first as a dictionary and other as a list. See the following example.
Example A. Data structure for disks_configuration as dictionary value example:
$ disks_configuration:
{
counts: [2,2,1],
names: [data,log,shared],
paths: [/hana/data,/hana/log,/hana/shared],
wwns:

[600507681082018bc8000000000057e4,600507681082018bc8000000000057e8,600507681082018bc8000000000057e5,600507681082018bc800000000
, 600507681082018bc8000000000057e7]
}

Example B. Data structure for disks_configuration as list value example:
$ disks_configuration: [
{
name: data,
path: /hana/data,
wwns: 600507681082018bc8000000000057e4,600507681082018bc8000000000057e8
},
{
name: log,
path: /hana/log,
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 286

wwns: 600507681082018bc8000000000057d9,600507681082018bc8000000000057ed7
},
{
name: shared,
path: /hana/shared,
wwns: 600507681082018bc8000000000057f1
}]

WWNs associated with disks that are passed as input parameters for running the ansible role.
3. To run this ansible playbook, run the following command after you update one of variable examples and store them in
the filesystem_creation_variables file.
For RedHat
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-rhel.yml -e @ filesystem_creation_variables

For SLES
$ ansible-playbook \--connection=local -i \"localhost,\" powervs-sles.yml -e @ filesystem_creation_variables

After successful execution, file systems that are required for HANA installations are available.

Preparing for SAP installation
Preparation for SAP installation is needed for SAP HANA and SAP NetWeaver and not required on Power Virtual Server instance for SAP shared
file systems.

Required additional Software Packages for SLES 15
Please install the insserv package before the SAP HANA installation:
$ zypper install insserv

Using saptune on SLES for SAP
Use the saptune tool to apply recommended operating system settings for SAP HANA or SAP NetWeaver on SUSE Linux® Enterprise Server. On
IBM Power Systems Virtual Servers, the same SUSE Linux® Enterprise Server image is used for SAP NetWeaver and SAP HANA.
The following workflow shows how you can use the saptune tool to apply the SAP solution to your server. For more information about saptune,
see SAP Note 1275776 - Linux: Preparing SLES for SAP environments .
1. Verify that the package status is current.
$ zypper info saptune

2. Verify that the saptune version is at least 3.
$ saptune version

3. List all available solutions. Numbered entries represent integrated SAP Notes for each of the solutions.
$ saptune solution list

4. Get an overview of saptune options.
$ saptune --help

5. Enable and start the saptune.service. This command also disables sapconf and tunes, which isn't used since saptune version 3.
$ saptune service takeover

6. Simulate the changes before you apply them. (optional)
For SAP HANA:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 287

$ saptune solution simulate HANA

For SAP NetWeaver:
$ saptune solution simulate NETWEAVER

7. Apply the saptune solution.
For SAP HANA:
$ saptune solution apply HANA

For SAP NetWeaver:
$ saptune solution apply NETWEAVER

8. Check the status of saptune with the following command.
$ saptune status

Configurig Red Hat Enterprise Linux with RHEL System Roles for SAP
RHEL System Roles for SAP are a collection of roles that are run by ansible to help you configure a RHEL system for the installation of SAP
HANA or SAP NetWeaver. Ansible files for SAP configuration are distributed and updated directly by Red Hat, so the executed tasks and
required parameters might vary depending on the version of rhel-system-roles-sap package. The RHEL image that is provided by IBM
includes the ansible execution engine, SAP-related system roles, and the ansible execution files. If you have the most recent updates, you
might get updated SAP-related system roles.
Note: Beginning with rhel-system-roles-sap-3.2.0-1.el8_4 , the role names changed. And files /root/sap-preconfigure.yml ,
/root/sap-netweaver.yml and /root/sap-hana.yml in the OS images with RHEL 8.1 and RHEL 8.4 must be adapted. For more

information, see following Red Hat article.

Previous role name

New role name

sap-preconfigure

sap_general_preconfigure

sap-netweaver-preconfigure

sap_netweaver_preconfigure

sap-hana-preconfigure

sap_hana_preconfigure
Table 9. RHEL System Roles

The execution files are in the root directory.
$ ls -ltr /root/
total 28
-rw\-\-\-\-\-\--. 1 root root 6777 Oct 29 2019 original-ks.cfg
-rw\-\-\-\-\-\--. 1 root root 7030 Oct 29 2019 anaconda-ks.cfg
-rw-r\--r\--. 1 root root 104 Jan 30 03:38 sap-netweaver.yml
-rw-r\--r\--. 1 root root 99 Jan 30 03:38 sap-hana.yml
-rw-r\--r\--. 1 root root 71 Jan 30 03:38 sap-preconfigure.yml

Use the following command to tune the operating system for the SAP HANA workload.
$ ansible-playbook /root/sap-hana.yml

2. Use the following command to tune the operating systemfor the SAP NetWeaver workload.
$ [root@rhel-84\]# ansible-playbook /root/sap-netweaver.yml

For more information about running tasks, see the following documentation.
SAP Note 2772999 "Red Hat Enterprise Linux 8.x: Installation and Configuration"
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 288

SAP Note 2777782 "SAP HANA DB: Recommended OS Settings for RHEL8"
SAP Note 2382421 "Optimizing the Network Configuration on HANA- and OS-Level"
Red Hat Enterprise Linux System Roles for SAP

Further Network Configurations on SLES
You must set jumbo frames( MTU='9000' ) and enable TSO on private networks that are used for communication between multiple instances in
the SAP three-tier system.
$ cd /etc/sysconfig/network
vi ifcfg-envX # choose correct name of tje ethernet device that is used for communication between SAP instances
(instead of envX)
BROADCAST=''
ETHTOOL_OPTS='-K ethX tso on ' # choose correct name of ethernet device used for communication between SAP instances
(instead of ethX)
BOOTPROTO='static'
IPADDR='xx.xx.xx.xx/xx'
NAME='Virtual Ethernet card 0' NETWORK=''
REMOTE_IPADDR=''
STARTMODE='auto'
USERCONTROL='no'
MTU='9000'

To activate the changes, restart your network ( ifdown ethX; ifup ethX ), or set the MTU for the current configuration by using

ip link set

dev <ethX> mtu 9000 .

Further Network Configurations on RHEL
You must set jumbo frames( MTU='9000' ) and enable TSO on private networks that are used for communication between multiple instances in
the SAP three-tier system.
$ cd /etc/sysconfig/network-scripts
vi ifcfg-envX # choose correct name of the ethernet device that is used for communication between SAP instances
(instead of envX)
BROADCAST=''
ETHTOOL_OPTS='-K envX tso on ' # choose correct name of ethernet device used for communication between SAP instances
(instead of envX)
config fileBOOTPROTO='static'
IPADDR='xx.xx.xx.xx/xx'
NAME='Virtual Ethernet card 0' NETWORK=''
REMOTE_IPADDR=''
STARTMODE='auto'
USERCONTROL='no'
MTU='9000'

To activate the changes, restart your network ( ifdown envX; nmcli con down 'System envX'; nmcli con up 'System envX' ), or set the
MTU for the current configuration (with ip link set dev <envX> mtu 9000 and ethtool -K <envX> tso on ).

NUMA layout
Check that the balance of CPU and memory placement is optimized for SAP HANA by running the

chk_numa_lpm.py script.

The chk_numa_lpm.py script does the following actions.
Checks the nonuniform memory access (NUMA) layout according to SAP HANA rules. The script verifies that no cores without memory
exist and that the memory distribution among the cores doesn't exceed a 50% margin. In the first case, the script generates an error; in
the latter case, the script generates a warning.
Checks whether a Live Partition Mobility (LPM) operation occurred. After LPM, the NUMA layout might differ from the configuration at
boot time. The script scans the system log for the last LPM. A warning is generated if an LPM operation occurred since the last system
boot.
1. Download the chk_numa_lpm.py script from the SAP Note 2923962. Then, run the chk_numa_lpm.py script on your newly
provisioned Power Virtual Server instance.
2. Run the script.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 289

$ ./chk_numa_lpm.py
WARNING: LPM might have occurred
ls
chk_numa_lpm.log chk_numa_lpm.py
cat chk_numa_lpm.log
### Check run on : 2020-09-10 09:37:21 #####
Hostname : ibmdmhan01
Partition UUID : 2e2fb3e5-ef18-48c6-819a-bd85bfefa953
WARNING: A possible Live Partition Migration (LPM) might have happened
after boot!
Date of latest started LPM : 2020-07-16 06:08:38
Date of latest boot : 2020-07-02 10:01:00
Numa Node : 0 Number of virt. CPUs : 32 Amount of memory : 255667 MB
Numa Node : 1 Number of virt. CPUs : 32 Amount of memory : 255738 MB

In this example, a warning is generated because two NUMA nodes with an equal amount of CPU and memory were created. For more
information, see SAP Note 2923962.

Next Steps
After the previous steps are completed, your infrastructure is ready to install the SAP software. Complete the following steps to install the SAP
software.
1. Install a Windows server in management or in workload VPCs and use it for SAP administration.
2. Move SAP installation binary files to NFS server in the virtual server instance that is running in workload VPC.
3. Log in through SSH and perform SAP installation by using the CLI on Power Virtual Server instances.
4. Log in with Windows server and perform SAP installation by using the SAP GUI on Power Virtual Server instances.
5. Create extra instances and extend the environment.
6. Create more instances on edge VPC and install internet-facing SAP applications such as SAP routed or SAP Web Dispatcher.
7. Install IBM Spectrum Protect as backup solution in workload VPC and configure IBM Spectrum Protect client on Power Virtual Server
instances.
8. Configure VPN in management VPC and deactivate floating IP address on the access host.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 290

Provisioning VMware SDDC for SAP HANA and SAP NetWeaver for SAP HANA and
SAP NetWeaver
Planning your deployment
Make sure that you are already familiar with the fundamental components and options that are provided by IBM Cloud Classic Infrastructure
for SAP. Before you start with the deployment of servers, make sure that you also read the Get Started section.
Intel Optane persistent memory (PMem) is available on the Bare Metal servers. You have three memory options for PMem on the Bare Metal
servers, 1.5 TB, 3.0 TB, and 6.0 TB. Which option you choose depends on the:
Application that you want to run, for example BW or BW/4 HANA.
SAP sizing, which determines the amount of memory and CPU that you need.
Network and storage configuration, disaster recovery, high availability, backups, and system replication are all configured and managed as part
of the Bare Metal provisioning and operation.

The 'Must-Reads' before you start deploying
To ensure that your first deployment is a success, review the information in Provisioning SAP HANA and SAP NetWeaver

Planning your

deployment

Other useful documents
See the respective topics in the Get Started section for the following information:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

Deploying your infrastructure
Before you begin
Determine the amount of memory that you need for your application.

Step 1: Provision your server
Order your Bare Metal SAP HANA server using the steps in Deploying your infrastructure. Select the profile for the amount of PMem that you
need for your application.

Step 2: Post-Provisioning Intel Optane PMem
After you order your Bare Metal server and the server is provisioned, you complete the provisioning by creating namespaces for your system.
PMem on Bare Metal supports the App Dir mode. In App Dir mode, PMem and DRAM DIMMs act as independent memory resources that are
directly accessed by the applications.
The App Dir mode uses regions, and namespaces to represent persistent memory devices in an interleaved set. A region represents the
physical persistent memory devices. A region is made up of one or more namespaces. A namespace represents a unit of storage that can be
used for input/output (I/O).
Regions are created as part of the provisioning process. You must create the namespaces, create mount points, and mount the PMem devices.
For more information about regions and namespaces, see Intel Optane Persistent Memory and SAP HANA Platform Configuration .
1. Log in to the Bare Metal server as root.
2. Download the current version of the zypper (for SLES) or yum (for RHEL).
3. Install the ndctl software for your system:
For SLES:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 291

$ zypper in ndctl
$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...
The following 2 NEW packages are going to be installed:
libndctl6 ndctl

For RHEL:
$ yum install ndctl
$ Refreshing service
'SMT-https_susesapsmtamr_service_networklayer_com'.
Loading repository data...
Reading installed packages...
Resolving package dependencies...

4. List the available regions for your system:
$ ndctl list -R -v
$

[
{
"dev":"region1",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":1,
"target_node":3,
"iset_id":-7847382400914477876,
"persistence_domain":"memory_controller"
},
{
"dev":"region0",
"size":1623497637888,
"available_size":1623497637888,
"max_available_extent":1623497637888,
"type":"pmem",
"numa_node":0,
"target_node":2,
"iset_id":9195364489516887244,
"persistence_domain":"memory_controller"
}

5. Create a namespace for each of your regions.
$ ndctl create-namespace -r region0
$

{
"dev":"namespace0.0",
"mode":"fsdax",
"map":"dev",
"size":"1488.37 GiB (1598.13 GB)",
"uuid":"75af4e28-1b99-4d34-a39a-a342a370232a",
"sector_size":512,
"align":2097152,
"blockdev":"pmem0"
}

Repeat this command for region1
6. Create an xfs on-top of the PMem devices:
$ mkfs -t xfs -f /dev/pmem0

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 292

$

meta-data=/dev/pmem0

isize=512

agcount=4, agsize=97542016 blks

=

sectsz=4096

attr=2, projid32bit=1

=

crc=1

finobt=1, sparse=0, rmapbt=0

=

reflink=0

=

bsize=4096

blocks=390168064, imaxpct=5

=

sunit=0

swidth=0 blks

=version 2

bsize=4096

ascii-ci=0, ftype=1

data
naming
log

=internal log

bsize=4096 blocks=190511, version=2

=
realtime =none

sectsz=4096

sunit=1 blks, lazy-count=1

extsz=4096

blocks=0, rtextents=0

Repeat this command for pmem1.
7. Mount the file system that you created by adding the following lines to /etc/fstab :
/dev/pmem0 /hana/pmem/nvmem0 xfs dax 0 0
/dev/pmem1 /hana/pmem/nvmem1 xfs dax 0 0
8. Create the path to the device.
$ mkdir -p /hana/pmem/nvmem0
$ mkdir -p /hana/pmem/nvmem1
$ mount -a
9. Verify the devices.
$ df -h | grep pmem
$

/dev/pmem0
/dev/pmem1

1.5T
1.5T

1.6G

1.6G

1.5T

1.5T

1% /hana/pmem/nvmem0
1% /hana/pmem/nvmem1

Moving existing SAP workloads on VMware to IBM Cloud for VMware
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Refer to overview table on #faq-moving-sap-workloads

Using VMware HCX for moving SAP workloads
Pre-requisites for VMware HCX Pre-requisites for moving SAP workload VMs using VMware HCX Using VMware vSphere Replication and
vMotion with SAP workloads

Using VMware vSphere Replication with SAP workloads
Using VMware vMotion with SAP workloads

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 293

Provisioning Red Hat OpenShift clusters for SAP Data Hub 2.x
Planning your deployment
Make sure that you are already familiar with the fundamental components and options that are provided by IBM Cloud Classic Infrastructure
for SAP. Before you start with the deployment of servers, make sure that you also read the Get Started section.
Intel Optane persistent memory (PMem) is available on the Bare Metal servers. You have three memory options for PMem on the Bare Metal
servers, 1.5 TB, 3.0 TB, and 6.0 TB. Which option you choose depends on the:
Application that you want to run, for example BW or BW/4 HANA.
SAP sizing, which determines the amount of memory and CPU that you need.
Network and storage configuration, disaster recovery, high availability, backups, and system replication are all configured and managed as part
of the Bare Metal provisioning and operation.

The 'Must-Reads' before you start deploying
To ensure that your first deployment is a success, review the information in Provisioning SAP HANA and SAP NetWeaver

Planning your

deployment

Other useful documents
See the respective topics in the Get Started section for the following information:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

Deploying your OpenShift cluster and jump host
This topic takes you through the steps for creating the Red Hat® OpenShift® on IBM Cloud® cluster and the associated jump host.

Before you begin
When you create the Red Hat OpenShift on IBM Cloud cluster, it is important that the flavor meets SAP's sizing recommendations and your
expected workload characteristics, as well as the expected data volumes. The following implementation scenario is based on Minimum Sizing
for SAP Data Intelligence and therefore is appropriate for a very basic test environment, only. When planning to setup and deploy a production
cluster you must carefully consult the Sizing Guide for SAP Data Intelligence and adapt the flavors that will meet your specific needs. Before
creating your cluster, please refer to the most recent SAP documentation, like Installation and Administration Guide. You may find more
related information in SAP's Community page.
Please check that your IBM Cloud account is eligible to create clusters. For more information and the steps to set up your account, see
Prepare to create clusters at the account level .

Provisioning your OpenShift cluster
Use the following steps to create your Red Hat OpenShift on IBM Cloud cluster. Again, the values used in this scenario are suggestions for a
test environment. Please, select additional optional values that will fit your specific needs.
Currently, IBM Cloud offers several Red Hat OpenShift on IBM Cloud versions, starting from 4.6.x up to 4.10.x.
Important: Please consider that SAP only supports Red Hat OpenShift on IBM Cloud version 4.8.x for SAP Data Intelligence 3.2

Tip: The Information button provides field-specific information on how to use a field.
1. Log in to IBM Cloud console and click Create cluster + .
2. Select your setup - Leave the value set to Manual Setup.
3. Select Classic for Infrastructure.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 294

4. Leave the value Default for Resource group.
5. Select the Geography and the Worker zone based on your geographic location and select Single zone for Availability.
6. Leave the default Private VLAN and Public VLAN settings that are based on your previous location selections.
Note: You can change these values if necessary, but make sure that your cluster, VLAN, and jump host are in the same worker
zone, i.e. data center.
7. Check you Worker pool and select at least 8 vCPUs, 32 GB RAM for Flavor and 3 Worker nodes per data center for the test environment.
8. Leave the values set to Worker pool name, Encrypt local disk and the Master service endpoint
9. Review the Orchestration service and Red Hat OpenShift on IBM Cloud version details and select Red Hat OpenShift on IBM Cloud
4.8.x.
Note: Please remember that SAP supports Red Hat OpenShift on IBM Cloud version 4.8.x only!
10. Check your OCP entitlement - Leave the value set to Purchase additional licenses for this worker pool .
11. Enter a Cluster name, for example sap-di32-cluster, and optionally Tags.
12. Check if you want to connect none, one or more of the available integrations, like Activity tracking, Logging and Monitoring
13. In the Summary pane on the left, review the order summary and then click Create.
For many more additional information on the fields, see Creating a classic standard cluster in the console .

Provisioning your jump host
The jump host's hardware and software requirements are 4 cores, 16 GB RAM, 20 GB disk space, OS: Red Hat 8.x. You can either use a
suitable jump server that is connected to the Red Hat OpenShift on IBM Cloud cluster in IBM Cloud, or you can use the following steps to
create an IBM® Virtual Servers instance to serve as your jump host.
1. Log in to IBM Cloud console and click Order +.
2. Select Virtual Servers for Classic.
3. Leave the default value Public for Type of virtual server .
4. Enter a name, for example jump4sdi, for Hostname. Click Information for formatting specifics.
5. Enter a name, for example, ocpsditest.org for Domain. Domain is the identification string that defines administrative control within the
internet. Click Information for formatting specifics.
6. Leave the default values 1, hourly and None for Quantity, Billing and Placement group.
7. Select the Location of the same data center (zone) where you set up your Red Hat OpenShift on IBM Cloud cluster.
8. Click View all profiles and select B1.4x16, which is the minimum requirement.
9. Provide your SSH key for SSH Keys or leave the default None. For more information on SSH keys, see About SSH keys .
10. Check your Operating System - Select Red Hat for Vendor and 8.x - Minimal (64 bit) - HVM for Version.
11. Leave the default values for all the other entry fields.
12. In the Summary pane on the left, check the Third-Party Service Agreements and click Create.
Your Red Hat OpenShift on IBM Cloud cluster and your virtual server should be available in about 15 minutes.

Preparing the jump host
Before setting up the Red Hat® OpenShift® on IBM Cloud® cluster on which SAP Data Intelligence will be deployed, you need to prepare your
jump host.
If you have created the jump server following the steps listed above, you first should update the operating system to the latest level, and then
restart the virtual server instance.
1. Update the OS
$ sudo dnf update

# press 'y' when prompted

2. reboot
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 295

$ sudo reboot

Before you begin
It is recommended that you become familiar with the Managing your IBM Cloud accounts. Your IBM Cloud user ID must at least have the
cluster Administrator role.

Install and verify the Command Line Interfaces (CLIs) for both, IBM Cloud and Red Hat OpenShift
on IBM Cloud
Use the following commands to download and install the CLIs you use to configure the connection between your Red Hat OpenShift on IBM
Cloud cluster and your jump host.
1. Login to the jump host and install the IBM Cloud CLI ibmcloud .
$ curl -fsSL https://clis.cloud.ibm.com/install/linux | sudo sh

For more information on IBM Cloud CLI, see Getting started with the IBM Cloud CLI .
2. Download and install the Red Hat OpenShift on IBM Cloud 4.8.x CLI oc and the related Kubernetes command line tool kubectl.
If not yet available, install wget.
$ sudo dnf install wget

Download the stable version Red Hat OpenShift on IBM Cloud 4.8.x CLI.
$ sudo wget https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/stable-4.8/openshift-clientlinux.tar.gz

Unpack the tar file that contains the Red Hat OpenShift on IBM Cloud client (oc) and the Kubernetes command line tool (kubectl).
$ tar -zxf openshift-client-linux.tar.gz

Set the executable attribute - if necessary.
$ $ chmod +x oc
$ chmod +x kubectl

Move both files to the local executables directory.
$ $ sudo mv oc /usr/local/bin
$ sudo mv kubectl /usr/local/bin

3. Verify the installation of the IBM Cloud CLI.
$ ibmcloud dev -v

Example output:
ibmcloud dev version 2.12.0

4. Verify oc.
$ oc version --client

Example output:
Client Version: 4.8.39

5. Verify kubectl.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 296

$ kubectl version --client

Example output:
Client Version: version.Info{Major:"1", Minor:"21", GitVersion:"v0.21.0-beta.1", ...

Install and verify Docker
1. Install Docker CLI emulator powered by podman.
$ sudo dnf install podman-docker

# press 'y' when prompted

Note: Docker daemon is no longer available on Red Hat 8.
2. Verify the Docker CLI emulator.
$ podman version

Example output:
Client:

Podman Engine

Version:

4.0.2

API Version:

4.0.2

Go Version:

go1.17.7

Built:

Tue Apr 19 05:16:32 2022

OS/Arch:

linux/amd64

Store your login credentials and create a working directory on your jump host
1. Log in to IBM Cloud for the first time.
Note: Refer to Configure your environment to learn more about the login command ibmcloud and the --sso parameter.

$ ibmcloud login [--sso]

# select the appropriate region, e.g. us-south

2. Create the API key file.
Create an IBM Cloud API key file. The command is:
ibmcloud iam api-key-create <APIKeyName> -d <description> --file <APIKeyFilename>

The API key file will be stored in your current directory.
$ $ ibmcloud iam api-key-create sdi-apikey-admin -d "API Key for managing the SAP Data Intelligence cluster" -file APIKey4sdi_file

3. Logout again after this initial step.
$ ibmcloud logout

4. Create a working directory
Choose a meaningful file path where you will copy the SAP installation files to and where you will launch the installer that will create log
files.
$ mkdir -p ~/sap/install

Creating a new Container Registry namespace.
1. Log in to IBM Cloud using the API key file that you have created during the previous step.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 297

The command is ibmcloud login --apikey @<APIKeyFilename> .
$ ibmcloud login --apikey @~/APIKey4sdi_file

2. Install the Red Hat® OpenShift® on IBM Cloud® Container Registry and the container services plug-ins.
$ $ ibmcloud plugin install container-registry
$ ibmcloud plugin install container-service

3. For this example, the namespace name is sap_di_cr , which is an acronym for SAP Data Intelligence - Container Registry - OpenShift.
$ $ ibmcloud cr login
$ ibmcloud cr namespace-add sap_di_cr

4. Verify that the namespace is created.
$ ibmcloud cr namespace-list

Accessing the Red Hat OpenShift on IBM Cloud cluster
After logging in to the jump host you must complete the following steps before you can work with your cluster.
1. Determine the cluster ID on which you want to install SAP Data Intelligence.
$ ibmcloud oc cluster ls

Name

ID

State

Created

Workers

...

sap-di32-cluster

bm****************kg

normal

1 days ago

3

...

...

2. Download the Kubernetes configuration files and certificates to connect the jump host to your cluster - copy the cluster name from the
previous step.
$ ibmcloud oc cluster config --admin --cluster sap-di32-cluster

3. Logout of IBM Cloud.
$ ibmcloud logout

You have created a Red Hat OpenShift on IBM Cloud cluster, prepared the jump host and are now ready to prepare and install SAP Data
Intelligence.

Next Step
Continue with Preparing and Installing SAP Data Intelligence .

Preparing and Installing SAP Data Hub
Deploying Red Hat's SAP Data Hub (SDH) Observer
Deploying the SAP Data Hub (SDH) Observer lets the SAP Data Hub installer and runtime components access images in the IBM Cloud®
Container Registry to provide the image pull secret for the project. In the Red Hat article, the project name is 'sdh'.
Note: The project's namespace and Container Registry names used in the following steps are the same as those used in previous
steps.
1. Copy the local pull image secret from the default area to the sdh project. For more information, see Copying an existing image pull
secret.
Note: The source secret should match your region, for example, 'de' for Central Europe. In this example, the source secret

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 298

default-de-icr-io is copied to sdh-de-icr-io .

Find your region.
$ ibmcloud cr api

The region code precedes the domain - in this example the domain is
Registry API endpoint

icr.io and the region code is de .

https://de.icr.io/api

The command line is: oc patch secret --dry-run -o yaml -n default <local_secret> -p '{"metadata":{"namespace": "
<project_name>"}}' | oc -n sdh create -f $ oc patch secret --dry-run -o yaml -n default default-de-icr-io -p '{"metadata": {"namespace": "sdh", "name":
"sdh-de-icr-io"}}' | oc -n sdh create -f -

2. Link the secret sdh-de-icr-io to the default service account’s pods.
$ oc secrets link -n sdh --for=pull default sdh-de-icr-io

3. Deploy the SAP Data Hub Observer in the sdh namespace.
Note: Review the Required Input Parameters to confirm the deployment instructions and the source URL are valid.

$ oc process -f https://raw.githubusercontent.com/redhat-sap/sap-datahub/master/sdh-observer.yaml \
BASE_IMAGE_TAG=v3.11 SDH_NAMESPACE=sdh MAKE_VSYSTEM_IPTABLES_PODS_PRIVILEGED=true NAMESPACE=sdh \
REGISTRY=de.icr.io/sdh_cr_os | oc create -f -

Preparing IBM Cloud IBM Cloud Object Storage for SAP Vora Checkpoint
For production environments, storage for the SAP Vora Checkpoint must be set up. Follow these instructions to set up IBM Cloud IBM Cloud
Object Storage and to define the parameters that will be handed over to the installation dialog.
For test and evaluation environments, you may skip this topic and go directly to the Manual Installation using an installation script (manual)
instructions, and the instructions for running the installation script for the IBM Cloud specific parameters.

Before you begin
Review Provision storage to provision your Object Storage.
$ The service instance name for the following example is `sdh_cos_k8`. Choose a name that fits your needs when creating
your service instance.
{: note}

Creating the bucket and the directory
1. Use the steps under Creating some buckets to store your data .
2. Choose Regional as your level of resiliency and select the same Location where your Red Hat OpenShift on IBM Cloud cluster is
deployed. For this example, the location is eu-de .
3. Select the Storage Class of Standard that will meet your performance needs.
Note: The bucket name in this example is sdh-cos-vora-bucket .
4. Create the directory by uploading an empty folder from your desktop to the bucket. In the console, navigate to your bucket. Select
Resource List > Storage > sdh_cos_k8 > sdh-cos-vora-bucket and click Upload.
5. Select the empty folder and name it checkpoints .
Note: The first time you upload, you may be required to install the free tool, Aspera Connect. Another option is to create the
directory by using the aws command line tool. Using this tool is not covered in this topic.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 299

Creating the service instance and credentials for accessing the bucket
1. Follow the steps under Service credentials to create the service credentials for accessing the bucket that is handed over to the SAP Data
Hub installation script. Make sure that you select the Writer role and click Include HMAC Credential.
Note: The credential name in this example is sdhOScred . Choose a name that fits your needs when creating your service
credentials.
After the service credentials have been created, click View credentials and note the values of access_key_id and
secret_access_key . See below for an example.
$

... "cos_hmac_keys": { "access_key_id": "383 cf3", "secret_access_key": "a24 ****************0f9" },
$
### Locating the Installation Dialog parameters {: #rhos-find-parameters}
During installation of SAP Data Hub, you're prompted to:
`Enable Vora checkpoint store? (yes/no)`.
If you're setting up a test environment, you can select **yes** or **no**. However, for a production environment,
select **yes**. You're next asked for the following parameters:
``` {: screen}
Please provide the following parameters for Vora's checkpoint store
Please enter type of shared storage (oss/s3/wasb/gcs/webhdfs):
Please enter S3 access key:
Please enter S3 secret access key:
Please enter S3 host (empty for default 'https://s3.amazonaws.com'):
Please enter S3 region you want to connect to (empty for default 'us-east-1'):
Please enter connection timeout in seconds (empty for default 180):
Please enter S3 bucket and directory (in the form my-bucket/directory):
Do you want to validate the checkpoint store? (yes/no)

1. Select s3 for type of shared storage . You can take advantage of Object Storage's compatibility with the S3 API.
2. Enter the access_key_id from the generation of the service credentials for the S3 access key.
3. Enter the secret_access_key from the generation of the service credentials for the S3 secret access key .
4. Use Endpoints and storage locations to find the S3 Host that matches the location where your bucket's created. In the example, it's
s3.eu-de.cloud-object-storage.appdomain.cloud . Leave S3 region blank. It's taken from the endpoint's URL, for example, eu-de .

Note: In a production environment, you should use the private endpoint.
5. Leave connection timeout in second blank. It will default to 180 seconds.
6. Enter the bucket and directory names you entered in Creating the bucket and the directory for S3 bucket and directory . In the example,
it's sdh-cos-vora-bucket/checkpoints .
7. Enter yes to validate the checkpoint store.

Running the installation shell script
We recommend manually installing the SAP Data Hub.

Before you begin
Follow the steps in the Red Hat article, section 4.5 Manual Installation using an installation script (manual) , to get the SAP Data Hub
Foundation image. Before you can unzip the SAP Data Hub Foundation image you must install unzip .
$ yum install unzip

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 300

The command line parameters provide IBM Cloud specific information for the SAP installation script. For the installation script, you need this
information from the previous tasks, the:
default storage provider
image registry, including the registry namespace and pull secret
domain to be used for the auto-generated certificates and the enablement of the Kaniko image builder.
Note: The default domain for Red Hat® OpenShift® on IBM Cloud® clusters on IBM Cloud is

<region>.containers.cloud.ibm.com .

You can see your region with the command oc project .
For more information about command-line parameters, see Command-Line Parameters of the SAP Data Hub Installer {. external}.

SAP Data Hub installation
1. Log in to the IBM Cloud® Container Registry.
$ ibmcloud cr login

2. Use the following command using parameters from previous steps. You will be entering your S-UserID and password.
$ ./install.sh --namespace sdh --registry de.icr.io/sdh_cr_os --pv-storage-class ibmc-block-bronze \
--cert-domain eu-de.containers.cloud.ibm.com --image-pull-secret sdh-de-icr-io --enable-kaniko yes

Note: The installation and the initialization of all pods may take a while to complete.

Provide the Modeler's Access Credentials for the IBM Cloud Container Registry
After installation has finished and the SAP Data Hub Launchpad is available, log in to SAP Data Hub, and provide the proper credentials for the
Modeler in System Management.
Use the following commands to provide the modeler's access credentials to the IBM Cloud® Container Registry.
1. Retrieve your user's API key that you have created during step 7a in Install the IBM Cloud and OpenShift client Command Line
Interfaces (CLI).
$ cat myAK4sdh_file
{
"name": "myAK4sdh",
"description": "This is your API Key for SAP Data Hub",
"apikey": "********************************************",
"createdAt": "2019-12-18T10:40+0000",
"locked": false,
"uuid": "ApiKey-********-****-****-****-************"
}
# copy the API key shown after "apikey".

2. Follow the instructions in Provide Access Credentials for a Password Protected Container Registry . Be sure to use the following
parameters, including pasting the copied API key into the password field.
$ cat >/tmp/vsystem-registry-secret.txt <<EOF
username: "iamapikey"
password: "********************************************"
EOF

Final Step
Testing your installation.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 301

Provisioning Red Hat OpenShift clusters for SAP Data Intelligence 3.x
Planning your SAP Data Intelligence deployment
Currently, SAP Data Intelligence 3.2 is available for Red Hat OpenShift Container Platform 4.8 in IBM Cloud. IBM Cloud manages the platform
for you; you select the size and number of worker nodes and the geographic locations of one or more data centers.
When planning your deployment, you set the flavor of your worker nodes within your Red Hat OpenShift on IBM Cloud on the IBM Cloud
cluster. Flavor describes the compute resources, such as number of CPUs or vCPUs, amount of memory, and disk capacity that you order when
provisioning your worker nodes. The total number of worker nodes in a cluster determines the compute capacity that is available to your apps
in the cluster. For more information, see Planning your worker node setup.

Red Hat OpenShift Cluster Network Connectivity
SAP Data Intelligence allows you to connect a wide range of systems and components, as long as the required network connectivity is in place.
To be sure the connections between systems and components meet the requirements, we strongly recommend to combine planning of the
SAP Data Intelligence network layout with planning the systems you want to connect. Planning both aspects jointly ensures that network
communication is possible for the required protocols (i.e. required firewall rules, DMZ setups, and so on).
For an enhanced security, we recommend using:
Properly encrypted communication for all channels, in particular leveraging transport layer security (TLS).
A common certificate authority (CA) that can be imported as a trusted source in the various components.
For more information, see the Administration Guide for SAP Data Intelligence .
For productive setups, we recommend preparing the required SSL certificates using the preferred tools. For non-productive setups, note that
the SAP Data Intelligence installer can generate self-signed certificates.

Red Hat OpenShift Cluster Storage
SAP Data Intelligence requires access to persistent storage that is attached to the OpenShift cluster. For importing, exporting, and checkpointing SAP Vora database tables, SAP Data Intelligence requires access to a persistent shared file system or an object store. In the IBM
Cloud environment, IBM Cloud Object Storage is utilized for that purpose.

Prerequisites
To be able to access the required installation binaries and authorizations to install SAP Data Intelligence
You need an SAP S-user ID and Download Authorization for login to the SAP ONE Support Launchpad .
You need a Red Hat account for login to the Red Hat Registry Service Accounts.

Next Step
Continue with Deploying your OpenShift cluster and jump host .

Deploying your OpenShift cluster and jump host
This topic takes you through the steps for creating the Red Hat® OpenShift® on IBM Cloud® cluster and the associated jump host.

Before you begin
When you create the Red Hat OpenShift on IBM Cloud cluster, it is important that the flavor meets SAP's sizing recommendations and your
expected workload characteristics, as well as the expected data volumes. The following implementation scenario is based on Minimum Sizing
for SAP Data Intelligence and therefore is appropriate for a very basic test environment, only. When planning to setup and deploy a production
cluster you must carefully consult the Sizing Guide for SAP Data Intelligence and adapt the flavors that will meet your specific needs. Before
creating your cluster, please refer to the most recent SAP documentation, like Installation and Administration Guide. You may find more
related information in SAP's Community page.
Please check that your IBM Cloud account is eligible to create clusters. For more information and the steps to set up your account, see
Prepare to create clusters at the account level .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 302

Provisioning your OpenShift cluster
Use the following steps to create your Red Hat OpenShift on IBM Cloud cluster. Again, the values used in this scenario are suggestions for a
test environment. Please, select additional optional values that will fit your specific needs.
Currently, IBM Cloud offers several Red Hat OpenShift on IBM Cloud versions, starting from 4.6.x up to 4.10.x.
Important: Please consider that SAP only supports Red Hat OpenShift on IBM Cloud version 4.8.x for SAP Data Intelligence 3.2

Tip: The Information button provides field-specific information on how to use a field.
1. Log in to IBM Cloud console and click Create cluster + .
2. Select your setup - Leave the value set to Manual Setup.
3. Select Classic for Infrastructure.
4. Leave the value Default for Resource group.
5. Select the Geography and the Worker zone based on your geographic location and select Single zone for Availability.
6. Leave the default Private VLAN and Public VLAN settings that are based on your previous location selections.
Note: You can change these values if necessary, but make sure that your cluster, VLAN, and jump host are in the same worker
zone, i.e. data center.
7. Check you Worker pool and select at least 8 vCPUs, 32 GB RAM for Flavor and 3 Worker nodes per data center for the test environment.
8. Leave the values set to Worker pool name, Encrypt local disk and the Master service endpoint
9. Review the Orchestration service and Red Hat OpenShift on IBM Cloud version details and select Red Hat OpenShift on IBM Cloud
4.8.x.
Note: Please remember that SAP supports Red Hat OpenShift on IBM Cloud version 4.8.x only!
10. Check your OCP entitlement - Leave the value set to Purchase additional licenses for this worker pool .
11. Enter a Cluster name, for example sap-di32-cluster, and optionally Tags.
12. Check if you want to connect none, one or more of the available integrations, like Activity tracking, Logging and Monitoring
13. In the Summary pane on the left, review the order summary and then click Create.
For many more additional information on the fields, see Creating a classic standard cluster in the console .

Provisioning your jump host
The jump host's hardware and software requirements are 4 cores, 16 GB RAM, 20 GB disk space, OS: Red Hat 8.x. You can either use a
suitable jump server that is connected to the Red Hat OpenShift on IBM Cloud cluster in IBM Cloud, or you can use the following steps to
create an IBM® Virtual Servers instance to serve as your jump host.
1. Log in to IBM Cloud console and click Order +.
2. Select Virtual Servers for Classic.
3. Leave the default value Public for Type of virtual server .
4. Enter a name, for example jump4sdi, for Hostname. Click Information for formatting specifics.
5. Enter a name, for example, ocpsditest.org for Domain. Domain is the identification string that defines administrative control within the
internet. Click Information for formatting specifics.
6. Leave the default values 1, hourly and None for Quantity, Billing and Placement group.
7. Select the Location of the same data center (zone) where you set up your Red Hat OpenShift on IBM Cloud cluster.
8. Click View all profiles and select B1.4x16, which is the minimum requirement.
9. Provide your SSH key for SSH Keys or leave the default None. For more information on SSH keys, see About SSH keys .
10. Check your Operating System - Select Red Hat for Vendor and 8.x - Minimal (64 bit) - HVM for Version.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 303

11. Leave the default values for all the other entry fields.
12. In the Summary pane on the left, check the Third-Party Service Agreements and click Create.
Your Red Hat OpenShift on IBM Cloud cluster and your virtual server should be available in about 15 minutes.

Preparing the jump host
Before setting up the Red Hat® OpenShift® on IBM Cloud® cluster on which SAP Data Intelligence will be deployed, you need to prepare your
jump host.
If you have created the jump server following the steps listed above, you first should update the operating system to the latest level, and then
restart the virtual server instance.
1. Update the OS
$ sudo dnf update

# press 'y' when prompted

2. reboot
$ sudo reboot

Before you begin
It is recommended that you become familiar with the Managing your IBM Cloud accounts. Your IBM Cloud user ID must at least have the
cluster Administrator role.

Install and verify the Command Line Interfaces (CLIs) for both, IBM Cloud and Red Hat OpenShift
on IBM Cloud
Use the following commands to download and install the CLIs you use to configure the connection between your Red Hat OpenShift on IBM
Cloud cluster and your jump host.
1. Login to the jump host and install the IBM Cloud CLI ibmcloud .
$ curl -fsSL https://clis.cloud.ibm.com/install/linux | sudo sh

For more information on IBM Cloud CLI, see Getting started with the IBM Cloud CLI .
2. Download and install the Red Hat OpenShift on IBM Cloud 4.8.x CLI oc and the related Kubernetes command line tool kubectl.
If not yet available, install wget.
$ sudo dnf install wget

Download the stable version Red Hat OpenShift on IBM Cloud 4.8.x CLI.
$ sudo wget https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/stable-4.8/openshift-clientlinux.tar.gz

Unpack the tar file that contains the Red Hat OpenShift on IBM Cloud client (oc) and the Kubernetes command line tool (kubectl).
$ tar -zxf openshift-client-linux.tar.gz

Set the executable attribute - if necessary.
$ $ chmod +x oc
$ chmod +x kubectl

Move both files to the local executables directory.
$ $ sudo mv oc /usr/local/bin
$ sudo mv kubectl /usr/local/bin

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 304

3. Verify the installation of the IBM Cloud CLI.
$ ibmcloud dev -v

Example output:
ibmcloud dev version 2.12.0

4. Verify oc.
$ oc version --client

Example output:
Client Version: 4.8.39

5. Verify kubectl.
$ kubectl version --client

Example output:
Client Version: version.Info{Major:"1", Minor:"21", GitVersion:"v0.21.0-beta.1", ...

Install and verify Docker
1. Install Docker CLI emulator powered by podman.
$ sudo dnf install podman-docker

# press 'y' when prompted

Note: Docker daemon is no longer available on Red Hat 8.
2. Verify the Docker CLI emulator.
$ podman version

Example output:
Client:

Podman Engine

Version:

4.0.2

API Version:

4.0.2

Go Version:

go1.17.7

Built:

Tue Apr 19 05:16:32 2022

OS/Arch:

linux/amd64

Store your login credentials and create a working directory on your jump host
1. Log in to IBM Cloud for the first time.
Note: Refer to Configure your environment to learn more about the login command ibmcloud and the --sso parameter.

$ ibmcloud login [--sso]

# select the appropriate region, e.g. us-south

2. Create the API key file.
Create an IBM Cloud API key file. The command is:
ibmcloud iam api-key-create <APIKeyName> -d <description> --file <APIKeyFilename>

The API key file will be stored in your current directory.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 305

$ $ ibmcloud iam api-key-create sdi-apikey-admin -d "API Key for managing the SAP Data Intelligence cluster" -file APIKey4sdi_file

3. Logout again after this initial step.
$ ibmcloud logout

4. Create a working directory
Choose a meaningful file path where you will copy the SAP installation files to and where you will launch the installer that will create log
files.
$ mkdir -p ~/sap/install

Creating a new Container Registry namespace.
1. Log in to IBM Cloud using the API key file that you have created during the previous step.
The command is ibmcloud login --apikey @<APIKeyFilename> .
$ ibmcloud login --apikey @~/APIKey4sdi_file

2. Install the Red Hat® OpenShift® on IBM Cloud® Container Registry and the container services plug-ins.
$ $ ibmcloud plugin install container-registry
$ ibmcloud plugin install container-service

3. For this example, the namespace name is sap_di_cr , which is an acronym for SAP Data Intelligence - Container Registry - OpenShift.
$ $ ibmcloud cr login
$ ibmcloud cr namespace-add sap_di_cr

4. Verify that the namespace is created.
$ ibmcloud cr namespace-list

Accessing the Red Hat OpenShift on IBM Cloud cluster
After logging in to the jump host you must complete the following steps before you can work with your cluster.
1. Determine the cluster ID on which you want to install SAP Data Intelligence.
$ ibmcloud oc cluster ls

Name

ID

State

Created

Workers

...

sap-di32-cluster

bm****************kg

normal

1 days ago

3

...

...

2. Download the Kubernetes configuration files and certificates to connect the jump host to your cluster - copy the cluster name from the
previous step.
$ ibmcloud oc cluster config --admin --cluster sap-di32-cluster

3. Logout of IBM Cloud.
$ ibmcloud logout

You have created a Red Hat OpenShift on IBM Cloud cluster, prepared the jump host and are now ready to prepare and install SAP Data
Intelligence.

Next Step
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 306

Continue with Preparing and Installing SAP Data Intelligence .

Preparing and Installing SAP Data Intelligence
In the previous chapter we have created Red Hat OpenShift on IBM Cloud cluster and prepared the jump host. The next steps cater to the
preparation of the cluster to be ready for the SAP Data Intelligence installation.
The instructions for implementing SAP Data Intelligence on the Red Hat OpenShift on IBM Cloud cluster follow the Red hat article (RHA)

SAP

Data Intelligence 3 on OpenShift Container Platform 4 starting from 3.3. OCP Post Installation Steps , because in this scenario Red Hat
OpenShift on IBM Cloud 4.8.x already has been provisioned.

Setting the sdi role for the worker nodes for SAP Data Intelligence
According to section 3.3.4.1. Label the compute nodes for SAP Data Intelligence in the RHA, set the sdi role for the worker nodes that will be
considered by Red Hat's SDI observer. See below the parameter SDI_NODE_SELECTOR in the SDI observers's installation script.
1. Determine the nodes names.
$ oc get nodes

Example output:
NAME

STATUS

ROLES

AGE

VERSION

10.**********.177

Ready

master,worker

1d

v1.21.8+ed4d8fd

10.**********.182

Ready

master,worker

1d

v1.21.8+ed4d8fd

10.**********.185

Ready

master,worker

1d

v1.21.8+ed4d8fd

2. Set the nodes' role.
$ $ oc label node/10.**********.177 node-role.kubernetes.io/sdi=""
$ oc label node/10.**********.182 node-role.kubernetes.io/sdi=""
$ oc label node/10.**********.185 node-role.kubernetes.io/sdi=""

3. Check the nodes.
$ oc get nodes

Example output:
NAME

STATUS

ROLES

AGE

VERSION

10.**********.177

Ready

master,sdi,worker

1d

v1.21.8+ed4d8fd

10.**********.182

Ready

master,sdi,worker

1d

v1.21.8+ed4d8fd

10.**********.185

Ready

master,sdi,worker

1d

v1.21.8+ed4d8fd

Note that the sdi role has been added.

Creating the related projects
For deployment of SAP applications in cloud-based environments, SAP provides the Software Lifecycle Container Bridge 1.0 tool with the
Maintenance Planner. In the following, we use the abbreviated tool name “SLC Bridge”. Find more information on SAP's SLC Bridge here . Red
Hat's SAP Data Intelligence (SDI) Observer, SLC Bridge and SDI runtime components require separate projects/namespaces for the related
pods that will be deployed.
In the RHA, the sample project names (i.e. namespaces) are sdi , sdi-observer and sap-slcbridge . Following these naming conventions
of the Red Hat article, create the related projects as follows.
1. Create the projects
$ $ oc new-project sdi-observer
$ oc new-project sap-slcbridge
$ oc new-project sdi

Deploying Red Hat's SAP Data Intelligence (SDI) Observer
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 307

SAP Data Intelligence (SDI) Observer monitors SDI and SLC Bridge namespaces and applies changes to SDI deployments to allow SDI to run on
OpenShift.
Note: The projects' namespaces and Container Registry names used in the following steps are the same as those used in previous
steps.
1. SDI Observer needs a secret with credentials for registry.redhat.io
Follow the section 4.2.1. Prerequisites for Connected OpenShift Cluster in the RHA and save your rht-registry-secret.yaml in the
~/sap/install directory. This yaml file will be required to automatically set the respective parameters below.
2. Get information about Red Hat's SDI Observer installation script.
Review the section 4.2.3. Instantiation of Observer's Template in the RHA to confirm the deployment instructions and the source URL
are valid.
3. Download the installation script.
$ curl -O https://raw.githubusercontent.com/redhat-sap/sap-data-intelligence/master/observer/run-observertemplate.sh

4. Edit the downloaded script file in your favorite editor; especially, mind the following parameters:
$ FLAVOUR=ubi-build
REDHAT_REGISTRY_SECRET_PATH="$HOME/sap/install/rht-registry-secret.yaml"
NAMESPACE=sdi-observer
SDI_NAMESPACE=sdi
SLCB_NAMESPACE=sap-slcbridge
SDI_NODE_SELECTOR="node-role.kubernetes.io/sdi="

5. Save the script.
6. Deploy the SAP Data Intelligence Observer in the sdi namespace - i.e. run the script using bash.
$ bash ./run-observer-template.sh

In chapter 4.3 Managing SDI Observer of the RHA you will learn how you can review and update SDI Observer's current configuration.
7. Get information about Red Hat's SDI node-configurator
The worker nodes need be configured to grant proper execution of SAP Data Intelligence - see also the documentation at

Red Hat's SDI Node

Configurator on GitHub.
1. First set security context constraints to the sdi-node-configurator service account:
$ oc adm policy add-scc-to-user -n sdi-observer privileged -z sdi-node-configurator

2. Copy the template from GitHub:
$ curl -O https://raw.githubusercontent.com/redhat-sap/sap-data-intelligence/master/node-configurator/ocptemplate.json

3. Create the objects directly from the downloaded template.
$ oc process NAMESPACE=sdi-observer -f ./ocp-template.json | oc create -f -

Preparing IBM Cloud Object Storage for SAP Data Intelligence
For production environments, storage for backup&restore as well as Semantic Data Lake (SDL) Connections must be set up. Follow these
instructions to set up IBM Cloud Object Storage and to define the parameters that will be handed over to the installation dialog.
For ad hoc small term test and evaluation environments, you may skip this topic and go directly to the

Installing the Software Lifecycle

Container Bridge (SLCB) section.

Before you begin
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 308

Review Provision storage to provision your Object Storage.
Note: The service instance name for the following example is sdi_cos_k8 . Choose a name that fits your needs when creating your
service instance.

Creating the bucket and the directory
1. Use the steps under Creating some buckets to store your data .
2. Choose Regional as your level of resiliency and select the same Location where your Red Hat OpenShift on IBM Cloud cluster is
deployed. For this example, the location is eu-de .
3. Select the Storage Class of Standard that will meet your performance needs.
Note: The bucket name in this example is sdi-cos-bucket .
4. Create the directory by uploading an empty folder from your desktop to the bucket. In the console, navigate to your bucket. Select
Resource List > Storage > sdi_cos_k8 > sdi-cos-bucket and click Upload.
5. Select the empty folder and name it checkpoints .
Note: The first time you upload, you may be required to install the free tool, Aspera Connect. Another option is to create the
directory by using an S3 bucket compatible tool. Using such tool is not covered in this topic.

Creating the service instance and credentials for accessing the bucket
1. Follow the steps under Service credentials to create the service credentials for accessing the bucket that is handed over to the SAP Data
Intelligence installation script. Make sure that you select the Writer role and click Include HMAC Credential.
Note: The credential name in this example is sdiOScred . Choose a name that fits your needs when creating your service
credentials.
2. After the service credentials have been created, click View credentials and note the values of access_key_id and
secret_access_key . You will need them during the SDI installation dialog later. See below for an example.
$ ...
"cos_hmac_keys": {
"access_key_id": "383**************************cf3",
"secret_access_key": "a24******************************************0f9"
},

3. Use Endpoints and storage locations to find the S3 Host that matches the location where your bucket's created. In the example, it's
s3.eu-de.cloud-object-storage.appdomain.cloud .

Note: In a production environment, you should use the private endpoint.

Installing the Software Lifecycle Container Bridge (SLCB)
Go directly to the (RHA) 5.1 Install Software Lifecycle Container Bridge (SLCB) instructions, and see the next section to learn the specific
parameters for IBM Cloud.
You need to copy the downloaded SLCB exectuable ( SLCB01_##-70003322.EXE ) to your working directory $HOME/sap/install and rename
it to slcb . Note that ## will be the current version number.

Locating the Installation Dialog parameters for SLCB
Note: In order to run SLCB for your SAP DI installation, several parameters need to be supplied. One of these parameters is the
address of the Container Image Repository . You can take advantage of the Red Hat® OpenShift® on IBM Cloud® Container Registry. The
address consists of the endpoint URL for the registry and the namespace that you have created during the setup of the jump host,
sap_di_cr - see: Creating a new Container Registry namespace .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 309

1. To find the endpoint URL of the registry that you are currently targeting, run the

ibmcloud cr api command.

$ ibmcloud cr api

Example output:
Registry API endpoint

https://de.icr.io/api

2. In this example the domain is icr.io .
3. The region code precedes the domain - here it is de .
4. Finally, the address of the Container Image Repository here is de.icr.io/sap_di_cr .
5. Run the SLCB installation process:
$ ./slcb init

During installation of the SLCB, you're prompted to enter following parameters:
Parameter

Value

Address of the Container Image Repo:

de.icr.io/sap_di_cr

S-User Name:

Sxxxxxxxxxx

S-User Password:

xxxxxxxx

New Technical User - xxxxx-#custnr#:

tUser

Path to the "kubeconfig" file:

~/.kube/config

Expert mode:

2

Kubernetes namespace for the SLC Bridge:

sap-slcbridge

name of the admin user for the SLCB Base:

admin

password of the administrator user admin:

xxxxxxx IMPORTANT: regard the password constraints below

NodePort:

2

Proxy Settings:

no

noFeedback:

3

Password constraints:
It must at least consist of 8 characters
It must contain at least one lower case, one upper case, one numerical and one special character
The allowed special characters are . @ # $ % * + _ ? ! You need to note the hostname and port of the SLCB service by following commands:
get the fully qualified hostname that you will need later
$ ibmcloud oc cluster get -c rv-sap-di-cl | grep -i subdomain

get the port number >PORT> that you will need later
$ oc get svc -n sap-slcbridge slcbridgebase-service -o jsonpath=$'{.spec.ports[0].nodePort}\n'

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 310

This URL will be required later to launch the SDI installation - https://HOSTNAME:PORT/docs/index.html.

SAP Data Intelligence installation via running the SAP Maintenance Planner
Review SAP documentation about the installation setup - Install SAP Data Intelligence with SLC Bridge .
Before installing SAP Data Intelligence you need to review the Red Hat article and do these steps:
(RHA) 5.3. Project setup
As described there execute all oc adm policy add-scc-to-* commands and then start the SAP Maintenance Planner.
Launch SAP Maintenance Planner (MP) in a browser and click Plan a New System .
1. Click Plan
2. Select CONTAINER BASED
3. Select SAP DATA INTELLIGENCE
4. Select SAP DATA INTELLIGENCE 3
5. Select 3.2 11/2021 from the drop-down box
6. Check DI - Platform full
7. Click Confirm Selection then Next
8. Select Linux on x86_64 64bit
9. Click Confirm Selection then Next
10. Click Execute Plan
11. Fill HOSTNAME that you found above into entry field Fully Qualified Domain Name
12. Fill PORT that you found above into entry field Port
13. Click Next
Important: Before you click Deploy you must enter your previously found URL https://HOSTNAME:PORT/docs/index.html into a
browser and login with your SLCB admin user credentials that you have provided during the ./slcb init installation process.
1. After successfull login, click Deploy then Next
Now, select the link in the tools column which will launch SAP Intelligence installer in a separate browser window. During installation of SAP
Data Intelligence, you're prompted to provide the following parameters:
Parameter

Value

When the installer is called for the first time it will download SLCB images
from SAP and therefore prompt you for your credentials
S-User Name:

Sxxxxxxxx

S-User Password:

xxxxxxxx

Then you will select Install and DI Platform Full and click Next two times
Kubernetes Namespace:

sdi

Installation Type:

advanced

Restore from Backup:

no

Address of the Container Image Repository:

de.icr.io/sdi_cr_os

Eventually you will need to enter your S-User credentials again
S-User Name:

Sxxxxxxxx

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 311

S-User Password:

xxxxxxxx

SAP DI System Tenant Administrator Password:

xxxxxxxx (you have specified this password before)

SAP DI Initial Tenant Name:

default

SAP DI Initial Tenant Administrator Username:

default-adm

Specify a password for "default" user of "default" tenant:

xxxxxxx

proxy

no

backup

confirm that SAP Note 2918288 is read

backup, restore and vora storage:

s3 compatible

Access Key:

xxxxxxxxxxxxxxxxxxxxxx (see above)

Secret Access Key:

xxxxxxxxxxxxxxxxxxxxxxx (see above)

Endpoint:

https://s3.direct.eu-de.cloud-objectstorage.appdomain.cloud

S3 bucket and directory:

sdi-cos-bucket/checkpoints

timeout for checkpoint store:

180

checkpoint store validation:

yes

disable checksum

yes

disable certificate validation

yes

Backup Schedule (Cron Expression):

0 0 * * * (daily at midnight)

want to configure storage classes for ReadWriteOnce PersistentVolumes

yes

define default storage class

ibmc-block-bronze

Default Storage Class:

ibmc-block-bronze

System Management Storage Class:

ibmc-block-bronze

Dlog Storage Class:

ibmc-block-bronze

Disk Storage Class:

ibmc-block-bronze

SAP HANA Storage Class:

ibmc-block-bronze

SAP Data Intelligence Diagnostics Storage Class:

ibmc-block-bronze

different log path:

no

Kaniko:

yes

different registry:

no

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 312

load NFS:

no

network policies:

no

timeout:

3600

Additional parameters:

-e hana.memoryRequest=7Gi -e
storageGateway.replicas=2 -e
vsystem.vRep.exportsMask=true

Cluster Name:

sap-di32-cluster

S-User Name:

Sxxxxxxxx

S-User Password:

xxxxxxxx

Note: The installation and the initialization of all pods may take a while to complete.
1. You may want to watch how the pods get initialized and start running
$ watch oc get -n sdi pods -o wide

Final Step
Testing your installation.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 313

Automating and deploying IBM Cloud architectures for SAP by using Terraform
Terraform deployment templates
IBM provides several templates with scripts to deploy different SAP NetWeaver and SAP HANA architectures:
Deploying SAP bastion server – SAP media storage repository
Deploying single-tier VPC for SAP on IBM Cloud VPC (Terraform)
Deploying SAP AnyDB (non-SAP HANA) 2-tier and 3-tier distributed architecture on IBM Cloud VPC (Terraform)
SAP NetWeaver and Db2 single-tier on IBM Cloud VPC
Overview SAP workload deployment on IBM Cloud® Virtual Private Cloud (VPC) (Terraform and Ansible)
Deploying SAP NetWeaver 7.x and Db2 on an existing IBM Cloud VPC (Terraform and Ansible)
SAP NetWeaver and Db2 3-tier on IBM Cloud VPC
Overview SAP workload deployment on IBM Cloud Virtual Private Cloud (VPC) (Terraform and Ansible)
Deploying SAP NetWeaver 7.x and Db2 on 3-tier IBM Cloud VPC (Terraform and Ansible)
SAP HANA stand-alone VSI on IBM Cloud VPC
Background for automating SAP HANA stand-alone virtual server instance on IBM Cloud VPC
Deploying SAP HANA stand-alone virtual server instance on IBM Cloud VPC (Terraform)
SAP NetWeaver and ASE SYB on IBM Cloud VPC
Introduction to SAP NetWeaver and ASE SYB
Deploying SAP NetWeaver 7.x and ASE SYB on an existing IBM Cloud VPC (Terraform and Ansible)
SAP AAS for SAP HANA and AnyDB on IBM Cloud VPC
Introduction to IBM Cloud VPC and Additional Application Server (AAS) to HANA and AnyDB
Deploying Additional Application Server (AAS) to SAP HANA and AnyDB on an existing IBM Cloud VPC (Terraform)
SAP S/4HANA HA deployment on IBM Cloud VPC
Overview for deploying SAP workload HA deployment on IBM Cloud Virtual Private Cloud (VPC) (Terraform and Ansible)
Deploying SAP workload S/4HANA HA deployment on IBM Cloud VPC (Terraform and Ansible)
SAP HANA DB backup to Cloud Object Storage
Introduction to IBM Cloud VPC and HANA db backup automation on Cloud Object Storage
Deploying SAP HANA db backup to Cloud Object Storage on existing IBM Cloud VPC (Terraform)
Deploying SAP S/4HANA on 3-tier IBM Cloud VPC (Terraform and Ansible)
SAP BW/4HANA 3-tier on IBM Cloud VPC
Overview SAP workload deployment on IBM Cloud Virtual Private Cloud (VPC) with Terraform and Ansible
Deploying SAP BW/4HANA on 3-tier IBM Cloud VPC (Terraform and Ansible)
Deploying SAP NetWeaver 7.x and SAP HANA 3-tier distributed architecture on IBM Cloud VPC (Terraform and Ansible)

Deploying the SAP bastion server – SAP media storage repository
This task describes how to do an automated deployment of SAP bastion and storage setup on top of Red Hat Enterprise Linux 8.4. It shows how
to deploy an IBM Cloud Virtual Private Cloud (VPC) with a bastion host with secure remote SSH access. In SAP Terraform and Ansible
deployments, the bastion host is used to give external administrative access to the other servers and applications. The bastion server is
accessed through the Floating IP. The bastion server includes a customizable security group and subnet to enable access to the same region
zones on its dedicated SAP/DBs and the VSI's IPs and ports. The Floating IP also allows the bastion host access to the internet so the sap and
DB kits can be downloaded.
Before you decide which SAP automated solution you want to deploy in IBM Cloud VPC, run the bastion server automated deployment. You
need to specify the amount of dedicated storage that is needed to download and store the SAP kits. The SAP kits are used to deploy wanted
SAP solution from the IBM Cloud VPC automated SAP solutions pool. The bastion server in IBM Cloud is primarily used for SAP solution
deployment. It can be used as a Jump Host, for example, to maintain and administer all SAP solutions within its respective IBM Cloud VPC
region.
Each customer is given an SAP S-user that reflects their contractual details with SAP, including:
SAP support
SAP Notes
System maintenance

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 314

Generate and maintain SAP and DB licenses
Migrations keys
It is the customer's responsibility to download and prepare the necessary SAP kits from SAP launchpad support and store them on the
dedicated and customizable storage. The SAP kits are used during automated deployment when Ansible is called.

Solution implemented
The Bastion server is used for remote software installation by using Terraform remote-exec and Ansible playbooks that are run by Schematics.

Figure 1. Standard Bastion within a VPC region with 3 zones

The Terraform modules implement a 'reasonable' set of best practices for bastion host configuration only. Your own Organization might have
more requirements that you must apply before the deployment.
It contains:
Terraform scripts for deploying a VPC, Subnet, Security Group with rules, a volume, and a VSI.
Bash scripts to install the prerequisites for SAP BASTION&STORAGE VSI and other SAP solutions.

VPC Configuration
The Security Rules are:
Allow all traffic in the Security group
Allow all outbound traffic
Allow inbound DNS traffic (UDP port 53)
Allow inbound SSH traffic (TCP port 22)
Option to Allow inbound TCP traffic with a custom port or a range of ports.

VSI Configuration
The VSI is configured with Red Hat Enterprise Linux 8.4 (amd64), has a minimal of two SSH keys that are configured to be accessed by the root
user and one storage volume.

Software configuration
Terraform - an open source infrastructure as code software tool created by HashiCorp
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 315

Ansible - an open source software provisioning and configuration management tool.
The IBM Cloud Command Line Interface provides commands for managing resources in IBM Cloud.

Bastion input variables
Parameter

Description

ibmcloud_api_key

IBM Cloud API key (Sensitive* value).

private_ssh_key

The id_rsa private key content from your local machine (Sensitive* value).

REGION

The cloud region where to deploy the resources. For more information about regions and
zones for VPC, see Locations. Review the supported locations in IBM Cloud Schematics that
are listed in Locations and endpoints. Sample value: eu-de.

ZONE

The cloud zone where to deploy the solution. Sample value: eu-de-2.

VPC_EXISTS

Specify whether the chosen VPC exists (enter 'yes' or 'no'). If you choose 'no', the VPC is
created.

SUBNET_EXISTS

Specify whether the chosen SUBNET/SECURITYGROUP exist (use 'yes' or 'no'). If you choose
'no', a SUBNET/SECURITYGROUP with OPEN PORTS is created in the specified VPC.

ADD_OPEN_PORTS_IN_NEW_SUBNET

Create new port/s only if a NEW SUBNET is created, use 'yes' or 'no'.

OPEN_PORT_MINIMUM (Required,
Integer)

The TCP port range that includes the minimum value. Valid values are 1 - 65535.

OPEN_PORT_MAXIMUM (Required,
Integer)

The TCP port range that includes the maximum value. Valid values are 1 - 65535.

VPC

The name of the VPC. View the list of available VPCs on the IBM Cloud Console
clouds page.

SUBNET

The name of the Subnet. View the list of available Subnets on the IBM Cloud Console
[Subnets] ( https://cloud.ibm.com/vpc-ext/network/subnets) page.

SECURITYGROUP

The name of the Security Group. View the list of available Security Groups on the IBM Cloud
Console Security groups for VPC page .

HOSTNAME

The hostname for the VSI. The hostname must have up to 13 characters.

PROFILE

The profile used for the VSI. For more information about profiles, see Instance profiles.
Default value: "bx2-2x8".

IMAGE

The OS image used for the VSI. For more information about available images, see Virtual
server images. Default value: ibm-redhat-8-4-minimal-amd64-1.

SSH_KEYS

List of SSH Keys IDs that are allowed to SSH as root to the VSI. Can contain one or more IDs.
View the list of available SSH Keys on the IBM Cloud Console SSH keys for VPC page. Sample
input (use your own SSH IDs from IIBM Cloud): [ "r010-57bfc315-f9e5-46bf-bf61d87a24a9ce7a", "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ]

VOL1 [ number ]

The size for the disk in GB to be attached to the BASTION VSI as storage for the SAP
deployment kits. The mount point for the new volume is: "/storage". Default value: 100 GB.

Virtual private

Sensitive* - The variable value is not displayed in your workspace details after it is stored. Make sure to select Sensitive on the Settings page
for all fields marked "Sensitive".
Note: VOL1 [ number ] variable represents the defined customer size of the storage that is needed to store downloaded SAP kits before

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 316

you run the automated SAP deployment. The storage size can be customized when you deploy the bastion SAP VPC and VSI. Default
storage that is allocated is 100 Gb.

Before you begin
1. To complete this procedure, you need a general understanding of IBM Cloud VPC and VSIs. To run the example in IBM Cloud
Schematics, you need an IBM Cloud account. The deployed resources are chargeable.
2. Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
3. Be sure that you have the required IBM Cloud IAM permissions to create and work with VPC infrastructure and you are assigned the
correct permissions to create the workspace and deploy resources.
4. Generate an SSH key. The SSH key is required to access the provisioned VPC virtual server instances through the bastion host. After you
create your SSH key, make sure to upload this SSH key to your IBM Cloud account in the VPC region and resource group where you want
to deploy the bastion server.
5. Verify that you can access the URL used for this solution Automation script for SAP solutions using a BASTION & STORAGE setup
deployment through Terraform and IBM Schematics.

Procedure
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the URL of bastion setup folder.
Select the Terraform version.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your API key
Your private SSH key from your local machine
The ID for the SSH key that you created and uploaded to IBM Cloud
The Region for your resources
The Zone for your resources
Whether to use an existing VPC or create one
Whether to use an existing subnet
Whether to create new port only when a new subnet is created
TCP port range, nimimun and maximum
VPC name
Subnet name
Security group name
Hostname
Profile
Image
Minimal recommended disk sizes.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 317

Click Save changes.
7. On the workspace Settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.
11. At the end of the log is information that you need to deploy different SAP products and databases. Copy and save this information for your
deployments. For example:
$ 2022/08/17 10:30:11 Terraform apply | FLOATING-IP = "xxx.xxx.xxx.xx"
2022/08/17 10:30:11 Terraform apply | HOSTNAME = "myhost"
2022/08/17 10:30:11 Terraform apply | PRIVATE-IP = "xx.xxx.xx.x"
2022/08/17 10:30:11 Terraform apply | REGION = "eu-gb"
2022/08/17 10:30:11 Terraform apply | SECURITY_GROUP = "secgrp-myhost"
2022/08/17 10:30:11 Terraform apply | SUBNET = "myvpc-subnet"
2022/08/17 10:30:11 Terraform apply | VPC = "myvpc"
2022/08/17 10:30:11 Terraform apply | ZONE = "eu-gb-1"

Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Creating single-tier VPC for SAP on IBM Cloud® VPC with Terraform
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud VPC infrastructure resources so that you can rapidly
build complex, cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware using Intel® Xeon CPUs and additional
Intel® technologies.
For more information about Terraform on IBM Cloud®, see Terraform on IBM Cloud getting started tutorial .
To create resources with Terraform, you use Terraform configuration files that describe the IBM Cloud resources that you need and how you
want to configure them. Based on your configuration, Terraform creates an execution plan and describes the actions that need to be run to
create the resources. You can review the execution plan, change it, or run the plan. When you change your configuration, Terraform on IBM
Cloud can determine what changed and create incremental execution plans that you can apply to your existing IBM Cloud resources.

Script files
The configuration and script files are provided on the GitHub repository https://github.com/IBM-Cloud/sap-infra-anydb-single/tree/main/cli.
For single-tier virtual private cloud on SAP, you modify the:
terraform.tfvars file to add your IBM Cloud API-key
input.auto.tfvars file to customize the resources for your solution. You specify zones, resource names, and SSH keys.

All of the other configuration files are provided and do not need to be modified.
The IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files to provision a VPC in your IBM Cloud account.

What is created
A VPC is a private space in IBM Cloud where you can run an isolated environment with custom network policies. The variables that you define
are used by the scripts to provision the following virtual private cloud infrastructure resources for you:
1 VPC where you provision your virtual server instance
1 security group and rules for this security group to allow DNS and SSH connections to your virtual server instance and all outbound
traffic
1 subnet to enable networking in your VPC
1 virtual server instance
2 storage volumes, 1 for swap and 1 for data
1 floating IP address that you use to access your VPC virtual server instance over the public network

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 318

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, re-adapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your permissions
for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.

Procedure
Use these steps to configure the IBM Cloud Provider Plug-in and use Terraform to create a VPC for SAP.
1. If you do not have Terraform installed, Install the Terraform CLI and the IBM Cloud Provider plug-in .
If you are using Terraform 0.13 and higher, you do not need to install the IBM Cloud Provider Plug-in. You modify the configuration files
provided on the 1-Tier VPC for SAP GitHub repository to specify the plug-in version to use.
If you are using Terraform 1.12.x and earlier, follow these IBM Cloud Provider Plug-in installation instructions. Do not configure the plugin.
Do not do any IBM Cloud Provider Plug-in configuration because those files are provided for you.
2. Create a project folder in the Terraform installation folder, and change directory to your project folder.
mkdir myproject && cd myproject

3. Copy the files from https://github.com/IBM-Cloud/sap-infra-anydb-single/tree/main/cli to the project folder that you created in the
Terraform installation directory.
4. Edit the terraform.tfvars variable file and enter the IBM Cloud API key that you retrieved.
ibmcloud_api_key = "<ibmcloud_apikey>"

Variables that are defined in the terraform.tfvars file are automatically loaded by Terraform when the IBM Cloud Provider plug-in is
initialized and you can reference them in every Terraform configuration file that you use.
Because the terraform.tfvars file contains confidential information, do not push this file to a version control system. Keep this file on
your local system only.
5. Edit the input.auto.tfvars file to customize your solution. Modify the file to specify your zone, VPC component names, profile, and
image. You need your 40-digit SSH key ID for this file. The second SSH key is optional. For more options for profile, see Instance
Profiles. For more options for image, see Images.
$ ZONE

= "eu-de-1"

VPC

= "test-vpc"

SECURITYGROUP = "test-securitygroup"
SUBNET

= "test-subnet"

HOSTNAME

= "test-vsi"

PROFILE

= "bx2-4x16"

IMAGE

= "ibm-redhat-7-6-amd64-sap-applications-1"

SSH_KEYS

= [ "<SSH Key ID 1>" , "<SSH Key ID 2>" ]

SWAP

= "16"

VOL1

= "10"

6. Initialize the Terraform CLI.
$ terraform init

7. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the VPC instance in
your account.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 319

$ terraform plan

8. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
9. Create the VPC for SAP instance and IAM access policy in IBM Cloud.
$ terraform apply

The VPC and components are created and you see output similar to the terraform plan output.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run terraform
plan and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The

Terraform scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove your VPC, go to your project folder and run terraform destroy .

Deploying SAP AnyDB (non-SAP HANA) 2-tier and 3-tier distributed architecture
on IBM Cloud® VPC (Terraform)
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud VPC infrastructure resources so that you can rapidly
build complex, cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware using Intel Xeon CPUs and additional Intel
technologies.
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
To create resources with Terraform, you use Terraform configuration files that describe the IBM Cloud resources that you need and how you
want to configure them. Based on your configuration, Terraform creates an execution plan and describes the actions that need to be run to
create the resources. You can review the execution plan, change it, or run the plan. When you change your configuration, Terraform on IBM
Cloud can determine what changed and create incremental execution plans that you can apply to your existing IBM Cloud resources.

Script files
The configuration and script files are provided on the GitHub repository https://github.com/IBM-Cloud/sap-infra-anydb-distributed.
For 2-tier and 3-tier VPC for SAP, you modify the:
terraform.tfvars file to add your IBM Cloud API-key
input.auto.tfvars file to customize the resources for your solution. You specify zones, resource names, and SSH keys.

All of the other configuration files are provided and do not need to be modified.
The IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files to provision a VPC in your IBM Cloud account.

What is created
A VPC is a private space in IBM Cloud where you can run an isolated environment with custom network policies. The variables that you define
are used by the scripts to provision the following VPC infrastructure resources for you:
1 VPC where you provision your virtual server instance
1 security group and rules for this security group to allow DNS and SSH connections to your virtual server instance and all outbound
traffic
1 subnet to enable networking in your VPC
2 virtual server instances (1 SAP App VSI and 1 DB(anydb) instance server VSI)
2 storage volumes, 1 for swap and 1 for data for SAP app VSI and 4 storage 1 x SWAP and 3 x DATA volumes for DB VSI
2 floating IP address that you use to access your VPC virtual server instances over the public network
The VSIs are configured with Red Hat Enterprise Linux 7.x for SAP Applications (amd64) and they have at least two SSH keys that are
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 320

configured to access as root user. The VSIs have the following storage volumes:
DB virtual server instance disks: • 1x 40 GB disk with 10 IOPS / GB - SWAP • 1 x 32 GB disk with 10 IOPS / GB - DATA (DB LOG) • 1x 64 GB
disk with 10 IOPS / GB - DATA (DB ARCHIVE LOG) • 1 x 128/256 GB disk with 10 IOPS / GB – DATA • 1 floating IP address that you use to
access your VPC virtual server instance over the public network
SAP app virtual server instance disks: • 1x 40 GB disk with 10 IOPS / GB - SWAP • 1 x 128 GB disk with 10 IOPS / GB – DATA • 1 floating IP
address that you use to access your VPC virtual server instance over the public network

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, re-adapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
1. If you do not have Terraform installed, Install the Terraform CLI and the IBM Cloud Provider plug-in .
If you are using Terraform 0.13 and higher, you do not need to install the IBM Cloud Provider Plug-in. You modify the configuration files
provided on the 1-Tier VPC for SAP GitHub repository to specify the plug-in version to use.
If you are using Terraform 1.12.x and earlier, follow these IBM Cloud Provider Plug-in installation instructions. Do not configure the plugin.
Do not do any IBM Cloud Provider Plug-in configuration because those files are provided for you.
2. Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
3. Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.

Procedure
Use these steps to configure the IBM Cloud Provider Plug-in and use Terraform to create a VPC for SAP.
1. Create a project folder in the Terraform installation folder, and change directory to your project folder.
mkdir myproject && cd myproject

2. Copy the files from https://github.com/IBM-Cloud/sap-infra-anydb-distributed/tree/main/cli to the project folder that you created in the
Terraform installation directory.
3. Edit the terraform.tfvars variable file and enter the IBM Cloud API key that you retrieved.
$ ibmcloud_api_key = "<ibmcloud_apikey>"

Variables that are defined in the terraform.tfvars file are automatically loaded by Terraform when the IBM Cloud Provider plug-in is
initialized and you can reference them in every Terraform configuration file that you use.
Because the terraform.tfvars file contains confidential information, do not push this file to a version control system. Keep this file on
your local system only.
4. Edit the input.auto.tfvars file to customize your solution. Modify the file to specify your VPC name, subnet, security group,
hostname, profile, image, SSH keys, and disk sizes. You must modify:
VPC - Unique VPC name.
SECURITYGROUP - Change ic4sap to the VPC name.
SUBNET - Change ic4sap to the VPC name.
DB/APP HOSTNAME - Enter a hostname up to 13 characters. For more information, see the README file.
For disk sizes, volumes are created with the required size and are attached to the VSIs. The size for the volumes is defined as a list in the
VOLUME_SIZES variable with each value specifying capacity for a volume in GB.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 321

You need your 40-digit SSH key ID for this file. The second SSH key is optional.
For more options for profile, see Instance Profiles. For more options for image, see Images.
# General VPC variables:
REGION

= "eu-de" # default value

ZONE

= "eu-de-2" # default value

VPC

= "ic4sap"

SECURITYGROUP = "ic4sap-securitygroup"
SUBNET

= "ic4sap-subnet"

SSH_KEYS

= [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a" , "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ]

PROFIL

= "bx2-4x16" # default value

IMAGE

= "ibm-redhat-7-6-amd64-sap-applications-1" # default value

# SAP Database VSI variables:
DB-HOSTNAME

= "ep12db"

DB-VOLUME_SIZES = [ "40" , "32" , "64" , "128" ]

# SAP APPs VSI variables:
APP-HOSTNAME

= "ep12app" # default value

APP-VOLUME_SIZES= [ "40" , "128" ]

Parameter

Description

REGION

The cloud region where the solution is deployed. The regions and zones for VPC are listed here.

ZONE

The cloud zone where the solution is deployed.

VPC

The name of the VPC. The list of VPCs is available here.

SECURITYGROUP

The name of the Security Group. The list of Security Groups is available here

SUBNET

The name of the Subnet. The list of Subnets is available here

PROFILE

The profile used for the VSI. A list of profiles is available here.

IMAGE

The OS image used for the VSI. A list of images is available here.

SSH_KEYS

List of SSH Keys IDs that are allowed to SSH as root to the VSI. Can contain one or more IDs. The list of SSH
Keys is available here.

[DB/APP]HOSTNAME

The hostname for the VSI. The hostname must have up to 13 characters as required by SAP. For more
information about rules regarding hostnames for SAP systems, see SAP Note 611361 - Hostnames of SAP
ABAP Platform servers.

5. Initialize the Terraform CLI.
$ terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the VPC instance in
your account.
$ terraform init

7. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
8. Create the VPC for SAP instance and IAM access policy in IBM Cloud.
$ terraform apply

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 322

The VPC and components are created and you see output similar to the terraform plan output.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run terraform
plan and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The

Terraform scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove your VPC, go to your project folder and run terraform destroy .

SAP NetWeaver and Db2 single-tier on IBM Cloud VPC
Overview SAP workload deployment on IBM Cloud® Virtual Private Cloud (VPC) (Terraform and
Ansible)
You can use Terraform to automate IBM Cloud VPC provisioning. The VPC provisioned includes virtual server instances with high network
performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers. After the VPC
is provisioned, the scripts use the Ansible Playbook to install the SAP system.

IBM Cloud® VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP on IBM Cloud®
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for ABAP and Java applications. SAP
system can be installed and configured in IBM Cloud for various system and database types.
For more information about SAP system architectures on IBM Cloud VPC, see the infrastructure reference architectures for SAP for each
supported database type. For example, SAP NetWeaver 7.x on UNIX with Db2 on IBM Cloud® VPC is the dedicated reference architecture for
this SAP solution.
Manually deploying a VPC and installing an SAP system can be time-consuming. The Terraform automation assures not only a much quicker
implementation, but also a standardized and less prone to error deployment. Terraform and Ansible are used for automating the deployment
processes.
The Terraform scripts solution provides the automated deployment of a single host with SAP NetWeaver with Db2 3-tier on the Red Hat
Enterprise Linux® and SUSE for SAP Applications (releases specified in README file.
The SAP installation media that are used for this deployment are the default media for SAP NetWeaver 7.5 with Db2 (releases specified in
README file available at the SAP Support Portal in the Installation and Upgrade area. You provide the installation media as an input parameter

for Terraform.

Ansible for SAP installation
Ansible is an automation tool for the deployment of several IT tasks. Ansible is used for automating the installation of an SAP NetWeaver with
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 323

Db2 3-tier. For more information about Ansible, see the Ansible Documentation.
The deployment is done by using the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found
on the Ansible core page.
The Ansible playbook is called directly by the Terraform script. The script starts with Terraform specific steps for creating the VPC, and
continues automatically with the Ansible-specific steps to install the SAP system.

Where to run the scripts
The recommended way to run the scripts is from your deployment (bastion) server because the deployment (bastion) server has Terraform
and Ansible already installed. If you want to run the scripts from your local workstation, you need to install Terraform and Ansible locally.
For both the deployment (bastion) server and local workstation, you must download the SAP kits to the temporary storage assigned to you on
the deployment (bastion) server. Ansible installs the kits for you. You specify the location of the kits in the configuration files.

Prerequisite, where to run the scripts
Before you deploy any of the SAP automated solutions on IBM Cloud VPC, you create a bastion server VPC in your chosen region. The bastion
server is used for downloading and storing specific SAP solution media that are needed for later automation deployment. The bastion server is
used for both CLI deployment scenarios, as well for Schematics UI deployments. For more information about how to create the bastion server
and its corresponding VPC, see Automate SAP bastion server – SAP media storage repository .
After bastion VPC deployment is complete, you must download the SAP kits to the temporary storage assigned to you on the bastion server.
Ansible installs the kits for you. You specify the location of the kits in the configuration files.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Note: To save costs, the bastion server, with its SAP media dedicated storage, can be decommissioned after the SAP solutions are
successfully implemented on IBM Cloud VPC. Or, you can keep the bastion server and use it as a jump host for that specific region.

Deploying SAP NetWeaver 7.x and Db2 on an existing IBM Cloud® VPC (Terraform and Ansible)
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so
that you can rapidly build complex, cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel Xeon
CPUs and additional Intel technologies.
You can use Terraform scripts to create a single-tier VPC and create the SAP and Db2 infrastructure on the VPC. The Terraform scripts use the
VPC information that you provide and then call the Ansible playbook to create the SAP architecture on the specified VPC.
You have three deployment methods to choose from:
Terraform scripts run from the CLI on your bastion server
Catalog Tile user interface accessed from the IBM Cloud Catalog
Schematics user interface accessed from the menu on your cloud dashboard.

What is created
The scripts use the information that you provide for an existing VPC and deploy NW7.X with Db2. For more information about this architecture,
see SAP NetWeaver 7.x on UNIX with Db2 on IBM Cloud® VPC . You specify the information for the VPC to use in the input.auto.tfvars file.
The scripts call the Ansible Playbook to install the SAP architecture.

Script files
The configuration and script files are provided on GitHub. Each supported interface for the SAP solution installation has its own folder in the
GitHub repository:
Using the Schematics user interface on IBM Cloud® - GitHub repository for IBM Schematics.

Terraform deployment
You use Terraform on the Bastion server CLI to download and run the scripts that are located in SAP NetWeaver ABAP Db2 GitHub repository
for Terraform.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 324

To run the Terraform scripts, you modify:
The input.auto.tfvars file to specify the information for your solution:
Enter the floating IP and subnet information from the Bastion server.
Enter existing VPC information:
VPC name
Security group
Subnet
HostName
Profile
Image
Up to two SSH keys
You can change the default SAP system configuration settings to match your solution.
You also specify the location where you downloaded the SAP kits.
The IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files to install NW7.X with Db2 on the specified VPC in
your IBM Cloud account.

Schematics deployment
When you run the scripts with the Schematics interface, you:
Enter Workspace information.
Enter the GitHub path.
Modify the parameters in the Schematics interface. They are the same parameters as the

input.auto.tfvars file that you use with the

cli.

Catalog Tile deployment
When you use the Catalog Tile for deployment, you:
Select the SAP NetWeaver (ABAP stack) with Db2 standard system tile from the catalog
Enter information for your workspace. The Catalog Tile creates a Schematics workspace for you.
Modify the parameters for your bastion server, personal credential information, and other parameters specific to your solution.

Support - Terraform and Schematics
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, re-adapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Support - Catalog Tile
The Catalog Tile offering is IBM Cloud supported. For more information, see Getting help and support from IBM Cloud or SAP .
If client issues are identified with SAP software, then SAP Support will assist client. Please follow the recommendations of SAP Note 90835,
which describes the SAP Incident Escalation Procedure. This SAP Note (and others) is found at https://support.sap.com/en/index.html

Before you begin
Before you use the scripts in the Bastion cli or Schematics:
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account .
If you have not already, create a bastion server to store the SAP kits. For more information, see

Automate SAP bastion server - SAP

media storage repository. You need the floating IP from your bastion server for deployment.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses the
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 325

files. For more information, see the readme file, in the respective GitHub repository for Schematics and Terraform and on the About page
for the Catalog Tile.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
Terraform should be already installed on the bastion server that you deployed. For more information, see

Bastion server for SAP

deployment.
(Optional - Catalog Tile) create secrets for your credentials and passwords by using the Secrets Manager.

Deploying SAP NetWeaver 7.x and Db2 by using Terraform with the Bastion server CLI
Use these steps to configure the IBM Cloud Provider plug-in and use Terraform to install SAP NW7.X with Db2 on your existing VPC. The scripts
can take 1 - 2 hours to complete.
1. Access the Bastion server cli.
2. Clone the solution repository from https://github.com/IBM-Cloud/sap-netweaver-abap-db2-standard and cd to the sapnetweaver-abap-db2-standard folder:
$ $ git clone https://github.com/IBM-Cloud/sap-netweaver-abap-db2-standard.git
$ cd sap-netweaver-abap-db2-standard

3. Specify your VPC. Modify the input.auto.tfvars file to specify the information for the existing VPC, your zone, VPC and component
names, profile, and image. You need your 40-digit SSH key ID for this file. The second SSH key is optional. For more options for profile,
see Instance Profiles. For more options for image, see Images. For descriptions of the variables, see the README file.
$ #Infra VPC variables
REGION = "eu-de"
ZONE = "eu-de-2"
VPC = "ex-vpc"
SECURITY_GROUP = "bastion-sg-ex-bastion"
RESOURCE_GROUP = "exres-group"
SUBNET = "ex-subnet"
SSH_KEYS = [ "r018-6c00506b-6be1-4395-b02e-ab8b052e2a6a" , "r018-6c00506b-6be1-4395-b02e-bb8b052e2a6b" ]
HOSTNAME = "exdb2nwss1"
PROFILE = "bx2-4x16"
IMAGE = "ibm-redhat-8-4-amd64-sap-applications-4"

4. Customize your SAP system configuration. In the same file, input.auto.tfvars , edit the SAP system configuration variables that are
passed to the Ansible automated deployment.
For descriptions of the variables, see the README file.
$ ##SAP system configuration
sap_sid = "DB2"
sap_ci_instance_number = "00"
sap_ascs_instance_number = "01"
#Kits paths
kit_sapcar_file = "/storage/NW75DB2/SAPCAR_1010-70006178.EXE"
kit_swpm_file =

"/storage/NW75DB2/SWPM10SP37_2-20009701.SAR"

kit_saphotagent_file = "/storage/NW75DB2/SAPHOSTAGENT51_51-20009394.SAR"
kit_sapexe_file = "/storage/NW75DB2/SAPEXE_800-80002573.SAR"
kit_sapexedb_file = "/storage/NW75DB2/SAPEXEDB_800-80002603.SAR"
kit_igsexe_file = "/storage/NW75DB2/igsexe_13-80003187.sar"
kit_igshelper_file = "/storage/NW75DB2/igshelper_17-10010245.sar"
kit_export_dir = "/storage/NW75DB2/51050829"
kit_db2_dir = "/storage/NW75DB2/51055138/DB2_FOR_LUW_11.5_MP6_FP0SAP2_LINUX_"
kit_db2client_dir = "/storage/NW75DB2/51055140"

Note: Remember, you must manually decompress the kit_export_dir , kit_db2_dir , and kit_db2client_dir files. Ansible
decompresses the rest of the SAP kit files. For more information, see the README file.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 326

5. Initialize the Terraform CLI.
$

terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
$

terraform plan --out plan1

You must enter an SAP main password and your API key.
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters:
a-z, A-Z, 0-9, @, #, $, _. This password cannot contain ! . It must not start with a digit or an underscore ( _ ).
7. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
8. Create the virtual private cloud for SAP instance and IAM access policy in IBM Cloud.
$ ```teraform
terraform apply "plan1"
```
The virtual private cloud and components are created and you see output similar to the `terraform plan` output.

9. Create the virtual private cloud for SAP instance and IAM access policy in IBM Cloud.
10. Add the SAP credentials and the virtual server instance IP to the SAP GUI. For more information about the SAP GUI, see

SAP GUI.

Deploying SAP NetWeaver 7.x and Db2 by using the Catalog Tile user interface
Use these steps to configure the SAP NetWeaver 7.X with Db2 on your existing VPC by using the Catalog Tile user interface. The scripts can
take 1 - 2 hours to complete.
1. From the IBM Cloud Catalog, select the SAP NetWeaver (ABAP stack) with Db2 standard system tile. The Tile opens the Create tab for
AP NetWeaver (ABAP stack) with Db2 standard system. For more information about this deployment, see the About tab or the Readme
file link.
2. On the SAP NetWeaver (ABAP stack) with Db2 standard system page, configure your workspace:
Enter a name for the workspace or use the default.
The Resource Group to use to create resources. Use the Default or create a Resource Group.
Select a Location to create your Schematics workspace. The workspace location does not have to match the resource location.
3. Enter the required deployment values, review the default input variables, and provide values that match your solution. These parameters
are specific to your deployment. For more detailed information, see the Readme file.
Parameter

Description

BASTION_FLOATING_IP

Input the floating IP of the Bastion Server you created before you started this deployment. For more
information, see Automate SAP bastion server - SAP media storage

HOSTNAME

VSI hostname

REGION

Cloud Region where resources are deployed

RESOURCE_GROUP

EXISTING Resource Group for VSIs and Volumes

SECURITY_GROUP

EXISTING Security group name

SSH_KEYS

SSH Keys ID list to access the VSI

SUBNET

EXISTING Subnet name

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 327

VPC

EXISTING VPC name

ZONE

Cloud Zone where resources are deployed

ibmcloud_api_key

IBM Cloud API key or use a secret that is stored in Secrets Manager

private_ssh_key

Input id_rsa private key content or use a secret that is stored in Secrets Manager

sap_main_password

SAP main password or use a secret that is stored in Secrets Manager

4. Review and update the optional parameters. The Ansible scripts expect the SAP kits to be in the default locations listed. For more
detailed information, see the Readme file.
Parameter

Description

IMAGE

VSI OS image

PROFILE

VSI profile

kit_db2_dir

kit_db2_dir

kit_db2client_dir

kit_db2client_dir

kit_export_dir

kit_export_dir

kit_igsexe_file

kit_igsexe_file

kit_igshelper_file

kit_igshelper_file

kit_sapcar_file

kit_sapcar_file

kit_sapexe_file

kit_sapexe_file

kit_saphotagent_file

kit_saphotagent_file

kit_swpm_file

kit_swpm_file

5. Accept the license agreement.
6. Select Install. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

Deploying SAP NetWeaver 7.x and Db2 by using the Schematics user interface
Use these steps to configure the SAP NetWeaver 7.X with Db2 on your existing VPC by using the Schematics user interface. The scripts can
take 1 - 2 hours to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the GitHub URL with the code you plan to deploy.
Select the Terraform version that is listed in the readme file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 328

Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your API key
Your private SSH key from your local machine
(Optional) you can change the ID_RSA_FILE_PATH for your SSH key that will be autogenerated on Schematics and Bastion Server
The ID for the SSH key that you created and uploaded to IBM Cloud. Enter the SSH key ID in square brackets and quotation marks,
for example [ "ibmcloud_ssh_key_UUID1","ibmcloud_ssh_key_UUID2",... ].
The Region for your resources
The Zone for your resources
Whether to use an existing VPC or create one
Whether to use an existing subnet
Whether to create new port only when a new subnet is created
TCP port range, nimimun and maximum
VPC name
Subnet name
Security group name
Hostname
Profile
Image
Minimal recommended disk sizes
SAP main password - must be at least 10 characters, upper and lowercase letters, a number, and a special character, not an
exclamation point.
Click Save changes.
For a more detailed description of each of the parameters, check the GitHub repo readme file, chapter “Input parameter file”. Also, make
sure to mark as “sensitive” the parameters that contain sensitive information like passwords, API, and ssh private keys (they are marked
as “sensitive” in the readme file, under “Input parameter file”)
7. On the workspace Settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run terraform
plan and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The

Terraform scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove the SAP NetWeaver 7.X and Db2 installation, go to your project folder and run

terraform destroy . The terraform

destroy command does not remove the VPC in this scenario because the VPC was not created with the Terraform scripts.

Related information
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier VPC for SAP

on IBM Cloud® VPC with Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 329

SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP NetWeaver and Db2 3-tier on IBM Cloud VPC
Overview SAP workload deployment on IBM Cloud® Virtual Private Cloud (VPC) (Terraform and
Ansible)
You can use Terraform to automate IBM Cloud VPC provisioning. The VPC provisioned includes virtual server instances with high network
performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers. After the VPC
is provisioned, the scripts use the Ansible Playbook to install the SAP system.

IBM Cloud® VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP on IBM Cloud®
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for ABAP and Java applications. SAP
system can be installed and configured in IBM Cloud for various system and database types.
For more information about SAP system architectures on IBM Cloud VPC, see the infrastructure reference architectures for SAP for each
supported database type. For example, SAP NetWeaver 7.x on UNIX with Db2 on IBM Cloud® VPC is the dedicated reference architecture for
this SAP solution.
Manually deploying a VPC and installing an SAP system can be time-consuming. The Terraform automation assures not only a much quicker
implementation, but also a standardized and less prone to error deployment. Terraform and Ansible are used for automating the deployment
processes.
The Terraform scripts solution provides the automated deployment of a single host with SAP NetWeaver with Db2 3-tier on the Red Hat
Enterprise Linux® and SUSE for SAP Applications (releases specified in README file.
The SAP installation media that are used for this deployment are the default media for SAP NetWeaver 7.5 with Db2 (releases specified in
README file available at the SAP Support Portal in the Installation and Upgrade area. You provide the installation media as an input parameter

for Terraform.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 330

Ansible for SAP installation
Ansible is an automation tool for the deployment of several IT tasks. Ansible is used for automating the installation of an SAP NetWeaver with
Db2 3-tier. For more information about Ansible, see the Ansible Documentation.
The deployment is done by using the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found
on the Ansible core page.
The Ansible playbook is called directly by the Terraform script. The script starts with Terraform specific steps for creating the VPC, and
continues automatically with the Ansible-specific steps to install the SAP system.

Where to run the scripts
The recommended way to run the scripts is from your deployment (bastion) server because the deployment (bastion) server has Terraform
and Ansible already installed. If you want to run the scripts from your local workstation, you need to install Terraform and Ansible locally.
For both the deployment (bastion) server and local workstation, you must download the SAP kits to the temporary storage assigned to you on
the deployment (bastion) server. Ansible installs the kits for you. You specify the location of the kits in the configuration files.

Prerequisite, where to run the scripts
Before you deploy any of the SAP automated solutions on IBM Cloud VPC, you create a bastion server VPC in your chosen region. The bastion
server is used for downloading and storing specific SAP solution media that are needed for later automation deployment. The bastion server is
used for both CLI deployment scenarios, as well for Schematics UI deployments. For more information about how to create the bastion server
and its corresponding VPC, see Automate SAP bastion server – SAP media storage repository .
After bastion VPC deployment is complete, you must download the SAP kits to the temporary storage assigned to you on the bastion server.
Ansible installs the kits for you. You specify the location of the kits in the configuration files.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Note: To save costs, the bastion server, with its SAP media dedicated storage, can be decommissioned after the SAP solutions are
successfully implemented on IBM Cloud VPC. Or, you can keep the bastion server and use it as a jump host for that specific region.

Deploying SAP NetWeaver 7.x and Db2 on 3-tier IBM Cloud® VPC (Terraform and Ansible)
You can use Terraform scripts to create a single-tier VPC and create the SAP NW and Db2 distributed 3-tier infrastructure on the VPC. The
Terraform scripts use the VPC information that you provide and then call the Ansible playbook to create the SAP architecture on the specified
VPC.
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud® Virtual Private Cloud (VPC) infrastructure resources so
that you can rapidly build complex cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon
CPUs and additional Intel® technologies.
You have two deployment methods to choose from:
Terraform scripts run from the CLI on your bastion server
Schematics user interface accessed from the menu on your cloud dashboard

What is created
The scripts use the information that you provide for an existing VPC and deploy NW7.X with Db2 3-tier. For more information about this
architecture, see SAP NetWeaver 7.x on UNIX with Db2 on IBM Cloud® VPC . You specify the information for the VPC to use in the
input.auto.tfvars file.

The scripts call the Ansible Playbook to install the SAP architecture.

Script files
The configuration and script files are provided on GitHub. Each supported interface for the SAP solution installation has its own folder in the
GitHub repository:
Using the Schematics user interface on IBM Cloud - GitHub repository for IBM Schematics.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 331

Schematics deployment
When you run the scripts with the Schematics interface, you:
Enter Workspace information.
Enter the GitHub path.
Modify the parameters in the Schematics interface. They are the same parameters as the

input.auto.tfvars file that you use with the

CLI.

Terraform deployment
You can use Terraform on the bastion server CLI to download and run the scripts that are located in SAP NetWeaver ABAP Db2 3-tier GitHub
repository for Terraform.
To run the Terraform scripts, you modify:
The input.auto.tfvars file to specify the information for your solution:
Enter the floating IP and subnet information from the bastion server.
Enter existing VPC information:
VPC name
Security group
Subnet
Hostname
Profile
Image
Up to two SSH keys
You can change the default SAP system configuration settings to match your solution.
You also specify the location where you downloaded the SAP kits.
The IBM Cloud Provider Plug-in for Terraform on IBM Cloud uses these configuration files to install NW 7.x with Db2 3-tier on the specified VPC
in your IBM Cloud account.

Support - Terraform and Schematics
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, re-adapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
Before you use the scripts in the bastion CLI or Schematics:
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account .
If you have not already, create a bastion server to store the SAP kits. For more information, see

Automate SAP bastion server - SAP

media storage repository. You need the floating IP from your bastion server for deployment.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses the
files. For more information, see the readme file, in the respective GitHub repository for Schematics and Terraform and on the About page
for the Catalog Tile.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
(Optional - Catalog Tile) create secrets for your credentials and passwords by using the Secrets Manager.

Deploying SAP NetWeaver 7.x and Db2 on 3-tier by using the Schematics user interface
Use these steps to configure the SAP NetWeaver 7.x with Db2 3-tier on your existing VPC by using the Schematics user interface. The scripts
can take 1 - 2 hours to complete.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 332

1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the GitHub URL for the code you plan to deploy.
Select the Terraform version that is listed in the README file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Click Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your API key
Your private SSH key from your local machine
(Optionl) You can change the ID_RSA_FILE_PATH for your SSH key that will be autogenerated on Schematics and Bastion Server
The ID for the SSH key that you created and uploaded to IBM Cloud. Enter the SSH key ID in square brackets and quotation marks,
for example [ "ibmcloud_ssh_key_UUID1","ibmcloud_ssh_key_UUID2",... ].
The region for your resources
The zone for your resources
Whether to use an existing VPC or create one
Whether to use an existing subnet
Whether to create new port only when a new subnet is created
TCP port range, nimimun and maximum
VPC name
Subnet name
Security group name
Hostname
Profile
Image
Minimal recommended disk sizes
SAP main password - must be at least 10 characters, upper and lowercase letters, a number, and a special character, not an
exclamation point.
Click Save changes.
For a more detailed description of each of the parameters, check the GitHub repo README file, chapter “Input parameter file”. Also,
make sure to mark as “sensitive” the parameters that contain sensitive information like passwords, API, and SSH private keys (they are
marked as “sensitive” in the README file in the “Input parameter file”).
7. On the workspace Settings page, click Generate plan. Wait for the plan to complate.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Deploying SAP NetWeaver 7.x and Db2 3-tier by using Terraform with the bastion server CLI
Use these steps to configure the IBM Cloud Provider plug-in and use Terraform to install SAP NW 7.x with Db2 3-tier on your existing VPC. The
scripts can take 1 - 2 hours to complete.
1. Access the bastion server CLI.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 333

2. Clone the solution repository from https://github.com/IBM-Cloud/sap-netweaver-abap-db2-distributed and cd to the sapnetweaver-abap-db2-distributed folder.
$ git clone https://github.com/IBM-Cloud/sap-netweaver-abap-db2-distributed.git
cd sap-netweaver-abap-db2-distributed

3. Specify your VPC. Modify the input.auto.tfvars file to specify the information for the existing VPC, your zone, VPC and component
names, profile, and image. You need your 40-digit SSH key ID for this file. The second SSH key is optional. For more options for profiles,
see Instance profiles. For more options for images, see Images. For descriptions of the variables, see the README file.
$ # Infra VPC variables
REGION

= "eu-de"

ZONE

= "eu-de-2"

VPC

= "sap"

# EXISTING VPC name

SECURITY_GROUP = "sap-securitygroup"

# EXISTING security group name

SUBNET

= "sap-subnet"

# EXISTING subnet name

RESOURCE_GROUP

= "wes-automation"

# EXISTING resource group

SSH_KEYS

= [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a" , "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ]

# SAP Database VSI variables:
DB-HOSTNAME

= "sapnwdb2"

DB-PROFILE

= "bx2-4x16"

DB-IMAGE

= "ibm-redhat-8-4-amd64-sap-applications-4" # For any manual change in the Terraform code, you

have to make sure that you use a certified image based on the SAP NOTE: 2927211.
# SAP APPs VSI variables:
APP-HOSTNAME

= "sapnwapp"

APP-PROFILE

= "bx2-4x16"

APP-IMAGE

= "ibm-redhat-8-4-amd64-sap-applications-4" # For any manual change in the Terraform code, you

have to make sure that you use a certified image based on the SAP NOTE: 2927211.

4. Customize your SAP system configuration. In the same file, input.auto.tfvars , edit the SAP system configuration variables that are
passed to the Ansible automated deployment.
For descriptions of the variables, see the README file.
$ # SAP system configuration
sap_sid = "NWA"
sap_ascs_instance_number = "01"
sap_ci_instance_number = "00"
# Kits paths
kit_sapcar_file = "/storage/NW75DB2/SAPCAR_1010-70006178.EXE"
kit_swpm_file =

"/storage/NW75DB2/SWPM10SP37_2-20009701.SAR"

kit_saphotagent_file = "/storage/NW75DB2/SAPHOSTAGENT51_51-20009394.SAR"
kit_sapexe_file = "/storage/NW75DB2/SAPEXE_800-80002573.SAR"
kit_sapexedb_file = "/storage/NW75DB2/SAPEXEDB_800-80002603.SAR"
kit_igsexe_file = "/storage/NW75DB2/igsexe_13-80003187.sar"
kit_igshelper_file = "/storage/NW75DB2/igshelper_17-10010245.sar"
kit_export_dir = "/storage/NW75DB2/51050829"
kit_db2_dir = "/storage/NW75DB2/51055138/DB2_FOR_LUW_11.5_MP6_FP0SAP2_LINUX_"
kit_db2client_dir = "/storage/NW75DB2/51055140"

Note: Remember, you must manually decompress the kit_export_dir , kit_db2_dir , and kit_db2client_dir files. Ansible
decompresses the rest of the SAP kit files. For more information, see the README file.
5. Initialize the Terraform CLI/
$ terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
$ terraform plan --out plan1

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 334

You must enter an SAP main password and your API key.
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters:
a-z, A-Z, 0-9, @, #, $, _. This password cannot contain ! . It must not start with a digit or an underscore ( _ ).
7. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
8. Create the virtual private cloud for SAP instance and IAM access policy in IBM Cloud.
$ terraform apply "plan1"

The virtual private cloud and components are created and you see output similar to the

terraform plan output.

9. Add the SAP credentials and the virtual server instance IP to the SAP GUI. For more information about the SAP GUI, see

SAP GUI.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run terraform
plan and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The

Terraform scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove the SAP NetWeaver 7.x and Db2 distributed installation, go to your project folder and run

terraform destroy . The

terraform destroy command does not remove the VPC in this scenario because the VPC was not created with the Terraform scripts.

Related information
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier VPC for SAP

on IBM Cloud® VPC with Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel® processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP HANA stand-alone VSI on IBM Cloud VPC
Background for automating SAP HANA stand-alone virtual server instance on IBM Cloud® VPC
IBM Cloud® Virtual Private Cloud (VPC) introduction
IBM Cloud® VPC offers the possibility to quickly provision virtual server instances for VPC with high network performance. VPC infrastructure
contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. A VPC is a public cloud offering that an
enterprise uses to establish its own private cloud-like computing environment on shared public cloud infrastructure. A VPC gives an enterprise
the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on
the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building with multiple families living inside. Being a public cloud tenant
is akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium. No one else has

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 335

the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to quickly provision virtual server instances for VPC with high network performance. VPC
infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information, see Getting started with Virtual Private Cloud (VPC) .

SAP HANA in IBM Cloud
The IBM public cloud is an open, security-rich, and enterprise-ready public cloud for business. This design makes it easier for global
enterprises to modernize and build new business applications in the cloud to meet the evolving needs of the business and its customers. IBM
Cloud offerings include a broader portfolio of SAP-certified infrastructure, ranging from bare metal, VMware, VPC, and IBM Power® Systems
Virtual Server products.

SAP HANA defined
SAP HANA (High-performance Analytic Appliance) is a multi-model database that stores data in its memory instead of keeping it on a disk. This
arrangement results in data processing that magnitudes faster than processing of disk-based data systems, allowing for advanced, real-time
analytics.
Serving as a platform for enterprise resource planning (ERP) software and other business applications, SAP HANA can be placed on premises,
in the cloud, or both, in a hybrid cloud system. For more information, see SAP HANA on IBM Cloud .
The number of hosts in an SAP HANA system landscape determines the SAP HANA system type.
An SAP HANA system can be configured as either:
A single-host system - One SAP HANA instance on one host
A distributed system (multiple-host system) - Multiple SAP HANA instances distributed over multiple hosts

Single-host SAP HANA system
A single-host system is the simplest system installation type that runs an SAP HANA system entirely on one host. You can scale the system up
as needed. The single-host system has these components:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 336

Figure 1. SAP NetWeaver 7.x SAP HANA single-host installation on bare metal and x86 VSIs

For more information about SAP systems architectures in IBM Cloud VPC, see reference architectures for each supported database type.
Manually deploying a VPC and installing an SAP system can be time-consuming. The automation assures not only a much quicker
implementation, but also a standardized and less prone to error deployment. Terraform and Ansible are used for automating the deployment
processes.
The solution that is presented in this how-to guide is the automated deployment of a single host with SAP HANA stand-alone VSI on Red Hat
Enterprise Linux or SUSE Linux Enterprise Server (SLES)for SAP applications.
Database instance (DB) - To assist your projects planning phase, more design considerations are provided at SAP HANA database with IBM
Cloud for SAP. For more information, see SAP HANA database design considerations and Infrastructure certified for SAP.
A dedicated reference architecture about this SAP HANA on IBM Cloud VPC cloud can be found on SAP HANA database design considerations .
SAP HANA installation media that are used for this deployment is the default one for SAP HANA, platform edition 2.0 SPS05. The media is
available at SAP Support Portal in the Installation and Upgrade area and it must be provided manually in the input parameter file.

Terraform for infrastructure deployment
Terraform on IBM Cloud enables predictable and consistent provisioning of IBM Cloud solutions. For more information about Terraform on IBM
Cloud, see Getting started with Terraform on IBM Cloud .
Terraform is used to provision of the infrastructure components in IBM Cloud. For the automating this process, the current solution uses a
Terraform script for deploying a VPC and a VSI with SAP certified storage and network configuration. The VPC contains one subnet and one
security group that has three rules:
Allow all outbound traffic from the VSI
Allow inbound DNS traffic (UDP port 53)
Allow inbound SSH traffic (TCP port 22)
After the successful deployment of the infrastructure, the Terraform script calls the Ansible Playbook, which automatically installs the SAP
application. Access creating single-tier VPC for SAP by using Terraform to get the detailed steps about using Terraform only for the creation of
a VPC for SAP.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Ansible for SAP installation
Ansible is an automation tool for the deployment of several IT tasks. This solution performs the automated deployment of SAP HANA 2.0 DB on
several validated OS platforms:
SUSE Linux Enterprise Server 15 SP 4 for SAP
SUSE Linux Enterprise Server 15 SP 3 for SAP
Red Hat Enterprise Linux 8.6 for SAP
Red Hat Enterprise Linux 8.4 for SAP in an existing IBM Cloud Gen2 VPC on stand-alone SAP HANA box VSI.
For more information about Ansible, see the documentation available on the Ansible page.
The deployment is done by the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found on
the Ansible core page .
The Ansible playbook is called directly by the Terraform script. The Terraform script is run in one run. During the run, the first steps are
Terraform specific for creating the VPC, and it continues automatically with the second, Ansible, steps for the installation of the SAP system.

Deploying SAP HANA stand-alone virtual server instance on IBM Cloud® VPC
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March
2025. Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM
Cloud Activity Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about
migrating from IBM Cloud Activity Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.
You can use Terraform scripts to create a single-tier SAP HANA DB on VSI or Bare Metal Server in a VPC. The Terraform scripts use the VPC
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 337

information that you provide and then call the Ansible playbooks to create the SAP architecture on the specified VPC.
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud VPC infrastructure resources so that you can rapidly
build complex cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware by using Intel® Xeon CPUs and additional
Intel® technologies.
For more information about Terraform on IBM Cloud, see Getting started with Terraform on IBM Cloud .
To create resources with Terraform, you can use Terraform configuration files that describe the IBM Cloud resources that you need and how
you want to configure them. Based on your configuration, Terraform creates an execution plan and describes the actions that need to be run to
create the resources. You can review the execution plan, change it, or run the plan.
You have two deployment methods to choose from:
Terraform scripts run from the CLI on your bastion server.
The schematic user interface is accessed from the menu on your cloud dashboard.

Prerequisites
A deployment server (bastion server) deployed by using the automation solution Automate SAP bastion server – SAP media storage repository ,
should exist in the same VPC, same region, and have the same subnet and security group that is configured for the SAP system VSIs.
Required IAM permissions for deploying SAP HANA on Bare Metal: Bare Metal Console Administrator role to access the ESXi Direct Console
User Interface (DCUI) and Bare Metal Advanced Network Operator role to modify IP spoofing and infrastructure NAT configuration on network
interfaces. For more information, see Planning for Bare Metal Servers on VPC .

What is created
The scripts automate the deployment of the virtual infrastructure resources and the provisioning processes for SAP architecture in an existing
VPC. An SAP HANA DB on a virtual server instance or bare metal server is provisioned in VPC. The deployment happens in two phases in one
run.
During the first phase, a virtual server instance or bare metal server with SAP HANA certified storage and network configuration is created. The
security group and a subnet used for the deployment server (bastion server) are required.
During the second phase, the Ansible playbooks are run and the SAP HANA 2.0 architecture is installed on the SAP HANA VSI box or on the SAP
HANA bare metal server.
There are two types of servers where this solution can be deployed on IBM Cloud Virtual Private Cloud (VPC): Virtual Server Instances (VSIs)
and Bare Metal servers. For each server type, there are specific profiles that are certified by SAP. A profile is a combination of instance
attributes, such as the number of vCPUs, amount of RAM, network bandwidth, and default bandwidth allocation. The attributes define the size
and capabilities of the virtual server instance that is provisioned.

x86-64 virtual server instance profiles
For IBM Cloud® virtual servers for VPC, there are eight profile families:
Balanced
Compute
Memory
Very High Memory
Ultra High Memory
GPU
Storage Optimized
Confidential Compute
For more information, see x86-64 instance profiles.
When you provision IBM Cloud® virtual server instances for SAP HANA on VPC, you can select from three families of certified profiles: Memory
Optimized, Very High Memory Optimized and Ultra High Memory Optimized. For more information about virtual server instances certified
profiles for SAP HANA, see Intel Virtual Server certified profiles on VPC infrastructure for SAP HANA .

x86-64 bare metal server profiles
IBM Cloud Bare Metal Servers on VPC Infrastructure are dedicated bare metal servers that provide enhanced networking and connectivity
through Virtual Private Cloud (VPC) capabilities. For more information on bare metal servers, see IBM Cloud Bare Metal Servers .
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 338

The bare metal servers on VPC are available as an integrated part of IBM Cloud®. For more information, see x86-64 bare metal server profiles
on IBM Cloud®.
When you provision an IBM Cloud® bare metal server for SAP HANA on VPC, you can select from four families of certified profiles:
Balanced
Compute Optimized
Memory Optimized
Ultra High Memory Optimized
For more information about the bare metal server certified profiles for SAP HANA, see Bare metal server certified profiles on VPC
infrastructure for SAP HANA.

SAP HANA server configuration
The following operating systems and OS images are supported:
Red Hat Enterprise Linux 8.6 for SAP HANA (amd64) - images: ibm-redhat-8-6-amd64-sap-hana-<x>
Red Hat Enterprise Linux 8.4 for SAP HANA (amd64) - images: ibm-redhat-8-4-amd64-sap-hana-<x>
SUSE Linux Enterprise Server 15 SP 4 for SAP Applications (amd64) - images:

ibm-sles-15-4-amd64-sap-hana-<x>

SUSE Linux Enterprise Server 15 SP 3 for SAP Applications (amd64) - images:

ibm-sles-15-3-amd64-sap-hana-<x>

The provided SSH keys are used to access the SAP HANA server via SSH, as a root user. The storage volumes for SAP HANA on VSI are
configured based on the Intel Virtual Server certified profiles on VPC infrastructure for SAP HANA . The storage volumes for SAP HANA on Bare
Metal Server are configured based on the Bare metal servers certified profiles on VPC infrastructure for SAP HANA .

Script files
The deployment automation script files are available in the GitHub repository.
The scripts use the information that you provide for an existing VPC and deploy SAP HANA DB on a VSI or on a Bare Metal Server.
The Terraform scripts run the Ansible Playbooks to install the SAP architecture.

Schematics deployment
When you use the Schematics interface to deploy SAP HANA, you need to provide the following information:
the workspace information
the GitHub repository path
the value for the parameters in the Schematics interface

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
If you don't have a deployment server (bastion server) in the same VPC, create a deployment server to store the SAP kits. For more information,
see Automate SAP bastion server - SAP media storage repository .
Log in to your Deployment Server and verify that Terraform and Ansible are installed.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses all of
the archive kits. For more information, see the Readme file.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
Required IAM permissions for deploying SAP HANA on Bare Metal: Bare Metal Console Administrator role to access the ESXi Direct
Console User Interface (DCUI) and Bare Metal Advanced Network Operator role to modify IP spoofing and infrastructure NAT
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 339

configuration on network interfaces, see: https://cloud.ibm.com/docs/vpc?topic=vpc-planning-for-bare-metal-servers.

Procedure
1. Log in to the Deployment Server (Bastion server) by using ssh command.
2. Clone the GitHub repository from https://github.com/IBM-Cloud/sap-hana-db and go to the sap-hana-db folder.
$ $ git clone https://github.com/IBM-Cloud/sap-hana-db.git
$ cd sap-hana-db

3. Customize the VPC variables according to your existing VPC data. Modify the input.auto.tfvars file to specify your options. You need
a 40-digit SSH key ID for the deployment. Additional SSH key IDs are optional. For more information related to SAP HANA certified
profiles, see Intel Virtual Server certified profiles on VPC infrastructure for SAP HANA and Bare metal servers certified profiles on VPC
infrastructure for SAP HANA. For more options about images, see Images.
The following input variable values must be provided:
REGION - Region for SAP HANA server. See the Readme file.
ZONE - Zone for SAP HANA server. See the Readme file.
VPC - The name of an existing VPC in the specified region.
SECURITY_GROUP - The name of an existing Security group in the same VPC.
RESOURCE_GROUP - The name of an existing Resource group, previously created by the user.
SUBNET - The name of an existing Subnet in the same region and zone as the SAP HANA server.
SSH_KEYS - A list of SSH keys UUIDs allowed to connect through SSH to the SAP HANA server.
ID_RSA_FILE_PATH - existing id_rsa private key file path in OpenSSH format with 0600 permissions.
HANA_SERVER_TYPE – The type of SAP HANA server: "virtual" server instance or "bare metal" server.
DB_HOSTNAME - The hostname of the SAP HANA server, up to 13 characters. For more information, see the

Readme file.

DB_PROFILE – The server certified profile to be used for SAP HANA. See the Readme file.
ATR_NAME – The name of an existing Activity Tracker in the same region as the SAP HANA server.
$ ######################################################
# General VPC variables:
######################################################
REGION = ""
# Region for SAP HANA server. Supported regions: https://cloud.ibm.com/docs/containers?topic=containers-regionsand-zones#zones-vpc
# Example: REGION = "eu-de"
ZONE = ""
# Availability zone for SAP HANA server. Supported zones: https://cloud.ibm.com/docs/containers?topic=containersregions-and-zones#zones-vpc
# Example: ZONE = "eu-de-1"
VPC = ""
# EXISTING VPC, previously created by the user in the same region as the SAP HANA server. The list of available
VPCs: https://cloud.ibm.com/vpc-ext/network/vpcs
# Example: VPC = "ic4sap"
SECURITY_GROUP = ""
# EXISTING Security group, previously created by the user in the same VPC. The list of available Security Groups:
https://cloud.ibm.com/vpc-ext/network/securityGroups
# Example: SECURITY_GROUP = "ic4sap-securitygroup"
RESOURCE_GROUP = ""
# EXISTING Resource group, previously created by the user. The list of available Resource Groups:
https://cloud.ibm.com/account/resource-groups
# Example: RESOURCE_GROUP = "wes-automation"
SUBNET = ""
# EXISTING Subnet in the same region and zone as the SAP HANA server, previously created by the user. The list of
available Subnets: https://cloud.ibm.com/vpc-ext/network/subnets
# Example: SUBNET = "ic4sap-subnet"

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 340

SSH_KEYS = [""]
# List of SSH Keys UUIDs that are allowed to SSH as root to the SAP HANA server. The SSH Keys should be created
for the same region as the SAP HANA server. The list of available SSH Keys UUIDs: https://cloud.ibm.com/vpcext/compute/sshKeys
# Example: SSH_KEYS = ["r010-8f72b994-c17f-4500-af8f-d05680374t3c", "r011-8f72v884-c17f-4500-af8f-d05900374t3c"]
ID_RSA_FILE_PATH = "ansible/id_rsa"
# Your existing id_rsa private key file path in OpenSSH format with 0600 permissions.
# This private key it is used only during the terraform provisioning and it is recommended to be changed after the
SAP deployment.
# It must contain the relative or absoute path from your Bastion.
# Examples: "ansible/id_rsa_s4hana" , "~/.ssh/id_rsa_s4hana" , "/root/.ssh/id_rsa".

$ ##########################################################
# SAP HANA Server variables:
##########################################################
HANA_SERVER_TYPE = ""
# The type of SAP HANA Server. Allowed vales: "virtual" or "bare metal"
# Example: HANA_SERVER_TYPE = "bare metal"
DB_HOSTNAME = ""
# The Hostname for the DB VSI. The hostname must be up to 13 characters, as required by SAP
# Example: DB_HOSTNAME = "icp4sapdb"
DB_PROFILE = ""
# The profile used for SAP HANA Server.
# The list of certified profiles for SAP HANA Virtual Servers is available here: https://cloud.ibm.com/docs/sap?
topic=sap-hana-iaas-offerings-profiles-intel-vs-vpc
# The list of certified profiles for SAP HANA Bare Metal Servers is available here:
https://cloud.ibm.com/docs/sap?topic=sap-hana-iaas-offerings-profiles-intel-bm-vpc.
# Details about all x86 instance profiles are available here: https://cloud.ibm.com/docs/vpc?topic=vpc-profiles.
# Example of Virtual Server Instance profile for SAP HANA: DB_PROFILE ="mx2-16x128".
# Example of Bare Metal profile for SAP HANA: DB_PROFILE = "bx2d-metal-96x384".
# For more information about supported DB/OS and IBM VPC, check SAP Note 2927211: "SAP Applications on IBM Virtual
Private Cloud".
DB_IMAGE = "ibm-redhat-8-6-amd64-sap-hana-5"
# OS image for DB Server. Validated OS images for SAP HANA Server: ibm-redhat-8-6-amd64-sap-hana-5, ibm-redhat-84-amd64-sap-hana-9, ibm-sles-15-4-amd64-sap-hana-6, ibm-sles-15-3-amd64-sap-hana-9.
# The list of available VPC Operating Systems supported by SAP: SAP note '2927211 - SAP Applications on IBM
Virtual Private Cloud (VPC) Infrastructure environment' https://launchpad.support.sap.com/#/notes/2927211; The
list of all available OS images: https://cloud.ibm.com/docs/vpc?topic=vpc-about-images
# Example: DB_IMAGE = "ibm-sles-15-4-amd64-sap-hana-6"
##########################################################
# Activity Tracker variables:
##########################################################
ATR_NAME = ""
# The name of an existent Activity Tracker instance, in the same region chosen for SAP system deployment.
# Example: ATR_NAME="Activity-Tracker-SAP-eu-de"

The hostname must be up to 13 characters as required by SAP. For more information about the rules that apply to hostnames for SAP
systems, see SAP Note 611361 - Hostnames of SAP ABAP Platform servers.
4. Customize your SAP system configuration. Modify the input.auto.tfvars file to specify SAP HANA system configuration and enter the
location of the downloaded SAP HANA Kit file.
$ ##########################################################
# SAP HANA configuration
##########################################################
HANA_SID = "HDB"
# SAP HANA system ID. Should follow the SAP rules for SID naming.
# Example: HANA_SID = "HDB"
HANA_SYSNO = "00"
# SAP HANA instance number. Should follow the SAP rules for instance number naming.
# Example: HANA_SYSNO = "01"
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 341

HANA_SYSTEM_USAGE = "custom"
# System usage. Default: custom. Suported values: production, test, development, custom
# Example: HANA_SYSTEM_USAGE = "custom"
HANA_COMPONENTS = "server"
# SAP HANA Components. Default: server. Supported values: all, client, es, ets, lcapps, server, smartda,
streaming, rdsync, xs, studio, afl, sca, sop, eml, rme, rtl, trp
# Example: HANA_COMPONENTS = "server"
KIT_SAPHANA_FILE = "/storage/HANADB/SP07/Rev73/51057281.ZIP"
# SAP HANA Installation kit path
# Example for Red Hat 8 or Suse 15: KIT_SAPHANA_FILE = "/storage/HANADB/SP07/Rev73/51057281.ZIP"
HDB_CONCURRENT_JOBS = "23"
# Number of concurrent jobs used to load and/or extract archives to HANA Host

5. Initialize the Terraform CLI.
terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
terraform plan --out plan1

You are asked to enter the IBM Cloud API key and the SAP HANA main password.
The SAP HANA main password must contain at least one digit (0-9), one lowercase letter (a-z), and one uppercase letter (A-Z). It can only
contain the following characters: a-z, A-Z, 0-9, !, @, #, $, _. It must not start with a digit or an underscore ( _ ).
7. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan --out plan1 again.
8. Deploy the SAP solution:
terraform apply "plan1"

Deploying SAP HANA DB on VSI or Bare Metal Server by using the Schematics user interface
Use these steps to configure the SAP HANA DB single VSI on your existing VPC by using the Schematics user interface. The scripts can take 1 2 hours to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the GitHub URL for the code you plan to deploy.
Select the Terraform version that is listed in the Readme file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Click Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your IBM Cloud API key.
A private SSH key to be used for the deployment.
(Optional) You can change the ID_RSA_FILE_PATH for your SSH key file that will be generated on Schematics and on the bastion
server.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 342

The ID(s) of the SSH key(s) that you created and uploaded to IBM Cloud. Enter the SSH key ID(s) in [] brackets and surrounded by
quotation marks, for example [ "ibmcloud_ssh_key_UUID1", "ibmcloud_ssh_key_UUID2",... ].
The floating IP address of the bastion server (deployment server).
The resource group where the IBM Cloud resources are created.
The region for your resources.
The zone for your resources.
Existing VPC name
Existing Subnet name
Existing Security group name
SAP HANA server type: virtual server instances or bare metal
Hostname
Profile
Image
Existing Activity Tracker name
SAP HANA SID
SAP HANA main password - must be at least 10 characters, upper, and lowercase letters, a number, and a special character, not an
exclamation point.
SAP HANA system number
SAP HANA system usage
SAP HANA components
SAP HANA kit file path
Number of SAP HANA concurrent jobs.
Click Save changes.
For a more detailed description of the parameters, check the GitHub repo Readme file, chapter General Input Variables. Also, make
sure to mark as “sensitive” the parameters that contain sensitive information like passwords, IBM Cloud API, the SSH private key and
SAP HANA password (they are marked as “sensitive” in the Readme file in the General Input Variables).
7. On the workspace Settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Next steps
For your SAP solution, in case you want to remove the resources that are created with the automation, then go to the Workspace page >
Actions and select Destroy Resources.
If you need to remove the resources created with the automation for your SAP solution, go to your project folder and run

terraform destroy .

Related information
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier VPC for SAP

on IBM Cloud® VPC with Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP license
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 343

This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP AAS for SAP HANA and AnyDB on IBM Cloud VPC
Introduction to IBM Cloud VPC and Additional Application Server (AAS) to HANA and AnyDB
You can use Terraform to automate IBM Cloud® VPC provisioning. The VPC provisioned includes virtual server instances with high network
performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers. After the VPC
is provisioned, the scripts use the Ansible Playbook to install the SAP system. IBM Cloud VPC infrastructure consists of SAP certified hardware
that uses Intel® Xeon CPUs and additional Intel® technologies.

IBM Cloud VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP on IBM Cloud
SAP NetWeaver is the core foundation of the SAP technology stack and is the platform that is used for ABAP and Java applications. The SAP
system can be installed and configured in IBM Cloud for various system and database types.
For more information about SAP system architectures on IBM Cloud VPC, see the infrastructure reference architectures for SAP for each
supported database type. The reference architecture section for SAP solutions running on IBM Cloud can be found here.

SAP Project Value Guide – Additional Application Server (AAS) to HANA
SAP projects vary widely in scope and budget, but none are considered trivial. Whether you are delivering a new SAP system or implementing
changes to an existing one, the requirements for error-free execution and reducing the project time to realized benefits are always present.
In many SAP project scenarios, the deployment of an SAP system is often a key and repeated task. This project value guide covers the
automated deployment of IBM Cloud VPC and Additional Application Server (AAS) to HANA. We will also discuss on SAP NetWeaver of HANA
database and Backing up the HANA database IBM Cloud Object Storage in their respective sections.
After your HANA DB and SAP NetWeaver application server are up and running, you may want additional SAP application servers deployed to
increase workload capacity. With this automation, deploying infrastructure, performing SAP software installation, and joining the existing SAP
system in less than twenty minutes is possible. For more information, go to VPC with Additional Application Server ABAP on Linux for SAP
HANA.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 344

Figure 1. Additional Application Server (AAS) to SAP instance and HANA instance

SAP Additional Application Server Instance
You can install one or more additional application server instances for an existing SAP system. Additional application server instances are
optional and can be installed on separate hosts.
An additional application server instance can run on:
The host of any instance of the existing SAP system
On a dedicated host - distributed on additional IBM VPC (VSI instance)

Figure 1. SAP NetWeaver 7.x with SAP HANA database single-host installation with AAS

For example, SAP NetWeaver (ABAP or Java stack) has a dedicated reference architecture that is running on SAP HANA or AnyDB databases
that are published on IBM cloud SAP NetWeaver on UNIX architecture diagram .
Manually deploying a VPC and installing an SAP system can be time-consuming. The Terraform automation assures not only a much quicker
implementation, but also a standardized and less prone to error deployment. Terraform and Ansible are used for automating the deployment
processes.
The Terraform scripts solution provides the automated deployment of a single host with SAP NetWeaver with either ASE SYB or SAP HANA db
on the Red Hat Enterprise Linux® 8.4 and SUSE 15.x for SAP Applications.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 345

The SAP installation media that are used for this deployment are the default media for SAP AAS of NetWeaver 7.x (ABAP stack) on SUSE/RHEL
with ASE SYB 16 or HANA 2.0 db as distributed instance available at the SAP Support Portal under INSTALLATION AND UPGRADE area. You
provide the installation media as an input parameter for Terraform for your SAP AAS solution chosen on dedicated kits storage from bastion
server.

Ansible for SAP installation
Ansible is an automation tool for the deployment of several IT tasks. Ansible is used for automating the installation of an SAP NetWeaver with
HANA or AnyDB. For more information about Ansible, see the Ansible Documentation.
The deployment is done by using the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found
on the Ansible core page.
The Ansible playbook is called directly by the Terraform script. The script starts with Terraform specific steps for creating the VPC, and
continues automatically with the Ansible specific steps to install the SAP system.

Where to run the scripts
The recommended way to run the scripts is from your Deployment Server because the Deployment Server has Terraform and Ansible already
installed. If you want to run the scripts from your local workstation, you need to install Terraform and Ansible locally.
For both the Deployment Server and local workstation, you must download the SAP Kits to the temporary storage assigned to you on the
Deployment Server. Ansible installs the kits for you. You specify the location of the Kits in the configuration files.

Prerequisites
Before you deploy any of the SAP automated solutions on IBM Cloud VPC, you create a Bastion server VPC in your chosen region. The Bastion
server is used for downloading and storing specific SAP solution media that are needed for later automation deployment. The Bastion server is
used for both CLI deployment scenarios, as well for Schematics UI deployments. For more information about how to create the Bastion server
and its corresponding VPC, see Automate SAP Bastion server – SAP media storage repository .
After bastion VPC deployment is complete, you must download the SAP Kits for the SAP AAS type and DB you want to deploy to the temporary
storage assigned to you on the Bastion Server.
Note: You need to have already deployed an SAP NetWeaver (ABAP) 7.X -standard or distributed installation on SUSE 15.3 /RHEL 8.4
either ASE SYB or HANA 2.0 db before you deploy SAP AAS of NetWeaver 7.x (ABAP stack) on SUSE/RHEL with ASE SYB 16 or HANA 2.0
as distributed instance. SAP AAS has to be connected to an already running SAP NW 7.X with the same type and version running on a
compatible DB version.
Ansible installs the kits for you. You specify the location of the Kits in the configuration files.
To save costs the Bastion server, with its SAP media dedicated storage, can be decommissioned after the SAP solutions are successfully
implemented on IBM Cloud VPC cloud. Or, you can keep the Bastion server and use it as a jump host for that specific region.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

VPC with Additional Application Server (AAS) ABAP on Linux for SAP HANA
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March
2025. Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM
Cloud Activity Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about
migrating from IBM Cloud Activity Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.
You can use Terraform scripts to create a single-tier VPC and create the AAS to HANA and AnyDB infrastructure on the VPC. The Terraform
scripts use the VPC information that you provide and then call the Ansible playbook to create the SAP architecture on the specified VPC.
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so
that you can rapidly build complex, cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon
CPUs and more Intel® technologies.
You have two deployment methods to choose from:
Terraform scripts that run from the CLI on your bastion server.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 346

Schematics user interface accessed from your cloud dashboard menu.
You can create SAP AAS NetWeaver 7.x on the SAP HANA-based ABAP stack.

SAP solution implemented
Many SAP enterprise solutions are built on the SAP platform (SAP NetWeaver) including:
SAP HANA as Primary Persistence for SAP NetWeaver-based applications
SAP Business Suite applications (ERP, CRM, and SCM, and other applications),
SAP Business Warehouse (BW), and
Other SAP enterprise solutions
SAP NetWeaver has two distinct aspects, ABAP and Java. Many applications that are built on the SAP NetWeaver’s ABAP or Java (or both)
application servers run on SAP DB owned HANA and ASE Sybase either in AnyDB platforms (MSSQL, Oracle, and Db2).
Technical interfaces are available for applications that are built on the SAP NetWeaver AS ABAP and AS Java to run on SAP HANA and AnyDB.
However, specific development enablement is normally required for each application to ensure that it runs optimally on the SAP HANA. SAP
Business Suite applications (ERP, CRM, SCM, and other applications), SAP Business Warehouse (BW), and other SAP NetWeaver-based
applications were modified to run on SAP HANA and have many advantages. Also, various components and complimentary applications that
are built on SAP NetWeaver can also run on SAP HANA or AnyDB by using the provided SAP NetWeaver DB interfaces.
The SAP HANA as primary persistence for SAP NetWeaver-based applications scenario has one restriction: SAP NetWeaver ABAP and Java
application servers must run on separate hardware servers from the SAP HANA hardware.

What is created
The scripts automate the virtual infrastructure resources, provisioning the processes for the SAP architecture in an existing VPC with a
distributed environment. SAP AAS NetWeaver 7.x (HANA or ASE SYB) application server on a distinct VSI VPC system and SAP HANA DB on a
dedicated server type VSI VPC box are provisioned. The scripts work in two phases.
During the first phase of Automate SAP bastion server – SAP media storage repository , the following virtual infrastructure resources based on
the components from the existing VPC created by the bastion server are:
1 VPC where the virtual server instance is provisioned.
1 security group. The rules for this security group are:
Allow inbound DNS traffic (port 53).
Allow inbound SSH traffic (TCP port 22).
Allow all outbound traffic from the virtual server instance.
Allow all traffic in the security group.
1 subnet to enable the networking in your VPC.
2 virtual server instances with SAP certified storage and network configurations.
1 floating IP address used to access your VPC virtual server instance over the public network.
During the second phase, the Ansible Playbooks is called and the SAP architecture is installed for both dedicated virtual server instance (VSI)
SAP application; VSI system and dedicated SAP HANA VSI box. The SAP architecture that is deployed on the SAP NetWeaver 7.x release is a
stand-alone dedicated SAP HANA 2.0 box release. For more information about this architecture, see Automating SAP HANA stand-alone
virtual server instance on IBM Cloud® VPC by using Terraform and Ansible.
The IBM Cloud Activity Tracker service should be used to capture the records of your IBM Cloud activities and monitor the activity of your IBM
Cloud account. You can use this service to investigate abnormal activity, critical actions, and comply with regulatory audit requirements. In
addition, you can be alert on the actions as they occur. The events that are collected comply with the Cloud Auditing Data Federation (CADF)
standard.
You can deploy an Activity Tracker instance along with the SAP system by using the SAP deployment Automation or if you have already created
one, you can specify the Activity Tracker name in the deployment variables. You can set the Activity Tracker plan variable according to your
chosen Service plans. By default, the Lite (free) plan is selected. For more information on how to provision an Activity Tracker instance, see
here.
Important:
Every user who accesses the IBM Cloud Activity Tracker service in your account must be assigned an access policy with an IAM user role
defined. The policy determines what actions that the user can perform within the context of the service or instance you select. The
allowable actions are customized and defined as operations that are allowed to be performed on the service. The actions are then

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 347

mapped to IAM user roles. For more information, see here.
You can provision only one instance of the service per IBM Cloud region.
IBM Cloud Activity Tracker provides a solution for administrators to capture, store, view, search, and monitor API activity in a single place. It
also offers a notification feature to alert you by using any of the supported notification channels.
Note: IBM Cloud Activity Tracker collects and stores audit records for API calls made to resources that run in the IBM Cloud. You can
archive these events on IBM Cloud for long-term storage.

Schematics deployment
When you run the scripts with the Schematics interface, you:
Enter the workspace information.
Enter the GitHub path for the chosen solution either on NetWeaver AAS for HANA.
Modify the parameters in the Schematics interface. They are the same parameters as the

input.auto.tfvars file that you use with the

cli.

Virtual server instance configuration
Following are the supported operating system images for SAP NetWeaver primary application server:
ibm-redhat-8-4-amd64-sap-applications-2
ibm-redhat-8-6-amd64-sap-applications-2
ibm-sles-15-3-amd64-sap-applications-2
ibm-sles-15-4-amd64-sap-applications-3
Following are the supported operating system images for SAP HANA database:
ibm-redhat-8-4-amd64-sap-hana-2
ibm-redhat-8-6-amd64-sap-hana-2
ibm-sles-15-3-amd64-sap-hana-2
ibm-sles-15-4-amd64-sap-hana-1
For both server instances there are:
Two SSH keys are configured to access SSH as root .
Three storage volumes as described in the input.auto.tfvars file.

What is created
The scripts use the information that you provide for an existing VPC and deploy AAS to SAP HANA or AnyDB on a different host than CI (SAP
Central Instance) VSI host. For more information about this architecture, see SAP NetWeaver 7.x on UNIX with HANA or AnyDB on IBM Cloud
VPC on IBM Cloud VPC. You specify the information for the VPC to use in the input.auto.tfvars file.
The scripts call the Ansible Playbooks to install the SAP architecture.

Script files
The configuration and script files are provided on GitHub. Each supported interface for the SAP solution installation has its own folder in the
GitHub repository:
GitHub repository for Terraform – AAS HANA

Terraform interface
To run the Terraform script, you modify:
The input.auto.tfvars file to specify the existing VPC resources for your solution. Specify the variables for the existing VPC:
VPC name
Security group
Subnet
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 348

Hostname
Profile
Image
Up to two SSH keys
You can change the default SAP system configuration settings to match your solution. You can also specify the location where you
downloaded the SAP kits.
The IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files to install AAS to SAP HANA and AnyDB on the
specified VPC in your IBM Cloud account.

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM® Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
Before you use the scripts in the bastion cli:
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account .
If you have not already, create a Bastion server to store the SAP kits. For more information, see

Automate SAP bastion server - SAP

media storage repository.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses the
files. For more information, see the readme file.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
Terraform should already be installed on the bastion server that you deployed. For more information, see

Bastion server for SAP

deployment.
(Optional - Catalog Tile) create secrets for your credentials and passwords by using the Secrets Manager.

Deploying SAP AAS NetWeaver 7.x on HANA by using the Schematics user interface
Use these steps to configure the SAP Additional Application Server (AAS) NetWeaver with HANA or AnyDB on your existing VPC by using the
Schematics interface. The script takes 2 - 3 hours to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the URL for the Schematics interface.
Select the Terraform version that is listed in the readme file.
Click Next.
4. On the workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace settings page, in the input variables section, review the default input variables and provide values that match your
solution.
For a more detailed description of each parameter, check the GitHub repo AAS HANA readme file, chapter “Input parameter file”. Also,

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 349

make sure to mark the parameters that contain sensitive information like passwords, API, and ssh private keys as "sensitive". These
parameters are marked as “sensitive” in the readme file, under “Input parameter file”.
7. On the workspace settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occur during the provisioning, modification, or deletion process.

Deploying SAP AAS NetWeaver (ABAP) on HANA with the Deployable Architecture tile interface
Use these steps to configure the SAP AAS NetWeaver (ABAP) on HANA on your existing VPC by using the catalog tile interface. The script takes
2 - 3 hours to complete.
1. From the IBM Cloud catalog, select VPC with Additional Application Server ABAP on Linux for SAP HANA on HANA tile. The Create tab
opens for VPC with Additional Application Server ABAP on Linux for SAP HANA. For more information about this deployment, see the
About tab or the readme file link.
2. Select the latest version.
3. Select VPC with Additional Application Server ABAP on Linux for SAP HANA on Deployable Architecture tile variation.
4. Click Review deployment options:
Add to project to add this deployment to an IBM Cloud project and combine it with other deployments. IBM Cloud projects include
several more pipeline steps before deployment, including deployment validation, cost calculation, compliance verification, and
approval process.
Create from the CLI to get the CLI command. With this command you can trigger the deployment from the CLI.
Work with code to embed the code into other terraform deployments.
Deploy with IBM Cloud Schematics to trigger the deployment process directly.
5. Select Deploy with IBM Cloud Schematics .
6. Add the input parameters for this installation. There are 3 categories of parameters:
Workspace - These parameters define the workspace that is automatically created in Schematics:
Enter a name for the workspace or use the default name.
The Resource Group used to create resources. Use default or create a Resource Group.
Select a location to create your Schematics workspace. The workspace location need not match the resource location.
Required input variables - Review the default input variables and provide values that match your solution. These parameters are
specific to your deployment. For more detailed information, see the Readme file.
Parameter

Description

BASTION_FLOATING_IP

Required only for Schematics Deployments. The Floating IP from the Bastion Server.

HOSTNAME

The hostname for the VSI. The hostname should be up to 13 characters as required by SAP. For
more information on the rules regarding hostnames for SAP systems, check SAP Note 611361:
Hostnames of SAP ABAP Platform servers

REGION

The cloud region to deploy the solution. The regions and zones for VPC are listed here. Review
supported locations in IBM Cloud Schematics here. Sample value: eu-de.

RESOURCE_GROUP

The name of an existing Resource Group for VSIs and Volumes resources. Default value: "Default".
The list of Resource Groups is available here.

SECURITY_GROUP

The name of an existing Security group. The list of security groups is available here.

SSH_KEYS

The list of SSH Keys UUIDs that are allowed to SSH as root to the VSI can contain one or more IDs.
The list of SSH Keys is available here. Sample input (use your own SSH UUIDs from IBM Cloud):
["r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a", "r010-3fcd9fe7-d4a7-41ce-8bb3d96e936b2c7e"]

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 350

SUBNET

The name of an existing subnet. The list of subnets is available here.

VPC

The name of an existing VPC. The list of VPCs is available here.

ZONE

The cloud zone where to deploy the solution. Sample value: eu-de-2.

ibmcloud_api_key

IBM Cloud API key (Sensitive* value).

private_ssh_key

Required only for Schematics Deployments - Input your id_rsa private key pair content in OpenSSH
format (Sensitive* value). This private key should be used only during the terraform provisioning
and it is recommended to be changed after the SAP deployment.

hdb_instance_number

The instance number of the SAP HANA database server.

sap_aas_instance_number

Technical identifier for the internal processes of the additional application server.

sap_ascs_instance_number

Technical identifier for the internal processes of ASCS.

sap_ci_host

IP address of the existing SAP Central Instance.

sap_ci_hostname

The hostname of the existing SAP Central Instance.

sap_ci_instance_number

Technical identifier for the internal processes of the Central Instance.

sap_sid

The SAP system ID identifies the entire SAP system.

sap_main_password

Common password for all users that are created during the installation (See Obs*).

Optional variables - Review and update the optional input variables. The Ansible scripts expect the SAP kits to be in the default
locations listed. For more information, see the Readme file - Input Parameters.
Parameter

Description

ID_RSA_FILE_PATH

The file path for private_ssh_key is automatically generated by default. If it is changed, it must contain the
relative path from Git repo folders. Default value: "ansible/id_rsa".

IMAGE

The OS image used for the VSI. A list of images is available here.

PROFILE

The profile used for the VSI. A list of profiles is available here. For more information about supported
DB/OS and IBM Gen 2 Virtual Server Instances (VSI), check SAP Note 2927211: SAP Applications on IBM
Virtual Private Cloud.

VOL1

Volume 1 Size - The size for the disks in GB that are to be attached to the VSI and used by SAP.

VOL2

Volume 2 Size - The size for the disks in GB that are to be attached to the VSI and used by SAP.

kit_sapcar_file

Path to the sapcar binary, as downloaded from SAP Support Portal.

kit_swpm_file

Path to the SWPM archive (SAR), as downloaded from SAP Support Portal.

kit_saphostagent_file

Path to the SAP Host Agent archive (SAR), as downloaded from SAP Support Portal.

kit_hdbclient_file

Path to the HANA DB client archive (SAR), as downloaded from SAP Support Portal.

7. Accept the license agreement.
8. Select Deploy. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 351

Creating the infrastructure using Terraform with the bastion server CLI
Use these steps to configure the IBM Cloud Provider plug-in and use Terraform to install SAP AAS to SAP HANA and AnyDB on your existing
VPC on an already deployed SAP NetWeaver 7.X with SAP HANA 2.0 or ASE SYB as a Central Instance.
The script takes 1 - 2 hours to complete.
1. Access the bastion server cli.
2. Clone the solution repository and change to the folder.
ASE SYB 16 Clone the solution repository from https://github.com/IBM-Cloud/sap-aas-abap-ase-syb and cd to the sap-aas-abap-asesyb/cli folder.
$ git clone https://github.com/IBM-Cloud/sap-aas-abap-ase-syb
cd sap-aas-abap-ase-syb/cli/

SAP HANA 2.0: Clone the solution repository from https://github.com/IBM-Cloud/sap-abap-hana-aas and cd to the sap-abap-hana-aas
folder.
$ git clone https://github.com/IBM-Cloud/sap-abap-hana-aas.git
cd sap-abap-hana-aas/

3. Modify the input.auto.tfvars file to specify the information for the existing VPC, your region, zone, networking component names,
hostname for the AAS VSI,profile, and image. You need your 40-digit SSH key ID for this file. The second SSH key is optional. For more
options for profile, see Instance Profiles. For more options, see Images. For descriptions of the variables, see the readme file.
The VSI OS images that are supported for this solution for Netweaver Additional Application Server are:
ibm-redhat-8-4-amd64-sap-applications-2
ibm-redhat-8-6-amd64-sap-applications-2
ibm-sles-15-3-amd64-sap-applications-2
ibm-sles-15-4-amd64-sap-applications-4
$ # Infra VPC variables for ASE SYB
REGION

= "eu-de"

ZONE

= "eu-de-2"

VPC

= "ic4sap"

# EXISTING Security group name

SECURITY_GROUP = "ic4sap-securitygroup"
RESOURCE_GROUP
SUBNET

# EXISTING Security group name

= "wes-automation"

= "ic4sap-subnet"

SSH_KEYS

# EXISTING Subnet name

= [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a" , "r010-3fcd9fe7-d4a7-41ce-8bb3-

d96e936b2c7e" ]
# SAP AAS VSI variables:
HOSTNAME = "sapnwase-as01"
PROFILE = "bx2-4x16"
IMAGE = "ibm-redhat-8-4-amd64-sap-applications-2

$ # Infra VPC variables for ABAP HANA
REGION

= "eu-de"

ZONE

= "eu-de-2"

VPC

= "ic4sap" # EXISTING Security group name

SECURITY_GROUP

= "ic4sap-securitygroup" # EXISTING Security group name

RESOURCE_GROUP

= "wes-automation"

SUBNET

= "ic4sap-subnet" # EXISTING Subnet name

SSH_KEYS

= [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a" , "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ]

ID_RSA_FILE_PATH = "ansible/id_rsa"
# SAP AAS variables:
HOSTNAME = "sapnwapp"
PROFILE = "bx2-4x16"
IMAGE = "ibm-redhat-8-6-amd64-sap-applications-2"

Edit your IBM Cloud Activity Tracker (only for ABAP stack) input variables:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 352

$ # Activity Tracker variables:
ATR_PROVISION = "true"
# Activity Tracker : Disable this to not provision Activity Tracker instance.
# If an Activity Tracker instance already exists in the same region where this solution is to be deployed then
# disable (ATR_PROVISION = "false") this to avoid provisioning an Activity Tracker instance.
# A new instance of Activity Tracker will be deployed with this solution if ATR_PROVISION=true
# Example to create Activity Tracker instance: ATR_PROVISION = "true"
# Example to integrate existing Activity Tracker instance : ATR_PROVISION = "false"
ATR_NAME = "Activity-Tracker-COS-eu-de"
# Provide the Activity Tracker instance name to create or
# provide the existing Activity Tracker instance name in the same region where this solution is to be be deployed.
# Example: ATR_NAME = "Activity-Tracker-COS-eu-de"
ATR_TAGS = [""]
# Activity Tracker: (Optional) only if ATR_PROVISION = "true", tags that should be applied to the Activity Tracker
instance.
# example ATR_TAGS = ["activity-tracker-cos"]
ATR_PLAN = "lite"
# Mandatory only if ATR_PROVISION is set to true. Activity Tracker: The type of plan the service instance should
run under (lite, 7-day, 14-day, or 30-day).
# The list of service plan is avaialble here: https://cloud.ibm.com/docs/activity-tracker?topic=activity-trackerservice_plan#service_plan"
# Example ATR_PLAN = "lite"

4. Customize your SAP system configuration. In the same file, input.auto.tfvars, edit the SAP system configuration variables that are passed
to the Ansible automated deployment. For descriptions of the variables, see the readme file.
$ # SAP system configuration - for ASE SYB
sap_sid = "NWD"
sap_ci_host = "10.243.132.10"
sap_ci_hostname = "sapnwase"
sap_ci_instance_number = "00"
sap_ascs_instance_number = "01"
sap_aas_instance_number = "00"
# Kits paths
kit_sapcar_file = "/storage/NW75SYB/SAPCAR_1010-70006178.EXE"
kit_swpm_file = "/storage/NW75SYB/SWPM10SP31_7-20009701.SAR"
kit_saphotagent_file = "/storage/NW75SYB/SAPHOSTAGENT51_51-20009394.SAR"

$ # SAP system configuration - for ABAP HANA
sap_sid = "NWD"
sap_ci_host = "10.243.132.10"
sap_ci_hostname = "sapnwapp01"
sap_ci_instance_number = "00"
sap_ascs_instance_number = "01"
hdb_instance_number = "00"
sap_aas_instance_number = "00"
# Kits paths
kit_sapcar_file = "/storage/NW75HDB/SAPCAR_1010-70006178.EXE"
kit_swpm_file = "/storage/NW75HDB/SWPM10SP31_7-20009701.SAR"
kit_saphotagent_file = "/storage/NW75HDB/SAPHOSTAGENT51_51-20009394.SAR"
kit_hdbclient_file = "/storage/NW75HDB/IMDB_CLIENT20_009_28-80002082.SAR"

Ansible decompresses the rest of the SAP kit files. For more information, see the readme file.
5. Initialize the Terraform CLI.
terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
terraform plan plan1

Enter an SAP main password and your API key.
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters:
a-z, A-Z, 0-9, @, #, $, . This password cannot contain exclamation points '!'. The password must not start with a digit or an underscore ( ).

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 353

7. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
8. Apply the saved plan.
$ terraform apply "plan1"

The virtual private cloud and components are created and you see output similar to the

terraform plan output.

9. Add the SAP credentials and the virtual server instance IP to the SAP GUI. For more information about the SAP GUI, see

SAP GUI.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run

terraform plan

and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The Terraform
scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove the SAP Netweaver 7.X on HANA or AnyDB installation, go to your project folder and run

terraform destroy . The

terraform destroy command does not remove the VPC in this scenario because the VPC was created before these Terraform scripts were

run.
If the resources created with the SAP deployment automation are removed, the Activity Tracker instance is also removed, if it is provisioned at
the same time with the SAP solution (when ATR_PROVISION parameter is set to true during the deployment of the SAP solution).

Related information
For more information about Terraform on IBM Cloud, see Getting started with Terraform on IBM Cloud .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier virtual

private cloud for SAP by using Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP license
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
IBM Cloud Activity Tracker

SAP NetWeaver and ASE SYB on IBM Cloud VPC
Introduction to SAP NetWeaver and ASE SYB DB 2-tier and 3-tier on IBM Cloud VPC
You can use Terraform to automate IBM Cloud® VPC provisioning. The VPC provisioned includes virtual server instances with high network
performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers. After the VPC
is provisioned, the scripts use the Ansible Playbook to install the SAP system. IBM Cloud VPC infrastructure consists of SAP certified hardware
that uses Intel® Xeon CPUs and additional Intel® technologies.

IBM Cloud VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 354

Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP on IBM Cloud
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for ABAP and Java applications. The SAP
system can be installed and configured in IBM Cloud for various system and database types.
For more information about SAP system architectures on IBM Cloud VPC, see the infrastructure reference architectures for SAP for each
supported database type. For example, SAP NetWeaver 7.x on UNIX with ASE SYB on IBM Cloud VPC is the dedicated reference architecture
for this SAP solution.
The SAP installation media that are used for this deployment are the default media for SAP NetWeaver 7.5 with ASE SYB v16. The media are
available at the SAP Support Portal under INSTALLATION AND UPGRADE area. You provide the installation media as an input parameter for
Terraform.
This automated solution can be deployed in 2 scenarios: standard deployment and distributed deployment.

Standard deployment
In a standard system, all main instances run on a single virtual server instance (VPC) within a private subnet. You can install a central system
on a single host.
Instances available in standard deployment:
ABAP central services instance (ASCS instance) Contains the ABAP message server and the ABAP enqueue server.
SAP recommends installing the ASCS instance because ASCS is used to cluster the message server and enqueue server separately from
the central instance. However, you can also install your SAP system without the ASCS instance. In this case, follow the instructions in
Installing a Central or Distributed System Without the ASCS Instance.
Optionally, you can install the ASCS instance with an embedded SAP Web Dispatcher. For more information, see ASCS Instance with
Embedded SAP Web Dispatcher.
Database instance (DB instance)
Central instance
Additionally, you can install one or more dialog instances. For more information, see SAP NW with SYB reference architecture section
Architectural design on IBM Cloud VPC on Unix .
Manually deploying a VPC and installing an SAP system can be time-consuming. The Terraform automation assures not only a much quicker
implementation, but also a standardized and less error-prone deployment. Terraform and Ansible are used for automating the deployment
processes.

Distributed deployment
In a distributed system, every instance can run on a separate host (VSI). Instances installed in a distributed hosts architecture include:
Database instance (DB instance)
Central instance
Additionally, you can install one or more dialog instances. For more information, see SAP NW with SYB reference architecture section
Architectural design on IBM Cloud VPC on Unix .
The Terraform scripts solution provides the automated deployment of a:
Distributed host for SAP NetWeaver App instance and a
Second host with an ASE SYB database instance on the Red Hat Enterprise Linux 8 and SUSE 15 for SAP Applications.
The SAP installation media that are used for this deployment are the default media for SAP NetWeaver 7.5 with ASE SYB ASE SYB v16. The
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 355

media are available at the SAP Support Portal under INSTALLATION AND UPGRADE area. You provide the installation media as an input
parameter for Terraform.

Ansible for SAP installation
Ansible is an automation tool for the deployment of several IT tasks. Ansible is used for automating the installation of an SAP NetWeaver with
ASE SYB. For more information about Ansible, see the Ansible Documentation.
The deployment is done by using the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found
on the Ansible core page.
The Ansible playbook is called directly by the Terraform script. The script starts with Terraform specific steps for creating the VPC, and
continues automatically with the Ansible specific steps to install the SAP system.

Where to run the scripts
The recommended way to run the scripts is from your Deployment Server because the Deployment Server has Terraform and Ansible already
installed. If you want to run the scripts from your local workstation, you need to install Terraform and Ansible locally.
For both the Deployment Server and local workstation, you must download the SAP Kits to the temporary storage assigned to you on the
Deployment Server. Ansible installs the kits for you. You specify the location of the Kits in the configuration files.

Prerequisite, create a Bastion server to run the scripts
Before you deploy any of the SAP automated solutions on IBM Cloud VPC, you create a Bastion server VPC in your chosen region. The Bastion
server is used for downloading and storing specific SAP solution media that are needed for later automation deployment. The Bastion server is
used for both CLI deployment scenarios, as well for Schematics UI deployments. For more information about how to create the Bastion server
and its corresponding VPC, see Automate SAP Bastion server – SAP media storage repository .
After Bastion VPC deployment is complete, you must download the SAP Kits to the temporary storage assigned to you on the Bastion Server.
Ansible installs the kits for you. You specify the location of the Kits in the configuration files.
To save costs the Bastion server, with its SAP media dedicated storage, can be decommissioned after the SAP solutions are successfully
implemented on IBM Cloud VPC cloud. Or, you can keep the Bastion server and use it as a jump host for that specific region.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Deploying SAP NetWeaver 7.x and ASE SYB on an existing IBM Cloud VPC (Terraform and Ansible)
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so
that you can rapidly build complex, cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon
CPUs and additional Intel® technologies.
You can use Terraform scripts to create either:
A single-tier VPC and create the SAP and ASE SYB infrastructure on the VPC within same host (VSI)
A 3-tier (distributed) system and create the SAP and ASE SYB infrastructure on the separate hosts (VSIs).
The Terraform scripts use the VPC information that you provide and then call the Ansible playbook to create the SAP architecture on the
specified VPC.

What is created
The scripts use the information that you provide for an existing VPC and deploy NW7.X with ASE SYB. For more information about this
architecture, see SAP NetWeaver 7.x on UNIX with ASE SYB on IBM Cloud VPC . You specify the information for the VPC to use in the
input.auto.tfvars file.

The scripts call the Ansible Playbook to install the SAP architecture.

Schematics deployment
When you run the scripts with the Schematics interface, you:
Enter the URL for the GitHub repository for the Schematics Terraform files
Modify the parameters in the Schematics interface. They are the same parameters as the input.auto.tfvars file that you use with the cli.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 356

Terraform deployment
The configuration and script files are provided on GitHub. Each supported interface for the SAP solution installation has its own folder in the
GitHub repository:
Using Terraform on the Bastion server for standard - https://github.com/IBM-Cloud/sap-netweaver-abap-ase-sybstandard/tree/main/cli
Using Terraform on the Bastion server for distributed deployment - https://github.com/IBM-Cloud/sap-netweaver-abap-sybdistributed/tree/main/cli
Beore you run the Terraform scripts, you modify:
The input.auto.tfvars file to specify the existing VPC resources for your solution. You specify the variables for the existing VPC:
VPC name
Security group
Subnet
HostName
Profile
Image
Up to two SSH keys
You can change the default SAP system configuration settings to match your solution. You also specify the location where you downloaded the
SAP kits.
The IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files to install SAP NetWeaver 7.X with ASE SYB v16 on
the specified VPC in your IBM Cloud account.

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from {{site.data.keyword.ibm}}.
As a recommended practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM® Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
Before you use the scripts in the Bastion cli or Schematics:
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account .
If you have not already, create a Bastion server to store the SAP kits. For more information, see

Automate SAP bastion server - SAP

media storage repository.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses the
files. For more information, see the readme file.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
Terraform should already be installed on the bastion server that you deployed. For more information, see Bastion server for SAP
deployment.

Creating the infrastructure with the Schematics user interface
Use these steps to configure the SAP NetWeaver 7.X with ASE SYB on your existing VPC by using the Schematics user interface. The scripts can
take 1 - 2 hours to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the URL of Schematics folder.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 357

Select the Terraform version that is listed in the readme file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your API key
Your private SSH key from your local machine
The ID for the SSH key that you created and uploaded to IBM Cloud. Enter the SSH key ID in square brackets and quotation marks,
for example [ "ibmcloud_ssh_key_UUID1","ibmcloud_ssh_key_UUID2",... ].
The Region for your resources
The Zone for your resources
Whether to use an existing VPC or create one
Whether to use an existing subnet
Whether to create new port only when a new subnet is created
TCP port range: mimimun and maximum
VPC name
Subnet name
Security group name
Hostname
Profile
Image
Minimal recommended disk sizes
SAP main password - must be at least 10 characters, uppercase and lowercase letters, a number, and a special character, not an
exclamation point.
Click Save changes.
For a more detailed description of each of the parameters, check the GitHub repo readme file, chapter “Input parameter file”. Also, make
sure to parameters that contain sensitive information, like passwords, API, and ssh private keys as "sensitive". These parameters are
marked as “sensitive” in the readme file, under “Input parameter file”.
7. On the workspace Settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Creating the infrastructure by using Terraform with the Bastion server CLI
Use these steps to configure the IBM Cloud Provider plug-in and use Terraform to install SAP NetWeaver 7.X with ASE SYB (standard or
distributed architecture) on your existing VPC. The scripts can take 1 - 2 hours to complete.
1. Access the Bastion server cli.
2. For Standard deployment: Clone the solution repository from https://github.com/IBM-Cloud/sap-netweaver-abap-ase-syb-standard and
cd to the sap-netweaver-abap-ase-syb-standard folder.
$ $ git clone https://github.com/IBM-Cloud/sap-netweaver-abap-ase-syb-standard.git
$ cd sap-netweaver-abap-ase-syb-standard

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 358

3. For Distributed deployment:
Clone the solution repository from https://github.com/IBM-Cloud/sap-netweaver-abap-syb-distributed and cd to the sap-netweaverabap-syb-distributed/cli folder.
$ $ git clone https://github.com/IBM-Cloud/sap-netweaver-abap-syb-distributed.git
$ cd sap-netweaver-abap-syb-distributed/cli

4. Specify your VPC variables, for standard or distributed deployment. Modify the input.auto.tfvars file to specify the information for the
existing VPC, your zone, VPC and component names, profile, and image. You need your 40-digit SSH key ID for this file. The second SSH
key is optional. For more options for profile, see Instance Profiles. For more options for image, see Images. For descriptions of the
variables, see the standard readme or distributed readme file.
For standard deployment:
$ #Infra VPC variables for standard deployment
ZONE

= "eu-de-2"

VPC

= "sap"

SECURITYGROUP

= "sap-securitygroup"

SUBNET

= "sap-subnet"

HOSTNAME

= "db2saps1"

PROFILE

= "bx2-4x16"

IMAGE

= "ibm-redhat-8-6-amd64-sap-applications-2"

SSH_KEYS

= [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a" , "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ]

For distributed deployment:
$ #Infra VPC variables for distributed deployment
ZONE

= "eu-de-2"

VPC

= "sap"

SECURITYGROUP
SUBNET

= "sap-securitygroup"

= "sap-subnet"

DB-HOSTNAME = "sapnwasedb"
DB-PROFILE = ""bx2-4x16"
DB-IMAGE = "ibm-redhat-8-6-amd64-sap-applications-2"
APP-HOSTNAME = "sapnwapp"
APP-PROFILE = "bx2-4x16"
APP-IMAGE = "ibm-redhat-8-6-amd64-sap-applications-2"
SSH_KEYS

= [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a" , "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ]

5. Customize your SAP system configuration, standard or distributed. In the same file, input.auto.tfvars, edit the SAP system configuration
variables that are passed to the Ansible automated deployment. For descriptions of the variables, see the readme file.
For standard deplyoment:
$ #SAP system configuration for standard deployment
sap_sid = "NWD"
sap_ci_instance_number = "00"
sap_ascs_instance_number = "01"
#Kits paths
kit_sapcar_file = "/storage/NW75SYB/SAPCAR_1010-70006178.EXE"
kit_swpm_file = "/storage/NW75SYB/SWPM10SP31_7-20009701.SAR"
kit_saphotagent_file = "/storage/NW75SYB/SAPHOSTAGENT51_51-20009394.SAR"
kit_sapexe_file = "/storage/NW75SYB/SAPEXE_900-80002573.SAR"
kit_sapexedb_file = "/storage/NW75SYB/SAPEXEDB_900-80002616.SAR"
kit_igsexe_file = "/storage/NW75SYB/igsexe_13-80003187.sar"
kit_igshelper_file = "/storage/NW75SYB/igshelper_17-10010245.sar"
kit_ase_file = "/storage/NW75SYB/51055443_1.ZIP"
kit_export_dir = "/storage/NW75SYB/EXP"

For distributed deployment
$ #SAP system configuration for distributed deployment
sap_sid

= "NWD"

sap_ci_instance_number = "00"
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 359

sap_ascs_instance_number = "01"
#Kits paths
kit_sapcar_file = "/storage/NW75SYB/SAPCAR_1010-70006178.EXE"
kit_swpm_file =

"/storage/NW75SYB/SWPM10SP31_7-20009701.SAR"

kit_saphotagent_file = "/storage/NW75SYB/SAPHOSTAGENT51_51-20009394.SAR"
kit_sapexe_file = "/storage/NW75SYB/SAPEXE_900-80002573.SAR"
kit_sapexedb_file = "/storage/NW75SYB/SAPEXEDB_900-80002616.SAR"
kit_igsexe_file = "/storage/NW75SYB/igsexe_13-80003187.sar"
kit_igshelper_file = "/storage/NW75SYB/igshelper_17-10010245.sar"
kit_ase_file = "/storage/NW75SYB/51055622_1.ZIP"
kit_export_dir = "/storage/NW75SYB/EXP"

6. Remember, you must manually decompress the kit_export_dir file. Ansible decompresses the rest of the SAP kit files. For more
information, see the readme file.
7. Initialize the Terraform CLI. terraform init
8. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
terraform plan --out plan1

You must enter an SAP main password and your API key.
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters:
a-z, A-Z, 0-9, @, #, $, _. This password cannot contain exclamation points '!'. The password must not start with a digit or an underscore (
_ ).
9. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
10. Create the virtual private cloud for SAP instance and IAM access policy in {{site.data.keyword.cloud_notm}}.
$ terraform apply "plan1"

The virtual private cloud and components are created and you see output similar to the

terraform plan output.

11. Create the virtual private cloud for SAP instance and IAM access policy in IBM Cloud.
12. Add the SAP credentials and the virtual server instance IP to the SAP GUI. For more information about the SAP GUI, see

SAP GUI.

Deploying SAP NetWeaver 7.x and Db2 on 3-tier by using the Schematics user interface
Use these steps to configure the SAP NetWeaver 7.x with Db2 3-tier on your existing VPC by using the Schematics user interface. The scripts
can take 1 - 2 hours to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the GitHub URL for the code you plan to deploy.
Select the Terraform version that is listed in the README file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Click Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 360

Your API key
Your private SSH key from your local machine
(Optionl) You can change the ID_RSA_FILE_PATH for your SSH key that will be autogenerated on Schematics and Bastion Server
The ID for the SSH key that you created and uploaded to IBM Cloud. Enter the SSH key ID in square brackets and quotation marks,
for example [ "ibmcloud_ssh_key_UUID1","ibmcloud_ssh_key_UUID2",... ].
The region for your resources
The zone for your resources
Whether to use an existing VPC or create one
Whether to use an existing subnet
Whether to create new port only when a new subnet is created
TCP port range, nimimun and maximum
VPC name
Subnet name
Security group name
Hostname
Profile
Image
Minimal recommended disk sizes
SAP main password - must be at least 10 characters, upper and lowercase letters, a number, and a special character, not an
exclamation point.
Click Save changes.
For a more detailed description of each of the parameters, check the GitHub repo README file, chapter “Input parameter file”. Also,
make sure to mark as “sensitive” the parameters that contain sensitive information like passwords, API, and SSH private keys (they are
marked as “sensitive” in the README file in the “Input parameter file”).
7. On the workspace Settings page, click Generate plan. Wait for the plan to complate.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run

terraform plan

and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The Terraform
scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove the Netweaver 7.X and ASE SYB installation, go to your project folder and run

terraform destroy . The terraform

destroy command does not remove the VPC in this scenario because the VPC was created before these Terraform scripts were run.

Related information
For more information about Terraform on IBM Cloud, see Getting started with Terraform on IBM Cloud .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier virtual

private cloud for SAP by using Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 361

SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP NetWeaver(ABAP) on ASE SYBASE HA SZ deployment on IBM Cloud VPC
Automating SAP workload HA deployment on IBM Cloud VPC with Terraform and Ansible
You can use Terraform to automate IBM Cloud® VPC provisioning. The VPC provisioned includes virtual server instances with high network
performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers. After the VPC
is provisioned, the scripts use the Ansible Playbooks to install the SAP system.

IBM Cloud VPC introduction
VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private and secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
VPC’s logical isolation is implemented by using virtual network functions and security features that gives the enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings including virtual servers for VPC.
Use the following information to understand a simple use-case for planning, creating, and configuring resources for your VPC, and learn more
about VPC overviews and VPC tutorials. For more information about the VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP products architecture on IBM Cloud VPC
A Virtual Private Cloud (VPC) contains one of the most secure and reliable cloud environments for SAP applications within your own VPC with
virtual server instances. This represents an Infrastructure-as-a-Service (IaaS) within IBM Cloud that offers all the benefits of isolated, secure,
and flexible virtual cloud infrastructure from IBM. In comparison, the IBM Cloud classic infrastructure virtual servers offering uses virtual
instances with native and VLAN networking to communicate with each other within a data center; however, the instances are restricted in one
well-working pod by using subnet and VLAN networking as a gap scale up of virtual resources should rely between the pods. The IBM Cloud
VPC network orchestrator layer concept eliminates the pod boundaries and restrictions, so this new concept handles all the networking for
every virtual instance running within VPC across regions and zones.

Highly available system for SAP NetWeaver on IBM Cloud VPC
In a Highly Available (HA) system, every instance can run on a separate IBM Cloud virtual server instance. The cluster HA configuration for the
SAP application server consists of two virtual server instances, each of them located in the same zone within the region by using placement
groups. Placement groups assure that both cluster resources and cloud resources are also located in different compute nodes as specified in
the following placement groups section:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 362

Figure 1. SAP HA for SAP applications cluster nodes PAS (Active) and AAS (Active)

Placement groups on IBM Cloud VPC for SAP HA architecture
Placement Groups (PG) for VPC have two different anti-affinity strategies for high availability. By using the placement strategies, you minimize
the chance of service disruption with virtual server instances that are placed on different hosts or into an infrastructure with separate power
and network supplies.
The design of placement groups for IBM Cloud virtual servers solves this issue. Placement groups gives a measure of control over the host on
which a new public virtual server is placed. In this release, a “spread” rule is implemented, which means that the virtual servers within a
placement group is spread onto different hosts. You can build a highly available application within a data center and know that your virtual
servers are isolated from each other.
Placement groups with the spread rule are available to create in selected IBM Cloud data centers. After a spread rule is created, you can
provision a virtual server into that group and ensure that it is not on the same host as any of your other virtual servers. This feature comes with
no cost.
You can create your placement group and assign upto four new virtual server instances. With the spread rule, each of your virtual servers are
provisioned on different physical hosts. In the following configuration example, the “Power Spread” option is used:

Figure 2. Placement groups host spread

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 363

Figure 3. Placement groups power spread

Following are the SAP instances required for HA scenario:
ABAP SAP Central Services (ASCS) instance - contains the ABAP message server and the ABAP enqueue server.
Enqueue Replication Server (ERS) instance for the ASCS instance.
Database instance
Primary Application Server (PAS) instance on node 1.
Additional Application Server (AAS) instance on node 2.
Note: It is recommended to run both the ASCS instance and the ERS instance in a switchover cluster infrastructure.

IBM Cloud File Storage for VPC for SAP HA architecture
IBM Cloud File Storage for VPC technology is used to make the SAP directories available to the SAP system. The technologies of choice are
NFS, shared disks, and cluster file system. If you have decided to use the HA solution for your SAP system, make sure that you properly
address the HA requirements of the SAP file systems in your SAP environment.

Figure 4. File shares for VPC

File shares that are mounted as NFS permanent file systems on both cluster nodes for SAP HA application:
/usr/sap/<SAPSID>/SYS
/sapmnt<SAPSID>
/usr/sap/trans

Cluster-managed file systems for SAP HA application: ASCS
/usr/sap/<SAPSID>/ASCS00
/usr/sap/<SAPSID>/ERS01

Permanent NFS mount on SAP HA application node 1 PAS instance:
/usr/sap/<SAPSID>/Dxx

Permanent NFS mount on SAP HA application node 2 dialog instance:
/usr/sap/<SAPSID>/Dyy

Prerequisites
You need to install the hardware (hosts, disks, and network) and decide how to distribute the database, SAP instances, and if required, the
Network File System (NFS) server over the cluster nodes.

Context
Following are the types of SAP directories:
Physically shared directories: /<sapmnt>/<SAPSID> and /usr/sap/trans
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 364

Logically shared directories that are bound to a node, such as /usr/sap , with the following local directories:
/usr/sap/<SAPSID>
/usr/sap/<SAPSID>/SYS
/usr/sap/hostctrl

Local directories that contain the SAP instances such as /usr/sap/<SAPSID>/ASCS<Instance_Number>
The global transport directory may reside on a separate SAP transport host as a standard three systems transport layer configuration.
You need atleast two nodes and a shared file system for distributed ASCS and ERS instances. The assumption is that the rest of the
components are distributed on other nodes.

ASCS and ERS installation
In order for the ASCS and ERS instances to be able to move from one node to the other, they need to be installed on a shared file system and
use virtual hostnames based on the virtual IP.
In this VPC-based SAP HA solution, the shared file system that is required by the cluster is replaced by the NFS-mounted file storage, and the
virtual IP is replaced by the Application Load Balancer for VPC (ALB).
In this scenario, three ALBs are used, one for each Single Point of Failure (SPOF) component in order to replace the virtual IP requirement: ALB
for ASCS, ALB for ERS, and ALB for ASE SYBASE. Each ALB is configured as a backend for the corresponding cluster servers and redirects all of
the communication that is received on the front-end ports to the active server in the backend pool.

Figure 5. Application load balancer management of HA IPs mechanism

Private application load balancer
A private application load balancer is accessible through your private subnets that you configured to create the load balancer.
Similar to a public application load balancer, your private application load balancer service instance is assigned an FQDN; however, this domain
name is registered with one or more private IP addresses.
IBM Cloud operations change the number and value of your assigned private IP addresses over time, based on maintenance and scaling
activities. The backend virtual server instances that host your application must run in the same region and under the same VPC.
Use the assigned ALB FQDN to send traffic to the private application load balancer to avoid connectivity problems to your applications during
system maintenance or scaling down activities.
Each ALB sends traffic to the cluster node where the application (ASCS, ERS, ASE SYBASE DB) is running. During the cluster failover, the ALB
redirects all the traffic to the new node where the resources are up and running.
Note: DNS-as-a-Service (DNSaaS) is the management IBM Cloud VPC DNS service of HA and FQDN (IPs) mechanism.

Note: The ALB has a default of 50 seconds for client and server timeout, so after 50 seconds of inactivity, the connection is closed. To
support SAP connections through ALB and not lose connection after 50 seconds, you need to request a change this value to a minimum
of 300 seconds (client-side idle connection = minimum 300s and server-side idle connection = minimum 300s). To request this
change, open a support ticket. This is an account-wide change that affects all of the ALBs in your account. For more information, see
Connection timeouts.

DNS Services with VPC
IBM Cloud DNS Services provide private DNS to VPC users. Private DNS zones are resolvable only on IBM Cloud and from explicitly

permitted

networks in an account. To get started, create a DNS Services instance using the IBM Cloud console.
DNS Services allows you to:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 365

Create the private DNS zones that are collections for holding the domain names.
Create the DNS resource records under these DNS zones.
Specify the access controls used for the DNS resolution of resource records on a zone-wide level.
DNS Services also maintains its own worldwide set of DNS resolvers. Instances that are provisioned under IBM Cloud on an IBM Cloud network
can use resource records that are configured through IBM Cloud DNS Services by querying DNS Services resolvers.
Resource records and zones that are configured through DNS Services are:
Separated from the wider, public DNS, and their publicly accessible records.
Hidden from the machines outside of and not part of the IBM Cloud private network.
Accessible only from the machines that you authorize on the IBM Cloud private network.
Resolvable only via the resolvers provided by the service.
The DNS service maps the FQDN of each ALB to the virtual hostnames of the ASCS, ERS, and ASE SYBASE that are used by SAP applications.

Figure 6. DNS records

Highly available system for SAP ASE SYBASE database with HADR system

Figure 2. SAP HA for ASE SYBASE DB instances cluster nodes Primary (Active) and Secondary (Companion)

At the most basic level, a standard HA ASE SYBASE cluster in an active(primary)-passive(companion) configuration has two nodes: one is the
primary node and the other is the standby node. This means that the primary node is actively serving the active SAP DB instances (Primary and
Companion), while the standby node is waiting to jump in if there is any failure.
The cluster is set with a virtual hostname IP (hostname is mapped to the FQDN of the ASE SYBASE ALB through DNS, which is same as
explained previously for SAP ASCS and ERS instances). Application instances (PAS and AAS) are used on the SAP profiles to call that particular

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 366

component. The cluster assigns the virtual IP to the active node and uses a heartbeat monitor to confirm the availability of the components. If
the primary node stops responding, it triggers the automatic failover mechanism that calls the standby node to step up to become the primary
node. The ALB detects the change, redirects the traffic to the new active node, and assigns the virtual IP to it, restoring the component
availability. Once fixed, the failed node comes online as a standby node.

SAP SYBASE HADR system supports synchronous replication
The SAP SYBASE HADR system supports synchronous replication between the primary and standby servers for high availability. An activeactive setup is a two-node configuration where both nodes in the cluster include SAP ASE managing independent workloads, capable of taking
over each others workload in the event of a failure.
The SAP ASE server that takes over the workload is called a secondary companion, and the SAP ASE server that fails is called the primary
companion. Together they are companion servers. This movement from one node to another is called failover. After the primary companion is
ready to resume its workload, it is moved back to its original node. This movement is called a failback.
When a system fails over, clients that are connected to the primary companion and use the failover property automatically re-establish their
network connections to the secondary companion. You must tune your operating system to successfully manage both servers during fail over.
See your operating system documentation for information about configuring your system for high availability. An SAP ASE configured for
failover in an active-active setup can be shut down using the shutdown command only after you have suspended SAP ASE from the companion
configuration, at both the server level and the platform level.
The always-on option in a High Availability and Disaster Recovery (HADR) system consists of two SAP ASE servers:
Primary on which all transaction processing takes place.
Warm standby (referred to as a "standby server" in DR mode, and as a "companion" in HA mode) for the primary server, and contains
copies of designated databases from the primary server.
Note: The HADR feature shipped with SAP ASE version 16.0 SP02 supports only a single-companion server.
Some high-availability solutions (for example, the SAP Adaptive Server Enterprise Cluster Edition) share or use common resources between
nodes. However, the HADR system is a "shared nothing" configuration, each node has separate resources including disks.
In an HADR system, servers are separate entities and data is replicated from the primary server to the companion server. If the primary server
fails, a companion server is promoted to the role of primary server either manually or automatically. Once the promotion is complete, clients
can reconnect to the new primary server, and see all committed data, including data that was committed on the previous primary server.
Servers can be separated geographically, which makes an HADR system capable of withstanding the loss of an entire computing facility.
Note: The HADR system includes embedded SAP Replication Server, which synchronizes the databases between the primary and
companion servers. SAP ASE uses the Replication Management Agent (RMA) to communicate with Replication Server and SAP
Replication Server uses Open Client connectivity to communicate with the companion SAP ASE.
The Replication Agent detects any data changes made on the primary server and sends them to the primary SAP Replication Server. In the
figure above, the unidirectional arrows indicate that, although both SAP Replication Servers are configured, only one direction is enabled at a
time.
The HADR system supports synchronous replication between the primary and standby servers for high availability so the two servers can keep
in sync with Zero Data Loss (ZDL). This requires a network link that is fast enough between the primary and standby server so that synchronous
replication can keep up with the primary servers workload. Generally, this means that the network latency is approximately the same speed as
the local disk IO speed, a few (fewer than 10) milliseconds. Anything longer than a few milliseconds may result in a slower response to write
operations at the primary.
The HADR system supports asynchronous replication between the primary and standby servers for disaster recovery. The primary and standby
servers using asynchronous replication can be geographically distant, meaning they can have a slower network link. With asynchronous
replication, Replication Agent Thread captures the primary servers workload, which is delivered asynchronously to SAP Replication Server. The
SAP Replication Server applies these workload change to the companion server.
The most fundamental service offered by the HADR system is the failover; planned or unplanned from the primary to the companion server,
which allows maintenance activity to occur on the old primary server, while applications continue on the new primary.
The HADR system provides protection in the event of a disaster. If the primary server is lost, the companion server can be used as a
replacement. Client applications can switch to the companion server, and the companion server is quickly available for users. If the SAP
Replication Server was in synchronous mode before the failure of the primary server, the Fault Manager automatically initiates failover with
zero data loss.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 367

Fault Manager installation on the SAP ASCS node
The required parameters are asked during the installation process to create a profile for the fault manager and then adds it to the instance
start profile. It is also possible to run the installation using an existing profile: sybdbfm install pf=<SYBHA.PFL> In this case, the installation
process will only ask for profile parameters missing in the profile.
Note: Fault manger is integrated with ASCS on same SAP PAS/AAS cluster (start/stop/move together).
There may be some data loss if the SAP Replication Server was in asynchronous mode and you must use manual intervention to failover for
disaster recovery.
Connection attempts to the companion server without the necessary privileges are silently redirected to the primary companion via the login
redirection mechanism, which is supported by Connectivity libraries. If login redirection is not enabled, client connections fail and are
disconnected.
The SAP ASE HADR option installs the below components:
SAP ASE
SAP Replication Server
Replication Management Agent (RMA)
SAP Host Agent
Fault Manager
SAP ASE Cockpit
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Automating SAP workload SAP NetWeaver on ASE SYBASE HA SZ deployment on IBM Cloud VPC
with Terraform and Ansible
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud® Virtual Private Cloud (VPC) infrastructure resources so
that you can rapidly build complex cloud environments. IBM Cloud® VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon
CPUs and other Intel® technologies.
You can use Terraform scripts to create a VPC and create 2 clustered layers, one for SAP NW(ABAP) and second for SAP ASE SYBASE inmemory database in a HA Single Zone architecture on the bastion server. Creating the bastion server is a prerequisite for all IBM SAP VPC
automated solutions. The automation scripts use the VPC information that you provide and then call the Ansible playbook to create the SAP
architecture on the specified VPC.
You have three deployment methods to choose from:
Terraform scripts that run from the CLI on your bastion server.
Catalog tile user interface from the IBM Cloud® catalog.
Schematics user interface accessed from your cloud dashboard menu.

Terraform scripts include
The terraform scripts included for deploying are:
One Power Placement group to include all the four VMs involved in this solution.
Four VSIs in an existing VPC with subnet and security group configurations.
Two for the ASE SYBASE database cluster instance
Two for the SAP application cluster
Configuring three Application Load Balancers like ASE SYBASE DB and SAP ASCS/ERS.
Configuring one VPC DNS service used to map the ALB FQDN to the SAP ASCS/ERS and ASE SYBASE virtual hostnames.
Configuring seven file shares for VPC.
The ansible scripts included are:
OS requirements for installation and configuration of SAP applications.
Cluster components installation.
Ansible scripts for SAP application cluster configuration and SAP ASE SYBASE cluster configuration.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 368

ASE SYBASE installation
ASE SYBASE db backup
ASE SYBASE system replica configuration
ASCS and ERS instances installation
DB load
Primary and extra application servers installation
Note: Ansible is started by Terraform and must be available on the same host.

SAP Solution implemented
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for ABAP and Java applications. The SAP
system can be installed and configured in IBM Cloud® for various system and database types.
For more information about SAP system architectures on IBM Cloud® VPC, see the infrastructure reference architectures for SAP for each
supported database type. For example, SAP NetWeaver 7.x on UNIX with ASE SYB on IBM Cloud® VPC is the dedicated reference architecture
for this SAP solution.
Manually deploying a VPC and installing a SAP system can be time-consuming. The terraform automation assures not only a much quicker
implementation, but also a standardized and less error-prone deployment. Terraform and Ansible are used for automating the deployment
processes.
The terraform scripts solution provides the automated deployment of a single host with SAP NetWeaver with ASE SYB on the Red Hat
Enterprise Linux 8 and SUSE 15 for SAP Applications.
The SAP installation media that is used for this deployment are the default media for SAP NetWeaver 7.5 with ASE SYB 16.0. The media are
available at the SAP Support Portal under Installation and Upgrade area. You provide the installation media as an input parameter for
Terraform.
An ERP system is used for demand-oriented business resource planning. It is used to control processes and to link departments and functional
areas in a meaningful way. Individual modules include applications for accounting, sales, production, and marketing. More complex tasks in
customer or supply chain management can also be done by ERP software. As the successor to the core product SAP ECC, SAP NetWeaver was
presented as the intelligent ERP system of the new generation. Thanks to modern technologies, the Software-as-a-Service (SaaS) version is
designed to help companies standardize processes and make the leap to digitalization.

What is created
The scripts work in two phases. The first phase automates creating the resources for the VPC provisioning process in an existing VPC created
when you deployed the bastion VSI. The second phase creates the SAP architecture in a distributed environment. This phase creates the:
SAP HA SZ SAP NetWeaver App cluster server on a distinct VSI as a single zone VPC.
SAP ASE SYBASE cluster DB on a dedicated server type VSI as a single zone VPC
For more information about this architecture, see SAP NetWeaver 7.x with SAP ASE SYBASE IBM Cloud® VPC .
During the first phase, the VPC is provisioned with these components:
1 VPC where the virtual server instances are provisioned
1 security group. The rules for this security group allow:
Inbound DNS (port 53) and
Inbound SSH (TCP port 22) connections to your virtual server instance
All outbound traffic from the virtual server instance
1 subnet to enable networking in your VPC
2 X virtual server instances with SAP certified storage and network configurations
2 floating IP’s address that you use to access your VPC virtual server instance over the public network
During the second phase, the Ansible Playbook is called and the SAP High availability architecture is installed for both dedicated VSIs SAP App
VSI machine and dedicated SAP ASE SYBASE VSI box. The SAP architecture that is deployed is the SAP NETWEAVER release on pacemaker
cluster HA dedicated SAP ASE SYBASE 16 SP0+VSI’s release as a distributed deployment model. For more information about this architecture,
see Automating SAP ASE SYBASE stand-alone virtual server instance on IBM Cloud® VPC by using Terraform and Ansible .

Highly available system for SAP ASE SYBASE database
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 369

Figure 1. SAP NetWeaver ASE Sybase HA on VPC Single zone

At the most basic level, a standard HA ASE SYBASE cluster in an active-passive configuration has two nodes: one is the primary node and the
other is the standby node. The primary node is actively serving the active SAP instances (PAS and AAS), while the standby node is waiting to
jump in if necessary.
The cluster is set with a virtual hostname IP. Hostname is mapped to the FQDN of the ASE SYBASE ALB through DNS, which is the same as SAP
ASCS and ERS instances. App instances (PAS and AAS), are the details to be used on the SAP profiles to call that particular component. The
cluster assigns that virtual IP to the active node and uses a heartbeat monitor to confirm the availability of the components. If the primary node
stops responding, it triggers the automatic failover mechanism that calls the standby node to become the primary node. The ALB detects the
change, redirects the traffic to the new active node, and assigns the virtual IP to it, restoring the component availability. After the failed node is
fixed, it comes online as a standby node.

Terraform deployment overview
You use Terraform on the bastion server CLI to download and run the scripts that are located here.
To run the Terraform scripts, you modify:
The input.auto.tfvars file to specify the information for your solution:
Enter the floating IP and subnet information from the bastion server.
Enter existing VPC information:
VPC name
Security group
Subnet
Hostname
Profile
Image
Up to two SSH keys
You can change the default SAP system configuration settings to match your solution.
You also specify the location where you downloaded the SAP kits.
The IBM Cloud® Provider Plug-in for Terraform on IBM Cloud® uses these configuration files to install SAP NetWeaver High Availability on Single
Zone on the specified VPC in your IBM Cloud® account.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 370

SAP Kits
For each IBM Cloud® region, IBM allocates temporary storage on a dedicated Jump host. It is your responsibility to download the necessary
SAP and DB kits to your Deployment Server. All files archives are decompressed by Ansible during the automation deployment process. For
more information, see the Readme file.

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM® Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
Before you deploy SAP NetWeaver High Availability on Single Zone:
The automation for this deployment requires IBM Cloud® File Storage for VPC to complete successfully. IBM Cloud® File Storage for VPC
is available for customers with special approval to preview this service in the Frankfurt, London, Dallas, Toronto, Washington, Sao Paulo,
Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative to get access. For more information, see IBM Cloud® File
Storage for VPC.
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account .
If you have not already, create a bastion server to store the SAP kits. For more information, see [Automate SAP bastion server - SAP
media storage repository]( https://cloud.ibm.com/docs/sap?topic=sap-sap-bastion-server. You need the floating IP from your bastion
server for deployment.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses the
files. For more information, see the README file, in the respective GitHub repository for Schematics and Terraform and on the About
page for the catalog tile.
Create or retrieve an IBM Cloud® API key . The API key is used to authenticate with the IBM Cloud® platform and to determine your
permissions for IBM Cloud® services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.

Deploying SAP HA SAP NetWeaver by using Terraform with the bastion server CLI
Use these steps to configure the IBM Cloud® Provider plug-in and use Terraform to install SAP HA SAP NetWeaver on your existing VPC. The
scripts can take 1 - 2 hours to complete.
1. Access the bastion server cli.
2. Clone the solution repository as below:
$ git clone https://github.com/IBM-Cloud/sap-s4ASE SYBASE-sz-ha.git
cd sap-s4ASE SYBASE-sz-ha/cli/terraform

3. Specify your VPC. Modify the input.auto.tfvars file to specify the information for the existing VPC, your zone, VPC and component
names, profile, and image. You need your 40-digit SSH key ID for this file. The second SSH key is optional.
For more options for profile, see Instance Profiles. For more options for images, see Images. For descriptions of the variables, see
README file.

General VPC variables
4. REGION = "eu-de" Region for the VSI. Supported regions: https://cloud.ibm.com/docs/containers?topic=containers-regions-andzones#zones-vpc Example: REGION = "eu-de"
5. ZONE = "eu-de-2" Availability zone for VSI. Supported zones: https://cloud.ibm.com/docs/containers?topic=containers-regions-andzones#zones-vpc Example: ZONE = "eu-de-2"
6. DOMAIN_NAME = "example.com" The DOMAIN_NAME variable should contain at least one "." as a separator. It is a private domain and it
is not reacheable to and from the outside world. The DOMAIN_NAME variable could be like a subdomain name. Example:
staging.example.com Domain names can only use letters, numbers, and hyphens. Hyphens cannot be used at the beginning or end of the

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 371

domain name. You can't use a domain name that is already in use. Domain names are not case sensitive.
7. ASCS-VIRT-HOSTNAME = "sapascs" ASCS Virtual hostname Default = "sap($your_sap_sid)ascs"
8. ERS-VIRT-HOSTNAME = "sapers" ERS Virtual Hostname
Default = "sap($your_sap_sid)ascs"
9. ASE SYBASE-VIRT-HOSTNAME = "dbASE SYBASE" ASE SYBASE Virtual Hostname Default = "db($your_ASE SYBASE_sid)ASE SYBASE"
10. VPC = "ic4sap" EXISTING VPC, previously created by the user in the same region as the VSI. The list of available VPCs:
https://cloud.ibm.com/vpc-ext/network/vpcs Example: VPC = "ic4sap"
11. SECURITY_GROUP = "ic4sap-securitygroup" EXISTING Security group, previously created by the user in the same VPC. The list of
available Security Groups: https://cloud.ibm.com/vpc-ext/network/securityGroups Example: SECURITY_GROUP = "ic4sapsecuritygroup"
12. RESOURCE_GROUP = "wes-automation" EXISTING Resource group, previously created by the user. The list of available Resource
Groups: https://cloud.ibm.com/account/resource-groups Example: RESOURCE_GROUP = "wes-automation"
13. SUBNET = "ic4sap-subnet" EXISTING Subnet in the same region and zone as the VSI, previously created by the user. The list of available
Subnets: https://cloud.ibm.com/vpc-ext/network/subnets Example: SUBNET = "ic4sap-subnet"
14. SSH_KEYS = [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a", "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ] List of SSH Keys
UUIDs that are allowed to SSH as root to the VSI. The SSH Keys should be created for the same region as the VSI. The list of available
SSH Keys UUIDs: https://cloud.ibm.com/vpc-ext/compute/sshKeys Example: SSH_KEYS = ["r010-8f72b994-c17f-4500-af8fd05680374t3c", "r011-8f72v884-c17f-4500-af8f-d05900374t3c"]

File share variables
$ share_profile = "tier-5iops"
Enter the IOPs (IOPS per GB) tier for File Share storage. Valid values are 3, 5, and 10.
File shares sizes:
usrsap-as1

= "20"

usrsap-as2

= "20"

usrsap-sapascs

= "20"

usrsap-sapers

= "20"

usrsap-sapmnt

= "20"

usrsap-sapsys

= "20"

usrsap-trans

= "80"

Enter Custom File Shares sizes for SAP mounts.

DB VSI variables
1. DB-HOSTNAME-1 = "ASE SYBASEdb-1" ASE SYBASE Cluster VSI1 Hostname. The Hostname for the DB VSI. The hostname should be up
to 13 characters, as required by SAP Default: DB-HOSTNAME-1 = "ASE SYBASEdb-$your_ASE SYBASE_sid-1"
2. DB-HOSTNAME-2 = "ASE SYBASEdb-2" ASE SYBASE Cluster VSI2 Hostname. The Hostname for the DB VSI. The hostname should be up
to 13 characters, as required by SAP Default: DB-HOSTNAME-2 = "ASE SYBASEdb-$your_ASE SYBASE_sid-2"
3. DB-PROFILE = "mx2-16x128" The DB VSI profile. Supported profiles for DB VSI: mx2-16x128. The list of available profiles:
https://cloud.ibm.com/docs/vpc?topic=vpc-profiles&interface=ui
4. DB-IMAGE = "ibm-redhat-8-4-amd64-sap-ASE SYBASE-4" OS image for DB VSI. Supported OS images for DB VSIs: ibm-redhat-8-4amd64-sap-ASE SYBASE-4 The list of available VPC Operating Systems supported by SAP: SAP note '2927211 - SAP Applications on
IBM Virtual Private Cloud (VPC) Infrastructure environment' https://launchpad.support.sap.com/#/notes/2927211; The list of all
available OS images: https://cloud.ibm.com/docs/vpc?topic=vpc-about-images Example: DB-IMAGE = "ibm-redhat-8-4-amd64-sapASE SYBASE-4"

SAP APP VSI variables
1. APP-HOSTNAME-1 = "sapapp-1" SAP Cluster VSI1 Hostname. The Hostname for the SAP APP VSI. The hostname should be up to 13
characters, as required by SAP Default: APP-HOSTNAME-1 = "sapapp-$your_sap_sid-1"
2. APP-HOSTNAME-2 = "sapapp-2" SAP Cluster VSI2 Hostname. The Hostname for the SAP APP VSI. The hostname should be up to 13
characters, as required by SAP Default: APP-HOSTNAME-2 = "sapapp-$your_sap_sid-2"
3. APP-PROFILE = "bx2-4x16" The APP VSI profile. Supported profiles: bx2-4x16. The list of available profiles:
https://cloud.ibm.com/docs/vpc?topic=vpc-profiles&interface=ui
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 372

4. APP-IMAGE = "ibm-redhat-8-4-amd64-sap-ASE SYBASE-4" OS image for SAP APP VSI. Supported OS images for APP VSIs: ibm-redhat8-4-amd64-sap-ASE SYBASE-4. The list of available VPC Operating Systems supported by SAP: SAP note '2927211 - SAP Applications
on IBM Virtual Private Cloud (VPC) Infrastructure environment' https://launchpad.support.sap.com/#/notes/2927211; The list of all
available OS images: https://cloud.ibm.com/docs/vpc?topic=vpc-about-images Example: APP-IMAGE = "ibm-redhat-8-4-amd64-sapASE SYBASE-4"
Customize your SAP system configuration. In input.auto.tfvars file, edit the SAP system configuration variables that are passed to the
Ansible automated deployment. For descriptions of the variables, see the Readme file.

SAP system configuration
1. ASE SYBASE_sid = "HDB" AP ASE SYBASE system ID. Should follow the SAP rules for SID naming. Obs. This is used as identification
number across different HA name resources. Duplicates are not allowed. Example: ASE SYBASE_sid = "HDB"
2. ASE SYBASE_sysno = "00" SAP ASE SYBASE instance number. Should follow the SAP rules for instance number naming. Example: ASE
SYBASE_sysno = "00"
3. ASE SYBASE_system_usage = "custom" System usage. Default: custom. Suported values: production, test, development, custom
Example: ASE SYBASE_system_usage = "custom"
4. ASE SYBASE_components = "server" SAP ASE SYBASE Components. Default: server. Supported values: all, client, es, ets, lcapps, server,
smartda, streaming, rdsync, xs, studio, afl, sca, sop, eml, rme, rtl, trp Example: ASE SYBASE_components = "server" kit_sapASE
SYBASE_file = "/storage/ASE SYBASEDB/51055299.ZIP" SAP ASE SYBASE Installation kit path Supported SAP ASE SYBASE versions on
Red Hat 8.4 and Suse 15.3: ASE SYBASE 16 SP0+SP 5 Rev 57, kit file: 51055299.ZIP Supported SAP ASE SYBASE versions on Red Hat
7.6: ASE SYBASE 16 SP0+SP 5 Rev 52, kit file: 51054623.ZIP Example for Red Hat 7: kit_sapASE SYBASE_file = "/storage/ASE
SYBASEDB/51054623.ZIP" Example for Red Hat 8 or Suse 15: kit_sapASE SYBASE_file = "/storage/ASE SYBASEDB/51055299.ZIP"
5. sap_sid = "NWD" SAP System ID Obs. This is used as identification number across different HA name resources. Duplicates are not
allowed.
6. sap_ascs_instance_number = "00" The central ABAP service instance number. Should follow the SAP rules for instance number
naming. Example: sap_ascs_instance_number = "00"
7. sap_ers_instance_number = "01" The enqueue replication server instance number. Should follow the SAP rules for instance number
naming. Example: sap_ers_instance_number = "01"
8. sap_ci_instance_number = "10" The primary application server instance number. Should follow the SAP rules for instance number
naming. Example: sap_ci_instance_number = "10"
9. sap_aas_instance_number = "20" The additional application server instance number. Should follow the SAP rules for instance number
naming. Example: sap_aas_instance_number = "20"
10. hdb_concurrent_jobs = "23" Number of concurrent jobs used to load and/or extract archives to ASE SYBASE Host

SAP NetWeaver application kit paths
1. kit_sapcar_file = "/storage/S4ASE SYBASE/SAPCAR_1010-70006178.EXE"
2. kit_swpm_file = "/storage/S4ASE SYBASE/SWPM20SP13_1-80003424.SAR"
3. kit_sapexe_file = "/storage/S4ASE SYBASE/SAPEXE_100-70005283.SAR"
4. kit_sapexedb_file = "/storage/S4ASE SYBASE/SAPEXEDB_100-70005282.SAR"
5. kit_igsexe_file = "/storage/S4ASE SYBASE/igsexe_1-70005417.sar"
6. kit_igshelper_file = "/storage/S4ASE SYBASE/igshelper_17-10010245.sar"
7. kit_saphotagent_file = "/storage/S4ASE SYBASE/SAPHOSTAGENT51_51-20009394.SAR"
8. kit_hdbclient_file = "/storage/S4ASE SYBASE/IMDB_CLIENT20_009_28-80002082.SAR"
9. kit_s4ASE SYBASE_export = "/storage/S4ASE SYBASE/export"
10. Remember, you must manually decompress the kit_export_dir , kit_db2_dir and kit_db2client_dir files. Ansible decompresses
the rest of the SAP kit files. For more information, see the Readme file.
11. Initialize the Terraform CLI.
12. terraform init

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 373

13. Create a terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
14. terraform plan --out plan1
You must enter a SAP main password and your API key.
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters: a-z,
A-Z, 0-9, @, #, $, _. This password cannot contain !. It must not start with a digit or an underscore ( _ ).
9. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
10. Create the VPC for SAP instance and IAM access policy in IBM Cloud.
11. terraform apply "plan1" The VPC and components are created and you see output similar to the terraform plan output.
12. Add the SAP credentials and the virtual server instance IP to the SAP GUI. For more information about the SAP GUI, see

SAP GUI.

Deploying SAP NetWeaver High Availability on Single Zone with the catalog tile interface
Use these steps to configure the SAP HA SZ SAP NetWeaver on your existing VPC by using the catalog tile interface. The scripts can take 2 - 3
hours to complete.
1. From the IBM Cloud Catalog, select SAP NetWeaver High Availability on Single Zone tile. The tile opens the Create tab for SAP HA SZ
S/4ASE SYBASE. For more information about this deployment, see the About tab or the readme file link.
2. On the SAP HA SZ SAP NetWeaver page, configure your workspace:
Enter a name for the workspace or use the default.
Select the Resource Group to use to create resources. Use the Default or create a Resource Group.
Select a Location to create your Schematics workspace. The workspace location does not have to match the resource location.
3. Enter the required deployment values, review the default input variables, and provide values that match your solution. These parameters
are specific to your deployment. For more information, see the Readme file - Input Parameters.
Parameter

Description

APP-HOSTNAME-1

APP VSI hostname-1

APP-HOSTNAME-2

APP VSI hostname-2

BASTION_FLOATING_IP

Input the floating IP of the Bastion Server you created before you started this deployment. For more
information, see Automate SAP bastion server - SAP media storage .

DB-HOSTNAME-1

DB VSI hostname-1

DB-HOSTNAME-2

DB VSI hostname-2

DOMAIN_NAME

Private Domain Name

REGION

Cloud Region where resources are deployed

RESOURCE_GROUP

EXISTING Resource Group for VSIs and Volumes

SECURITY_GROUP

EXISTING Security group name

SSH_KEYS

SSH Keys ID list to access the VSI

SUBNET

EXISTING Subnet name

VPC

EXISTING VPC name

ZONE

Cloud Zone where resources are deployed

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 374

ha_password

HA cluster password

ASE
SYBASE_components

ASE SYBASE Components, for example, server

ASE
SYBASE_main_password

ASE SYBASE main password or use a secret that is stored in Secrets Manager

ASE SYBASE_sid

ASE SYBASE sid

ibmcloud_api_key

IBM Cloud API key or use a secret stored in Secrets Manager

private_ssh_key

Input id_rsa private key content or use a secret stored in Secrets Manager

sap_main_password

SAP main password or use a secret stored in Secrets Manager

sap_sid

SAP sid

Review and update the optional input variables. The Ansible scripts expect the SAP kits to be in the default locations listed. For
more information, see the Readme file - Input Parameters.
Parameter

Description

APP-IMAGE

APP VSI OS image

APP-PROFILE

APP VSI profile

ASCS-VIRT-HOSTNAME

ASCS Virtual hostname

DB-IMAGE

DB VSI OS image

DB-PROFILE

DB VSI profile

ERS-VIRT-HOSTNAME

ERS Virtual hostname

ASE SYBASE-VIRT-HOSTNAME

ASE SYBASE Virtual hostname

ASE SYBASE_sysno

ASE SYBASE_sysno

ASE SYBASE_system_usage

ASE SYBASE_system_usage

hdb_concurent_jobs

hdb_concurent_jobs

kit_hdbclient_file

kit_hdbclient_file

kit_igsexe_file

kit_igsexe_file

kit_igshelper_file

kit_igshelper_file

kit_s4ASE SYBASE_export

kit_s4ASE SYBASE_export

kit_sapcar_file

kit_sapcar_file

kit_sapexe_file

kit_sapexe_file

kit_sapexedb_file

kit_sapexedb_file

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 375

kit_sapASE SYBASE_file

kit_sapASE SYBASE_file

kit_saphotagent_file

kit_saphotagent_file

kit_swpm_file

kit_swpm_file

sap_aas_instance_number

sap_aas_instance_number

sap_ascs_instance_number

sap_ascs_instance_number

sap_ci_instance_number

sap_ci_instance_number

sap_ers_instance_number

sap_ers_instance_number

share_profile

Enter the IOPs (IOPS per GB) tier for File Share storage. Valid values are 3, 5, and 10.

usrsap-as1

FS Size in GB for usrsap-as1

usrsap-as2

FS Size in GB for usrsap-as2

usrsap-sapascs

FS Size in GB for usrsap-sapascs

usrsap-sapers

FS Size in GB for usrsap-sapers

usrsap-sapsys

FS Size in GB for usrsap-sapsys

usrsap-trans

FS Size in GB for usrsap-trans

4. Accept the license agreement.
5. Select Deploy. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run

terraform plan

and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The Terraform
scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove the SAP HA SAP NetWeaver installation, go to your project folder and run

terraform destroy . The terraform

destroy command does not remove the VPC in this scenario because the VPC was created before these Terraform scripts were run.

Related information
For more information about Terraform on IBM Cloud, see Getting started with Terraform on IBM Cloud .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier virtual

private cloud for SAP by using Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 376

SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP S/4HANA HA deployment on IBM Cloud VPC
Overview for automating SAP workload HA deployment on IBM Cloud® Virtual Private Cloud (VPC)
(Terraform and Ansible)
You can use Terraform to automate IBM Cloud VPC provisioning. The VPC provisioned includes virtual server instances with high network
performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers. After the VPC
is provisioned, the scripts use the Ansible Playbook to install the SAP system.

IBM Cloud® VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP products architecture on IBM Cloud VPC
A Virtual Private Cloud (VPC) contains one of the most secure and reliable cloud environments for SAP applications within your own VPC with
its included virtual server instances. This represents an Infrastructure as a Service (IaaS) within IBM Cloud that offers all of the benefits of
isolated, secure, and flexible virtual cloud infrastructure from IBM. In comparison, the IBM Cloud classic infrastructure virtual servers offering
uses virtual instances with native and VLAN networking to communicate to each other within a data center; however, the instances are
restricted in one well-working pod by using subnet and VLAN networking as a gap scale up of virtual resources should rely between the pods.
What’s new with IBM Cloud VPC is a network orchestrator layer concept that eliminates the pod boundaries and restrictions, so this new
concept handles all the networking for every virtual instance running within VPC across regions and zones.

Highly available system for SAP NetWeaver on IBM Cloud VPC
In a highly available (HA) system, every instance can run on a separate IBM Cloud virtual server instance. The cluster HA configuration for the
SAP application server consists of two virtual server instances, each of them located in the same zone for single zone or in different zones for
multi zone within the same region by using placement groups. Placement groups assure that both cluster resources and cloud resources are
also located in different compute nodes as specified in the following placement groups section.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 377

Figure 1. SAP HA SZ for SAP applications cluster nodes PAS (Active) and AAS (Active) with HANA DB instance HA cluster

Figure 2. SAP HA MZ for SAP applications cluster nodes PAS (Active) and AAS (Active) with HANA DB instance in HA cluster

Placement groups on IBM Cloud VPC for SAP HA architecture
Placement groups (PG) for VPC have two different anti-affinity strategies for high availability. By using placement strategies, you minimize the
chance of service disruption with virtual server instances that are placed on different hosts or into an infrastructure with separate power and

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 378

network supplies.
The design of placement groups for IBM Cloud virtual servers solves this issue. Placement groups give you a measure of control over the host
on which a new public virtual server is placed. With this release, a “spread” rule is implemented, which means that virtual servers within a
placement group are all spread onto different hosts. You can build a highly available application within a data center and know that your virtual
servers are isolated from each other.
Placement groups with the “spread” rule are available to create in select IBM Cloud data centers. After a "spread" rule is created, you can
provision a virtual server into that group and ensure that it won't be on the same host as any of your other virtual servers. The best part?
There’s absolutely no charge for using this feature.
You can create your placement group, then assign up to four new virtual server instances. With the "spread" rule, each of your virtual servers
are provisioned on different physical hosts. In the following example configurations, the “Power Spread” option is used.

Figure 3. Placement groups host spread

Figure 4. Placement groups power spread

These are the following SAP instances that are needed for an HA scenario:
ABAP central services instance (ASCS instance)- contains the ABAP message server and the ABAP enqueue server
Enqueue replication server instance (ERS instance) for the ASCS instance
Database instance
Primary application instance (PAS) on node 1
Additional application instance (AAS) on node 2
It is recommended that you run both the ASCS instance and ERS instance in a switchover cluster infrastructure.

IBM Cloud File Storage for VPC for SAP HA architecture
IBM Cloud File Storage for VPC technology is used to make the SAP directories available to the SAP system. The technologies of choice are
NFS, shared disks, and cluster file system. If you have decided to use a highly available (HA) solution for your SAP system, make sure that you
properly address the HA requirements of the SAP file systems in your SAP environment.

Figure 5. File shares for VPC

File shares that are mounted as NFS permanent file systems on both cluster nodes for SAP apps HA:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 379

/usr/sap/<SAPSID>/SYS
/sapmnt<SAPSID>
/usr/sap/trans

Cluster-managed file systems for SAP Apps HA: ASCS si ERS
/usr/sap/<SAPSID>/ASCS00
/usr/sap/<SAPSID>/ERS01

Permanent NFS mount on SAP Apps HA node 1 PAS instance:
/usr/sap/<SAPSID>/Dxx

Permanent NFS mount on SAP Apps HA node 2 dialog instance:
/usr/sap/<SAPSID>/Dyy

Prerequisites
You need to install the hardware (hosts, disks, and network) and decide how to distribute the database, SAP instances, and, if required, the
Network File System (NFS) server over the cluster nodes.

Context
From the perspective of an SAP application, these are the types of SAP directories:
Physically shared directories: /<sapmnt>/<SAPSID> and /usr/sap/trans
Logically shared directories that are bound to a node, such as /usr/sap , with the following local directories:
/usr/sap/<SAPSID>
/usr/sap/<SAPSID>/SYS
/usr/sap/hostctrl

Local directories that contain the SAP instances, such as /usr/sap/<SAPSID>/ASCS<Instance_Number>
The global transport directory might reside on a separate SAP transport host as a standard three systems transport layer configuration.
You need at least two nodes and a shared file system for distributed ASCS and ERS instances, and the assumption is that the rest of the
components are distributed on other nodes.

ASCS and ERS installation
In order for the ASCS and ERS instances to be able to move from one node to the other, they need to be installed on a shared file system and
use virtual hostnames based on the virtual IP.
In this VPC-based SAP HA solution, the shared file system that is required by the cluster is replaced by the NFS-mounted file storage, and the
virtual IP is replaced by the Application Load Balancer for VPC (ALB).
In this scenario, three ALBs are used, one for each Single Point of Failure component (SPOF) in order to replace the virtual IP requirement: ALB
for ASCS, ALB for ERS, and ALB for HANA. Each ALB is configured as a backend for the corresponding cluster servers and redirects all of the
communication that is received on the front-end ports to the active server in the backend pool.

Figure 6. Application load balancer management of HA IPs mechanism

Private application load balancer
A private application load balancer is accessible through your private subnets that you configured to create the load balancer.
Similar to a public application load balancer, your private application load balancer service instance is assigned an FQDN; however, this domain
name is registered with one or more private IP addresses.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 380

IBM Cloud operations might change the number and value of your assigned private IP addresses over time, based on maintenance and scaling
activities. The back-end virtual server instances that host your application must run in the same region and under the same VPC.
Use the assigned ALB FQDN to send traffic to the private application load balancer to avoid connectivity problems to your applications during
system maintenance or scaling down activities.
Each ALB sends traffic to the cluster node where the application (ASCS, ERS, HANA DB) is running. During the cluster failover, the ALB redirects
all the traffic to the new node where the resources are up and running.
Note: DNSaaS (DNS as a Service) is the management IBM Cloud VPC DNS service of HA and FQDN (IPs) mechanism.

Note: The ALB has a default of 50 seconds for client and server timeout, so after 50 seconds of inactivity, the connections close. To
support SAP connections through ALB and not lose connection after 50 seconds, you need to request a change this value to a minimum
of 300 seconds (client-side idle connection = minimum 300s and server-side idle connection = minimum 300s). To request this
change, open a support ticket. This is an account-wide change that affects all of the ALBs in your account. For more information, see
Connection timeouts.

DNS Services with VPC
IBM Cloud DNS Services provides private DNS to VPC users. Private DNS zones are resolvable only on IBM Cloud, and only from explicitly
permitted networks in an account. To get started, create a DNS Services instance using the IBM Cloud console.
DNS Services allow you to:
Create private DNS zones that are collections for holding domain names.
Create DNS resource records under these DNS zones.
Specify access controls used for the DNS resolution of resource records on a zone-wide level.
DNS Services also maintains its own worldwide set of DNS resolvers. Instances that are provisioned under IBM Cloud on an IBM Cloud network
can use resource records that are configured through IBM Cloud DNS Services by querying DNS Services resolvers.
Resource records and zones that are configured through DNS Services are:
Separated from the wider, public DNS and their publicly accessible records.
Hidden from machines outside of and not part of the IBM Cloud private network.
Accessible only from machines that you authorize on the IBM Cloud private network.
Resolvable only via the resolvers provided by the service.
The DNS service maps the FQDN of each ALB to the virtual hostnames of the ASCS, ERS, and HANA that are used by SAP applications.

Figure 7. DNS records

Network latency between VPC Zones and Regions
For network latency between VPC zones and regions, see the VPC Network latency dashboards topic and run your own measurement
according with SAP note "500235 - Network Diagnosis with NIPING" to perform a latency check using SAP tool niping.
The results reported are as measured. There are no performance guarantees implied by these measurement. These statistics provide visibility
into latency between all regions and zones to help you plan the optimal selection for your cloud deployment and plan for scenarios, such as
data residency and performance.

Highly available system for SAP HANA database

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 381

Figure 8. SAP HA for HANA DB instances cluster nodes Primary (Active) and Secondary (Passive) in a Single Zone architecture

At the most basic level, a standard HA HANA cluster in an active-passive configuration has two nodes: one is the primary node and the other is
the standby node. This simply means that the primary node is actively serving the active SAP instances (PAS and AAS), while the standby node
is waiting to jump in if there is a failure.

Highly available system for SAP application instance

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 382

Figure 9. SAP HA for SAP applications cluster nodes PAS (Active) and AAS (Active) in a Single Zone architecture

The cluster is set with a virtual hostname IP (hostname is mapped to the FQDN of the HANA ALB through DNS, which is the same as explained
previously for SAP ASCS and ERS instances). App instances (PAS and AAS), these are the details to be used on the SAP profiles to call that
particular component. The cluster assigns that virtual IP to the active node and uses a heartbeat monitor to confirm the availability of the
components. If the primary node stops responding, it triggers the automatic failover mechanism that calls the standby node to step up to
become the primary node. The ALB detects the change, redirects the traffic to the new active node, and assigns the virtual IP to it, restoring the
component availability. After the failed node is fixed, it comes online as a standby node.

Synchronous on disk (sync) HANA database replication mechanism supported by SAP
The primary system waits to commit the transaction until it gets a reply that the log is persisted in the secondary system. This option
guarantees immediate consistency between both systems, at a cost of delaying the transaction by the time for data transmission and persisting
in the secondary system.
When the connection to the secondary system is lost, the primary system continues the transaction processing and writes the changes only to
the local disk. No data loss occurs in this scenario if the secondary system is connected. Data loss can occur when a takeover is run while the
secondary system is disconnected.
Additionally, this replication mode can run with a full sync option. This means that log write is successful when the log buffer has been written
to the log file of the primary and the secondary system. When the secondary system is disconnected (for example, because of network failure),
the primary system suspends the transaction processing until the connection to the secondary system is reestablished. No data loss occurs in
this scenario. You can set the full sync option for system replication with the parameter [system_replication]/enable_full_sync .
Note: If SAP HANA system replication runs in the sync replication mode with the full sync option enabled, and if the connection to the
secondary site is interrupted, no write operations on the primary site are possible. The operation of creating a tenant database, for
example, waits until the connection to the secondary is reestablished or the SQL statement times out.

Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Deploying SAP workload S/4HANA HA deployment on IBM Cloud® VPC (Terraform and Ansible)
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 383

2025. Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM
Cloud Activity Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about
migrating from IBM Cloud Activity Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so
that you can rapidly build complex cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon
CPUs and other Intel® technologies.
Terraform scripts are used to create a VPC and 2 clustered layers, one for SAP S/4HANA and another for SAP HANA in-memory database in a
HA Single and Multi Zone architecture on the bastion server. Creating the bastion server is a prerequisite for all IBM SAP VPC automated
solutions. The automation scripts use the VPC information that you provide and then call the Ansible playbook to create the SAP architecture
on the specified VPC.
You have three deployment methods to choose from:
Terraform scripts run from the CLI on your bastion server.
Catalog tile user interfaced from the IBM Cloud catalog.
IBM Cloud Schematics user interface accessed from the menu on your cloud dashboard.

SAP solution implemented
SAP S/4HANA is an ERP system from SAP's ERP software product line. The software is based on the innovative SAP HANA database technology
and was started as the fourth product generation in 2015. Users can choose between the SAP S/4HANA Cloud and on-premises solution.
An ERP system is used for demand-oriented business resource planning. It is used to control processes and to link departments and functional
areas in a meaningful way. Individual modules include applications for accounting, sales, production, and marketing. More complex tasks in
customer or supply chain management can also be done by ERP software. As the successor to the core product SAP ECC, SAP S/4HANA was
presented as the intelligent ERP system of the new generation. With the help of modern technologies, the Software as Service (SaaS) version is
designed to help companies standardize processes and make the leap to digitalization.
While previous SAP ERP solutions support the most common databases, SAP S/4HANA uses exclusively the SAP HANA in-memory database
developed by SAP. This in-memory database offers users the greatest technical benefit and they benefit from increased performance. The "S"
in S/4HANA stands for "simple", while the "4" refers to the generation sequence. Compared to the SAP core product SAP ECC, which is still
used in most companies, SAP S/4HANA offers many innovative functions that revolutionize the system landscape from the ground up. As SAP
plans to discontinue the mainstream maintenance of its existing ERP solutions by 2027, many SAP ECC users are already considering a
migration to SAP HA SZ or MZ S/4HANA.

What is created
The scripts work in two phases. The first phase automates creating the resources for the VPC provisioning process in an existing VPC created
when you deploy the bastion VSI. The second phase creates the SAP architecture in a distributed environment.
1. Architecture for S/4HANA HA in a single zone
SAP HA SZ S/4HANA App cluster server on a distinct VSI as a single zone VPC
SAP HANA cluster DB on a dedicated server type VSI as a single zone VPC
2. Architecture for S/4HANA HA in a multi-zone
SAP HA MZ S/4HANA App cluster server on a distinct VSI as multi-zone VPC
SAP HANA cluster DB on a dedicated server type VSI as multi-zone VPC
Note: It is recommended to read the guidelines from the readme file when deploying this solution.
For more information about this architecture, see SAP NetWeaver 7.x with SAP HANA IBM Cloud VPC .
During the first phase, the following resources are provisioned in the VPC:
1 Power Placement group for all 4 virtual machines created by this solution
4 VSIs, with Subnet and Security Group configurations
3 Application Load Balancers for HANA DB and SAP ASCS/ERS
1 VPC DNS service used to map the ALB FQDN to the SAP ASCS/ERS and HANA virtual hostnames
7 file shares for VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 384

During the second phase, the Ansible Playbooks are called and the SAP High availability architecture is installed for both dedicated VSIs SAP
App VSI box and dedicated SAP HANA VSI box. The SAP architecture that is deployed is the SAP S/4HANA release on the pacemaker cluster.
HA dedicated SAP HANA 2.0 VSI’s release as a distributed deployment model. For more information about this architecture, see Automating
SAP HANA stand-alone virtual server instance on IBM Cloud VPC by using Terraform and Ansible.

Highly available system for SAP S/4HANA in a Single zone or Multi zone architectures

Figure 1. SAP HA for SAP applications cluster nodes PAS (Active) and AAS (Active) Schematics deployment (Single Zone architecture)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 385

Figure 2. SAP HA for HANA DB instances cluster nodes primary (Active) and Secondary (Passive) (Single Zone architecture)

At the most basic level, a standard HA HANA cluster in an active-passive configuration has two nodes: one is the primary node and the other is
the standby node. The primary node is actively serving the active SAP instances (PAS and AAS), while the standby node is waiting to jump in if
necessary.
The cluster is set with a virtual hostname IP. Hostname is mapped to the FQDN of the HANA ALB through DNS, which is the same as SAP ASCS
and ERS instances. App instances (PAS and AAS), are the details to be used on the SAP profiles to call that particular component. The cluster
assigns that virtual IP to the active node and uses a heartbeat monitor to confirm the availability of the components. If the primary node stops
responding, it triggers the automatic failover mechanism that calls the standby node to become the primary node. The ALB detects the change,
redirects the traffic to the new active node, and assigns the virtual IP to it, restoring the component availability. After the failed node is fixed, it
comes online as a standby node.

Terraform scripts
The Terraform scripts included for deploying are:
One Power Placement group to include all the four VMs involved in this solution.
Four VSIs in an existing VPC with subnet and security group configurations. The VSIs scope: two for the HANA database cluster instance
and two for the SAP application cluster.
Configuring three Application Load Balancers like HANA DB and SAP ASCS/ERS.
Configuring one VPC DNS service that is used to map the ALB FQDN to the SAP ASCS/ERS and HANA virtual hostnames.
Configuring seven file shares for VPC.
The Ansible scripts that are included for deploying are:
OS requirements installation and configuration for SAP applications.
Cluster components installation
Ansible scripts for SAP application cluster configuration and SAP HANA cluster configuration.
HANA installation
HANA DB backup
HANA system replica configuration
ASCS and ERS instances installation

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 386

DB load
Primary and extra application server installation
Note: For CLI deployment, Ansible is started by Terraform and both must be available on the same host (bastion server).

SAP Kits
It is your responsibility to download the necessary SAP and DB kits to your Deployment Server (bastion server).All file archives are
decompressed by Ansible during the automation deployment process. For more information, see the readme file.

Terraform deployment overview
The automation scripts from the GitHub repository can be executed by running the Terraform scripts in CLI, from the bastion server
(deployment server).
Edit the input parameter file input.auto.tfvars , and modify the variables to match your solution:
VPC - An existing VPC name
REGION - Region for the VSIs
DOMAIN_NAME - Private domain that is not reachable to and from the outside world
ZONE_1 - Availability zone for DB_HOSTNAME_1 and APP_HOSTNAME_1 VSIs
ZONE_2 - Availability zone for DB_HOSTNAME_2 and APP_HOSTNAME_2VSIs
SECURITY_GROUP - Existing Security Group, previously created by the user in the same VPC.
SUBNET_1 - The name of an existing subnet, in the same VPC, ZONE_1, where DB_HOSTNAME_1 and APP_HOSTNAME_1 VSIs will be
created.
SUBNET_2 - The name of an existing subnet, in the same VPC, ZONE_2, where DB_HOSTNAME_2 and APP_HOSTNAME_2 VSIs will be
created.
RESOURCE_GROUP - Existing resource group, previously created by the user.
SSH_KEYS - List of SSH Key UUIDs that are allowed to SSH as root to the VSIs.
ID_RSA_FILE_PATH - id_rsa private key file path in OpenSSH format with 0600 permissions
APP_HOSTNAME_1/ APP_HOSTNAME_2/DB_HOSTNAME_1/ DB_HOSTNAME_2 - Enter a hostname up to 12 characters. For more
information, see the readme file.
DB_PROFILE/APP_PROFILE - The instance profile used for the HANA/APP VSI
DB_IMAGE/APP_IMAGE - OS image for DB/APP VSI

Schematics deployment overview
Schematics user interface is used on the IBM Cloud. Enter the GitHub repository for SAP S/4HANA High Availability on single zone Schematics.
When you run the scripts with the Schematics interface, you:
Enter workspace information.
Enter the GitHub path for the Terraform scripts used.
Modify the parameters in the Schematics interface.

Catalog tile deployment
When you use the catalog tile for deployment, you:
Select the SAP S/4HANA High Availability on Single Zone tile from the catalog.
Enter your workspace information. The catalog tile creates a Schematics workspace.
Modify the parameters for your bastion server, personal credential information, and other parameters specific to your solution.

Support - Terraform and Schematics
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM. As a recommended
practice, carefully review any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 387

GitHub issue.

Support - catalog tile
The catalog tile offering is IBM Cloud supported. For more information, see Getting help and support from IBM Cloud or SAP .
If client issues are identified with SAP software, then SAP support assists the client. Follow the recommendations of SAP Note 90835, which
describes the SAP Incident Escalation Procedure. This SAP Note (and others) is found at https://support.sap.com/en/index.html

Before you begin
Before you deploy SAP S/4HANA High Availability on Single Zone or Multi Zone:
The automation for this deployment requires IBM Cloud File Storage for VPC to complete successfully. IBM Cloud File Storage for VPC is
available for customers with special approval to preview this service in the Frankfurt, London, Dallas, Toronto, Washington, Sao Paulo,
Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative to get access. For more information, see IBM Cloud File
Storage for VPC.
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account .
If you have not already, create a bastion server to store the SAP kits. For more information, see

Automate SAP bastion server - SAP

media storage repository.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the downloaded locations. Ansible decompresses
the files. For more information, see the Readme file in the GitHub repository and on the About page for the catalog tile.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
(Optional - catalog tile) create secrets for your credentials and passwords by using the Secrets Manager.

Deploying SAP HA S/4HANA by using Terraform with the bastion server CLI
Use these steps to configure the IBM Cloud Provider plug-in and use Terraform to install SAP HA SZ or MZ S/4HANA on your existing VPC. The
scripts can take upto 4 hours to complete. The supported versions available for S/4HANA are 2020, 2021, 2022, and 2023. For more
information, see the readme for recommended kits versions.
1. Access the bastion server CLI.
2. Clone the solution repository from https://github.com/IBM-Cloud/sap-s4hana-ha and cd to the sap-s4hana-ha folder.
$ git clone https://github.com/IBM-Cloud/sap-s4hana-ha.git
cd sap-s4hana-ha

3. Specify your VPC. Modify the input.auto.tfvars file to specify the information for the existing VPC, your zone, VPC and component
names, profile, and image. You need your 40-digit SSH key ID for this file. The second SSH key is optional. For more options for profile,
see Instance Profiles. For more options on images, see Images. For descriptions of the variables, see the readme file.
$ ##########################################################
# General VPC variables:
##########################################################
REGION = ""
# The cloud region where to deploy the solution. Supported regions: https://cloud.ibm.com/docs/containers?
topic=containers-regions-and-zones#zones-vpc
# Example: REGION = "eu-de"
DOMAIN_NAME = "ha.mzexample.com"
# The DOMAIN_NAME variable should contain at least one "." as a separator. It is a private domain and it is not
reacheable to and from the outside world.
# The DOMAIN_NAME variable could be like a subdomain name. Ex.: staging.example.com
# Domain names can only use letters, numbers, and hyphens.
# Hyphens cannot be used at the beginning or end of the domain name.
# You can't use a domain name that is already in use.
# Domain names are not case sensitive.
ASCS_VIRT_HOSTNAME = "sapascs"

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 388

# ASCS Virtual Hostname
# Default value: sapascs
# When the default value is used, the virtual hostname will automatically be changed based on <SAP_SID> to
"sap<sap_sid>ascs"
ERS_VIRT_HOSTNAME = "sapers"
# ERS Virtual Hostname
# Default value: sapers
# When the default value is used, the virtual hostname will automatically be changed based on <SAP_SID> to
"sap<sap_sid>ers"
HANA_VIRT_HOSTNAME = "dbhana"
# Hana Virtual Hostname
# Default value: dbhana
# When the default value is used, the virtual hostname will automatically be changed based on <SAP_SID> to
"db<hana_sid>hana"
VPC = ""
# The name of an EXISTING VPC. Must be in the same region as the solution to be deployed. The list of VPCs is
available here: https://cloud.ibm.com/vpc-ext/network/vpcs.
# Example: VPC = "ic4sap"
ZONE_1 = ""
# Availability zone for DB_HOSTNAME_1 and APP_HOSTNAME_1 VSIs, in the same VPC. Supported zones:
https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zones#zones-vpc
# Example: ZONE = "eu-de-1"
SUBNET_1 = ""
# The name of an EXISTING Subnet, in the same VPC, ZONE_1, where DB_HOSTNAME_1 and APP_HOSTNAME_1 VSIs will be
created. The list of Subnets is available here: https://cloud.ibm.com/vpc-ext/network/subnets
# Example: SUBNET = "ic4sap-subnet_1"
ZONE_2 = ""
# Availability zone for DB_HOSTNAME_2 and APP_HOSTNAME_2 VSIs, in the same VPC. Supported zones:
https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zones#zones-vpc.
# If the same value as for ZONE_1 is used, and the value for SUBNET_1 is the same with the value for SUBNET_2, the
deployment will be done in a single zone. If the values for ZONE_1, SUBNET_1 are different than the ones for
ZONE_2, SUBNET_2 then an SAP Multizone deployment will be done.
# Example: ZONE = "eu-de-2"
SUBNET_2 = ""
# The name of an EXISTING Subnet, in the same VPC, ZONE_2, where DB_HOSTNAME_2 and APP_HOSTNAME_2 VSIs will be
created. The list of Subnets is available here: https://cloud.ibm.com/vpc-ext/network/subnets.
# If the same value as for SUBNET_1 is used, and the value for ZONE_1 is the same with the value for ZONE_2, the
deployment will be done in a single zone. If the values for ZONE_1, SUBNET_1 are different than the ones for
ZONE_2, SUBNET_2 then it an SAP Multizone deployment will be done.
# Example: SUBNET = "ic4sap-subnet_2"
SECURITY_GROUP = ""
# The name of an EXISTING Security group for the same VPC. It can be found at the end of the Bastion Server
deployment log, in \"Outputs\", before \"Command finished successfully\" message. The list of Security Groups is
available here: https://cloud.ibm.com/vpc-ext/network/securityGroups.
# Example: SECURITY_GROUP = "ic4sap-securitygroup"
RESOURCE_GROUP = ""
# EXISTING Resource group, previously created by the user. The list of available Resource Groups:
https://cloud.ibm.com/account/resource-groups
# Example: RESOURCE_GROUP = "wes-automation"
SSH_KEYS = [""]
# List of SSH Keys UUIDs that are allowed to connect via SSH, as root, to the VSI. Can contain one or more IDs.
The list of SSH Keys is available here: https://cloud.ibm.com/vpc-ext/compute/sshKeys.
# Example: SSH_KEYS = ["r010-8f72b994-c17f-4500-af8f-d05680374t3c", "r011-8f72v884-c17f-4500-af8f-d05900374t3c"]
ID_RSA_FILE_PATH = "ansible/id_rsa"
# The path to an existing id_rsa private key file, with 0600 permissions. The private key must be in OpenSSH
format.
# This private key is used only during the provisioning and it is recommended to be changed after the SAP
deployment.
# It must contain the relative or absoute path from your Bastion.
# Examples: "ansible/id_rsa_s4hana_ha" , "~/.ssh/id_rsa_s4hana_ha" , "/root/.ssh/id_rsa".
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 389

##########################################################
# File Shares variables:
##########################################################
SHARE_PROFILE = "dp2"
# The Storage Profile for the File Share
# More details on https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-profiles&interface=ui#dp2-profile."
USRSAP_AS1

= "20"

USRSAP_AS2

= "20"

USRSAP_SAPASCS

= "20"

USRSAP_SAPERS

= "20"

USRSAP_SAPMNT

= "20"

USRSAP_SAPSYS

= "20"

USRSAP_TRANS

= "80"

# Default File shares sizes:
##########################################################
# DB VSI variables:
##########################################################
DB_HOSTNAME_1 = "hanadb-1"
# HANA DB VSI HOSTNAME 1 in SAP HANA Cluster. The hostname should be up to 13 characters, as required by SAP
# Default value: "hanadb-1"
# When the default value is used, the virtual hostname will automatically be changed based on <HANA_SID> to
"hanadb-<hana_sid>-1"
DB_HOSTNAME_2 = "hanadb-2"
# HANA DB VSI HOSTNAME 2 in SAP HANA Cluster. The hostname should be up to 13 characters, as required by SAP
# Default value: "hanadb-2"
# When the default value is used, the virtual hostname will automatically be changed based on <HANA_SID> to
"hanadb-<hana_sid>-2"
DB_PROFILE = "mx2-16x128"
# The instance profile used for the HANA VSI. The list of certified profiles for HANA VSIs:
https://cloud.ibm.com/docs/sap?topic=sap-hana-iaas-offerings-profiles-intel-vs-vpc
# Details about all x86 instance profiles: https://cloud.ibm.com/docs/vpc?topic=vpc-profiles).
# For more information about supported DB/OS and IBM Gen 2 Virtual Server Instances (VSI), check [SAP Note
2927211: SAP Applications on IBM Virtual Private Cloud](https://launchpad.support.sap.com/#/notes/2927211)
# Default value: "mx2-16x128"
DB_IMAGE = "ibm-redhat-8-6-amd64-sap-hana-5"
# OS image for DB VSI. Supported OS images for DB VSIs: ibm-redhat-8-6-amd64-sap-hana-5, ibm-redhat-8-4-amd64-saphana-9
# The list of available VPC Operating Systems supported by SAP: SAP note '2927211 - SAP Applications on IBM
Virtual Private Cloud (VPC) Infrastructure environment' https://launchpad.support.sap.com/#/notes/2927211; The
list of all available OS images: https://cloud.ibm.com/docs/vpc?topic=vpc-about-images
# Example: DB_IMAGE = "ibm-redhat-8-4-amd64-sap-hana-9"
##########################################################
# SAP APP VSI variables:
##########################################################
APP_HOSTNAME_1 = "sapapp-1"
# APP VSI HOSTNAME 1 in SAP APP Cluster. The hostname should be up to 13 characters.
# Default value: "sapapp-1"
# When the default value is used, the virtual hostname will automatically be changed based on <SAP_SID> to
"sapapp-<sap_sid>-1"
APP_HOSTNAME_2 = "sapapp-2"
# APP VSI HOSTNAME 2 in SAP APP Cluster. The hostname should be up to 13 characters.
# Default value: "sapapp-2"
# When the default value is used, the virtual hostname will automatically be changed based on <SAP_SID> to
"sapapp-<sap_sid>-2"
APP_PROFILE = "bx2-4x16"
# The APP VSI profile. Supported profiles: bx2-4x16. The list of available profiles:
https://cloud.ibm.com/docs/vpc?topic=vpc-profiles&interface=ui
APP_IMAGE = "ibm-redhat-8-6-amd64-sap-hana-5"
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 390

# OS image for SAP APP VSI. Supported OS images for APP VSIs: ibm-redhat-8-6-amd64-sap-hana-5, ibm-redhat-8-4amd64-sap-hana-9.
# The list of available VPC Operating Systems supported by SAP: SAP note '2927211 - SAP Applications on IBM
Virtual Private Cloud (VPC) Infrastructure environment' https://launchpad.support.sap.com/#/notes/2927211; The
list of all available OS images: https://cloud.ibm.com/docs/vpc?topic=vpc-about-images
# Example: APP_IMAGE = "ibm-redhat-8-4-amd64-sap-hana-9"
##########################################################
# Activity Tracker variables:
##########################################################
ATR_NAME = ""
# The name of the EXISTING Activity Tracker instance, in the same region chosen for SAP system deployment.
# Example: ATR_NAME="Activity-Tracker-SAP-eu-de"

4. Customize your SAP system configuration. In the same input.auto.tfvars file, edit the SAP system configuration variables that are
passed to the Ansible automated deployment. For descriptions of the variables, see the readme file.
$ ##########################################################
# S/4HANA version
##########################################################
S4HANA_VERSION = "2023"
# The version of S/4HANA. Supported values: 2023, 2022, 2021, 2020.
# Example: S4HANA_VERSION = "2022"
##########################################################
# SAP HANA configuration
##########################################################
HANA_SID = "HDB"
# SAP HANA system ID. Should follow the SAP rules for SID naming.
# Obs. This will be used

also as identification number across different HA name resources. Duplicates are not

allowed.
# Example: HANA_SID = "HDB"
HANA_SYSNO = "00"
# SAP HANA instance number. Should follow the SAP rules for instance number naming.
# Example: HANA_SYSNO = "00"
HANA_SYSTEM_USAGE = "custom"
# System usage. Default: custom. Suported values: production, test, development, custom
# Example: HANA_SYSTEM_USAGE = "custom"
HANA_COMPONENTS = "server"
# SAP HANA Components. Default: server. Supported values: all, client, es, ets, lcapps, server, smartda,
streaming, rdsync, xs, studio, afl, sca, sop, eml, rme, rtl, trp
# Example: HANA_COMPONENTS = "server"
KIT_SAPHANA_FILE = "/storage/HANADB/51057281.ZIP"
# SAP HANA Installation kit path
# Validated SAP HANA versions for S/4HANA 2023 on Red Hat 8: HANA 2.0 SP 7 Rev 73, kit file: 51057281.ZIP
# Validated SAP HANA versions for S/4HANA 2022, 2021, 2020 on Red Hat 8: HANA 2.0 SP 5 Rev 57, kit file:
51056441.ZIP
# Example for Red Hat 8: KIT_SAPHANA_FILE = "/storage/HANADB/51056441.ZIP"
##########################################################
# SAP system configuration
##########################################################
SAP_SID= "S4A"
# SAP System ID
# Obs. This will be used

also as identification number across different HA name resources. Duplicates are not

allowed.
SAP_ASCS_INSTANCE_NUMBER = "00"
# The central ABAP service instance number. Should follow the SAP rules for instance number naming.
# Example: SAP_ASCS_INSTANCE_NUMBER = "00"
SAP_ERS_INSTANCE_NUMBER = "01"

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 391

# The enqueue replication server instance number. Should follow the SAP rules for instance number naming.
# Example: SAP_ERS_INSTANCE_NUMBER = "01"
SAP_CI_INSTANCE_NUMBER = "10"
# The primary application server instance number. Should follow the SAP rules for instance number naming.
# Example: SAP_CI_INSTANCE_NUMBER = "10"
SAP_AAS_INSTANCE_NUMBER = "20"
# The additional application server instance number. Should follow the SAP rules for instance number naming.
# Example: SAP_AAS_INSTANCE_NUMBER = "20"
HDB_CONCURRENT_JOBS = "23"
# Number of concurrent jobs used to load and/or extract archives to HANA Host
##########################################################
# SAP S/4HANA APP Kit Paths
##########################################################
KIT_SAPCAR_FILE = "/storage/S4HANA/SAPCAR_1010-70006178.EXE"
KIT_SWPM_FILE = "/storage/S4HANA/SWPM20SP17_0-80003424.SAR"
KIT_SAPEXE_FILE = "/storage/S4HANA/KERNEL/793/SAPEXE_60-70007807.SAR"
KIT_SAPEXEDB_FILE = "/storage/S4HANA/KERNEL/793/SAPEXEDB_60-70007806.SAR"
KIT_IGSEXE_FILE = "/storage/S4HANA/KERNEL/793/igsexe_4-70005417.sar"
KIT_IGSHELPER_FILE = "/storage/S4HANA/igshelper_17-10010245.sar"
KIT_SAPHOSTAGENT_FILE = "/storage/S4HANA/SAPHOSTAGENT61_61-80004822.SAR"
KIT_HDBCLIENT_FILE = "/storage/S4HANA/IMDB_CLIENT20_018_27-80002082.SAR"
KIT_S4HANA_EXPORT = "/storage/S4HANA/2023"

Note: Ansible decompresses the rest of the SAP kit files. For more information, see the readme file.
5. Initialize the Terraform CLI.
$ terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
$ terraform plan --out plan1

You will be asked for the following sensitive variables: 'IBMCLOUD_API_KEY', 'SAP_MAIN_PASSWORD' HANA_MAIN_PASSWORD, and
'HA_PASSWORD' .

The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters:
a-z, A-Z, 0-9, @, #, $, _. This password cannot contain ! . It must not start with a digit or an underscore ( _ ).
7. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
8. Create the IBM Cloud resources for S/4HANA HA system and install the SAP system.
$ terraform apply "plan1"

The virtual private cloud and components are created and you see output similar to the

terraform plan output.

$ terraform destroy

You will be asked for the following sensitive variables as a destroy confirmation phase: 'IBMCLOUD_API_KEY', 'SAP_MAIN_PASSWORD'
HANA_MAIN_PASSWORD, and 'HA_PASSWORD' .

Deploying SAP S/4HANA High Availability on Single zone or Multi zone with the catalog tile
interface
Use these steps to configure the SAP HA SZ or MZ S/4HANA on your existing VPC by using the catalog tile interface. The available supported
S/4HANA versions are 2020, 2021, 2022, and 2023. For more information, see the readme file for recommended kits versions. The scripts
can take 2 - 3 hours to complete.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 392

1. From the IBM Cloud catalog, select the SAP S/4HANA High Availability tile. The tile opens the Create tab for SAP HA S/4HANA. For more
information about this deployment, see the About tab or the readme file link.
2. On the SAP HA S/4HANA page, configure your workspace:
Enter a name for the workspace or use the default.
Select the Resource Group to use to create resources. Use the Default or create a Resource Group.
Select a Location to create your Schematics workspace. The workspace location does not have to match the resource location.
3. Enter the required deployment values, review the default input variables, and provide values that match your solution. These parameters
are specific to your deployment. For more information, see the Readme file - Input Parameters.
Parameter

Description

APP_HOSTNAME_1

APP VSI HOSTNAME 1 in SAP APP Cluster. The hostname should be up to 13 characters. Obs: When
the default value is used, the virtual hostname will automatically be changed based on <SAP_SID> to
"sapapp-<sap_sid>-1"

APP_HOSTNAME_2

APP VSI HOSTNAME 2 in SAP APP Cluster. The hostname should be up to 13 characters. Obs: When
the default value is used, the virtual hostname will automatically be changed based on <SAP_SID> to
"sapapp-<sap_sid>-2"

BASTION_FLOATING_IP

Input the floating IP of the bastion server you created before you started this deployment. For more
information, see Automate SAP bastion server - SAP media storage repository.

DB_HOSTNAME_1

HANA DB VSI HOSTNAME 1 in SAP HANA Cluster. The hostname should be up to 13 characters. Obs:
When the default value is used, the virtual hostname will automatically be changed based on
<HANA_SID> to "hanadb-<hana_sid>-1"

DB_HOSTNAME_2

HANA DB VSI HOSTNAME 2 in SAP HANA Cluster. The hostname should be up to 13 characters. Obs:
When the default value is used, the virtual hostname will automatically be changed based on
<HANA_SID> to "hanadb-<hana_sid>-2"

DOMAIN_NAME

The Domain Name used for DNS and ALB. Duplicates are not allowed. The list with DNS resources
can be found here: https://cloud.ibm.com/resources.

REGION

Cloud Region where resources are deployed.

RESOURCE_GROUP

Existing Resource Group for VSIs and Volumes

SECURITY_GROUP

Existing Security group name

SSH_KEYS

SSH Keys ID list to access the VSI.

SUBNET

Existing Subnet name

VPC

Existing VPC name

ZONE

Cloud zone where resources are deployed.

HA_PASSWORD

HA cluster password

HANA_COMPONENTS

HANA components for example, server

HANA_MAIN_PASSWORD

HANA main password or use a secret that is stored in Secrets Manager.

HANA_SID

HANA sid

IBMCLOUD_API_KEY

IBM Cloud API key or use a secret that is stored in Secrets Manager.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 393

PRIVATE_SSH_KEY

Input id_rsa private key content or use a secret that is stored in Secrets Manager.

SAP_MAIN_PASSWORD

SAP main password or use a secret that is stored in Secrets Manager.

SAP_SID

SAP sid

4. Review and update the optional parameters. The Ansible scripts expect the SAP kits to be in the default locations listed. For more
information, see the Readme file - Input Parameters.
Parameter

Description

APP_IMAGE

APP VSI OS image

APP_PROFILE

APP VSI profile

ASCS_VIRT_HOSTNAME

ASCS Virtual hostname

DB_IMAGE

DB VSI OS image

DB_PROFILE

DB VSI profile

ERS_VIRT_HOSTNAME

ERS Virtual hostname

HANA_VIRT_HOSTNAME

HANA Virtual hostname

HANA_SYSNO

The instance number of the SAP HANA system.

HANA_SYSTEM_USAGE

System Usage. Default: "custom". Valid values: "production", "test", "development", "custom".

HDB_CONCURRENT_JOBS

Number of concurrent jobs used to load and/or extract archives to HANA Host.

KIT_HDBCLIENT_FILE

Path to HANA DB client archive (SAR), as downloaded from SAP Support Portal.

KIT_IGSEXE_FILE

Path to IGS archive (SAR), as downloaded from SAP Support Portal.

KIT_IGSHELPER_FILE

Path to IGS Helper archive (SAR), as downloaded from SAP Support Portal.

KIT_S4HANA_EXPORT

Path to S/4HANA Installation Export dir. The archives downloaded from SAP Support Portal
should be present in this path.

KIT_SAPCAR_FILE

Path to sapcar binary, as downloaded from SAP Support Portal.

KIT_SAPEXE_FILE

Path to SAP Kernel OS archive (SAR), as downloaded from SAP Support Portal.

KIT_SAPEXEDB_FILE

Path to SAP Kernel DB archive (SAR), as downloaded from SAP Support Portal.

KIT_SAPHANA_FILE

Path to SAP HANA ZIP file, as downloaded from SAP Support Portal.

KIT_SAPHOSTAGENT_FILE

Path to SAP Host Agent archive (SAR), as downloaded from SAP Support Portal.

KIT_SWPM_FILE

Path to SWPM archive (SAR), as downloaded from SAP Support Portal.

SAP_AAS_INSTANCE_NUMBER

The SAP additional application server instance number. Technical identifier for internal
processes of AAS. Consists of a two-digit number from 00 to 97. Must be unique on a host.
Must follow the SAP rules for instance number naming.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 394

SAP_ASCS_INSTANCE_NUMBER

The central ABAP service instance number. Technical identifier for internal processes of ASCS.
Consists of a two-digit number from 00 to 97. Must be unique on a host. Must follow the SAP
rules for instance number naming.

SAP_CI_INSTANCE_NUMBER

The SAP central instance number. Technical identifier for internal processes of PAS. Consists
of a two-digit number from 00 to 97. Must be unique on a host. Must follow the SAP rules for
instance number naming.

SAP_ERS_INSTANCE_NUMBER

The enqueue replication server instance number. Technical identifier for internal processes of
ERS. Consists of a two-digit number from 00 to 97. Must be unique on a host. Must follow the
SAP rules for instance number naming.

SHARE_PROFILE

Enter the IOPs (IOPS per GB) tier for File Share storage. Valid values are 3, 5, and 10.

S4HANA_VERSION

The version of S/4HANA. Supported values: 2023, 2022, 2021, and 2020.

USRSAP_AS1

FS size in GB for usrsap-as1

USRSAP_AS2

FS size in GB for usrsap-as2

USRSAP_SAPASCS

FS size in GB for usrsap-sapascs

USRSAP_SAPERS

FS size in GB for usrsap-sapers

USRSAP_SAPMNT

FS size in GB for usrsap-mnt

USRSAP_SAPSYS

FS size in GB for usrsap-sapsys

USRSAP_TRANS

FS size in GB for usrsap-trans

5. Accept the license agreement.
6. Select Install. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

Deploying SAP S/4HANA High Availability on Single Zone with the Schematics interface
Use these steps to configure the SAP S/4HANA High Availability on Single Zone on your existing VPC by using the Schematics interface. The
scripts can take 2 - 3 hours to complete. The supported versions available for S/4HANA are 2020, 2021, 2022, and 2023. For more
information, see the readme for recommended kits versions.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the GitHub repository URL that contains the Schematics code for this offering.
Select the Terraform version.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 395

For more detailed description of each of these parameters, check the GitHub repo readme file, chapter “Input parameter file”. Also,
make sure to mark the parameters that contain sensitive information like passwords, API, and ssh private keys as "sensitive". These
parameters are marked as “sensitive” in the readme file, under “Input parameter file”.
Save each parameter that you modify.
7. On the workspace settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Next steps
If you need to remove the SAP HA S/4HANA installation, go to your project folder and run

terraform destroy . The terraform destroy

command does not remove the VPC in this scenario because the VPC was not created with the same Terraform script.

Related information
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier VPC for SAP

on IBM Cloud® VPC with Terraform.
Following are the SAP One Support Notes, that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP license
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel® processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP HANA DB backup to Cloud Object Storage
Introduction to IBM Cloud VPC and HANA db backup on Cloud Object Storage automation
You can use Terraform to automate IBM Cloud® VPC provisioning. The provisioning includes virtual server instances with high network
performance. For the VPC infrastructure there are a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers. After the
VPC infrastructure components are provisioned, the scripts use the Ansible playbooks to install the SAP system. IBM Cloud VPC infrastructure
consists of SAP certified hardware that uses Intel® Xeon CPUs and additional Intel® technologies.

IBM Cloud VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission. A VPC’s logical isolation is implemented by using virtual network functions
and security features that give an enterprise customer granular control over which IP addresses or applications can access particular
resources. It is analogous to the “friends-only” or “public/private” controls on social media accounts used to restrict who can or can’t see your
otherwise public posts.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 396

With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains several Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP on IBM Cloud
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for ABAP and Java applications. The SAP
system can be installed and configured in IBM Cloud for various system and database types.
For more information about SAP system architectures on IBM Cloud VPC, see the infrastructure reference architectures for SAP for each
supported database type. For example, SAP NetWeaver 7.x on UNIX with HANA on IBM Cloud VPC is the dedicated reference architecture for
this SAP solution.

SAP Project Value Guide – IBM Cloud VPC and HANA db backup automation on Cloud Object
Storage
SAP projects vary widely in scope and budget, but none are considered trivial. Whether you are delivering a new SAP system or implementing
changes to an existing one, the requirements for error-free execution and reducing the project time to realized benefits are always present.
In many SAP project scenarios, the deployment of an SAP system is often a key and repeated task. This project value guide covers the
automated deployment of IBM Cloud VPC and HANA db backup automation on Cloud Object Storage (Cloud Object Storage). We will also
discuss on SAP NetWeaver of HANA database and Additional Application Server (AAS) to SAP instance and HANA instance in their respective
sections.
With this system being a key part of your SAP project, you will want to backup the HANA database. For more information, go to

Cloud Object

Storage on VPC for SAP HANA Backup to automatically provision IBM Cloud Object Storage resources as a backup target within HANA Studio,
using the backint agent for IBM Cloud available from SAP.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 397

Figure 1. SAP HANA database backup to IBM Cloud Object Storage

HANA db backup to IBM Cloud Object Storage (Cloud Object Storage)
IBM Cloud Object Storage stores encrypted and dispersed data across multiple geographic locations. This getting started tutorial walks through
the steps that are needed to use IBM Cloud Object Storage to create buckets, upload objects, and set up access policies to allow other users
to work with your data.
Manually deploying a VPC and configure a backup/restore on Cloud Object Storage with a backint HANA agent on a cloud platform can be timeconsuming. The Terraform automation assures not only a quicker implementation, but also a standardized and less prone to error deployment.
Terraform and Ansible are used for automating the deployment processes.

Ansible for SAP installation
Ansible is a command-line IT automation software application that can be used to configure systems, deploy software, orchestrate workflows
to support application deployment, system updates. It is used to automate the configuration of a Hana db backup for Cloud Object Storage. For
more information about Ansible, see the Ansible Documentation.
The Ansible playbooks are called directly by the Terraform scripts. The scripts start with Terraform specific steps for creating the VPC
infrastructure elements, and continues automatically with the Ansible specific steps, which configure Hana db backup for Cloud Object
Storage.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 398

Where to run the scripts
The scripts should be run from your Deployment Server because the Deployment Server has Terraform and Ansible already installed. The SAP
Kits should be downloaded to the temporary storage assigned to you on the Deployment Server. Ansible playbooks install the kits for you based
on the location of the kits that are specified in the configuration files.

Prerequisites
Before you deploy any of the SAP automated solutions on IBM Cloud VPC, a deployment server (bastion server) should be created in your
chosen region. The deployment server (bastion server) is used for downloading and storing specific SAP solution media that are needed
for later automation deployment. The deployment server (bastion server) is used for both CLI deployment scenarios, as well for
Schematics UI deployments. For more information about how to create the deployment server (bastion server) and its corresponding
VPC, see Automate SAP bastion server - SAP media storage repository . "HANA Backup to Cloud Object Storage" automation module
requires a deployment server in the same region as HANA VSI(s) to be backed up.
A pair of SSH keys to be used to run the automation for the backup configuration should be available. The public SSH key should be
manually added on SAP HANA VSI, in /root/.ssh/authorized_keys and uploaded in IBM Cloud.
The IBM Cloud user running the automation for SAP HANA backup should have the role of Manager on IBM Cloud Object Storage. To
view/use the credential, the user must have the IAM level access action resource-controller.credential.retrieve_all. This action is given
with the Administrator role, and overrides any credential level access enabling the user to view the credential. For more information on
granting the necessary authorizations to your IBM cloud user, see https://cloud.ibm.com/iam/users and select the USER_ID which runs
the automation and then check/grant the required roles. More information on Readme file.
The kit of the backup agent for IBM Cloud Object Storage aws-s3-backint-.*-linuxx86_64.tar.gz should be manually uploaded on the
bastion server. This kit is part of SAP HANA kit file and can be found in */DATA_UNITS/HDB_SERVER_LINUX_X86_64/server path. Either
the entire SAP HANA kit or only the kit of the backup agent for IBM Cloud Object Storage can be provided, but the minimum backint
agent kit version to be used is aws-s3-backint-1.2.17-linuxx86_64
The Python script create_hdbbackint.py provided by SAP (SAP note 2935898 - Install and Configure SAP HANA Backint Agent for
Amazon S3) to modify the "hdbbackint" script so that it points to the Python 3 libraries should be manually uploaded on the bastion
server.
You need to have already deployed an SAP HANA system (built on one of the following OS: SUSE Linux Enterprise Server 15 SP 4 for SAP,
SUSE Linux Enterprise Server 15 SP 3 for SAP, Red Hat Enterprise Linux 8.6 for SAP or Red Hat Enterprise Linux 8.4 for SAP) in an IBM
Cloud Gen2 VPC, on a single host (with or without HA).
The HANA DB SYSTEM user should have the same password for SYSTEMDB and all tenant databases.
Note: This HANA backup solution was implemented and tested on the following OS images available in IBM Cloud: ibm-sles-15-4amd64-sap-hana-3, ibm-sles-15-3-amd64-sap-hana-3, ibm-redhat-8-6-amd64-sap-hana-2, ibm-redhat-8-4-amd64-sap-hana-2.
The kits are installed by Ansible playbooks based on the location of the kits that are specified in the configuration files.
To save costs, the deployment server (bastion server), with its SAP media dedicated storage, can be decommissioned after the SAP solutions
are successfully implemented on IBM Cloud VPC cloud. Or, you can keep the deployment server (bastion server) and use it as a jump host for
that specific region.
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Deploying SAP HANA db backup to Cloud Object Storage on existing IBM Cloud VPC with
automation
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March
2025. Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM
Cloud Activity Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about
migrating from IBM Cloud Activity Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.
You can use Terraform scripts to create the required setup for storing HANA db backup in IBM Cloud Object Storage (COS), in case of a HANA
database instance that is already deployed in the VPC. The Terraform scripts use the VPC information that you provide and then call the
Ansible playbooks to create the SAP architecture on the specified VPC. Terraform on IBM Cloud enables predictable and consistent
provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so that you can rapidly build complex cloud environments. IBM
Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon CPUs and additional Intel® technologies.
You have two deployment methods to choose from:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 399

Terraform scripts run from the CLI on your deployment server (bastion server).
Schematics user interface accessed from your cloud dashboard menu.
You can store the SAP HANA db backup into the Cloud Object Storage.

SAP solution implemented

Figure 1. Backup SAP HANA db into Cloud Object Storage from a standard SAP NW on HANA db architecture

What is created
This automation solution is designed for the implementation of SAP HANA Backup solution that uses Backint and

IBM Cloud Object Storage. It

is based on SAP note "2935898 - Install and Configure SAP HANA Backint Agent for Amazon S3".
The minimum version of SAP HANA Backint Agent for Amazon S3 to be used for IBM Cloud Object Storage is 1.2.17. SAP HANA Backint Agent
for Amazon S3 requires Python 3.7 including SSL support. The Python package delivered as part of the SAP HANA 2 installation does not
include SSL support. Python 3.7 with SSL support is installed in /usr/local/bin directory, if it is not previously installed. SAP HANA Backint Agent
for Amazon S3 is installed in the /hana/shared/< SID >/backint_agent directory.
The setup runs initial full data backup to Cloud Object Storage for system and tenant databases. The regular backup policy for the databases
must be configured by the customer.
All data backup, log backup, and catalog backup files are saved in the same dedicated bucket (with no enforced storage quota) created in a
Cloud Object Storage instance by using an existing bastion host with secure remote SSH access in the same IBM Cloud Gen2 VPC as the SAP
HANA system. The setup uses the Regional Storage Class with the Smart Tier pricing option and the standard pricing plan. The SAP HANA
system is deployed on one of the following operating systems:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 400

SUSE Linux Enterprise Server 15 SP 4 for SAP
SUSE Linux Enterprise Server 15 SP 3 for SAP
Red Hat Enterprise Linux 8.6 for SAP
Red Hat Enterprise Linux 8.4 for SAP
The IBM Cloud Activity Tracker service should be used to capture the records of your IBM Cloud activities and monitor the activity of your IBM
Cloud account. You can use this service to investigate abnormal activity, critical actions, and comply with regulatory audit requirements. In
addition, you can be alert on the actions as they occur. The events that are collected comply with the Cloud Auditing Data Federation (CADF)
standard.
You can deploy an Activity Tracker instance along with the SAP system by using the SAP deployment Automation or if you already have created
one, you can specify the Activity Tracker name in the deployment variables. You can set the Activity Tracker plan variable according to your
chosen Service plans. By default, the Lite (free) plan is selected. For more information on how to provision an Activity Tracker instance, see
here.
Important:
Every user who accesses the IBM Cloud Activity Tracker service in your account must be assigned an access policy with an IAM user role
defined. The policy determines what actions the user can perform within the context of the service or instance you select. The allowable
actions are customized and defined as operations that are allowed to be performed on the service. The actions are then mapped to IAM
user roles. For more information, see here.
You can provision only one instance of the service per IBM Cloud region.
IBM Cloud Activity Tracker provides a solution for administrators to capture, store, view, search, and monitor API activity in a single place. It
also offers a notification feature to alert you by using any of the supported notification channels.
Note: IBM Cloud Activity Tracker collects and stores audit records for API calls made to resources that run in the IBM Cloud. You can
archive these events on IBM Cloud for long-term storage.

Script files
The configuration and script files are available in GitHub. GitHub repository for Terraform - HANA backup Cloud Object Storage

Schematics deployment
The configuration and script files are provided in GitHub. When the Schematics interface is used, the following information should be provided:
the workspace information.
the GitHub path for the solution.
the values for the parameters in the Schematics interface; they are the same as the parameters from

input.auto.tfvars file, which

are used in CLI.

Terraform interface
To run the Terraform script, you should modify:
The input.auto.tfvars file, to specify the existing VPC resources for your solution. You should provide the values for the following
variables:
VPC name
Region
Security group
Subnet
Resource Group
HostName(s)
Setup for HA
Number of backup retention days
You can change the default SAP system configuration settings to match your solution. You also specify the location where you downloaded the
SAP kits.
The IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files and the Ansible playbooks to store the HANA db
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 401

backup into Cloud Object Storage for an already installed HANA database instance, in the specified VPC, in your IBM Cloud account.

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before you use them on a live system.
Though the materials provided herein are not supported by the IBM® Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Virtual server instance configuration
This solution is applied on existing VSIs with SAP HANA deployed in an existing VPC. See below for more information:
https://github.com/IBM-Cloud/sap-netweaver-abap-hana
https://github.com/IBM-Cloud/sap-netweaver-java-hana
https://github.com/IBM-Cloud/sap-s4hana
https://github.com/IBM-Cloud/sap-bw4hana
https://github.com/IBM-Cloud/sap-netweaver-abap-hana
https://github.com/IBM-Cloud/sap-s4hana-sz-ha

Before you begin
Before you use the scripts:
An SAP HANA system that is built on one of the above OS should be deployed in an IBM Cloud Gen2 VPC, on a single host with or without
HA. This HANA backup solution is implemented and tested on the following OS images available in IBM Cloud:
ibm-sles-15-4-amd64-sap-hana-3
ibm-sles-15-3-amd64-sap-hana-2
ibm-redhat-8-6-amd64-sap-hana-2
ibm-redhat-8-4-amd64-sap-hana-2
A bastion server with secure remote SSH access must be deployed in the same region and zone of IBM Cloud Gen2 VPC as the SAP
HANA system.
A pair of SSH keys used to run the automation for the backup configuration should be available. The public SSH key should be manually
added on SAP HANA VSI in /root/.ssh/authorized_keys and uploaded in IBM Cloud.
The IBM Cloud user running the automation for SAP HANA backup should have the role of Manager on IBM Cloud Object Storage. To view
or use the credentials, the user should have the IAM level access action "resource-controller.credential.retrieve_all". This permission is
given to the administrator role and overrides any credential level access enabling the user to view the credentials.
To provide the access for the required roles to run the "SAP HANA db backup to Cloud Object Storage", go to

https://cloud.ibm.com/iam/users

and select the USER_ID to run the automation.
Figure 1. SAP HANA db backup to Cloud Object Storage

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 402

The kit of the backup agent for the IBM COS aws-s3-backint-.*-linuxx86_64.tar.gz should be manually uploaded on the
deployment server (bastion server). This kit is part of the SAP HANA kit file and can be found in
*/DATA_UNITS/HDB_SERVER_LINUX_X86_64/server path. Either the entire SAP HANA kit or only the kit of the backup agent for IBM COS

can be provided, but the minimum backint agent kit version to be used is aws-s3-backint-1.2.17-linuxx86_64
The Python script create_hdbbackint.py provided by SAP (SAP note 2935898 - Install and Configure SAP HANA Backint Agent for
Amazon S3) to modify the hdbbackint script so that it points to the Python 3 libraries must be manually uploaded on the bastion
server.
The HANA DB system user should have the same password for SYSTEMDB and all tenant databases.

Deploying SAP HANA Backup to IBM Cloud Object Storage on VPC by using the Schematics user
interface
Use these steps to configure the SAP HANA Backup for COS by using the Schematics interface. The script takes one hour to complete if they
run after a SAP HANA fresh install.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the URL for the github repository that contains the Schematics code for this offering.
Select the Terraform version that is listed in the Readme file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 403

5. Select Create to create your workspace.
6. On the workspace settings page, in the input variables section, review the default input variables and provide values that match your
solution.
For a more detailed description of each of the parameters, check the GitHub repo Readme file, chapter “Input parameter file”. Also,
ensure to mark the parameters that contain sensitive information like passwords, API, and ssh private keys as "sensitive". These
parameters are marked as “sensitive” in the readme file, under Input parameter file. Save each parameter that you modify.
7. On the workspace settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Deploying SAP HANA Backup to IBM Cloud Object Storage on VPC via the Deployable Architecture
tile
Use these steps to configure the SAP NetWeaver (ABAP) Linux/HANA on your existing VPC by using the catalog tile interface. The script takes 2
- 3 hours to complete.
1. From the IBM Cloud Catalog menu, select Cloud Object Storage on VPC for SAP HANA Backup on Deployable Architecture tile. For
more information about this deployment, see the Readme file.
2. Select the latest version.
3. Select the Standard variation.
4. Click Review deployment options:
Add to project to add this deployment to an IBM Cloud project and combine it with other deployments. The IBM Cloud projects
include several other pipeline steps, including deployment validation, cost calculation, compliance verification, and approval
process.
Create from the CLI to get the CLI command. With this command you can trigger the deployment from the CLI.
Work with code to embed the code into other terraform deployment.
Deploy with IBM Cloud Schematics to trigger deployment process directly.
5. Select the Deploy with IBM Cloud Schematics option. Now, add the input parameters for this installation. There are 3 categories of
parameters:
Workspace - These parameters define the workspace is automatically created in the Schematics:
Enter a name for the workspace or use default name.
The Resource Group used to create resources. Use default or create a Resource Group.
Select a location to create your Schematics workspace. The workspace location need not match the resource location.
Required input variables - Review the default input variables and provide values that match your solution. These parameters are
specific to your deployment. For more detailed information, see the Readme file.
Parameter

Description

BACKINT_COS_KIT

The full path to the backup agent for IBM COS kit. Mandatory only if
HANA_KIT_FOR_BACKINT_COS is not provided. Make sure the version of the backint agent kit
is at least aws-s3-backint-1.2.17-linuxx86_64.

BASTION_FLOATING_IP

Input the floating IP from the bastion server.

CREATE_HDBBACKINT_SCRIPT

The full path to the Python script provided by SAP (SAP note 2935898 - Install and Configure
SAP HANA Backint Agent for Amazon S3) to modify the "hdbbackint" script so that it points to
the Python 3 libraries.

HANA_MAIN_PASSWORD

HANA system master password. The HANA DB system user must have the same password for
SYSTEMDB and all tenant databases.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 404

DB_HOSTNAME_1

The hostname of an existing HANA VSI. Required. If High Availability is configured for HANA
Database must be the hostname of HANA DB VSI 1.

HANA_SID

Existing SAP HANA system ID. The SAP system ID identifies the SAP HANA system.

HANA_SYSNO

Existing SAP HANA instance number. Specifies the instance number of the SAP HANA system.

HANA_TENANTS

A list of existent SAP HANA tenant databases.

HA_CLUSTER

Choose if High Availability is configured for HANA Database. Accepted values: yes/no. For the
value "no" it is required that only the "DB_HOSTNAME_1" variable to be filled in. For the value
"yes" it is required that both next variables to be filled in: DB_HOSTNAME_1,
DB_HOSTNAME_2.

IBM_CLOUD_API_KEY

IBM Cloud API key (Sensitive* value).

LIFECYCLE_POLICY

The number of retention days for HANA database backup and transaction log backup.

REGION

The cloud region where HANA VSI was deployed. The COS is created in the same region as
HANA VSI. The regions and zones for VPC are listed here. Review supported locations in IBM
Cloud Schematics here.

RESOURCE_GROUP

The name of an existing Resource Group for VSIs and Volumes resources. The list of Resource
Groups is available here.

SECURITY_GROUP

The name of an existing Security group. The list of Security Groups is available here.

SUBNET

The name of an existing subnet. The list of subnets is available here.

VPC

The name of an existin VPC. The list of VPCs is available here.

private_ssh_key

Input your id_rsa private key pair content in OpenSSH format (Sensitive* value). This private
key must be used only during the terraform provisioning and it is recommended to be changed
after the SAP deployment.

Optional input variables - Review and update the optional parameters. For more detailed information, see the

Readme file.

Parameter

Description

DB_HOSTNAME_2

The Hostname of an existing HANA VSI 2. Required only if High Availability is configured for
HANA Database.

HANA_KIT_FOR_BACKINT_COS

The full path to SAP HANA kit file to be used by the automation to extract backint agent kit for
IBM COS aws-s3-backint-....-linuxx86_64.tar.gz. Mandatory only if BACKINT_COS_KIT is not
provided. Make sure the version of the contained backint agent kit is at least aws-s3-backint1.2.17-linuxx86_64.

ID_RSA_FILE_PATH

The file path for private_ssh_key is automatically generated by default. If it is changed, it must
contain the relative path from git repo folders.

6. Accept the license agreement.
7. Select Deploy. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

Before you begin
You need the following to get started with IBM Cloud Object Storage:
Go to IBM Cloud Platform account.
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 405

Create a deployment server (bastion server) to store the SAP kits. For more information, see the Automate SAP bastion server - SAP
media storage repository
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the downloaded locations. Ansible decompresses
the files. For more information, see the Readme file.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the create or retrieve your SSH key ID.
Log in to the IBM Cloud platform and to determine your permissions for IBM Cloud services.
Terraform should be already installed on the deployment server (bastion server) that you deployed. For more information, see the
Bastion server for SAP deployment.
Before using "HANA db backup to Cloud Object Storage" automation module the HANA database instance(s) should be installed on the
specified VPC in your IBM Cloud account.
Ensure you have the same password for all your HANA db system users before you run this automation module for HANA backup in
Cloud Object Storage.

Creating the infrastructure by using the Terraform CLI and the deployment server (bastion server)
Use these steps and "HANA db backup to Cloud Object Storage" automation module to configure the backup of SAP HANA db into Cloud Object
Storage for an already deployed SAP HANA db 2.0, in your existing VPC.
The scripts take 1-2 hours to complete. A full backup of System DB and Tenant DB is executed at the end.
1. Access the deployment server (bastion server) CLI.
2. Clone the solution repository from https://github.com/IBM-Cloud/sap-hana-backup-cos
$ git clone https://github.com/IBM-Cloud/sap-hana-backup-cos.git
cd sap-hana-backup-cos

3. Specify your VPC. Modify the input.auto.tfvars file to specify the information for the existing VPC and component names. For
descriptions of the variables, see the Readme file. The VSI OS images that are validated for the automation solution "HANA db backup to
Cloud Object Storage" are:
SUSE Linux Enterprise Server 15 SP 4 for SAP
SUSE Linux Enterprise Server 15 SP 3 for SAP,
Red Hat Enterprise Linux 8.6 for SAP or
Red Hat Enterprise Linux 8.4 for SAP
Note: Any of the above OS distributions and versions can be used for the prior deployment of the host(s) for the HANA db (with or without
HA) in an IBM Cloud Gen2 VPC. This HANA backup solution was implemented and tested on the following OS images available in IBM
Cloud: ibm-sles-15-4-amd64-sap-hana-3, ibm-sles-15-3-amd64-sap-hana-3, ibm-redhat-8-6-amd64-sap-hana-2, ibm-redhat-8-4amd64-sap-hana-2.
$ # Infra VPC variables
REGION

= "eu-de"

VPC

= "ic4sap"

SECURITY_GROUP

= "ic4sap-securitygroup"

RESOURCE_GROUP

= "wes-automation"

SUBNET

= "ic4sap-subnet"

ID_RSA_FILE_PATH = "/root/.ssh/id_rsa_backup"
# Cloud Object Storage variables:
LIFECYCLE_POLICY = "60"
# HANA VSI variables:
HA_CLUSTER

= "yes/no"

DB_HOSTNAME_1

= "hanadb-vsi1"

DB_HOSTNAME_2

= ""

Edit your IBM Cloud Activity Tracker (only for ABAP stack) input variables below:
$ # Activity Tracker variables:
ATR_PROVISION = "true"

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 406

# Activity Tracker : Disable this to not provision Activity Tracker instance.
# If an Activity Tracker instance already exists in the same region where this solution is to be deployed then
# disable (ATR_PROVISION = "false") this to avoid provisioning an Activity Tracker instance.
# A new instance of Activity Tracker will be deployed with this solution if ATR_PROVISION=true
# Example to create Activity Tracker instance: ATR_PROVISION = "true"
# Example to integrate existing Activity Tracker instance : ATR_PROVISION = "false"
ATR_NAME = "Activity-Tracker-COS-eu-de"
# Provide the Activity Tracker instance name to create or
# provide the existing Activity Tracker instance name in the same region where this solution is to be be deployed.
# Example: ATR_NAME = "Activity-Tracker-COS-eu-de"
ATR_TAGS = [""]
# Activity Tracker: (Optional) only if ATR_PROVISION = "true", tags that should be applied to the Activity Tracker
instance.
# example ATR_TAGS = ["activity-tracker-cos"]
ATR_PLAN = "lite"
# Mandatory only if ATR_PROVISION is set to true. Activity Tracker: The type of plan the service instance should
run under (lite, 7-day, 14-day, or 30-day).
# The list of service plan is avaialble here: https://cloud.ibm.com/docs/activity-tracker?topic=activity-trackerservice_plan#service_plan"
# Example ATR_PLAN = "lite"

4. Customize your SAP system configuration. In the same input.auto.tfvars file, edit the SAP system configuration variables that are
passed to the Ansible automated deployment. For descriptions of the variables, see the Readme file.
$ # SAP HANA backup configuration
HANA_SID

= "HDB"

HANA_SYSNO

= "00"

HANA_TENANTS

= ["Ten_HDB1", "Ten_HDB2"]

# Kits paths - for HANA db backup to Cloud Object Storage
BACKINT_COS_KIT

= "/storage/hdb_backup_kit_files/aws-s3-backint/aws-s3-backint-1.2.18-linuxx86_64.tar.gz"

HANA_KIT_FOR_BACKINT_COS = ""
CREATE_HDBBACKINT_SCRIPT ="/storage/hana_backup_kit_files/create_hdbbackint.py"

5. Initialize the Terraform CLI.
$ terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are performed by the automation
scripts based on the input variables.
$ terraform plan --out plan1

You should enter an SAP HANA main password (which should be the same for all your HANA SYSTEM db users) and your API key. The
SAP main password should be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters: az, A-Z, 0-9, @, #, $, . This password cannot contain exclamation points '!'. The password should not start with a digit or an underscore ().
7. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
8. Apply the saved terraform plan.
$ terraform apply "plan1"

Resources are created and you see output similar to the terraform plan output.
9. IBM Cloud Object Storage instance and bucket are created and the Hana DB system is configured to use backint backup.
10. Add the SAP credentials and the virtual server instance IP to the SAP GUI or HANA STUDIO. For more information about the SAP GUI, see
SAP GUI.

Next steps
Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The Terraform scripts create a complete solution
and selectively modifying resources with the user interface might cause unexpected results.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 407

If you need to remove the backup service:
Remove the "Hana backup to Cloud Object Storage" configuration and delete the Cloud Object Storage.
First change/adapt Hana backup configuration to not use backint/backup to IBM Cloud Object Storage:
1. Check and change/delete any Hana database backup job (for SYSTEM and tenant DBs) already scheduled, by using the same tool that
you used to schedule the job (OS crontab, SAP DB13, SAP HANA Cockpit, Hana Studio) to not use the backint/backup to IBM Cloud
Object Storage.
2. Make sure that the Hana "LOG Backup Settings" is changed from backint/backup to Cloud Object Storage to any other "Destination type"
(file/disk, other backup tool). You can use SAP HANA Cockpit, Hana Studio, or other tool. Double check in the "Hana backup log" file and
the new backup location to see whether Hana logs are automatically backed up as needed.
3. Make sure that Hana "Backup Catalog" destination is changed from backint/backup to Cloud Object Storage to any other "Destination
type" (file/disk, other backup tool). You might use SAP Hana Cockpit, Hana Studio.
4. Make sure that you don't need the previous backups of Hana data and logs saved to Cloud Object Storage. Cloud Object Storage and all
Hana data backups and logs backups are deleted. Make sure you saved them before in another location if you still need them.
5. Run a full DATA backup test for SYSTEM and Tenant DBs using the new backup location (file/disk, other backup tool), different from IBM
Cloud Object Storage. Make sure that all backups complete succesfuly in the new location.
6. Check and reschedule full data backups for SYSTEM and tenant DBs using the new "Destination type" (file/disk, other backup tool).
Second, release the IBM Bucket and delete all the backups:
1. Run terraform destroy to delete the used IBM bucket (the Cloud Object Storage instance, as well) and all its contents/backups.
The used files/directories for "Python 3.7 with ssl support" and "S3 backint" are still present at the OS level on Hana VSI but Hana will no
longer use them.
If the resources created with the SAP deployment automation is removed, the Activity Tracker instance is also removed, if it is provisioned at
the same time with the SAP solution (when ATR_PROVISION parameter is set to true during the deployment of the SAP solution).

Next steps
Do not use the IBM Cloud dashboard and user interface to modify your VPC after it is created. The Terraform scripts create a complete solution
and selectively modifying resources with the user interface might cause unexpected results.
If the resources created with the SAP deployment automation is removed, the Activity Tracker instance is also removed, if it is provisioned at
the same time with the SAP solution (when ATR_PROVISION parameter is set to true during the deployment of the SAP solution).

Related information
For more information about the Terraform on IBM Cloud, see Getting started with Terraform on IBM Cloud .
For more information about using the Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier virtual

private cloud for SAP by using Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
IBM Cloud Activity Tracker
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 408

Deploying SAP S/4HANA on 3-tier IBM Cloud® VPC (Terraform and Ansible)
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March
2025. Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM
Cloud Activity Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about
migrating from IBM Cloud Activity Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.
You can use Terraform scripts to create a single-tier VPC and create the SAP/SAP HANA in a distributed architecture on the bastion server.
Creating the bastion server is a prerequisite for all IBM SAP VPC automated solutions. The automation scripts use the VPC information that you
provide and then call the Ansible playbooks to create the SAP architecture on the specified VPC. Terraform on IBM Cloud® enables predictable
and consistent provisioning of IBM Cloud VPC infrastructure resources so that you can rapidly build complex, cloud environments. IBM Cloud
VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon CPUs and other Intel® technologies.
You have three deployment methods to choose from:
Terraform scripts that run from the CLI on your bastion server.
Catalog Tile user interface accessed from the IBM Cloud Catalog.
IBM Cloud® Schematics user interface accessed from the menu on your cloud dashboard.

SAP Solution implemented
SAP S/4HANA is an ERP system from SAP's ERP software product line. The software is based on the innovative SAP HANA database technology
and was launched as the fourth product generation in 2015. Users can choose between the SAP S/4HANA Cloud and On-Premise solution.
An ERP system is used for demand-oriented business resource planning. It is used to control processes and to link departments and functional
areas in a meaningful way. Individual modules include applications for accounting, sales, production, and marketing. More complex tasks in
customer or supply chain management can also be done by ERP software. As the successor to the core product SAP ECC, SAP S/4HANA was
presented as the intelligent ERP system of the new generation. Thanks to modern technologies, the Software as Service (SaaS) version is
designed to help companies standardize processes and make the leap to digitalization.
While previous SAP ERP solutions support the most common databases, SAP S/4HANA uses exclusively the SAP HANA in-memory database
developed by SAP. This in-memory database offers users the greatest technical benefit and they benefit from increased performance. The "S"
in S/4HANA stands for "simple", while the "4" refers to the generation sequence. Compared to the SAP core product SAP ECC, which is still
used in most companies, SAP S/4HANA offers many innovative functions that revolutionize the system landscape from the ground up. As SAP
plans to discontinue the mainstream maintenance of its existing ERP solutions by 2027, many SAP ECC users are already considering a
migration to SAP S/4HANA.

What is created
The scripts work in two phases. The first phase automates the provisioning of the IBM Cloud resources in the VPC created when you deployed
the bastion VSI. The second phase creates the SAP architecture in a distributed environment SAP S/4HANA application server on a distinct
VSI VPC system and SAP HANA DB on a dedicated server type VSI VPC box system. For more information about this architecture, see SAP
NetWeaver 7.x with SAP HANA IBM Cloud® VPC.
During the first phase, the VPC is provisioned with 2 X virtual server instances with SAP certified storage and network configurations.
During the second phase, the Ansible playbooks are called and the SAP architecture is installed for both dedicated VSIs SAP App VSI system
and dedicated SAP HANA VSI box. The SAP architecture that is deployed is the SAP S/4HANA release on stand-alone dedicated SAP HANA 2.0
box release as a distributed deployment model. For more information about this architecture, see Automating SAP HANA stand-alone virtual
server instance on IBM Cloud® VPC by using Terraform and Ansible.

Single-host SAP HANA system
A single-host system is the simplest system installation type that runs an SAP HANA db system entirely on one host. You can scale the system
up as needed. The single-host system has these components:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 409

Figure 1. SAP NetWeaver 7.x SAP HANA 3-tier architecture

The scripts are designed to install SAP (SAP S/4HANA release) solution on an existing VPC together with its dedicated DB SAP HANA box in one
task flow.

SAP Kits
It is your responsibility to download the necessary SAP and DB kits to your Deployment Server (bastion server). All files archives are
decompressed by Ansible during the automation deployment process. For more information, see the readme file.

Terraform deployment
You use the Bastion server CLI to run the Terraform scripts that are located in the GitHub repository for SAP S/4HANA for Terraform .
To run the scripts to deploy the SAP S/4HANA release on dedicated SAP HANA 2.0 BOX VSI, you need to:
Customize the resources for your solution in input.auto.tfvars file.
Enter the floating IP and subnet information from the Bastion server.
By default, the VSIs are configured with:
Red Hat Enterprise Linux® 8.6 for SAP HANA/Applications (amd64),
SSH keys to access as root user on SSH,
Storage volumes
You can change the default settings to match your solution.
You can change the default SAP system configuration settings to match your solution.
You also specify the location where you downloaded the SAP kits.
The IBM Cloud Provider plug-ins for Terraform on IBM Cloud uses these configuration files to provision a S/4HANA system in your IBM Cloud
account.

Schematics deployment
You use the Schematics user interface on IBM Cloud® and enter the GitHub repository for S/4HANA Schematics .
When you run the scripts with the Schematics interface, you:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 410

Enter Workspace information.
Enter the Github path.
Modify the parameters in the Schematics interface.

Catalog Tile deployment
When you use the Catalog Tile for deployment, you:
Select the SAP S/4HANA tile from the catalog
Enter information for your workspace. The Catalog Tile creates a Schematics workspace for you.
Modify the parameters for your bastion server, personal credential information, and other parameters specific to your solution.

Support - Schematics and Terraform
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, re-adapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Support - Catalog Tile
The Catalog Tile offering is IBM Cloud supported. For more information, see Getting help and support from IBM Cloud or SAP .
If client issues are identified with SAP software, then SAP Support will assist client. Please follow the recommendations of SAP Note 90835,
which describes the SAP Incident Escalation Procedure. This SAP Note (and others) is found at https://support.sap.com/en/index.html

Before you begin
Before you deploy SAP S/4HANA:
Make sure that your account is upgraded to a paid account.
If you have not already, create a bastion server to store the SAP kits. For more information, see

Automate SAP bastion server - SAP

media storage repository. You need the floating IP from your bastion server for deployment.
Download the SAP kits from the SAP Portal to your bastion Server. Make note of the download locations. Ansible decompresses all of the
archive kits and needs the paths. For more information, see the Readme file in the GitHub repository and on the About page for the
catalog tile.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
(Optional - Catalog Tile) create secrets for your credentials and passwords by using the Secrets Manager.

Deploying SAP S/4HANA using Terraform scripts
Use these steps to deploy the SAP S/4HANA 3 tiers architecture on your existing VPC. The scripts can take 2 - 3 hours to complete. The scripts
can take 1 - 2 hours to complete. The supported versions available for S/4HANA are 2020, 2021, 2022, and 2023. For more information, see
the readme for recommended kits versions.
1. Log in to the Deployment Server by using ssh .
2. Clone the repository and change the path to sap-s4hana folder.
$ $ git clone https://github.com/IBM-Cloud/sap-s4hana.git
$ cd sap-s4hana

3. Edit the input parameter file, input.auto.tfvars , and modify the variables to match your solution. The file is preset with the minimal
recommended disk sizes. For using an existing VPC, you must modify:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 411

VPC - An existing VPC name
REGION - Region for the VSIs
ZONE - Availability zone for VSIs
SECURITY_GROUP - Existing Security Group, previously created by the user in the same VPC.
SUBNET - Existing subnet in the same region and zone as the VSIs, previously created by the user.
RESOURCE_GROUP - Existing resource group, previously created by the user.
SSH_KEYS - List of SSH Keys UUIDs that are allowed to SSH as root to the VSIs.
ID_RSA_FILE_PATH - id_rsa private key file path in OpenSSH format with 0600 per-missions.
APP_HOSTNAME/DB_HOSTNAME - Enter a hostname up to 12 characters. For more information, see the readme file.
DB_PROFILE/APP_PROFILE - The instance profile used for the HANA/APP VSI.
DB_IMAGE/APP_IMAGE - The OS image for DB/APP VSI.
For more options for profile, see Instance Profiles. For more options for image, see Images. For descriptions of the variables, see the
readme file.
$ REGION

= ""

ZONE

= ""

VPC

= ""

SECURITYGROUP

= ""

SUBNET

= ""

SSH_KEYS

= [""]

ID_RSA_FILE_PATH
ATR_NAME

= "ansible/id_rsa"
= ""

# SAP Database VSI variables:
DB_HOSTNAME

= ""

DB_PROFILE

= "mx2-16x128"

DB_IMAGE

= "ibm-redhat-8-6-amd64-sap-hana-5" # For any manual change in the terraform code, you have to

make sure that you use a certified image based on the SAP NOTE: 2927211.
# SAP APPs VSI variables:
APP_HOSTNAME

= ""

APP_PROFILE

= "bx2-4x16"

APP_IMAGE

= "ibm-redhat-8-6-amd64-sap-applications-5" # For any manual change in the terraform code, you

have to make sure that you use a certified image based on the SAP NOTE: 2927211.

4. Customize your SAP system configuration with the values to be passed to the Ansible playbooks for the automated deployment.
$ # S/4HANA version
S4HANA_VERSION = "2023"
# SAP HANA DB configuration
HANA_SID = "HDB"
HANA_SYSNO = "00"
HANA_SYSTEM_USAGE = "custom"
HANA_COMPONENTS = "server"
# SAP HANA Installation kit path
KIT_SAPHANA_FILE = "/storage/HANADB/51057281.ZIP"
#SAP system configuration
SAP_SID= "S4A"
SAP_ASCS_INSTANCE_NUMBER = "01"
SAP_CI_INSTANCE_NUMBER = "00"
# Number of concurrent jobs used to load and/or extract archives to SAP HANA Host
HDB_CONCURRENT_JOBS = "23"
# SAP S4HANA APP Installation kit path
KIT_SAPCAR_FILE = "/storage/S4HANA/SAPCAR_1010-70006178.EXE"
KIT_SWPM_FILE = "/storage/S4HANA/SWPM20SP17_0-80003424.SAR"
KIT_SAPEXE_FILE = "/storage/S4HANA/KERNEL/793/SAPEXE_60-70007807.SAR"
KIT_SAPEXEDB_FILE = "/storage/S4HANA/KERNEL/793/SAPEXEDB_60-70007806.SAR"
KIT_IGSEXE_FILE = "/storage/S4HANA/KERNEL/793/igsexe_4-70005417.sar"
KIT_IGSHELPER_FILE = "/storage/S4HANA/igshelper_17-10010245.sar"
KIT_SAPHOTAGENT_FILE = "/storage/S4HANA/SAPHOSTAGENT61_61-80004822.SAR"

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 412

KIT_HDBCLIENT_FILE = "/storage/S4HANA/IMDB_CLIENT20_018_27-80002082.SAR"
KIT_S4HANA_EXPORT = "/storage/S4HANA/2023"

5. Initialize the Terraform CLI.
$ terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
$ terraform plan --out plan1

You will be asked to provide an SAP HANA main password, an SAP main password, and the IBM Cloud API key.
The SAP HANA main password must consist of at least one digit (0-9), one lowercase letter (a-z), and one uppercase letter (A-Z). It can
contain only the following characters: a-z, A-Z, 0-9, !, @, #, $, _. It must not start with a digit or an underscore ( _ ).
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters:
a-z, A-Z, 0-9, @, #, $, _. This password cannot contain ! and must not start with a digit or an underscore ( _ ).
Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
7. Create the IBM Cloud resources for S/4HANA and install the SAP system.
$ terraform apply "plan1"

The IBM Cloud resources are created and you will see the output similar to the terraform plan output.

Next steps for Terraform
If you need to remove your S/4HANA system, go to your project folder and run the terraform destroy .

Deploying SAP S/4HANA with the Catalog Tile interface
Use these steps to configure the SAP S/4HANA on your existing VPC by using the Catalog Tile interface. The available supported S/4HANA
versions are 2020, 2021, 2022, and 2023. For more information, see the readme file for recommended kits versions. The scripts can take 1 2 hours to complete.
1. From the IBM Cloud Catalog, select the SAP S/4HANA tile. The Tile opens the Create tab for SAP S/4HANA. For more information about
this deployment, see the About tab or the Readme file link.
2. On the SAP S/4HANA page, configure your workspace:
Enter a name for the workspace or use the default.
The Resource Group to use to create resources. Use the Default or create a Resource Group.
Select a Location to create your Schematics workspace. The workspace location does not have to match the resource location.
3. Enter the required deployment values, review the default input variables, and provide values that match your solution. These parameters
are specific to your deployment. For more detailed information, see the Readme file - Input Parameters.
Parameter

Description

APP_HOSTNAME

APP VSI hostname

BASTION_FLOATING_IP

Input the floating IP of the Bastion Server you created before you started this deployment. For more
information, see Automate SAP bastion server - SAP media storage .

DB_HOSTNAME

DB VSI hostname

REGION

Cloud Region where resources are deployed

RESOURCE_GROUP

EXISTING Resource Group for VSIs and Volumes

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 413

SECURITY_GROUP

EXISTING Security group name

SSH_KEYS

SSH Keys ID list to access the VSI

SUBNET

EXISTING Subnet name

VPC

EXISTING VPC name

ZONE

Cloud Zone where resources are deployed

HANA_MAIN_PASSWORD

HANA main password or use a secret stored in Secrets Manager

IBMCLOUD_API_KEY

IBM Cloud API key or use a secret stored in Secrets Manager

PRIVATE_SSH_KEY

Input id_rsa private key content or use a secret stored in Secrets Manager

SAP_MAIN_PASSWORD

SAP main password or use a secret stored in Secrets Manager

ATR_NAME

The name of the existing Activity Tracker instance, in the same region as HANA VSI

4. Review and update the optional parameters. The Ansible scripts expect the SAP kits to be in the default locations listed. For more
detailed information, see the Readme file - Input Parameters.
Parameter

Description

APP_IMAGE

APP VSI OS image

APP_PROFILE

APP VSI profile

DB_IMAGE

DB VSI OS image

DB_PROFILE

DB VSI profile

HANA_COMPONENTS

hana_components

HANA_SID

hana_sid

HANA_SYSNO

hana_sysno

HANA_SYSTEM_USAGE

hana_system_usage

HDB_CONCURRENT_JOBS

hdb_concurent_jobs

KIT_HDBCLIENT_FILE

kit_hdbclient_file

KIT_IGSEXE_FILE

kit_igsexe_file

KIT_IGSHELPER_FILE

kit_igshelper_file

KIT_S4HANA_EXPORT

kit_s4hana_export

KIT_SAPCAR_FILE

kit_sapcar_file

KIT_SAPEXE_FILE

kit_sapexe_file

KIT_SAPEXEDB_FILE

kit_sapexedb_file

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 414

KIT_SAPHANA_FILE

kit_saphana_file

KIT_SAPHOTAGENT_FILE

kit_saphotagent_file

KIT_SWPM_FILE

kit_swpm_file

SAP_ASCS_INSTANCE_NUMBER

sap_ascs_instance_number

SAP_CI_INSTANCE_NUMBER

sap_ci_instance_number

SAP_SID

sap_sid

S4HANA_VERSION

The version of S/4HANA

5. Accept the license agreement.
6. Select Install. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

Deploying SAP S/4HANA with the Schematics interface
Use these steps to configure the SAP S/4HANA on your existing VPC by using the Schematics interface. The scripts can take 1 - 2 hours to
complete. The supported versions available for S/4HANA are 2020, 2021, 2022, and 2023. For more information, see the readme for
recommended kits versions.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the URL for the Schematics interface.
Select the Terraform version.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your API key
Your private SSH key from your local system
The ID for the SSH key that you created and uploaded to IBM Cloud. Enter the SSH key ID in square brackets and quotation marks,
for example [ "ibmcloud_ssh_key_UUID1","ibmcloud_ssh_key_UUID2",... ].
The floating IP address for your bastion server.
Resource group
Activity Tracker instance name
The Region for your resources
The Zone for your resources
VPC name
Subnet name
Security group name
Hostname

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 415

Profile
Image
SAP HANA main password - This password must be 8 - 14 characters, upper and lowercase letters, a number, and a special
character.
SAP main password - This password must be 10 - 14 characters, upper and lowercase letters, a number, and a special character
that is not an exclamation point.
Click Save changes.
For a more detailed description of each of the parameters, check the GitHub repo readme file, chapter “Input parameter file”. Also, make
sure to mark the parameters that contain sensitive information like passwords, API, and ssh private keys as "sensitive". These
parameters are marked as “sensitive” in the readme file, under “Input parameter file”.
7. On the workspace Settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Related information
For more information about Terraform on IBM Cloud, see Getting started with Terraform on IBM Cloud tutorial.
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier virtual

private cloud for SAP by using Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

SAP BW/4HANA 3-tier on IBM Cloud VPC
Overview SAP workload deployment on IBM Cloud® Virtual Private Cloud (VPC) with Terraform
and Ansible
You can use Terraform scripts to create a single-tier VPC and create the SAP and SAP HANA in a distributed architecture on the bastion server
that you create. Creating the bastion server is a prerequisite for all IBM SAP VPC automated solutions. The Terraform scripts use the VPC
information that you provide and then call the Ansible playbook to create the SAP architecture on the specified VPC. Terraform on IBM Cloud®
enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so that you can rapidly build
complex, cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon CPUs and other Intel®
technologies.

IBM Cloud® VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 416

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP solution implemented
SAP BW/4HANA is a packaged data warehouse based on SAP HANA. As the on-premises data warehouse layer of SAP’s Business Technology
Platform, SAP BW/4HANA can be used to consolidate data across the enterprise to get a consistent, agreed-upon view of your data.
SAP BW/4HANA is a next-generation data warehouse SAP product that, like SAP S/4HANA®, is optimized for the SAP HANA platform, including
inheriting the high performance, simplicity, and agility of SAP HANA. SAP BW/4HANA delivers real-time, enterprise-wide analytics that
minimize the movement of data and can connect all the data in an organization into a single, logical view, including new data types and
sources. Organizations now have a data warehousing solution that can meet their current and future business needs. A solution that handles
more data, from more sources to deliver the solutions that increase an organization’s success in the next generation of business.
SAP BW/4HANA, combined with SAP S/4HANA and the SAP HANA platform, combines traditional data warehousing, such as operational
reporting and historical analysis, with the future - logical data warehouse, Internet of Things, and data lakes.
SAP BW/4HANA combines with SAP S/4HANA to meet your operational and historical analytics needs by using the same data as your
applications, so you are always using fresh data.
With a logical data warehouse approach that uses intelligent data integration, SAP BW/4HANA eliminates duplication and expensive data
movement to connect the data silos in your organization. All data sources can be connected, including SAP and non-SAP data sources.

Ansible for SAP installation
Ansible is an automation tool for the deployment of several IT tasks. For more information about Ansible, see the Ansible Documentation.
The deployment is done by using the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found
on the Ansible core page.
The Ansible playbook is called directly by the Terraform script. The script starts with Terraform specific steps for creating the VPC, and
continues automatically with the Ansible-specific steps to install the SAP system.

Where to run the scripts
The recommended way to run the scripts is from your deployment (bastion) server because the deployment (bastion) server has Terraform
and Ansible already installed. If you want to run the scripts from your local workstation, you need to install Terraform and Ansible locally.
For both the deployment (bastion) server and local workstation, you must download the SAP kits to the temporary storage assigned to you on
the deployment (bastion) server. Ansible installs the kits for you. You specify the location of the kits in the configuration files.

Prerequisite, where to run the scripts
Before you deploy any of the SAP automated solutions on IBM Cloud VPC, you create a bastion server VPC in your chosen region. The bastion
server is used for downloading and storing specific SAP solution media that are needed for later automation deployment. The bastion server is
used for both CLI deployment scenarios, as well for Schematics UI deployments. For more information about how to create the bastion server
and its corresponding VPC, see Automate SAP bastion server – SAP media storage repository .
After bastion VPC deployment is complete, you must download the SAP kits to the temporary storage assigned to you on the bastion server.
Ansible installs the kits for you. You specify the location of the kits in the configuration files.
Note: To save costs, the bastion server, with its SAP media dedicated storage, can be decommissioned after the SAP solutions are
successfully implemented on IBM Cloud VPC. Or, you can keep the bastion server and use it as a jump host for that specific region.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 417

Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

Deploying SAP BW/4HANA on 3-tier IBM Cloud® VPC (Terraform and Ansible)
Single-host SAP HANA system
A single-host system is the simplest system installation type that runs an SAP HANA system entirely on one host. You can scale the system up
as needed. The single-host system has these components:

Figure 1. SAP NetWeaver 7.x SAP HANA single-host installation with AAS

The scripts are designed to create a new VPC and install SAP (SAP BW/4HANA release) solution together with its dedicated DB Hana box in one
task flow.

What is created
The scripts work in two phases. The first phase automates the resources for the VPC provisioning process in an existing VPC created when you
deployed the bastion VSI. The second phase creates the SAP architecture in a distributed environment SAP BW/4HANA App server on a
distinct VSI VPC machine and SAP HANA DB on a dedicated server type VSI VPC box machine.
During the first phase, the VPC is provisioned in an existing VSI created when you deployed the bastion VSI:
1 VPC where the virtual server instances are provisioned
1 security group. The rules for this security group allow:
Inbound DNS (port 53) and
Inbound SSH (TCP port 22) connections to your virtual server instance
All outbound traffic from the virtual server instance
1 subnet to enable networking in your VPC
2 X virtual server instance with SAP certified storage and network configurations
2 floating IP’s address that you use to access your VPC virtual server instance over the public network
During the second phase, the Ansible Playbook is called and the SAP architecture is installed for both dedicated VSI’s SAP App VSI machine
and dedicated SAP HANA VSI box. The SAP architecture that is deployed is the SAP BW/4HANA release on stand-alone dedicated SAP HANA
2.0 box release. For more information about this architecture, see Automating SAP HANA stand-alone virtual server instance on IBM Cloud®
VPC by using Terraform and Ansible.

Script files
The configuration and script files are provided in GitHub. There are two repositories for each SAP solution:
Using the bastion server CLI to run the Terraform scripts - GitHub repository
Using Schematics user interface on IBM Cloud - GitHub repository

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 418

SAP Kits
For each IBM Cloud region, IBM allocates temporary storage on a dedicated Jump host. It is your responsibility to download the necessary SAP
and DB kits to your Deployment (Bastion) Server. All file archives are decompressed by Ansible during the automatic deploying process. For
more information, see the readme file.

Schematics deployment
You use the Schematics interface to deploy your infrastructure with the scripts in the GitHub repository. When you run the scripts with the
Schematics interface, you:
Enter the URL for the GitHub repository for the Terraform files
Modify the parameters in the Schematics interface. They are the same parameters as the

input.auto.tfvars file that you use when

you are running the Terraform scripts in the CLI.

Catalog Tile deployment
When you use the Catalog Tile for deployment, you:
Select the SAP BW/4HANA tile from the catalog
Enter information for your workspace. The Catalog Tile creates a Schematics workspace for you.
Modify the parameters for your bastion server, personal credential information, and other parameters specific to your solution.

Terraform deployment
You use the Bastion server CLI to run the Terraform scripts that are located in the GitHub repository.
To run the scripts to deploy the SAP BW/4HANA release on dedicated SAP HANA 2.0 BOX VSI, you need to:
The input.auto.tfvars file to customize the resources for your solution.
Enter the floating IP and subnet information from the Bastion server.
By default, the VSI is configured with:
Red Hat Enterprise Linux® 7.x for SAP Applications (amd64),
Two SSH keys that are configured to access as root user on SSH,
Five storage volumes.
You can change the default settings to match your solution.
You can change the default SAP system configuration settings to match your solution.
You also specify the location where you downloaded the SAP kits.
The IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files to provision a VPC in your IBM Cloud account.
For SAP BW/4HANA virtual server instance on IBM Cloud VPC, you modify the:
terraform.tfvars file to add your IBM Cloud API key
input.auto.tfvars file to customize the resources for your solution. You specify zones, resource names, SSH keys, and SAP variables.

All of the other configuration files are provided and do not need to be modified.
The IBM Cloud Provider Plug-in for Terraform on IBM Cloud uses these configuration files to provision a VPC in your IBM Cloud account.

Support - Schematics and Terraform
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, re-adapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Support - Catalog Tile
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 419

The catalog tile offering is IBM Cloud supported. For more information, see Getting help and support from IBM Cloud or SAP .
If client issues are identified with SAP software, then SAP Support will assist the client. Follow the recommendations of SAP Note 90835, which
describes the SAP Incident Escalation Procedure. This SAP Note (and others) is found at https://support.sap.com/en/index.html.

Virtual server instance configuration
The virtual server instance is configured with:
Red Hat Enterprise Linux 7.6 for SAP HANA (x86_64)
Minimum one or more SSH keys that are configured to access as root user on SSH

Before you begin
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account.
If you have not already, create a bastion server to store the SAP kits. For more information, see

Automate SAP bastion server - SAP

media storage repository.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses all of
the archive kits. For more information, see the readme file.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
During configuration you can specify an existing VPC to use, instead of creating a new VPC.
For the detailed steps about using Terraform to create only a VPC for SAP, see Creating single-tier virtual private cloud for SAP by using
Terraform.

Deploying SAP BW/4HANA with the Catalog Tile interface
Use these steps to configure the SAP BW/4HANA on your existing VPC by using the Catalog Tile interface. The scripts can take 1 - 2 hours to
complete.
1. From the IBM Cloud Catalog, select the SAP BW/4HANA tile. The tile opens the Create tab for SAP BW/4HANA. For more information
about this deployment, see the About tab or the Readme file link.
2. On the SAP BW/4HANA page, configure your workspace:
Enter a name for the workspace or use the default.
The Resource Group to use to create resources. Use the Default or create a Resource Group.
Select a Location to create your Schematics workspace. The workspace location does not have to match the resource location.
3. Enter the required deployment values, review the default input variables, and provide values that match your solution. These parameters
are specific to your deployment. For more detailed information, see the Readme file - Input Parameters.
Parameter

Description

APP-HOSTNAME

APP VSI hostname

BASTION_FLOATING_IP

Input the floating IP of the Bastion Server you created before you started this deployment. For more
information, see Automate SAP bastion server - SAP media storage .

DB-HOSTNAME

DB VSI hostname

REGION

Cloud Region where resources are deployed

RESOURCE_GROUP

EXISTING Resource Group for VSIs and Volumes

SECURITY_GROUP

EXISTING Security group name

SSH_KEYS

SSH Keys ID list to access the VSI

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 420

SUBNET

EXISTING Subnet name

VPC

EXISTING VPC name

ZONE

Cloud Zone where resources are deployed

hana_main_password

HANA main password or use a secret stored in Secrets Manager

ibmcloud_api_key

IBM Cloud API key or use a secret stored in Secrets Manager

private_ssh_key

Input id_rsa private key content or use a secret stored in Secrets Manager

sap_main_password

SAP main password or use a secret stored in Secrets Manager

4. Review and update the optional parameters. The Ansible scripts expect the SAP kits to be in the default locations listed. For more
detailed information, see the Readme file - Input Parameters.
Parameter

Description

APP-IMAGE

APP VSI OS image

APP-PROFILE

APP VSI profile

DB-IMAGE

DB VSI OS image

DB-PROFILE

DB VSI profile

hana_components

hana_components

hana_sid

hana_sid

hana_sysno

hana_sysno

hana_system_usage

hana_system_usage

hdb_concurent_jobs

hdb_concurent_jobs

kit_hdbclient_file

kit_hdbclient_file

kit_igsexe_file

kit_igsexe_file

kit_igshelper_file

kit_igshelper_file

kit_s4hana_export

kit_s4hana_export

kit_sapcar_file

kit_sapcar_file

kit_sapexe_file

kit_sapexe_file

kit_sapexedb_file

kit_sapexedb_file

kit_saphana_file

kit_saphana_file

kit_saphotagent_file

kit_saphotagent_file

kit_swpm_file

kit_swpm_file

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 421

sap_ascs_instance_number

sap_ascs_instance_number

sap_ci_instance_number

sap_ci_instance_number

sap_sid

sap_sid

5. Accept the license agreement.
6. Select Install. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

Procedure for Schematics interface
Use these steps to configure the SAP BW/4HANA on your existing VPC by using the Schematics user interface. The scripts can take 1 - 2 hours
to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the URL for the Schematics interface.
Select the Terraform version.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your API key
Your private SSH key from your local machine
The ID for the SSH key that you created and uploaded to IBM Cloud. Enter the SSH key ID in square brackets and quotation marks,
for example [ "ibmcloud_ssh_key_UUID1","ibmcloud_ssh_key_UUID2",... ].
The floating IP address for your bastion server.
The Region for your resources
The Zone for your resources
Whether to use an existing VPC or create one
Whether to use an existing subnet
Whether to create new port only when a new subnet is created
TCP port range, nimimun and maximum
VPC name
Subnet name
Security group name
Hostname
Profile
Image
Minimal recommended disk sizes
SAP HANA main password - This password must be 8 - 14 characters, upper and lowercase letters, a number, and a special
character.
SAP main password - This password must be 10 - 14 characters, upper and lowercase letters, a number, and a special character
that is not an exclamation point.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 422

Click Save changes.
For a more detailed description of each of the parameters, check the GitHub repo readme file, chapter “Input parameter file”. Also, make
sure to mark the parameters that contain sensitive information like passwords, API, and ssh private keys as "sensitive". these paramters
are marked as “sensitive” in the readme file, under “Input parameter file”.
7. On the workspace Settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Procedure for Terraform scripts
1. Log in to the Deployment Server by using ssh .
2. Clone the terraform and ansbile folders and readme file from https://github.com/IBM-Cloud/sap-bw4hana/tree/main/cli and
change to the sap-bw4hana/terraform folder.
$ $ git clone https://github.com/IBM-Cloud/sap-bw4hana.git
$ cd sap-bw4hana/cli/terraform

3. Edit the terraform.tfvars variable file and enter the IBM Cloud API key that you retrieved.
ibmcloud_api_key = "<ibmcloud_apikey>"

Variables that are defined in the terraform.tfvars file are automatically loaded by Terraform when the IBM Cloud Provider plug-in is
initialized and you can reference them in every Terraform configuration file that you use.
Because the terraform.tfvars file contains confidential information, do not push this file to a version control system. Keep this file on
your local system only.
4. Edit the input parameter file, input.auto.tfvars , and modify the variables to match your solution. The file is preset with the minimal
recommended disk sizes. For using an existing VPC, you must modify:
VPC - An existing VPC name. By defulat, the scripts expect an existing VPC name.
SECURITYGROUP - change ic4sap to the VPC name.
SUBNET - change ic4sap to the VPC name.
DB-HOSTNAME - enter a hostname up to 13 characters. For more information, see the readme file.
APP-HOSTNAME - enter a hostname up to 13 characters. For more information, see the readme file.
Replace the SSH keys in the file with your SSH key 40-digit ID.
$ #General VPC variables
REGION

= "ed-de"

ZONE

= "eu-de-2"

VPC

= "ic4sap"

SECURITYGROUP

= "ic4sap-securitygroup"

SUBNET

= "ic4sap-subnet"

SSH_KEYS

= [ "ssh key1" , "ssh key2" ]

# SAP Database VSI variables:
DB-HOSTNAME

= "sapbw4db"

DB-PROFILE

= "mx2-16x128"

DB-IMAGE

= "ibm-redhat-7-6-amd64-sap-hana-1" # For any manual change in the terraform code, you have to

make sure that you use a certified image based on the SAP Note: 2927211.
# SAP APPs VSI variables:
APP-HOSTNAME

= "sapbw4app"

APP-PROFILE

= "bx2-4x16"

APP-IMAGE

= "ibm-redhat-7-6-amd64-sap-applications-1" # For any manual change in the terraform code, you

have to make sure that you use a certified image based on the SAP Note: 2927211.

Note: The hostname must have up to 13 characters as required by SAP. For more information about the rules that apply to
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 423

hostnames for SAP systems, see SAP Note 611361 - Hostnames of SAP ABAP Platform servers
5. In the same file ( input.auto.tfvars ), edit the SAP system configuration variables that are passed to the Ansible automated
deployment.
$ #SAP HANA DB configuration
hana_sid = "BWH"
hana_sysno = "00"
hana_system_usage = "custom"
hana_components = "server"
#SAP HANA Installation kit path
kit_saphana_file = "/storage/HANADB/51054623.ZIP"
#SAP system configuration
sap_sid = "BWH"
sap_ascs_instance_number = "01"
sap_ci_instance_number = "00"
# Number of concurrent jobs used to load and/or extract archives to HANA Host
hdb_concurrent_jobs = "6"
#SAP BW4HANA APP Installation kit path
kit_sapcar_file = "/storage/BW4HANA/SAPCAR_1010-70006178.EXE"
kit_swpm_file = "/storage/BW4HANA/SWPM20SP09_4-80003424.SAR"
kit_sapexe_file = "/storage/BW4HANA/SAPEXE_400-80004393.SAR"
kit_sapexedb_file = "/storage/BW4HANA/SAPEXEDB_400-80004392.SAR"
kit_igsexe_file = "/storage/BW4HANA/igsexe_13-80003187.sar"
kit_igshelper_file = "/storage/BW4HANA/igshelper_17-10010245.sar"
kit_saphotagent_file = "/storage/BW4HANA/SAPHOSTAGENT51_51-20009394.SAR"
kit_hdbclient_file = "/storage/BW4HANA/IMDB_CLIENT20_009_28-80002082.SAR"
kit_bw4hana_export = "/storage/BW4HANA/export"

6. Initialize the Terraform CLI.
terraform init

7. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account.
terraform plan

You must enter an SAP HANA main password and an SAP main password.
The SAP HANA main password must consist of at least one digit (0-9), one lowercase letter (a-z), and one uppercase letter (A-Z). It can
contain only the following characters: a-z, A-Z, 0-9, !, @, #, $, _. It must not start with a digit or an underscore ( _ ).
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can only contain the following characters:
a-z, A-Z, 0-9, @, #, $, _. This password cannot contain ! . It must not start with a digit or an underscore ( _ ).
8. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan again.
9. Create the virtual private cloud for SAP instance and IAM access policy in IBM Cloud.
terraform apply

The virtual private cloud and components are created and you see output similar to the

terraform plan output.

Next steps
If you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run terraform
plan and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The

Terraform scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove your VPC, go to your project folder and run terraform destroy .

Related information
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 424

For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier virtual

private cloud for SAP by using Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP NetWeaver 7.x on HANA db 3-tier on IBM Cloud VPC
Automating SAP workload deployment on IBM Cloud® VPC with Terraform and Ansible
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so
that you can rapidly build complex, cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon
CPUs and other Intel® technologies.
You can use Terraform scripts to create a single-tier VPC and create the SAP and SAP HANA in a distributed architecture on the bastion server
that you create. Creating the bastion server is a prerequisite for all IBM Cloud SAP VPC automated solutions. The Terraform scripts use the VPC
information that you provide and then call the Ansible playbook to create the SAP architecture on the specified VPC.

IBM Cloud VPC introduction
A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared

public cloud

infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud
tenants, creating a private, secure place on the public cloud.
Imagine that a cloud provider’s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is
akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular
control over which IP addresses or applications can access particular resources. It is analogous to the “friends-only” or “public/private”
controls on social media accounts used to restrict who can or can’t see your otherwise public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance.
VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following
information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC
overviews and VPC tutorials. For more information about VPC, see Getting started with Virtual Private Cloud (VPC) .

SAP solution implemented
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for ABAP and Java applications. The SAP
system can be installed and configured in IBM Cloud for various system and database types.
For more information about SAP system architectures on IBM Cloud VPC, see the infrastructure reference architectures for SAP for each
supported database type. The reference architecture section for SAP solutions running on IBM Cloud can be found here.
Manually deploying a VPC and installing an SAP system can be time-consuming. The Terraform automation assures not only a much quicker
implementation, but also a standardized and less prone to error deployment. Terraform and Ansible are used for automating the deployment
processes.
The Terraform scripts solution provides the automated deployment of a single host with SAP NetWeaver with either ASE SYB or SAP HANA db
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 425

on the Red Hat Enterprise Linux® 8.4 and SUSE 15.x for SAP Applications.
The SAP installation media that are used for this deployment are the default media for SAP AAS of NetWeaver 7.x (ABAP stack) on SUSE/RHEL
with ASE SYB 16 or HANA 2.0 db as distributed instance available at the SAP Support Portal under INSTALLATION AND UPGRADE area. You
provide the installation media as an input parameter for Terraform for your SAP AAS solution chosen on dedicated kits storage from bastion
server.

SAP Project Value Guide – SAP NetWeaver with HANA landscape deployment
SAP projects vary widely in scope and budget, but none are considered trivial. Whether you are delivering a new SAP system or implementing
changes to an existing one, the requirements for error-free execution and reducing the project time to realized benefits are always present.
In many SAP project scenarios, the deployment of an SAP system is often a key and repeated task. This project value guide covers the
automated deployment of SAP NetWeaver (ABAP) with HANA database on IBM Cloud VPC. We will also discuss Additional Application Server
(AAS) to SAP instance and HANA instance and Backing up the HANA database IBM Cloud Object Storage in their respective sections.

Whom does the automation help?
The SAP NetWeaver with HANA landscape deployment automation helps, if:
You are an early adopter of the HANA database and deployed SAP Suite on HANA.
You would like to run the SAP NetWeaver with HANA on cloud.
Migration of SAP database(s) to HANA is part of your SAP NetWeaver implementation plan.
This deployment automation helps the business who plans to migrate SAP databases to HANA while keeping SAP NetWeaver as the
application layer. From deployment launch to SAP logon, you are only hours away from having test and target SAP systems.

What does the automation deploy?
This deployment automation delivers two VSIs along with storage and secure network. You can choose the VSI profile size for HANA database
and SAP NetWeaver application server.
Prerequisites to deploy the automation:
Follow the instructional documentation.
Obtain the SAP NetWeaver (ABAP) with SAP HANA installation software from SAP.
Deploy the bastion (SAP install kit) server.
The automation deploys SAP certified infrastructure and the application/database software in one step. The installation process follows the
SAP Master Installation Guides. For more information, go to VPC for SAP HANA NetWeaver ABAP .

Figure 1. SAP NetWeaver with HANA landscape deployment

Ansible for SAP installation
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 426

Ansible is an automation tool for the deployment of several IT tasks. Ansible is used for automating the installation of an SAP NetWeaver with
HANA or AnyDB. For more information about Ansible, see the Ansible Documentation.
The deployment is done by using the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found
on the Ansible core page.
The Ansible playbook is called directly by the Terraform script. The script starts with Terraform specific steps for creating the VPC, and
continues automatically with the Ansible specific steps to install the SAP system.

Where to run the scripts?
The recommended way to run the scripts is from your deployment (bastion) server because the deployment (bastion) server has Terraform
and Ansible already installed. If you want to run the scripts from your local workstation, you need to install Terraform and Ansible locally.
For both the deployment (bastion) server and local workstation, you must download the SAP kits to the temporary storage assigned to you on
the deployment (bastion) server. Ansible installs the kits for you. You specify the location of the kits in the configuration files.

Prerequisites
Before you deploy any of the SAP automated solutions on IBM Cloud VPC, you create a Bastion server VPC in your chosen region. The Bastion
server is used for downloading and storing specific SAP solution media that are needed for later automation deployment. The Bastion server is
used for both CLI deployment scenarios, as well for Schematics UI deployments. For more information about how to create the Bastion server
and its corresponding VPC, see Automate SAP Bastion server – SAP media storage repository .
After bastion VPC deployment is complete, you must download the SAP kits to the temporary storage assigned to you on the bastion server.
Ansible installs the kits for you. You specify the location of the kits in the configuration files.
To save costs, the bastion server, with its SAP media dedicated storage, can be decommissioned after the SAP solutions are successfully
implemented on IBM Cloud VPC. Or, you can keep the bastion server and use it as a jump host for that specific region.
Note: This automation is offered free of charge however, the provisioned infrastructure comes at cost.

Automating SAP NetWeaver 7.x on HANA db 3-tier architecture on IBM Cloud® VPC (Terraform
and Ansible)
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March
2025. Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM
Cloud Activity Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about
migrating from IBM Cloud Activity Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.
You can use Terraform scripts to create a single-tier VPC and also create SAP and SAP HANA infrastructure on the VPC. The Terraform scripts
use the VPC information that you provide and then call the Ansible playbooks to create the SAP architecture on the specified VPC. Terraform
on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so that you
can rapidly build complex cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel® Xeon CPUs
and additional Intel® technologies.
You have two deployment methods to choose from:
Terraform scripts run from the CLI on your deployment server (bastion server).
Schematics user interface accessed from your cloud dashboard menu.
You can create either:
SAP NetWeaver 7.x on SAP HANA-based ABAP stack
SAP NetWeaver 7.x on SAP HANA-based Java stack

SAP Solution implemented
Many SAP enterprise solutions are built on SAP’s extensive platform, SAP NetWeaver, including:
SAP HANA as Primary Persistence for SAP NetWeaver-Based Applications
SAP Business Suite applications (ERP, CRM, and SCM, and other applications)
SAP Business Warehouse (BW), and
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 427

Other SAP enterprise solutions
SAP NetWeaver (SAP NW) uses mainly ABAP and Java programming languages. Many applications that are built on SAP NetWeaver’s ABAP or
Java (or both) application servers can run “on” SAP HANA. In this instance, SAP HANA serves as the sole database in the architecture.
Technical interfaces are available for applications that are built on SAP NetWeaver AS ABAP and AS Java to run on SAP HANA. However,
specific development enablement is normally required for each application to ensure that it runs optimally on SAP HANA. SAP Business Suite
applications (ERP, CRM, SCM, and other applications), SAP Business Warehouse (BW), and other SAP NetWeaver-based applications were
modified to run on SAP HANA and use its many advantages. Also, various components and complimentary applications that are built on SAP
NetWeaver can also run on SAP HANA by using the provided SAP NetWeaver DB interfaces.
The SAP HANA as primary persistence database for SAP NetWeaver-based applications scenario has one restriction: SAP NetWeaver ABAP and
Java application servers must run on separate hardware servers from the SAP HANA hardware.

Prerequisites
A deployment server (bastion server) deployed using the automation solution Automate SAP bastion server – SAP media storage repository ,
should exist in the same VPC, same region, and have the same subnet and security group configured as for the SAP system VSIs.

What is created
The scripts automate the deployment of the virtual infrastructure resources, provisioning processes for the SAP architecture, in an existing
VPC, with a distributed environment. SAP NW 7.x (ABAP or Java) App server, on a distinct virtual server instance VPC system, and SAP HANA
DB, on a dedicated server type virtual server instance VPC box, are provisioned. The scripts work in two phases.
During the first phase, two virtual server instances, with SAP certified storage and network configuration (the same subnet and security group
as for the deployment server (bastion server)) are configured.
During the second phase, the Ansible playbooks are called and the SAP architecture is installed for both dedicated VSIs: SAP App VSI system
and dedicated SAP HANA VSI box. The SAP architecture that is deployed is the SAP NW 7.x release on a stand-alone dedicated SAP HANA 2.0
box.
The IBM Cloud Activity Tracker service should be used to capture the records of your IBM Cloud activities and monitor the activity of your IBM
Cloud account. You can use this service to investigate abnormal activity, critical actions, and comply with regulatory audit requirements. In
addition, you can be alert on the actions as they occur. The events that are collected comply with the Cloud Auditing Data Federation (CADF)
standard.
You can deploy an Activity Tracker instance along with the SAP system by using the SAP deployment Automation or if you already have created
one, you can specify the Activity Tracker name in the deployment variables. You can set the Activity Tracker plan variable according to your
chosen Service plans. By default, the Lite (free) plan is selected. For more information on how to provision an Activity Tracker instance, see
here.
Important:
Every user who accesses the IBM Cloud Activity Tracker service in your account must be assigned an access policy with an IAM user role
defined. The policy determines what actions the user can perform within the context of the service or instance you select. The allowable
actions are customized and defined as operations that are allowed to be performed on the service. The actions are then mapped to IAM
user roles. For more information, see here.
You can provision only one instance of the service per IBM Cloud region.
IBM Cloud Activity Tracker provides a solution for administrators to capture, store, view, search, and monitor API activity in a single place. It
also offers a notification feature to alert you by using any of the supported notification channels.
Note: IBM Cloud Activity Tracker collects and stores audit records for API calls made to resources that run in the IBM Cloud. You can
archive these events on IBM Cloud for long-term storage.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 428

Figure 1. SAP NetWeaver 7.x with SAP HANA standard 3-tier installation to IBM Cloud VPC

The scripts are designed to install SAP (SAP NW 7.x release) solution together with its dedicated DB SAP HANA box in one task flow.

Terraform deployment script files
The configuration and script files are available in the GitHub repository:
For Java stack : https://github.com/IBM-Cloud/sap-netweaver-java-hana
For ABAP stack : https://github.com/IBM-Cloud/sap-netweaver-abap-hana
The input.auto.tfvars file allows the customization of the resources and variable values should be provided.
Other configuration files are provided and no modification is required.

Virtual server instance configuration
Following are the supported operating system images for SAP NetWeaver primary application server:
ibm-redhat-8-6-amd64-sap-applications-2
ibm-redhat-8-4-amd64-sap-applications-2
ibm-sles-15-4-amd64-sap-applications-3
ibm-sles-15-3-amd64-sap-applications-2
Following are the supported operating system images for HANA database:
ibm-redhat-8-6-amd64-sap-hana-2
ibm-redhat-8-4-amd64-sap-hana-2
ibm-sles-15-4-amd64-sap-hana-1
ibm-sles-15-3-amd64-sap-hana-2
For both server instances, the provided SSH key is used to access the VSIs via SSH as a

root user.

Schematics script files
The configuration and script files are available in the GitHub repository:
ABAP: https://github.com/IBM-Cloud/sap-netweaver-abap-hana/tree/main

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 429

Java: https://github.com/IBM-Cloud/sap-netweaver-java-hana/tree/main/schematics
When the Schematics interface is used, the following information should be provided:
the workspace information.
the GitHub path for the chosen solution either on ABAP or Java stack.
the values for the parameters in the Schematics interface. They are the same parameters as the

input.auto.tfvars file that you use

with the cli.

SAP Kits
For each IBM Cloud region, a dedicated deployment server (bastion server) is used for the Terraform environment. It is your responsibility to
download the necessary SAP and DB kits to your Deployment (Bastion) Server. All file archives are decompressed by Ansible during the
automatic deploying process. For more information, see the Readme file in the dedicated GitHub repository.

Support - Terraform and Schematics
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
Before you use the scripts:
If you have not created already, create a deployment server (bastion server) to store the SAP kits. For more information, see

Automate

SAP bastion server - SAP media storage repository.
Log in to your previously created deployment server and verify that Terraform and Ansible are installed.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses all of
the files. For more information, see the Java README file or the ABAP README file.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.

Before you begin
Before you deploy SAP NetWeaver ABAP or Java stack on HANA db:
Set up your account to access the VPC. Make sure that your account is upgraded to a paid account.
If you have not already, create a deployment server (bastion server) to store the SAP kits. For more information, see

Automate SAP

bastion server - SAP media storage repository. You need the Floating IP from your deployment server (bastion server) for deployment.
Download the SAP kits from the SAP Portal to your deployment server (bastion server). Make note of the download locations. Ansible
decompresses all of the archive kits and needs the paths. For more information, see the Readme file for:
ABAP: Schematics, Terraform, or the Catalog Tile
JAVA: Schematics and Terraform
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.
Optional - (Catalog Tile) create secrets for your credentials and passwords by using the Secrets Manager.

Deploying SAP NetWeaver 7.x and SAP HANA by using the Schematics user interface
Use these steps to configure the NetWeaver ABAP or Java stack on your existing VPC by using the Schematics interface. The scripts can take 2
- 3 hours to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 430

Enter the URL for the Schematics interface.
Select the Terraform version that is listed in the Readme file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Select Next.
5. Select Create to create your workspace.
6. On the workspace settings page, in the Input variables section, review the default input variables and provide values that match your
solution.
For a more detailed description of each of the parameters, check the GitHub repo Java Readme or ABAP Readme file, chapter “Input
parameter file”. Also, make sure to mark the parameters that contain sensitive information like passwords, API, and ssh private keys as
"sensitive". These parameters are marked as “sensitive” in the Readme file, under “Input parameter file”.
7. On the workspace settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occur during the provisioning, modification, or deletion process.

Deploying SAP NetWeaver (ABAP) Linux/HANA on VPC via Deployable Architecture tile
Use these steps to configure the SAP NetWeaver (ABAP) Linux/HANA on your existing VPC by using the catalog tile interface. The scripts can
take 2 - 3 hours to complete.
1. From the IBM Cloud Catalog menu, select the VPC for SAP HANA NetWeaver ABAP on Deployable Architecture tile. For more
information about this deployment, see the Readme file.
2. Select the latest version.
3. Select Standard variation.
4. Click Review deployment options:
Add to project to add this deployment to an IBM Cloud project and combine it with other deployments. The IBM Cloud projects
include several other pipeline steps, including deployment validation, cost calculation, compliance verification, and approval
process.
Create from the CLI to get the CLI command. With this command you can trigger the deployment from the CLI.
Work with code to embed the code into other terraform deployment.
Deploy with IBM Cloud Schematics to trigger deployment process directly.
5. Select Deploy with IBM Cloud Schematics option. Now, add the input parameters for this installation. There are 3 categories of
parameters:
Workspace - These parameters define the workspace that is automatically created in the Schematics:
Enter a name for the workspace or use default name.
The Resource Group used to create resources. Use default or create a Resource Group.
Select a location to create your Schematics workspace. The workspace location need not match the resource location.
Required input variables - Review the default input variables and provide values that match your solution. These parameters are
specific to your deployment. For more detailed information, see the Readme file.
Parameter

Description

APP-HOSTNAME

The Hostname for the SAP Application VSI. The hostname should be up to 13 characters as
required by SAP. For more information on the rules regarding hostnames for SAP systems, check
SAP Note 611361: "Hostnames of SAP ABAP Platform servers".

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 431

DB-HOSTNAME

The Hostname for the HANA VSI. The hostname should be up to 13 characters as required by
SAP. For more information on the rules regarding hostnames for SAP systems, check SAP Note
611361: "Hostnames of SAP ABAP Platform servers".

BASTION_FLOATING_IP

Input the FLOATING IP from the Bastion Server.

REGION

The cloud region where to deploy the solution. The regions and zones for VPC are listed here.
Review supported locations in IBM Cloud Schematics here.

RESOURCE_GROUP

The name of an EXISTING Resource Group for VSIs and Volumes resources. The list of Resource
Groups is available here.

SECURITY_GROUP

The name of an EXISTING Security group. The list of Security Groups is available here.

SSH_KEYS

List of SSH Keys UUIDs that are allowed to SSH as root to the VSI. Can contain one or more IDs.
The list of SSH Keys is available here.

SUBNET

The name of an EXISTING Subnet. The list of Subnets is available here.

VPC

The name of an EXISTING VPC. The list of VPCs is available here.

ZONE

The cloud zone where to deploy the solution.

hana_main_password

Common password for all users that are created during the installation. A list of images is
available here.

ibmcloud_api_key

IBM Cloud API key (Sensitive* value).

private_ssh_key

Input your id_rsa private key pair content in OpenSSH format (Sensitive* value). This private key
should be used only during the terraform provisioning and it is recommended to be changed
after the SAP deployment.

sap_main_password

Common password for all users that are created during the installation. See Obs* section.

Optional input variables - Review and update the optional parameters. For more detailed information, see the

Readme file.

Parameter

Description

APP-IMAGE

The OS image used for SAP Application VSI. See Obs* section. A list of images is available
here.

APP-PROFILE

The instance profile used for SAP Application VSI. A list of profiles is available here. For more
information about supported DB/OS and IBM Gen 2 Virtual Server Instances (VSI), check SAP
Note 2927211: "SAP Applications on IBM Virtual Private Cloud".

DB-IMAGE

The OS image used for HANA VSI. See Obs* section. A list of images is available here.

DB-PROFILE

The instance profile used for the HANA VSI. The list of profiles is available here. For more
information about supported DB/OS and IBM Gen 2 Virtual Server Instances (VSI), check SAP
Note 2927211: "SAP Applications on IBM Virtual Private Cloud".

ID_RSA_FILE_PATH

The file path for private_ssh_key is automatically generated by default. If it is changed, it
must contain the relative path from git repo folders.

hana_components

SAP HANA Components. Default: "server". Valid values: "all", "client", "es", "ets", "lcapps",
"server", "smartda", "streaming", "rdsync", "xs", "studio", "afl", "sca", "sop", "eml", "rme",
"rtl", "trp".

hana_sid

The SAP system ID identifies the SAP HANA system.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 432

hana_sysno

Specifies the instance number of the SAP HANA system.

hana_system_usage

System Usage. Default: "custom". Valid values: "production", "test", "development",
"custom".

hdb_concurent_jobs

Number of concurrent jobs used to load and/or extract archives to HANA Host.

kit_hdbclient_file

Path to the HANA DB client archive (SAR), as downloaded from SAP Support Portal.

kit_igsexe_file

Path to the IGS archive (SAR), as downloaded from SAP Support Portal.

kit_igshelper_file

Path to the IGS Helper archive (SAR), as downloaded from SAP Support Portal.

kit_nwhana_export

Path to the NetWeaver Installation Export dir. The archives downloaded from SAP Support
Portal should be present in this path.

kit_sapcar_file

Path to the sapcar binary, as downloaded from SAP Support Portal.

kit_sapexe_file

Path to the SAP Kernel OS archive (SAR), as downloaded from SAP Support Portal.

kit_sapexedb_file

Path to the SAP Kernel DB archive (SAR), as downloaded from SAP Support Portal.

kit_saphana_file

Path to the SAP HANA ZIP file. See Obs* section. As downloaded from SAP Support Portal.

kit_saphotagent_file

Path to the SAP Host Agent archive (SAR), as downloaded from SAP Support Portal.

kit_swpm_file

Path to SWPM archive (SAR), as downloaded from SAP Support Portal.

sap_ascs_instance_number

Technical identifier for the internal processes of ASCS.

sap_ci_instance_number

Technical identifier for the internal processes of CI.

sap_sid

The SAP system ID identifies the entire SAP system.

6. Accept the license agreement.
7. Select Deploy. The deployment starts and you are directed to the Schematics page that displays the script log files for you to monitor the
deployment progress.

Deploying SAP NetWeaver 7.x and SAP HANA by using Terraform
Use these steps to create the VPC resources and install the SAP architecture. The scripts can take 2 hours to complete.
1. Log in to the deployment server (bastion server) using ssh .
2. Clone the GitHub repository.
For Java: Clone the repository https://github.com/IBM-Cloud/sap-netweaver-java-hana and change the path to the sap-netweaverjava-hana/cli folder.
$ $ git clone https://github.com/IBM-Cloud/sap-netweaver-java-hana.git
$ cd sap-netweaver-java-hana/cli

For ABAP: Clone the repository https://github.com/IBM-Cloud/sap-netweaver-abap-hana and change to the sap-netweaver-abaphana folder.
$ $ git clone https://github.com/IBM-Cloud/sap-netweaver-abap-hana.git
$ cd sap-netweaver-abap-hana

3. Define your existing VPC variables. Modify the input.auto.tfvars file to specify your zone, VPC component names, profile, and image.
The file is preset with the minimal recommended disk sizes. You need your 40-digit SSH key ID for this file. The second SSH key is
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 433

optional. For more options for profile, see Instance Profiles. For more options for image, see Images. For descriptions of the variables,
see the Java README file or the ABAP README file.
For Java, the following variable values should be modified:
REGION - Region for the VSI. See the Readme file.
ZONE - Zone for the VSI. See the Readme file.
VPC - The name of an existing VPC in the specified region.
SECURITY_GROUP - The name of an existing Security group in the same VPC
RESOURCE_GROUP - The name of an existing Resource group, previously created by the user.
SUBNET - The name of an existing Subnet in the same region and zone as the VSI
SSH_KEYS - A list of SSH keys UUIDs allowed to connect via SSH to the VSIs
DB_HOSTNAME - The hostname of the database VSI, up to 13 characters. For more information, see the Readme file.
APP_HOSTNAME - The hostname of the application server VSI, up to 13 characters. For more information, see the Readme file.
$ # General VPC variables for Java stack
REGION

= "ed-de"

ZONE

= "eu-de-2"

VPC

= "ic4sap"

SECURITYGROUP = "ic4sap-securitygroup"
SUBNET

= "ic4sap-subnet"

SSH_KEYS

= [ "ssh key1" , "ssh key2" ]

# SAP Database VSI variables:
DB_HOSTNAME

= "sapjavadb"

DB_PROFILE

= "mx2-16x128"

DB_IMAGE

= "ibm-redhat-8-6-amd64-sap-hana-2" # For any manual change in the Terraform code, you have to make

sure that you use a certified image based on the SAP Note: 2927211.
# SAP APPs VSI variables:
APP-HOSTNAME

= "sapjavci"

APP-PROFILE

= "bx2-4x16"

APP_IMAGE = "ibm-redhat-8-6-amd64-sap-applications-2" # For any manual change in the terraform code, you have to
make sure that you use a certified image based on the SAP Note: 2927211.

For ABAP, the following variable values should be modified:
REGION - Region for the VSI. See the Readme file.
ZONE - Zone for the VSI. See the Readme file.
VPC - The name of an existing VPC in the specified region.
SECURITY_GROUP - The name of an existing Security group in the same VPC
RESOURCE_GROUP - The name of an existing Resource group, previously created by the user
SUBNET - The name of an existing Subnet in the same region and zone as the VSI
SSH_KEYS - A list of SSH keys UUIDs allowed to connect via SSH to the VSIs
DB-HOSTNAME - The hostname of the database VSI, up to 13 characters. For more information, see the Readme file.
APP-HOSTNAME - The hostname of the application server VSI, up to 13 characters. For more information, see the Readme file.
$ # General VPC variables for ABAP stack
REGION

= "eu-de"

ZONE

= "eu-de-2"

VPC

= "ic4sap"

# EXISTING Security group name

SECURITY_GROUP

= "ic4sap-securitygroup"

# EXISTING Security group name

RESOURCE_GROUP

= "wes-automation"

SUBNET

= "ic4sap-subnet"

SSH_KEYS

= [ "r010-57bfc315-f9e5-46bf-bf61-d87a24a9ce7a" , "r010-3fcd9fe7-d4a7-41ce-8bb3-d96e936b2c7e" ]

# EXISTING Subnet name

# SAP Database VSI variables:
DB-HOSTNAME

= "sapnwhdb"

DB-PROFILE

= "mx2-16x128"

DB_IMAGE

= "ibm-redhat-8-6-amd64-sap-hana-2"

# SAP APPs VSI variables:
APP-HOSTNAME = "sapnwci"

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 434

APP-PROFILE

= "bx2-4x16"

APP_IMAGE = "ibm-redhat-8-6-amd64-sap-applications-2"

Edit your IBM Cloud Activity Tracker (only for ABAP stack) input variables below:
$ # Activity Tracker variables:
ATR_PROVISION = "true"
# Activity Tracker : Disable this to not provision Activity Tracker instance.
# If an Activity Tracker instance already exists in the same region where this solution is to be deployed then
# disable (ATR_PROVISION = "false") this to avoid provisioning an Activity Tracker instance.
# A new instance of Activity Tracker will be deployed with this solution if ATR_PROVISION=true
# Example to create Activity Tracker instance: ATR_PROVISION = "true"
# Example to integrate existing Activity Tracker instance : ATR_PROVISION = "false"
ATR_NAME = "Activity-Tracker-COS-eu-de"
# Provide the Activity Tracker instance name to create or
# provide the existing Activity Tracker instance name in the same region where this solution is to be be deployed.
# Example: ATR_NAME = "Activity-Tracker-COS-eu-de"
ATR_TAGS = [""]
# Activity Tracker: (Optional) only if ATR_PROVISION = "true", tags that should be applied to the Activity Tracker
instance.
# example ATR_TAGS = ["activity-tracker-cos"]
ATR_PLAN = "lite"
# Mandatory only if ATR_PROVISION is set to true. Activity Tracker: The type of plan the service instance should
run under (lite, 7-day, 14-day, or 30-day).
# The list of service plan is avaialble here: https://cloud.ibm.com/docs/activity-tracker?topic=activity-trackerservice_plan#service_plan"
# Example ATR_PLAN = "lite"

The hostname must have up to 13 characters as required by SAP. For more information about the rules that apply to hostnames for SAP
systems, see SAP Note 611361 - Hostnames of SAP ABAP Platform servers
4. Customize your SAP system configuration. Modify the input.auto.tfvars file to specify SAP system configuration and enter the
location of the downloaded SAP Kits. For descriptions of the variables, see the Java README file or the ABAP README file.
For Java:
$ # SAP HANA DB configuration for Java stack
HANA_SID

= "HDB"

HANA_SYSNO

= "00"

HANA_SYSTEM_USAGE

= "custom"

HANA_COMPONENTS

= "server"

# SAP HANA Installation kit path
KIT_SAPHANA_FILE

= "/storage/HANADB/51055299.ZIP"

# SAP system configuration
SAP_SID

= "JV1"

SAP_SCS_INSTANCE_NUMBER = "01"
SAP_CI_INSTANCE_NUMBER

= "00"

# SAP JAVA APP Installation kit path
KIT_SAPCAR_FILE = "/storage/NW75HDB/SAPCAR_1010-70006178.EXE"
KIT_SWPM_FILE = "/storage/NW75HDB/SWPM10SP31_7-20009701.SAR"
KIT_SAPEXE_FILE = "/storage/NW75HDB/SAPEXE_801-80002573.SAR"
KIT_SAPEXEDB_FILE = "/storage/NW75HDB/SAPEXEDB_801-80002572.SAR"
KIT_IGSEXE_FILE = "/storage/NW75HDB/igsexe_13-80003187.sar"
KIT_IGSHELPER_FILE = "/storage/NW75HDB/igshelper_17-10010245.sar"
KIT_SAPHOSTAGENT_FILE = "/storage/NW75HDB/SAPHOSTAGENT51_51-20009394.SAR"
KIT_HDBCLIENT_FILE = "/storage/NW75HDB/IMDB_CLIENT20_009_28-80002082.SAR"
KIT_SAPJVM_FILE = "/storage/NW75HDB/SAPJVM8_73-80000202.SAR"
KIT_JAVA_EXPORT = "/storage/NW75HDB/export"

For ABAP:
$ # HANA DB configuration for ABAP stack
hana_sid

= "HDB"

hana_sysno

= "00"

hana_system_usage

= "custom"

hana_components

= "server"

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 435

# SAP HANA Installation kit path
kit_saphana_file

= "/storage/HANADB/51055299.ZIP"

# SAP system configuration
sap_sid = "NWD"
sap_ascs_instance_number = "01"
sap_ci_instance_number

= "00"

# Number of concurrent jobs used to load and/or extract archives to HANA Host
hdb_concurrent_jobs

= "12"

# SAP NW APP Installation kit path
kit_sapcar_file = "/storage/NW75HDB/SAPCAR_1010-70006178.EXE"
kit_swpm_file = "/storage/NW75HDB/SWPM10SP31_7-20009701.SAR"
kit_sapexe_file = "/storage/NW75HDB/SAPEXE_801-80002573.SAR"
kit_sapexedb_file = "/storage/NW75HDB/SAPEXEDB_801-80002572.SAR"
kit_igsexe_file = "/storage/NW75HDB/igsexe_13-80003187.sar"
kit_igshelper_file = "/storage/NW75HDB/igshelper_17-10010245.sar"
kit_saphotagent_file = "/storage/NW75HDB/SAPHOSTAGENT51_51-20009394.SAR"
kit_hdbclient_file = "/storage/NW75HDB/IMDB_CLIENT20_009_28-80002082.SAR"
kit_nwhana_export = "/storage/NW75HDB/ABAPEXP"

5. Initialize the Terraform CLI.
$ terraform init

6. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account. During the Terraform plan, you are prompted to enter your API key, and initial SAP and DB passwords.
$ terraform plan --out plan1

You must enter an SAP main password.
The SAP main password must be 10 - 14 characters long and contain at least one digit (0-9). It can contain only the following characters:
a-z, A-Z, 0-9, @, #, $, _. This password cannot contain !. It must not start with a digit or an underscore ( _ ).
7. Verify that the plan shows all the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run ``terraform plan --out plan1` again.
8. Create the virtual private cloud for SAP instance and IAM access policy in IBM Cloud.
$

terraform apply "plan1"

The virtual private cloud and components are created and you see output similar to the

terraform plan output.

Next steps
Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The Terraform scripts create a complete solution
and selectively modifying resources with the user interface might cause unexpected results.
If you need to remove your VPC, go to your project folder and run terraform destroy .
If the resources created with the SAP deployment automation is removed, the Activity Tracker instance is also removed, if it is provisioned at
the same time with the SAP solution (when ATR_PROVISION parameter is set to true during the deployment of the SAP solution).

Related information
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier virtual

private cloud for SAP by using Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 436

SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP license
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
IBM Cloud Activity Tracker
Note: This automation is offered at no cost; however, the provisioned infrastructure comes at cost.

SAP ASE Sybase standalone database instance on IBM Cloud VPC
Background for automating ASE Sybase stand-alone virtual server instance deployment in IBM
Cloud® VPC
IBM Cloud® Virtual Private Cloud (VPC) introduction
SAP Adaptive Server Enterprise (SAP ASE) is a high-performance relational database management system for mission-critical, data-intensive
environments optimized for SAP Business Suite applications. IBM Cloud® VPC offers the possibility to quickly provision virtual server instances
for VPC with high network performance. VPC infrastructure contains several Infrastructure-as-a-Service (IaaS) offerings, including Virtual
Servers for VPC. A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on
shared public cloud infrastructure. A VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all
other public cloud tenants. This helps creating a private and secure place on the public cloud.
Imagine that a cloud providers infrastructure is a residential apartment building with multiple families living inside. Being a public cloud tenant
is akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium. No one else has
the key, and no one can enter the space without your permission.
A VPC’s logical isolation is implemented by using virtual network functions and security features that give an enterprise user a granular control,
over which the IP addresses or applications can access the particular resources. It is similar to the “friends-only” or “public/private” controls
on social media accounts used to restrict who can or cannot see your public posts.
With IBM Cloud VPC, you can use the UI, CLI, and API to quickly provision virtual server instances for VPC with high network performance. VPC
infrastructure contains several Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to
understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC
tutorials. For more information, see Getting started with Virtual Private Cloud (VPC) .

SAP ASE Sybase in IBM Cloud
The IBM public cloud is an open, security-rich, and enterprise-ready public cloud for business. This design makes it easier for global
enterprises to modernize and build new business applications in the cloud to meet the requirements of the business and its customers. IBM
Cloud offerings include a broader portfolio of SAP-certified infrastructure, ranging from bare metal, VMware, VPC, and IBM Power® Systems
Virtual Server products.

SAP ASE Sybase defined
SAP ASE is based on a client/server model, communicating with its clients over the network through the Tabular Data Stream™ (TDS) protocol.
Each client process runs on one system and communicate with a database server on the same or a different system. SAP ASE runs as an
application for the operating system. The hardware that the operating system runs on is open to SAP ASE, which identifies only the operating
systems user interfaces. To enhance the performance on multiprocessor systems, configure multiple processes (engines).
SAP ASE is divided into a DBMS (database) component and a kernel component. The kernel component uses the operating system services for
process creation and manipulation, device and file processing, and interprocess communication. The DBMS component manages SQL
statement processing, accesses data in a database, and manages different types of server resources.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 437

SAP ASE Editions
Analyze your system and scalability requirements to determine which edition of SAP ASE is appropriate for your enterprise. Some of the SAP
ASE editions are:
Enterprise edition - has no limit on scalability and supports all the options that can be purchased or licensed separately.
Small business edition - has limited scalability and supports a limited set of options that are purchased or licensed separately.
Developer edition - has limited scalability and includes many of the options that are included in the enterprise edition.
The SAP ASE installer automatically installs a SySAM license server. You can choose the full installation option or enter the license key when
prompted for the SySAM license. You can also install the license server by using the installers custom installation option.

SAP ASE Options
SAP offers various optional features for SAP ASE, such as data compression, partitions, and encrypted columns.
Data compression - Enables compression for regular and large object data, which uses less storage space for the same amount of data,
reduces cache memory consumption, and improves performance due to lack of input/output demands.
Security and directory services - Provides lightweight directory services, network-based authentication, and encryption by using SSL and
Kerberos.
Partitions - Enables semantic partitioning for table row data.
Encrypted columns - Increases security parameters and allows for addition of data types.
Tivoli storage manager - Enables the database to back up and restore operations to IBM Tivoli Storage Manager.
In-memory database - Provides zero-disk footprint in-memory database support that is fully integrated with SAP ASE for highperformance transactional applications. Provides performance enhancements to disk-resident databases with relaxed durability
properties.
SAP ASE includes server components that are installed into specific directories. The SAP ASE is installed into the ASE-16_0 directory.
SAP ASE – the database server.
Backup server – an application based on SAP® Open Server™ that manages all database backup (dump) and restore (load) operations.
XP server – an Open Server application that manages and runs extended stored procedures (ESPs) from within SAP ASE.
Job Scheduler – provides a job scheduler for SAP ASE. Job Scheduler components are located in

ASE-16_0/jobscheduler/ path.

Single-host SAP ASE Sybase Instance Database
A single-host system is the simplest installation type that runs an SAP ASE Sybase system entirely on one host. You can scale the system up as
needed. The single-host system has these components as shown in the architecture:

Figure 1. SAP ASE Sybase single-host installation

Note: The SAP ASE Sybase stand-alone deployment does not support any additional SAP application instance, as this is not deployed
based on SAP Software Provisioning Manager (SWPM) phases for SAP applications running on ASE Sybase. This stand-alone database is
suitable for applications like SAP Business Objects, Business Intelligence Platform, and SAP Data Services etc.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 438

For more information about SAP systems architectures in IBM Cloud VPC, see reference architectures for each supported database type.
Manually deploying a VPC and installing an SAP system can be time-consuming. The automation assures not only a quicker implementation,
but also a standardized and less error-prone deployment. Terraform and Ansible are used for automating the deployment processes.
The solution that is documented in this topic is the automated deployment of a single host with SAP ASE Sybase stand-alone VSI on Red Hat
Enterprise Linux or SUSE Linux Enterprise Server (SLES) for SAP Applications.
Database instance (DB) - To assist your project planning phase, more design considerations are provided at SAP AnyDB – SAP ASE Sybase
database with IBM Cloud for SAP. For more information, see AnyDB - SAP ASE Sybase and Infrastructure certified for SAP. A dedicated
reference architecture about this AnyDB SAP ASE Sybase on IBM Cloud VPC cloud can be found on AnyDB - SAP ASE Sybase Database .
SAP ASE Sybase installation media that are used for this deployment is the default one for SAP ASE Sybase, platform edition 16.0 SPSXX. The
media is available at the SAP Support Portal in the Installation and Upgrade area and it must be provided manually in the input parameter file.

Terraform for infrastructure deployment
Terraform on IBM Cloud enables predictable and consistent provisioning of IBM Cloud solutions. For more information about Terraform on IBM
Cloud, see Getting started with Terraform on IBM Cloud .
Terraform is used to provision the infrastructure components in IBM Cloud. For automating this process, the current solution uses a Terraform
script for deploying a VPC and a VSI with SAP certified storage and network configuration. The VPC is created along with the bastion
(deployment) server, with one to three subnets and the following security rules:
Allow all traffic in the Security group for private networks.
Allow outbound traffic (ALL for port 53, TCP for ports 80, 443, 8443).
Allow inbound SSH traffic (TCP for port 22) from IBM Schematics Servers.
Option to Allow inbound SSH traffic with a custom source IP/CIDR list.
After the successful deployment of the infrastructure, the Terraform script calls the Ansible Playbooks, which perform the file system setup
and the OS configuration before automatically installing the SAP application.

Ansible for SAP installation
Ansible is an IT automation engine that automates provisioning, configuration management, application deployment, and other IT tasks. This
solution performs the automated deployment of a stand-alone SAP ASE Sybase 2.0 DB on a Red Hat Enterprise Linux 8.6|8.4 for SAP or on a
SUSE Linux Enterprise Server 15 SP 4|3 for SAP Applications VSI box. For more information about Ansible, check out the documentation
available on the Ansible page.
Ansible core provides CLI tools for automation. More information about Ansible core can be found on the Ansible core page .
The Ansible playbooks are called directly by the Terraform script. The Terraform script is run in one run. During the run, the first steps are
Terraform specific for creating the VPC resources, and it continues automatically with Ansible steps for the installation of the SAP system.
Note: This automation is offered free of charge however, the provisioned infrastructure comes at a cost.

Deploying SAP ASE Sybase stand-alone virtual server instance on IBM Cloud® VPC
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March
2025. Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM
Cloud Activity Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about
migrating from IBM Cloud Activity Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.
You can use Terraform scripts to create a VPC and SAP ASE Sybase database single VSI infrastructure in the VPC. The Terraform scripts use
the information that you provide and then call the Ansible playbooks to create the SAP architecture in the specified VPC.
You can use Schematics User Interface that calls Terraform scripts to create a VPC and SAP ASE Sybase database single VSI infrastructure in
the VPC. The Terraform scripts use the information that you provide and then call the Ansible playbooks to create the SAP architecture in the
specified VPC.
Terraform on IBM Cloud® enables predictable and consistent provisioning of IBM Cloud VPC infrastructure resources so that you can rapidly
build complex cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware by using Intel® Xeon CPUs and additional
Intel® technologies.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 439

For more information about Terraform on IBM Cloud, see Getting started with Terraform on IBM Cloud .
To create resources with Terraform, you can use Terraform configuration files that describe the IBM Cloud resources that you need and how
you want to configure them. Based on your configuration, Terraform creates an execution plan and describes the actions that need to be run to
create the resources. You can review the execution plan, change it, or run the plan.
You have two deployment methods to choose from:
In CLI, by running the Terraform script on your bastion server.
In Schematics User Interface, which is accessed from your IBM Cloud dashboard menu.

Prerequisites
A deployment server (bastion server) deployed by using the automation solution Automate SAP bastion server – SAP media storage repository ,
must exist in the same VPC and same region. This should have the same subnet and security group that is configured for the SAP system VSI.

What is created
The scripts automate the deployment of the virtual infrastructure resources and the provisioning processes for the SAP architecture in an
existing VPC. An SAP ASE Sybase DB, on a VPC virtual server instance box, is provisioned. The scripts work in two phases.
During the first phase, a virtual server instance, with SAP certified storage and network configuration (the same subnet and security group as
for the deployment server (bastion server)) is configured.
During the second phase, the Ansible playbooks are called and the SAP ASE Sybase 2.0 architecture is installed on the SAP ASE Sybase VSI
box.
There are IBM Cloud VPC SAP certified server profiles where this solution can be deployed.

x86-64 instance profiles
During provisioning IBM Cloud® Virtual Servers for Virtual Private Cloud, you can select from the following families of profiles:
Compute Optimized
Balanced
Memory Optimized
Very High Memory Optimized
Ultra High Memory Optimized
A profile is a combination of instance attributes, such as the number of vCPUs, amount of RAM, network bandwidth, and default bandwidth
allocation. The attributes define the size and capabilities of the virtual server instance that is provisioned. In the IBM Cloud console, you can
select the most recently used profile or click View All Profiles tab to choose the profile that best fits your needs.
For more information about SAP profiles, see Intel Virtual Server certified profiles on VPC infrastructure for SAP NetWeaver .
The Terraform scripts use the information that you provide in input.auto.tfvars file, call the Ansible Playbooks and deploy SAP ASE Sybase
database single VSI and the SAP architecture.

Virtual server instance configuration
The following operating systems are supported:
Red Hat Enterprise Linux 8.6 for SAP (amd64)
Red Hat Enterprise Linux 8.4 for SAP (amd64)
SUSE Linux Enterprise Server 15 SP 4 for SAP Applications (amd64)
SUSE Linux Enterprise Server 15 SP 3 for SAP Applications (amd64)
The provided SSH keys are used to access the VSI through SSH, as a root user.

Script files
The configuration and script files are available in the GitHub repository.
The input.auto.tfvars file allows the customization of the input parameters.
All other configuration files are provided and no modification is required.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 440

Schematics deployment
When you are using the Schematics interface for the deployment, you need to:
Provide the workspace information.
Provide the GitHub repository path.
Update the value of the parameters in the Schematics interface. The parameters are similar to the ones from

input.auto.tfvars file,

which is used in the deployment from CLI.

Support
There are no warranties of any kind, and there is no service or technical support available for these materials from IBM®. As a recommended
practice, review carefully any materials that you download from this site before using them on a live system.
Though the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers,
who reserve the right to revise, readapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a
GitHub issue.

Before you begin
If you don't have a deployment server (bastion server) in the same VPC, create a deployment server to store the SAP kits. For more information,
see Automate SAP bastion server - SAP media storage repository .
Log in to your Deployment Server and verify that Terraform and Ansible are installed.
Download the SAP kits from the SAP Portal to your Deployment Server. Make note of the download locations. Ansible decompresses all
the archive kits. For more information, see the Readme file.
Create or retrieve an IBM Cloud API key . The API key is used to authenticate with the IBM Cloud platform and to determine your
permissions for IBM Cloud services.
Create or retrieve your SSH key ID . You need the 40-digit UUID for the SSH key, not the SSH key name.

Procedure
1. Log in to the Deployment Server (Bastion server) through ssh .
2. Clone the GitHub repository from https://github.com/IBM-Cloud/sap-ase-db and go to the sap-ase-db folder.
$ $ git clone https://github.com/IBM-Cloud/sap-ase-db.git
$ cd sap-ase-db

3. Customize the values for VPC variable resources according to your existing VPC data. Your options can be specified by updating
input.auto.tfvars file. You need a 40-digit SSH key ID for the deployment. Additional SSH key IDs are optional.

The following input variable values must be provided:
REGION - Region for SAP HANA server. See the Readme file.
ZONE - Zone for SAP HANA server. See the Readme file.
VPC - The name of an existing VPC in the specified region.
SECURITY_GROUP - The name of an existing security group in the same VPC.
RESOURCE_GROUP - The name of an existing resource group, previously created by the user.
SUBNET - The name of an existing subnet in the same region and zone as the VSI.
SSH_KEYS - A list of SSH keys UUIDs allowed to connect through SSH to the VSIs.
ID_RSA_FILE_PATH - existing id_rsa private key file path in OpenSSH format with 0600 permissions.
DB_HOSTNAME - The hostname of the SAP HANA server, up to 13 characters. For more information, see the

Readme file.

$ ######################################################
# General & Default VPC variables for CLI deployment
######################################################
REGION = "eu-de"
# Region for the VSI. Supported regions: https://cloud.ibm.com/docs/containers?topic=containers-regions-andzones#zones-vpc
# Example: REGION = "eu-de"
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 441

ZONE = "eu-de-1"
#

Availability zone for VSI. Supported zones: https://cloud.ibm.com/docs/containers?topic=containers-regions-

and-zones#zones-vpc
# Example: ZONE = "eu-de-1"
VPC = "ic4sap"
# EXISTING VPC, previously created by the user in the same region as the VSI. The list of available VPCs:
https://cloud.ibm.com/vpc-ext/network/vpcs
# Example: VPC = "ic4sap"
SECURITY_GROUP = "ic4sap-securitygroup"
# EXISTING Security group, previously created by the user in the same VPC. The list of available Security Groups:
https://cloud.ibm.com/vpc-ext/network/securityGroups
# Example: SECURITY_GROUP = "ic4sap-securitygroup"
RESOURCE_GROUP = "wes-automation"
# EXISTING Resource group, previously created by the user. The list of available Resource Groups:
https://cloud.ibm.com/account/resource-groups
# Example: RESOURCE_GROUP = "wes-automation"
SUBNET = "ic4sap-subnet"
# EXISTING Subnet in the same region and zone as the VSI, previously created by the user. The list of available
Subnets: https://cloud.ibm.com/vpc-ext/network/subnets
# Example: SUBNET = "ic4sap-subnet"
SSH_KEYS = ["r010-8f72b994-c17f-4500-af8f-d05680374t3c", "r011-8f72v884-c17f-4500-af8f-d05900374t3c"]
# List of SSH Keys UUIDs that are allowed to SSH as root to the VSI. The SSH Keys should be created for the same
region as the VSI. The list of available SSH Keys UUIDs: https://cloud.ibm.com/vpc-ext/compute/sshKeys
# Example: SSH_KEYS = ["r010-8f72b994-c17f-4500-af8f-d05680374t3c", "r011-8f72v884-c17f-4500-af8f-d05900374t3c"]
ID_RSA_FILE_PATH = "ansible/id_rsa"
# The id_rsa private key file path in OpenSSH format with 0600 permissions.
# This private key is used only during the terraform provisioning and it is recommended to be changed after the
SAP deployment.
# It must contain the relative or absoute path from your Bastion.
# Examples: "ansible/id_rsa_abap_syb_dst" , "~/.ssh/id_rsa_abap_syb_dst" , "/root/.ssh/id_rsa".
##########################################################
# Activity Tracker variables:
##########################################################
ATR_NAME="Activity-Tracker-SAP-eu-de"
# The name of the Activity Tracker instance, in the same region chosen for SAP system deployment.
# Example: ATR_NAME="Activity-Tracker-SAP-eu-de"
##########################################################
# DB VSI variables:
##########################################################
DB_HOSTNAME = "ic4sapdb"
# The Hostname for the DB VSI. The hostname should be up to 13 characters, as required by SAP
# Example: DB-HOSTNAME = "ic4sapdb"
DB_PROFILE = "bx2-4x16"
# The DB VSI profile. Supported profiles for DB VSI: bx2-4x16. The list of available profiles:
https://cloud.ibm.com/docs/vpc?topic=vpc-profiles&interface=ui
DB_IMAGE = "ibm-redhat-8-6-amd64-sap-applications-6"
# OS image for DB VSI. Supported OS images for DB VSIs: ibm-redhat-8-6-amd64-sap-applications-6, ibm-redhat-8-4amd64-sap-applications-10, ibm-sles-15-4-amd64-sap-applications-8, ibm-sles-15-3-amd64-sap-applications-11.
# The list of available VPC Operating Systems supported by SAP: SAP note '2927211 - SAP Applications on IBM
Virtual Private Cloud (VPC) Infrastructure environment' https://launchpad.support.sap.com/#/notes/2927211; The
list of all available OS images: https://cloud.ibm.com/docs/vpc?topic=vpc-about-images
# Example: DB-IMAGE = "ibm-sles-15-4-amd64-sap-applications-8"

The hostname must be up to 13 characters as required by SAP. For more information about the rules that apply to hostnames for
SAP systems, see SAP Note 611361 - Hostnames of SAP ABAP Platform servers.
Customize your SAP system configuration. Modify the input.auto.tfvars file to specify SAP ASE Sybase system configuration
and enter the location of the downloaded SAP Kits.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 442

$ # SAP ASE SYBASE configuration
##########################################################
# SAP system configuration
##########################################################
ASE_SID = "NWD"
# The SAP ASE system ID. Identifies the entire ASE system.
# Consists of exactly three alphanumeric characters and the first character must be a letter.
# Does not include any of the reserved IDs listed in SAP Note 1979280
DATA_DISK_SIZE = "30"
# The size of data disk, in GB.
##########################################################
# Kit Paths
##########################################################
KIT_ASE_FILE = "/storage/ASEDB/SP04/PL06/ASESERV160004P_6-80008862.TGZ"

4. Initialize the Terraform CLI. terraform init
5. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private
cloud instance in your account. terraform plan --out plan1
You are asked to enter the IBM Cloud API key and the SAP ASE Sybase main password. The SAP ASE Sybase main password must
contain at least one digit (0-9), one lowercase letter (a-z), and one uppercase letter (A-Z). It can contain the following characters only: az, A-Z, 0-9, !, @, #, $, _. It must not start with a digit or an underscore ( _ ).
6. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be
adjusted, edit the input.auto.tfvars file to correct resources and run terraform plan --out plan1 again.
7. Deploy the SAP solution. terraform apply "plan1"

Deploying SAP ASE Sybase database on a single VSI by using the Schematics user interface
Follow the steps to deploy the SAP ASE Sybase database on a single VSI in your existing VPC by using the Schematics User Interface. The
scripts can take 1 - 2 hours to complete.
1. From the IBM Cloud menu, select Schematics.
2. Click Create workspace.
3. On the Specify template page:
Enter the GitHub URL for the code that you plan to deploy.
Select the Terraform version that is listed in the Readme file.
Click Next.
4. On the Workspace details page:
Enter a name for the workspace.
Select a Resource group.
Select a Location for your workspace. The workspace location does not have to match the resource location.
Click Next.
5. Select Create to create your workspace.
6. On the workspace Settings page, in the Input variables section, review the default input variables and provide values that match your
solution:
Your IBM Cloud API key.
A private SSH key is used for the deployment.
(Optional) You can change the ID_RSA_FILE_PATH for your SSH key file that is autogenerated on Schematics and on the bastion
server.
The IDs of the SSH keys that you created and uploaded to IBM Cloud. Enter the SSH key IDs in brackets and surrounded by
quotation marks, for example [ "ibmcloud_ssh_key_UUID1", "ibmcloud_ssh_key_UUID2",... ].

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 443

The region for your resources.
The zone for your resources.
Existing VPC name
Existing Subnet name
VPC name
Subnet name
Security group name
Hostname
Profile
Image
Data disk size
SAP main password - must be at least 10 characters, upper and lowercase letters, a number, and a special character, not an
exclamation point.
Click Save changes.
For a more detailed description of the parameters, check the GitHub repo Readme file, chapter “Input parameter file”. Also, mark as
“sensitive” for the parameters that contain sensitive information like passwords, IBM Cloud API, the SSH private keys (they are marked
as “sensitive” in the Readme in the “Input parameter file”).
7. On the workspace Settings page, click Generate plan. Wait for the plan to complete.
8. Click View log to review the log files of your Terraform execution plan.
9. Apply your Terraform template by clicking Apply plan.
10. Review the log file to ensure that no errors occurred during the provisioning, modification, or deletion process.

Next steps
For your SAP solution, in case you want to remove the resources that are created with the automation, then go to the Workspace page >
Actions and select Destroy Resources.
If you need to remove the resources created with the automation for your SAP solution, go to your project folder and run

terraform destroy .

Related information
For more information about Terraform on IBM Cloud, see Terraform on IBM Cloud getting started tutorial .
For more information about using Terraform for creating only a VPC for SAP, without the SAP architecture, see

Creating single-tier VPC for SAP

on IBM Cloud® VPC with Terraform.
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux®, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux® on IBM Cloud (IaaS): Adaption of your SAP license
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux®: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 444

High Availability Scenarios on Power Virtual Server
Implementing High Availability for SAP Applications on IBM Power Virtual Server
Running SAP on IBM® Power® Virtual Server offers a consistent platform for SAP HANA based and traditional applications, world-class
performance, resiliency for critical workloads, and a flexible infrastructure.
Use the following information to understand how to implement high availability solutions for SAP systems by using Power Virtual Server
instances.

SAP system architecture
The main components of an SAP system are as follows.

SAP HANA system
The SAP HANA system provides the tenant database for SAP application servers.
SAP application server
SAP application servers provide the functional part of an SAP S/4HANA or other application solution. All customization and application
data of an SAP system is stored in a tenant database of an SAP HANA system.
An SAP application system is installed and configured as a single unit and consists of the following application instances.
One ABAP System Central Services instance (ASCS instance) Each SAP application system has exactly one ASCS instance, which
consists of a message server and an enqueue server.
One or more application server instances (AS instances)
The primary application server (PAS) is the first AS instance that is installed for an ABAP system.
Other AS instances that are installed for an ABAP system are called additional application servers (AAS).
Both the application server instances and the ASCS instance depend on a shared file system and require read/write access to it.
Shared file system
Typically, the shared file system is exported on an NFS server and mounted on all instances.

Figure 1 illustrates the technical components of an SAP system.

Figure 1. Technical components for SAP systems

Considerations for implementing an SAP high availability solution
For high availability protection, it is recommended to install application servers redundantly. Install at least two application servers (PAS and
AAS) and use login groups to implement load balancing. If an application server fails, all user sessions that are connected to that instance are

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 445

stopped. The user logs in again, and load balancing redirects the user to another application server that is still running.
The other technical components, such as the ASCS instance, the SAP HANA database, and the shared file system, are single points of failure
and must be protected.
ASCS instance
The best way to safeguard the ASCS instance is to deploy an Enqueue Replication Server (ERS) instance on an extra virtual server and
use HA clustering software for automating failover.
Install ASCS and ERS either on a shared disk that is attached to both virtual server instances or on an NFS file system.
The enqueue server of the ASCS instance manages the lock table, and the ERS creates a replicated copy of the lock table in its main
memory. If the enqueue server must be restarted, the lock table is rebuilt by using the copy on the ERS, and all of the locks are retained.
A simple restart of the message server is sufficient because no data needs to be retained.
To set up an HA cluster for the ABAP System Central Services instance, follow the steps that are in Configuring high availability for SAP
S/4HANA (ASCS and ERS) in a RHEL HA Add-On cluster.
Shared file system
The recommended method of protecting the NFS server is to implement an extra virtual server instance. Then, create the NFS exported
file systems on shared disks that are attached to both virtual server instances and automate the failover by using HA cluster software.
To set up an HA cluster for the shared file system, follow the steps that are in Configuring an active-passive NFS server in a Red Hat
High Availability cluster.
SAP HANA system
Note: SAP HANA provides two approaches to scale a system: scale-up and scale-out. With the comprehensive and highly scalable
set of IBM Power Virtual Server certified profiles for SAP HANA that are available in IBM Power Virtual Server, the focus is on SAP
HANA scale-up solutions.
The best way to protect an SAP HANA system is to set up a secondary SAP HANA system on a separate virtual server instance. Then,
configure SAP HANA system replication, and automate failover with HA cluster software.
The following figure shows an architectural overview of a highly available SAP system that is implemented on Power Virtual Server.

Figure 2. SAP on Power Virtual Server HA architecture overview

SAP HANA high availability solution scenarios
The solution varies depending on the recovery time objective (RTO).

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 446

Scenario

Typical

Comment

RTO
Performance
Optimized

A few
minutes

Unless you have specific requirements, this scenario is the default.

Active/Active
(read
enabled)

A few
minutes

In an Active/Active (read enabled) configuration, SAP HANA system replication allows read access to the
database content on the secondary system.

Cost
Optimized

A few
tens of
minutes

In a cost-optimized configuration, a nonproduction SAP HANA system runs on the secondary node during
normal operation. The hardware resources on the secondary node are shared between the nonproduction
system and the SAP HANA System Replication secondary. The memory consumption of the production SAP
HANA System Replication secondary is reduced by turning off the preloading of data in the column tables.
When a failover occurs, the nonproduction instance is automatically stopped before the node takes over the
production workload. The take-over time is longer compared to a performance-optimized configuration.
Table 1. Variations for high availability solutions for SAP HANA

Depending on your requirements, select the documentation for one of the scenarios.
SAP HANA System Replication performance-optimized scenario
Configuring SAP HANA Scale-Up System Replication in a RHEL HA Add-On cluster .
SAP HANA System Replication cost-optimized scenario
Configuring SAP HANA Cost-Optimized Scale-Up System Replication in a RHEL HA Add-On cluster .
SAP HANA System Replication Active-Active (Read Enabled) scenario
Configuring SAP HANA Active/Active (Read Enabled) System Replication in a RHEL HA Add-On cluster .

SAP HANA disaster recovery solution scenarios
For extra protection of the database system, replicate the SAP HANA system to a third system that is located in a different region by using SAP
HANA system replication. Depending on your requirements, select one of the two available topologies.
SAP HANA multitier system replication scenario
With SAP HANA multitier system replication, you can chain multiple systems together to achieve a higher level of availability.
Configuring SAP HANA multitier system replication in a RHEL HA Add-On cluster .
SAP HANA multitarget system replication scenario
Multitarget system replication allows primary and secondary systems to replicate changes to more than one system.
Configuring SAP HANA multitarget system replication in a RHEL HA Add-On cluster .

Implementing High Availability for SAP Applications on IBM Power Virtual Server
References
The following is a comprehensive list of product documentation, Red Hat Knowledge Base articles, and SAP notes that you need to review
before you implement high availability for SAP solutions. A Red Hat Customer Portal ID is required to access Knowledge Base articles and an
SAP User ID is required to access SAP Notes.

General requirements
An IBM Cloud account
An SAP for Me account
A Red Hat Customer Portal account
A valid RHEL for SAP Applications or RHEL for SAP Solutions subscription is required to enable the repositories that you need to install SAP
HANA and the resource agents for HA configurations.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 447

Red Hat Enterprise Linux Cluster product documentation
Product Documentation
Configuring and managing high availability clusters
Table 1. RHEL 8 cluster documentation

Product Documentation
Configuring and managing high availability clusters
Table 1. RHEL 9 cluster documentation

Red Hat Enterprise Linux for SAP Solutions product documentation
Product Documentation
Configuring RHEL 8 for SAP HANA2 installation
Red Hat HA Solutions for SAP HANA, S/4HANA, and NetWeaver based SAP Applications
Automating SAP HANA Scale-Up System Replication by using the RHEL HA Add-On
Configuring a Cost-Optimized SAP S/4HANA HA cluster (HANA System Replication + ENSA2) by using the RHEL HA Add-On
Configuring SAP HANA Scale-Up Multitarget System Replication for disaster recovery
Configuring an active-passive NFS server in a Red Hat High Availability cluster
Table 2. RHEL 8 for SAP documentation

Product Documentation
Configuring RHEL 9 for SAP HANA2 installation
Red Hat HA Solutions for SAP HANA, S/4HANA, and NetWeaver based SAP Applications
Automating SAP HANA Scale-Up System Replication by using the RHEL HA Add-On
Configuring SAP HANA Scale-Up Multitarget System Replication for disaster recovery
Configuring HA clusters to manage SAP NetWeaver or SAP S/4HANA Application server instances by using the RHEL HA Add-On
Table 2. RHEL 9 for SAP documentation

Red Hat Enterprise Linux general cluster knowledge base articles
Support Policies for RHEL High Availability Clusters
Support Policies for RHEL High Availability Clusters - General Requirements for Fencing/STONITH
Support Policies for RHEL High Availability Clusters - IBM Power Virtual Server (PowerVS) Virtual Machines as Cluster Members
Configuring a RHEL HA Cluster Fence Agent for an IBM Power Virtual Server
How to configure HA-LVM Cluster by using system_id in RHEL 8 and above

Red Hat Enterprise Linux for SAP cluster knowledge base articles
Support Policies for RHEL High Availability Clusters - Management of SAP HANA in a Cluster
Automating SAP HANA Scale-Up System Replication by using the RHEL HA Add-On
Support Policies for RHEL High Availability Clusters - Management of SAP S/4HANA in a cluster
Configuring SAP S/4HANA ASCS/ERS with Standalone Enqueue Server 2 (ENSA2) in Pacemaker

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 448

SAP HANA product documentation
SAP HANA Server Installation and Update Guide
SAP HANA Administration Guide
SAP HANA System Replication
SAP HANA System Replication - Active/Active (Read Enabled)
SAP HANA SQL and System Views Reference Guide
Implementing a HA/DR Provider

SAP Notes
SAP Notes
SAP Note 2772999 - Red Hat Enterprise Linux 8.x: Installation and Configuration
SAP Note 2235581 - SAP HANA: Supported Operating Systems
SAP Note 2777782 - SAP HANA DB: Recommended OS Settings for RHEL 8
SAP Note 2369981 - Required configuration steps for authentication with HANA System Replication
Table 3. SAP Notes for RHEL 8

SAP Notes
SAP Note 3108316 - Red Hat Enterprise Linux 9.x: Installation and Configuration
SAP Note 2235581 - SAP HANA: Supported Operating Systems
SAP Note 3108302 - SAP HANA DB: Recommended OS Settings for RHEL 9
SAP Note 2369981 - Required configuration steps for authentication with HANA System Replication
Table 3. SAP Notes for RHEL 9

Creating instances for a high availability cluster on IBM Power Virtual Server
Use the following information and procedures to create the Power Virtual Server instances that are required for a high availability cluster
implementation.
The following information is provided in the following sections.
Creating the Power Virtual Server workspace in IBM Cloud®
After the workspace is created, you can create and configure virtual server instances, network resources, and storage volumes.
Creating a Service ID API Key in IBM Cloud®
For monitoring and management, the fencing agent authenticates to the Power Virtual Server API by using the Service API key.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Creating the workspace
A workspace is the environment that acts as a folder for all the Power Virtual Server resources in a specific geographic region. These resources
include computing, network, and storage volumes. Resources cannot be moved or shared between different workspaces. Each workspace is
tied to a single data center.
Log in into Power Virtual Server in IBM Cloud®.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 449

1. Select Workspaces in the navigation bar and press Create to open the Create workspace menu.
2. Enter the Workspace name and select a Resource group according to the intended assignment of the cluster resources.
3. Select the Region where you want the resources to deploy.
4. Add any User tags and Access management tags according to your policies.
5. Click Create to initiate the workspace.

Creating subnets
The virtual server instance is connected to the network and gets an IP address from the assigned IP range.
It is recommended that you connect the cluster nodes to a private network, not to a public network.
An extra bastion node can access both public and private networks and can be used to tunnel SSH connections to the cluster nodes.
Private subnets are created in the context of the Power Virtual Server workspace. When you connect different networks, you can use GRE
Tunneling if a subnet range conflicts with existing classical infrastructure.
Tip: You need at least one private subnet in the workspace.
Use the following steps to create a subnet.
1. Go to Subnets in Power Virtual Server .
2. Select the workspace that you created.
3. Click Create subnet and enter the following information for the new subnet.
Name for the new subnet.
Classless Inter-Domain Routing (CIDR) in form of an address prefix.
Number of bits reserved for the netmask separated by a slash.
By entering a specific IP range, you can restrict the IP address range to a subset of the full CIDR range. Restricting the IP address range
prevents IP addresses from being automatically assigned to another virtual server instance during a provisioning request.
4. Click Create subnet.

Reserving virtual IP addresses
A high availability cluster typically needs virtual IP addresses that must move with the application in a failover scenario.
Reserve an IP address in the subnet to prevent Power Virtual Server from assigning a specific IP address to a virtual server instance. See
Reserving IP addresses.
Open Subnets in IBM Cloud for your Power Virtual Server workspace.
From the list of subnets, click the subnet for which you want to reserve the IP address.
Click Reserve IP.
Enter your IP address in the IP address field.
Tip: Make sure that the IP address you want to reserve is within the CIDR range of the subnet and within the

IP range that you

previously restricted.
Provide a description of your reserved IP in the Reserved IP description (optional) field.

Exploring more network architecture options
If your Power Virtual Server workspace is enabled for Power Edge Router (PER), you already have network communication with parts of the
IBM network. The PER solution creates a direct connection to the IBM Cloud MPLS Multi Protocol Label Switching (MPLS) backbone, making it
easy for different parts of the IBM network to communicate with each other. For more information, see Getting started with the Power Edge
Router.
Otherwise, use an IBM Cloud® connection to connect your Power Virtual Server instances to other IBM Cloud® resources within your account.
IBM Cloud® connections are not required to configure a Red Hat High Availability cluster on Power Virtual Server, but might be required for
integration scenarios when you use the IBM Cloud® Classic network and Virtual Private Cloud (VPC) infrastructures. For more information, see

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 450

Managing IBM Cloud® connections .
Use IBM Transit Gateway to connect your Power Virtual Server to IBM Cloud® classic and Virtual Private Cloud (VPC) infrastructures outside
your account or region. For more information about integrating the on-premises network and Power Virtual Server, see Network architecture
diagrams.

Creating an SSH key
Use the following steps to create one or more root login SSH keys.
First, you need to create a keypair and load the public key to the SSH keys store in Power Virtual Server. For deployment of the virtual server
instance, specify one or more keys out of the keystore. These keys are added to the authorized key file of the root user, and allow you to
securely log in to the virtual server instance by using your private key.
For more information, see Generating an SSH key.
Tip: The recommendation is to use key type Ed25519 because this key type is fast and secure.
1. Log in to SSH keys in Power Virtual Server
2. Select the workspace that you created.
3. Click Create SSH key .
4. Enter a Key name, then copy and paste the Public key that you generated before into the field.
5. Click Add SSH key.

Selecting a boot image
You have different options for obtaining operating system images for your cluster. Use the following steps to select a boot image.
You have access to several types of stock images that are already prepared for Power Virtual Server. Images are sorted into "IBM Provided
Subscription" and "Client Provided Subscription" sections on the Power Virtual Server provisioning page. For more information, see Full Linux®
subscription for Power Virtual Server instances.
If you want to import a custom Linux image, you need to first upload the image to IBM Cloud® Object Storage in OVA format.
Deploying a custom image within a Power Virtual Server workspace , which outlines the necessary steps for
Creating an IBM Cloud® Storage bucket
Generating secret and access keys
Before you begin, make sure that the OVA image is loaded in the storage bucket.
1. Log in to Boot images in Power Virtual Server .
2. Select the workspace that you created.
3. Click Import image.
4. Enter a Custom image name for the image name in your catalog.
5. Select Storage type either as Tier 1 or Tier 3. A virtual server instance can use volumes from one storage type only, and the custom
image need to be prepared for this storage type.
6. Select the Region for your deployment.
7. Enter the file name of the image as Image file name.
8. Enter the Bucket name of your Cloud Object Storage.
9. Enter Cloud Object Storage access key and Cloud Object Storage secret key .
10. Click Import image.

Creating a Service ID and API key in IBM Cloud®
A Service ID in IBM Cloud® identifies a service or an application in a similar way as a user ID identifies a user in IBM Cloud®. The service ID is
used by the cluster fencing agent to monitor the status of and control the virtual server instances in the cluster.
1. Log in to IBM Cloud®.
2. In the toolbar, click Manage to expand the drop-down menu, then select Access (IAM).
3. Click Service IDs > Create.
4. Enter Name and Description for the service ID.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 451

5. Click Create.
6. In the Access policies section, click Assign access.
7. As Service, click Workspace for Power Virtual Server > Next.
8. Click Specific Resources > Attribute Type Service Instance > name of the workspace that you created earlier > Next.
9. In Service access, select Manager > Add > Assign.
10. Click API Keys to toggle the screen to manage API keys for the service ID.
11. Click Create.
12. Enter the Name and Description for the key.
13. Click Create.
Copy the API key or download it to save it.
Important: The key is available for 300 seconds. After the 300 seconds, you won't be able to display or retrieve the key.

Creating virtual server instances for the cluster
Complete the following steps to create the virtual server instances that you want to use as high availability cluster nodes.
1. Log in to Workspaces - Power Virtual Server .
2. Select the Workspace that you created.
3. Click View virtual server instances > Create Instance. You need to step through the subsections General, Boot Image, Profile, Storage
Volume, Network Interfaces.
4. In subsection General, enter the Instance name and click + to increase the Number of instances to 2.
5. Select Numerical postfix as Instance naming convention, and select Different server as Placement group colocation policy. A
placement group with colocation policy Different server is automatically created as part of the virtual server instances deployment.
6. Select the SSH key that you created and click Continue.
7. In Boot image, select the Operating system according to your subscription model.
Use one of the Linux selections either from the IBM-provided subscription or through your Client-provided subscription.
Keep Auto-select pool for selecting the Storage Pool.
Click Continue.
8. In Profile, select Machine type, Core type, and the virtual server instance profile according to your workload requirements. Click
Continue.
9. In Storage volumes, click Continue.
Important: When you deploy multiple instances, the storage volumes that are created are shared by both instances. Certain high
availability cluster scenarios require shared volumes. In these cases, create the shared volumes later. For SAP HANA, see Storage
configuration for SAP HANA. Those volumes must be created later for the individual server instances after their provisioning
completes.
10. In subsection Network Interfaces, it is recommended that the cluster nodes are not accessible directly from a public network, so keep
the configuration for Public networks as Off.
11. Click Attach existing to attach the virtual server instances to a subnet.
12. In the Attach an existing network screen, select one of the Existing networks. You can either select Automatically assign IP address from
IP range, or Manually specify an IP address from IP range to specify an available IP address.
13. Click Attach.
14. Click Finish, check the I agree to the Terms and Conditions flag, and click Create.
The deployment of the virtual server instances starts.

Preparing remote login for virtual server instances
Set up SSH forwarding on the bastion host, and prepare or test SSH remote login from your workstation by using your private SSH key.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 452

Preparing operating system for SAP installation
Important: If you deployed a virtual server instance from a stock image, you need to perform extra configuration tasks before you can
install SAP software. For more information, see Configuring a Power Virtual Server instance .

Implementing a RHEL HA Add-On cluster on IBM Power Virtual Server
Use the following information and procedures to implement a Red Hat Enterprise Linux (RHEL) High Availability (HA) cluster. The cluster uses
instances in IBM® Power® Virtual Server as cluster nodes.
The information describes how to transform the individual virtual server instances into a cluster.
These procedures include installing the high availability packages and agents on each cluster node and configuring the fencing devices.
Note: This information is intended for architects and specialists who are planning a high availability deployment of SAP applications on
Power Virtual Server. It is not intended to replace existing SAP or Red Hat documentation.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Creating virtual server instances for the cluster
Use the instructions in Creating instances for a high availability cluster on IBM® Power® Virtual Server to create the virtual server instances that
you want to use as cluster nodes.

Gathering parameters for the cluster configuration
Parameters that are required for fencing agent configuration include the Cloud Resource Name (CRN) of the Power Virtual Server workspace
and the instance IDs of the virtual server instances. Some extra parameters need to be derived from the CRN. The fencing agent also uses the
API Key of the Service ID to authenticate with the Power Virtual Server API.
The uppercase variables in the following section indicate that these parameters need to be set as environment variables on the virtual server
instances to simplify the setup of the cluster.
1. Log in to Workspaces - Power Virtual Server .
2. The list contains the name and CRN of the workspaces.
Locate your Workspace. Click Copy next to the CRN and paste it into a temporary document.
A CRN has multiple sections that are divided by a colon. The base format of a CRN is:
crn:version:cname:ctype:service-name:location:scope:service-instance:resource-type:resource

service-name
The fifth field of the CRN of the workspace is always power-iaas, the service name.
location
The sixth field is the location that needs to be mapped to the region.
scope
The seventh field is the Tenant ID.
service_instance
The eighth field is the Cloud Instance ID or GUID.

3. Set IBMCLOUD_CRN to the full CRN and GUID to the content of the service_instance field.
4. Set the CLOUD_REGION to the prefix that represents the geographic area of your service instance to target the correct

Power Cloud API

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 453

endpoint.

CLOUD_REGION when you use a public network
For a public network, map the location to its respective geographic area ( us-east, us-south, eu-de, lon, tor, syd, or tok ).
CLOUD_REGION when you use a private network
For a private network, map the location to its respective geographic area ( us-east, us-south, eu-de, eu-gb, ca-tor, au-syd, jp-tok, jposa, br-sao, or ca-mon).

5. On the tile for the workspace, click View Instances.
6. In the list of the virtual server instances, click each of the cluster nodes and take a note of each ID.
7. Set these IDs as POWERVSI_01 and POWERVSI_02.

Preparing the nodes for RHEL HA Add-On installation
The following section describes basic preparation steps on the cluster nodes. Make sure that you follow the steps on both nodes.
Log in as the root user to each of the cluster nodes.

Populating entries for each node in the hosts file
On both nodes, use the following information to populate entries.
Add the IP addresses and hostnames of both nodes to the hosts file

/etc/hosts .

For more information, see Setting up /etc/hosts files on RHEL cluster nodes .

Preparing environment variables
To simplify the setup process, prepare the following environment variables for the root user on both nodes.
On both nodes, create a file with the following environment variables and update to your environment.
export CLUSTERNAME=SAP_CLUSTER

# Cluster Name

export APIKEY=<APIKEY>

# API Key of the ServiceID

export IBMCLOUD_CRN=<IBMCLOUD_CRN>

# CRN of workspace

export GUID=<GUID>

# GUID of workspace

export CLOUD_REGION=<CLOUD_REGION>

# Region of workspace

export PROXY_IP=<IP_ADDRESS>

# IP address of proxy server

export NODE1=<HOSTNAME_01>

# <Hostname of virtual server instance 1

export NODE2=<HOSTNAME_02>

# <Hostname of virtual server instance 2

export POWERVSI_01=<POWERVSI_01>

# ID virtual server instance 1

export POWERVSI_02=<POWERVSI_02>

# ID virtual server instance 2

Installing and configuring a RHEL HA Add-On cluster
Use the following steps to set up a two-node cluster for an IBM Power Virtual Server.
The instructions are based on the Red Hat product documentation and articles that are listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.
Tip: You need to perform some steps on both nodes and some steps on either NODE1 or on NODE2.

Installing RHEL HA Add-On software
Install the required software packages.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 454

Checking the RHEL HA repository
Check that the RHEL High Availability repository is enabled.
On both nodes, use the following command.
$ dnf repolist

Use the following command to enable the HA repository if it is missing.
$ subscription-manager repos \
--enable="rhel-8-for-ppc64le-highavailability-e4s-rpms"

For RHEL 9, use this command.
$ subscription-manager repos \
--enable="rhel-9-for-ppc64le-highavailability-e4s-rpms"

$ dnf clean all

$ dnf repolist

Installing the RHEL HA Add-On software packages
Install the required software packages.
On both nodes, run the following command.
$ dnf install -y pcs pacemaker fence-agents-ibm-powervs

Make sure that you install the minimal version of the fence-agents-ibm-powervs package dependent on your Red Hat Enterprise Linux release:

RHEL 8
fence-agents-ibm-powervs-4.2.1-121.el8
RHEL 9
fence-agents-ibm-powervs-4.10.0-55.el9

Configuring a RHEL HA Add-On cluster
Configuring firewall services
Add the high availability service to the RHEL firewall if firewalld.service is installed and enabled.
On both nodes, run the following commands.
$ firewall-cmd --permanent --add-service=high-availability

$ firewall-cmd --reload

Starting the PCS daemon
Start the PCS daemon that is used for controlling and configuring RHEL HA Add-On clusters through PCS.
On both nodes, run the following commands.
$ systemctl enable --now pcsd.service

Make sure that the PCS service is running:
$ systemctl status pcsd.service

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 455

Setting a password for hacluster user ID
Set the password for the hacluster user ID.
On both nodes, run the following command.
$ passwd hacluster

Authenticating the cluster nodes
Use the following command to authenticate user hacluster to the PCS daemon on the nodes in the cluster. The command prompts you for the
password that you set in the previous step.
On NODE1, run the following command.
$ pcs host auth ${NODE1} ${NODE2} -u hacluster

Tip: If you get an error message similar to Error: Unable to communicate with {NODE2} , check whether you have any proxy
variables set in your environment ( env | grep -i proxy ). You need to unset these variables or define a no_proxy variable to exclude
the cluster nodes: export no_proxy=${NODE1},${NODE2},$no_proxy

Configuring and starting the cluster nodes
Configure the cluster configuration file and synchronize the configuration to the specified nodes.
The --start option also starts the cluster service on the nodes.
On NODE1, run the following command.
$ pcs cluster setup ${CLUSTERNAME} --start ${NODE1} ${NODE2}

$ pcs status

Creating the fencing device
STONITH is an acronym for "Shoot The Other Node In The Head" and protects your data from corruption in a split-brain situation.
Important: You must enable STONITH (fencing) for a RHEL HA Add-On production cluster.
Fence agent fence_ibm_powervs is the only supported agent for a STONITH device on Power Virtual Server clusters.
The fence agent connects to the Power Cloud API by using parameters APIKEY, IBMCLOUD_CRN, CLOUD_REGION, GUID, and the instance IDs
POWERVSI_01 and POWERVSI_02. You can test the agent invocation by using the parameters that you gathered in the

Gathering required

parameters for the cluster configuration section.

Identifying the virtual server instances for fencing
Use the list option of fence_ibm_powervs to identify and or verify the instance IDs of the two cluster nodes:
On any node, run the following command.
$ fence_ibm_powervs \
--token=${APIKEY} \
--crn=${IBMCLOUD_CRN} \
--instance=${GUID} \
--region=${CLOUD_REGION} \
--api-type=public \
-o list

If the virtual server instances have access to only a private network, you must use the --api-type=private option, which also requires an extra -proxy option.
Example:
$ fence_ibm_powervs \

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 456

--token=${APIKEY} \
--crn=${IBMCLOUD_CRN} \
--instance=${GUID} \
--region=${CLOUD_REGION} \
--api-type=private \
--proxy=http://${PROXY_IP}:3128 \
-o list

Continue by using --api-type=private in the following examples.

Checking the status of both virtual server instances
On both nodes, run the following commands.
$ time fence_ibm_powervs \
--token=${APIKEY} \
--crn=${IBMCLOUD_CRN} \
--instance=${GUID} \
--region=${CLOUD_REGION} \
--plug=${POWERVSI_01} \
--api-type=private \
--proxy=http://${PROXY_IP}:3128 \
-o status

$ time fence_ibm_powervs \
--token=${APIKEY} \
--crn=${IBMCLOUD_CRN} \
--instance=${GUID} \
--region=${CLOUD_REGION} \
--plug=${POWERVSI_02} \
--api-type=private \
--proxy=http://${PROXY_IP}:3128 \
-o status

The status action of the fence agent against a virtual server instance {pvm_instance_id} displays its power status.
On both nodes, the two commands must report Status: ON .
The output of the time command might be useful later when you choose timeouts for the STONITH device.
You can add the -v flag for verbose output, which shows more information about connecting to the Power Cloud API and querying virtual
server power status.

Creating a stonith device
The following command shows the device-specific options for the fence_ibm_powervs fencing agent.
$ pcs stonith describe fence_ibm_powervs

Create the stonith device for both virtual server instances.
On NODE1, run the following command.
$ pcs stonith create res_fence_ibm_powervs fence_ibm_powervs \
token=${APIKEY} \
crn=${IBMCLOUD_CRN} \
instance=${GUID} \
region=${CLOUD_REGION} \
api_type=private \
proxy=http://${PROXY_IP}:3128 \
pcmk_host_map="${NODE1}:${POWERVSI_01};${NODE2}:${POWERVSI_02}" \
pcmk_reboot_timeout=600 \
pcmk_monitor_timeout=600 \
pcmk_status_timeout=60

Important: Although the fence_ibm_powervs agent uses api-type as an option when started from the command line, the stonith
resource needs to be created by using api_type .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 457

Verify the configuration with the following commands.
$ pcs config

$ pcs status

$ pcs stonith config

$ pcs stonith status

Setting the stonith-action cluster property
To speed up failover times in an IBM Power Virtual Server cluster, you can change the cluster property stonith-action to off. When the cluster
performs a fencing action, it triggers a power off operation instead of a reboot for the fenced instance.
After this change, you always need to log in to the IBM Cloud Console, and manually start an instance that was fenced by the cluster.
$ pcs property set stonith-action=off

Verify the change.
$ pcs config

Testing fencing operations
To test the STONITH configuration, you need to manually fence the nodes.
Note: When fencing is manually triggered through pcs stonith fence , the stonith-action cluster attribute is not used and the
node is restarted.
On NODE1, run the following commands.
$ pcs stonith fence ${NODE2}

$ pcs status

As a result, NODE2 restarts.
After NODE2 is running again, start the cluster on NODE2 and try to fence NODE1.
On NODE2, run the following commands.
$ pcs cluster start

$ pcs status

$ pcs stonith status

$ pcs stonith fence ${NODE1}

NODE1 restarts.
After the node is running, start the cluster on NODE1 again.
On NODE1, run the following command.
$ pcs cluster start

$ pcs status

$ pcs stonith status

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 458

Configuring SAP HANA Scale-Up System Replication in a RHEL HA Add-On cluster
The following information describes the configuration of a Red Hat Enterprise Linux (RHEL) HA Add-On cluster for managing SAP HANA ScaleUp System Replication. The cluster uses virtual server instances in IBM® Power® Virtual Server as cluster nodes.
The instructions describe how to automate SAP HANA Scale-Up System Replication for a single database deployment in a performanceoptimized scenario on a RHEL HA Add-on cluster.
Note: This information is intended for architects and specialists that are planning a high-availability deployment of SAP HANA on Power
Virtual Server.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Prerequisites
A Red Hat High Availability cluster is deployed on two virtual server instances in Power Virtual Server.
Install and set up the RHEL HA Add-On cluster according to Implementing a RHEL HA Add-On cluster on Power Virtual Server .
Configure and verify fencing as described in the preceding document.
The virtual server instances need to fulfill hardware and resource requirements for the SAP HANA systems in scope. Follow the
guidelines in the Planning the Deployment document.
The hostnames of the virtual server instances must meet the SAP HANA requirement.
SAP HANA is installed on both virtual server instances and SAP HANA System Replication is configured. The installation of SAP HANA and
setup of HANA System Replication is not specific to the Power Virtual Server environment, and you need to follow the standard
procedures.
A valid RHEL for SAP Applications or RHEL for SAP Solutions subscription is required to enable the repositories that you need to install
SAP HANA and the resource agents for HA configurations.

Configuring SAP HANA System Replication in a RHEL HA Add-On cluster on IBM Power Virtual
Server
The instructions are based on the Red Hat product documentation and articles that are listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Preparing environment variables
To simplify the setup, prepare the following environment variables for root on both nodes. These environment variables are used in
subsequent commands in the remainder of the examples.
On both nodes, run the following commands.
export SID=<SID>

# SAP HANA System ID (uppercase)

export sid=<sid>

# SAP HANA System ID (lowercase)

export INSTNO=<INSTNO>

# SAP HANA Instance Number

export DC1=<Site1>

# HANA System Replication Site Name 1

export DC2=<Site2>

# HANA System Replication Site Name 2

export NODE1=<Hostname 1>

# Hostname of virtual server instance 1

export NODE2=<Hostname 2>

# Hostname of virtual server instance 2

Installing SAP HANA resource agents
Run the following command to install the RHEL HA Add-On resource agents for SAP HANA System Replication.
$ dnf install -y resource-agents-sap-hana

Starting the SAP HANA system
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 459

Start SAP HANA and verify that HANA System Replication is active. For more information, see 2.4. Checking SAP HANA System Replication
state.
On both nodes, run the following commands.
$ sudo -i -u ${sid}adm -- HDB start

$ sudo -i -u ${sid}adm -- <<EOT
hdbnsutil -sr_state
HDBSettings.sh systemReplicationStatus.py
EOT

Enabling the SAP HANA srConnectionChanged() hook
Recent versions of SAP HANA provide hooks so SAP HANA can send out notifications for certain events. For more information, see
Implementing a HA/DR Provider.
The srConnectionChanged() hook improves the ability of the cluster to detect a status change of HANA System Replication that requires an
action from the cluster. The goal is to prevent data loss and corruption by preventing accidental takeovers.

Activating the srConnectionChanged() hook on all SAP HANA instances
1. Stop the cluster.
On NODE1, run the following command.
$ pcs cluster stop --all

2. Install the hook script that is provided by the resource-agents-sap-hana package in the /hana/shared/myHooks directory for each
HANA instance, and set the required ownership.
On both nodes, run the following commands.
$ mkdir -p /hana/shared/myHooks

$ cp /usr/share/SAPHanaSR/srHook/SAPHanaSR.py /hana/shared/myHooks

$ chown -R ${sid}adm:sapsys /hana/shared/myHooks

3. Update the global.ini file on each HANA node to enable the hook script.
On both nodes, run the following command.
$ sudo -i -u ${sid}adm -- <<EOT
python \$DIR_INSTANCE/exe/python_support/setParameter.py \
-set SYSTEM/global.ini/ha_dr_provider_SAPHanaSR/provider=SAPHanaSR \
-set SYSTEM/global.ini/ha_dr_provider_SAPHanaSR/path=/hana/shared/myHooks \
-set SYSTEM/global.ini/ha_dr_provider_SAPHanaSR/execution_order=1 \
-set SYSTEM/global.ini/trace/ha_dr_saphanasr=info
EOT

4. Verify the changed file.
On both nodes, run the following command.
$ cat /hana/shared/${SID}/global/hdb/custom/config/global.ini

5. Create sudo settings for SAP HANA OS user.
You need the following sudo settings to allow the ${sid}adm user script can update the node attributes when the
srConnectionChanged() hook runs.
On both nodes, run the following commands.
Create a file with the required sudo aliases and user specifications.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 460

$ cat >> /etc/sudoers.d/20-saphana << EOT
Cmnd_Alias DC1_SOK = /usr/sbin/crm_attribute -n hana_${sid}_site_srHook_${DC1} -v SOK -t crm_config -s SAPHanaSR
Cmnd_Alias DC1_SFAIL = /usr/sbin/crm_attribute -n hana_${sid}_site_srHook_${DC1} -v SFAIL -t crm_config -s
SAPHanaSR
Cmnd_Alias DC2_SOK = /usr/sbin/crm_attribute -n hana_${sid}_site_srHook_${DC2} -v SOK -t crm_config -s SAPHanaSR
Cmnd_Alias DC2_SFAIL = /usr/sbin/crm_attribute -n hana_${sid}_site_srHook_${DC2} -v SFAIL -t crm_config -s
SAPHanaSR
${sid}adm ALL=(ALL) NOPASSWD: DC1_SOK, DC1_SFAIL, DC2_SOK, DC2_SFAIL
Defaults!DC1_SOK, DC1_SFAIL, DC2_SOK, DC2_SFAIL !requiretty
EOT

Adjust the permissions and check for syntax errors.
$ chown root:root /etc/sudoers.d/20-saphana

$ chmod 0440 /etc/sudoers.d/20-saphana

$ cat /etc/sudoers.d/20-saphana

$ visudo -c

Note: Any problems that are reported by the visudo -c command must be corrected.
1. Verify that the hook functions.
Restart both HANA instances and verify that the hook script works as expected.
Perform an action to trigger the hook, such as stopping a HANA instance.
Check whether the hook logged anything in the trace files.
On both nodes, run the following commands.
Stop the HANA instance.
$ sudo -i -u ${sid}adm -- HDB stop

Start the HANA instance.
$ sudo -i -u ${sid}adm -- HDB start

Check that the hook has logged some messages to the trace files.
$ sudo -i -u ${sid}adm -- sh -c 'grep "ha_dr_SAPHanaSR.*crm_attribute"
$DIR_INSTANCE/$VTHOSTNAME/trace/nameserver_* | cut -d" " -f2,3,5,17'

After you verify that the hooks function, you can restart the HA cluster.
2. Start cluster.
On NODE1, run the following commands.
Start the cluster.
$ pcs cluster start --all

Check the status of the cluster.
$ pcs status --full

Configuring general cluster properties
To avoid resource failover during initial testing and post-production, set the following default values for the resource-stickiness and migrationthreshold parameters.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 461

Keep in mind that defaults don't apply to resources that override them with their own defined values.
On NODE1, run the following commands.
$ pcs resource defaults update resource-stickiness=1000

$ pcs resource defaults update migration-threshold=5000

Creating a cloned SAPHanaTopology resource
The SAPHanaTopology resource gathers status and configuration of SAP HANA System Replication on each node. It also starts and monitors
the local SAP HostAgent, which is required for starting, stopping, and monitoring SAP HANA instances.
On NODE1, run the following commands.
Create the SAPHanaTopology resource.
$ pcs resource create SAPHanaTopology_${SID}_${INSTNO} SAPHanaTopology \
SID=${SID} InstanceNumber=${INSTNO} \
op start timeout=600 \
op stop timeout=300 \
op monitor interval=10 timeout=600 \
clone clone-max=2 clone-node-max=1 interleave=true

Check the configuration and the cluster status by running the following commands.
$ pcs resource config SAPHanaTopology_${SID}_${INSTNO}

$ pcs resource config SAPHanaTopology_${SID}_${INSTNO}-clone

$ pcs status --full

Creating a promotable SAPHana resource
The SAPHana resource manages two SAP HANA instances that are configured as HANA System Replication nodes.
On NODE1, create the SAPHana resource, by running the following command.
$ pcs resource create SAPHana_${SID}_${INSTNO} SAPHana \
SID=${SID} InstanceNumber=${INSTNO} \
PREFER_SITE_TAKEOVER=true \
DUPLICATE_PRIMARY_TIMEOUT=7200 \
AUTOMATED_REGISTER=false \
op start timeout=3600 \
op stop timeout=3600 \
op monitor interval=61 role="Unpromoted" timeout=700 \
op monitor interval=59 role="Promoted" timeout=700 \
op promote timeout=3600 \
op demote timeout=3600 \
promotable notify=true clone-max=2 clone-node-max=1 interleave=true

Check the configuration and the cluster status.
$ pcs resource config SAPHana_${SID}_${INSTNO}

$ pcs status --full

Creating a virtual IP address resource
Review the information in Reserving virtual IP addresses and reserve a virtual IP address for the SAP HANA System Replication cluster.
Use the reserved IP address to create a virtual IP address resource. This virtual IP address is used to reach the System Replication primary
instance.
On NODE1, assign the reserved IP address to a VIP environment variable and create the virtual IP address cluster resource by running the
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 462

following commands.
$ export VIP=<reserved IP address>

$ echo $VIP

$ pcs resource create vip_${SID}_${INSTNO} IPaddr2 ip=$VIP

Check the configured virtual IP address and the cluster status.
$ pcs resource config vip_${SID}_${INSTNO}

$ pcs status --full

Creating constraints
Make sure that SAPHanaTopology resources are started before you start the SAPHana resources.
The virtual IP address must be present on the node where the primary resource of "SAPHana" is running.
1. Create constraint to start "SAPHanaTopology" before "SAPHana". This constraint mandates the start order of these resources.
On NODE1, use the following command to create the SAPHanaTopology order constraint:
$ pcs constraint order SAPHanaTopology_${SID}_${INSTNO}-clone \
then SAPHana_${SID}_${INSTNO}-clone symmetrical=false

Check the configuration.
$ pcs constraint

2. Create constraint to colocate the virtual IP address with primary. This constraint colocates the virtual IP address resource with the
SAPHana resource that was promoted as primary.
On NODE1, run the following command to create the virtual IP address colocation constraint.
$ pcs constraint colocation add vip_${SID}_${INSTNO} \
with Promoted SAPHana_${SID}_${INSTNO}-clone 2000

Check the configuration and the cluster status.
$ pcs constraint

Sample output:
# pcs constraint
Location Constraints:
Ordering Constraints:
start SAPHanaTopology_HDB_00-clone then start SAPHana_HDB_00-clone (kind:Mandatory) (non-symmetrical)
Colocation Constraints:
vip_HDB_00 with SAPHana_HDB_00-clone (score:2000) (rsc-role:Started) (with-rsc-role:Promoted)
Ticket Constraints:

Verify the cluster status.
$ pcs status --full

On the promoted cluster node, verify that the cluster service IP address is active.
$ ip addr show

Enabling automated registration of secondary instance

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 463

You need to set the parameter AUTOMATED_REGISTER according to your operational requirements. If you want to keep the ability to revert to
the state of the previous primary SAP HANA instance, then AUTOMATED_REGISTER=false avoids an automatic registration of the previous
primary as a new secondary.
If you experience an issue with the data after a takeover that was triggered by the cluster, you can manually revert if

AUTOMATED_REGISTER is

set to false .
If AUTOMATED_REGISTER is set to true , the previous primary SAP HANA instance automatically registers as secondary, and cannot be
activated on its previous history. The advantage of AUTOMATED_REGISTER=true is that high-availability capability is automatically reestablished
after the failed node reappears in the cluster.
For now, it is recommended to keep AUTOMATED_REGISTER on default value false until the cluster is fully tested and that you verify that the
failover scenarios work as expected.
Tip: The pcs resource update command is used to modify resource attributes and pcs resource update
SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=true sets the attribute to true .

Testing SAP HANA System Replication cluster
It is vital to thoroughly test the cluster configuration to make sure that the cluster is working correctly. The following information provides a few
sample failover test scenarios, but is not a complete list of test scenarios.
For example, the description of each test case includes the following information.
Component that is being tested
Description of the test
Prerequisites and the cluster state before you start the failover test
Test procedure
Expected behavior and results
Recovery procedure

Test1 - Testing failure of the primary database instance
Use the following information to test the failure of the primary database instance.

Test1 - Description
Simulate a crash of the primary HANA database instance that is running on NODE1.

Test1 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster that is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} that is configured with AUTOMATED_REGISTER=false .
Check SAP HANA System Replication status:
Primary SAP HANA database is running on NODE1
Secondary SAP HANA database is running on NODE2
HANA System Replication is activated and in sync

Test1 - Test procedure
Crash SAP HANA primary by sending a SIGKILL signal as user ${sid}adm .
On NODE1, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test1 - Expected behavior
SAP HANA primary instance on NODE1 crashes.
The cluster detects the stopped primary HANA database and marks the resource as failed .
The cluster promotes the secondary HANA database on NODE2 to take over as new primary.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 464

The cluster releases the virtual IP address on NODE1, and acquires it on the new primary on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.

Test1 - Recovery procedure
As cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false , the cluster doesn't restart the failed HANA
database, and doesn't register it against the new primary. Which means that the status on the new primary (NODE2) also shows the secondary
in status 'CONNECTION TIMEOUT'.
To reregister the previous primary as new secondary use the following commands.
On NODE1, run the following command.
$ sudo -i -u ${sid}adm -- <<EOT
hdbnsutil -sr_register \
--name=${DC1} \
--remoteHost=${NODE2} \
--remoteInstance=00 \
--replicationMode=sync \
--operationMode=logreplay \
--online
EOT

Verify the system replication status:
$ sudo -i -u ${sid}adm -- <<EOT
hdbnsutil -sr_state
HDBSettings.sh systemReplicationStatus.py
EOT

After the manual register and resource refreshes, the new secondary instance restarts and shows up in status synced ( SOK ).
On NODE1, run the following command.
$ pcs resource refresh SAPHana_${SID}_${INSTNO}

$ pcs status --full

Test2 - Testing failure of the node that is running the primary database
Use the following information to test the failure of the node that is running the primary database.

Test2 - Description
Simulate a crash of the node that is running the primary HANA database.

Test2 - Preparation
Make sure that Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
On NODE1, run the following command.
$ pcs resource update SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=true

$ pcs resource config SAPHana_${SID}_${INSTNO}

Test2 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both nodes active.
Cluster is started on NODE1 and NODE2.
Check SAP HANA System Replication status.
Primary SAP HANA database is running on NODE2
Secondary SAP HANA database is running on NODE1
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 465

HANA System Replication is activated and in sync

Test2 - Test procedure
Crash primary on NODE2 by sending a shutoff system request.
On NODE2, run the following command.
$ sync; echo o > /proc/sysrq-trigger

Test2 - Expected behavior
NODE2 shuts down.
The cluster detects the failed node and sets its state to OFFLINE .
The cluster promotes the secondary HANA database on NODE1 to take over as new primary.
The cluster acquires the virtual IP address on NODE1 on the new primary.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.

Test2 - Recovery procedure
Log in to the IBM Cloud® Console and start the NODE2 instance. Wait until NODE2 is available again, then restart the cluster framework.
On NODE2, run the following command.
$ pcs cluster start

$ pcs status --full

As cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true , SAP HANA restarts when NODE2 rejoins the
cluster and the former primary reregisters as a secondary.

Test3 - Testing the failure of the secondary database instance
Use the following information to test the failure of the secondary database instance.

Test3 - Description
Simulate a crash of the secondary HANA database.

Test3 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA System Replication status:
Primary SAP HANA database is running on NODE1
Secondary SAP HANA database is running on NODE2
HANA System Replication is activated and in sync

Test3 - Test Procedure
Crash SAP HANA secondary by sending a SIGKILL signal as user ${sid}adm .
On NODE2, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test3 - Expected behavior
SAP HANA secondary on NODE2 crashes.
The cluster detects the stopped secondary HANA database and marks the resource as failed .
The cluster restarts the secondary HANA database.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 466

The cluster detects that the system replication is in sync again.

Test3 - Recovery procedure
Wait until the secondary HANA instance starts and syncs again ( SOK ), then cleanup the failed resource actions as shown in pcs status .
On NODE2, run the following command.
$ pcs resource refresh SAPHana_${SID}_${INSTNO}

$ pcs status --full

Test4 - Testing the manual move of a SAPHana resource to another node
Use the following information to test the manual move of a SAPHana resource to another node.

Test4 - Description
Use cluster commands to move the primary instance to the other node for maintenance purposes.

Test4 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA System Replication status:
Primary SAP HANA database is running on NODE1
Secondary SAP HANA database is running on NODE2
HANA System Replication is activated and in sync

Test4 - Test procedure
Move SAP HANA primary to other node by using the pcs resource move command.
On NODE1, run the following command.
$ pcs resource move SAPHana_${SID}_${INSTNO}-clone

Test4 - Expected behavior
The cluster creates location constraints to move the resource.
The cluster triggers a takeover to the secondary HANA database.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.

Test4 - Recovery procedure
The automatically created location constraints must be removed to allow automatic failover in the future.
Wait until the primary HANA instance is active and remove the constraints.
The cluster registers and starts the HANA database as new secondary instance.
On NODE1, run the following command.
$ pcs constraint

$ pcs resource clear SAPHana_${SID}_${INSTNO}-clone

$ pcs constraint

$ pcs status --full

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 467

Configuring SAP HANA Cost-Optimized Scale-Up System Replication in a RHEL HA
Add-On cluster
The following information describes the configuration of a Red Hat Enterprise Linux 8 (RHEL) HA Add-On cluster for managing SAP HANA&reg
Cost-Optimized Scale-Up System Replication. The cluster uses virtual server instances in IBM® Power® Virtual Server as cluster nodes.
In a cost-optimized configuration, a nonproduction SAP HANA system runs on the secondary node during normal operation. The hardware
resources on the secondary node are shared between the nonproduction system and the SAP HANA System Replication secondary. The
memory usage of the production System Replication secondary is reduced by disabling the preload of column table data.
If a failover occurs, the nonproduction instance is stopped automatically before the node takes over the production workload. The takeover
time is longer compared to a performance optimized configuration.
Note: This information is intended for architects and specialists that are planning a high-availability deployment of SAP HANA on Power
Virtual Server.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Prerequisites
A Red Hat High Availability cluster is deployed on two virtual server instances in Power Virtual Server.
Install and set up the RHEL HA Add-On cluster according to Implementing a RHEL HA Add-On cluster on Power Virtual Server .
Configure and verify fencing as described in the preceding document.
The virtual server instances need to fulfill hardware and resource requirements for the SAP HANA systems in scope. Follow the
guidelines in the Planning the Deployment document.
The hostnames of the virtual server instances must meet the SAP HANA requirement.
SAP HANA is installed on both virtual server instances and SAP HANA System Replication is configured. The installation of SAP HANA and
setup of HANA System Replication is not specific to the Power Virtual Server environment, and you need to follow the standard
procedures.
A nonproduction SAP HANA System is installed on NODE2 with a different

SID and Instance Number than the production system. The

nonproduction system needs its own dedicated storage volumes and file systems. Restrict the Global Memory Allocation Limit for the
nonproduction system to ensure sufficient memory for the HANA system replication workload on the secondary. The limit is set with the
global_allocation_limit parameter in the [memorymanager] section of the global.ini configuration file.

Optional, a virtual IP address is reserved for the nonproduction system as described in Reserving virtual IP addresses.

Setting up the cost optimized scenario
The cost optimized scenario is an extension of the setup that is described in Configure SAP HANA Scale-Up System Replication in a RHEL HA
Add-On cluster. Complete the setup for the production system System Replication cluster before you continue with the following steps.

Configuring the nonproduction SAP HANA Instance on NODE2
To simplify the setup, prepare the following environment variables for user ID root on NODE2. These environment variables are used in
subsequent commands in the remainder of the instructions.
On NODE2, create a file with the following environment variables. Then, adapt them according to the configuration of the nonproduction
system.
export SID_np=<SID>

# SAP HANA System ID of non-production system (uppercase)

export sid_np=<sid>

# SAP HANA System ID of non-production system (lowercase)

export INSTNO_np=<INSTNO>

# SAP HANA Instance Number of non-production system

export NODE1=<Hostname 1>

# Hostname of virtual server instance 1 (production primary)

export NODE2=<Hostname 2>

# Hostname of virtual server instance 2 (non-production, production secondary)

export vIP_np=<vIP>

# Optional: virtual IP address assigned to the non-production system

You must source this file before you use the sample commands in the remainder of this document.
For example, if you created a file that is called sap_non_prod.sh , run the following command on NODE2 to set the environment variables.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 468

$ source sap_non_prod.sh

Important: Every time that you start a new terminal session, you must run the previous

source command. As an alternative, you can

move add the environment variables file to the /etc/profile.d directory during the cluster configuration. In this example, the file is
sourced automatically each time you log in to the server.

Configuring the SAP HANA HA/DR provider hook
The SAP HANA nameserver provides a Python-based API that is called at important points during the HANA System Replication takeover
process. These API calls are used to run customer-specific operations ( Implementing a HA/DR Provider).
In the cost-optimized scenario, the SAP HANA HA/DR provider hook is used to automatically reconfigure the SAP HANA instance during the
takeover event.
The following section shows a sample set up of a hook script for a cost-optimized SAP HANA System Replication environment. When you
implement automation of the cost-optimized SAP HANA System Replication HA environment in the cluster, the takeover hook script must be
thoroughly tested. Run the tests manually. Shut down the nonproduction SAP HANA instance on the secondary node, perform a takeover, and
verify that the hook script correctly reconfigures the primary HANA DB.

Creating a database user in the SAP HANA production database
Use the following steps to create a database user in the SAP HANA production database.
1. Create a database user in the SystemDB of the SAP HANA production system, or provide credentials of an existing user. The hook script
uses this database user to connect to the production database and alter the configuration parameters.
Log in to the SystemDB of the primary instance by using the SAP HANA database interactive terminal hdbsql or SAP HANA Cockpit, and
create a new user.
For example, connect to the database by using hdbsql in a terminal session.
$ sudo -i -u ${sid}adm -- hdbsql -i ${INSTNO} -d SYSTEMDB -u SYSTEM

Create a user.
CREATE USER HA_HOOK PASSWORD <Password> no force_first_password_change;

Grant the required privileges to the user.
Grant privilege INIFILE ADMIN to allow for changes of profile parameters.
GRANT INIFILE ADMIN TO HA_HOOK;

Verify the HA_HOOK user.
$

sudo -i -u ${sid}adm -- hdbsql -d SYSTEMDB -u SYSTEM select \* from users where user_name = \'HA_HOOK\';

2. Add the user credentials to the secure user store hdbuserstore.
On both nodes, run the following command. Use the password that you set in the previous step.
$ sudo -i -u ${sid}adm -- hdbuserstore SET HA_HOOK_KEY localhost:3${INSTNO}13 HA_HOOK <Password>

Check the update to the hdbuserstore.
$ sudo -i -u ${sid}adm -- hdbuserstore list

On the primary instance, test the connection with the stored user key.
$ sudo -i -u ${sid}adm

-- hdbsql -U HA_HOOK_KEY select \* from m_inifiles;

Creating the hook script
Python sample files for creating hook scripts are delivered as part of the SAP HANA installation. The samples are located in directory
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 469

$DIR_INSTANCE/exe/python_support/hdb_ha_dr .

The target directory /hana/shared/myHooks was already created for hook SAPHanaSR.py . Create a HA/DR provider hook in
/hana/shared/myHooks . The following hook script is based on the

HADRdummy.py sample.

On NODE2, edit the file /hana/shared/myHooks/SAPHanaCostOptSR.py and add the following content.
"""
Sample for a HA/DR hook provider.
When using your own code in here, please copy this file to location on /hana/shared outside the HANA installation.
This file will be overwritten with each hdbupd call! To configure your own changed version of this file, please add
to your global.ini lines similar to this:
[ha_dr_provider_<className>]
provider = <className>
path = /hana/shared/haHook
execution_order = 1

For all hooks, 0 must be returned in case of success.
"""
from __future__ import absolute_import
from hdb_ha_dr.client import HADRBase, Helper
from hdbcli import dbapi
import os, time
class SAPHanaCostOptSR(HADRBase):
def __init__(self, *args, **kwargs):
# delegate construction to base class
super(SAPHanaCostOptSR, self).__init__(*args, **kwargs)
def about(self):
return {"provider_company" :

"SAP",

"provider_name" :

"SAPHanaCostOptSR", # provider name = class name

"provider_description" :

"Handle reconfiguration event for cost-optimized system replication",

"provider_version" :

"1.0"}

def postTakeover(self, rc, **kwargs):
"""Post takeover hook."""
# prepared SQL statements to remove memory allocation limit and pre-load of column tables
stmnt1 = "ALTER SYSTEM ALTER CONFIGURATION ('global.ini','SYSTEM') UNSET
('memorymanager','global_allocation_limit') WITH RECONFIGURE"
stmnt2 = "ALTER SYSTEM ALTER CONFIGURATION ('global.ini','SYSTEM') UNSET
('system_replication','preload_column_tables') WITH RECONFIGURE"
myPort = int('3' + os.environ.get('DIR_INSTANCE')[-2:] + '15')
myKey = self.config.get("userkey") if self.config.hasKey("userkey") else "HA_HOOK_KEY"
self.tracer.info("%s.postTakeover method called with rc=%s" % (self.__class__.__name__, rc))
self.tracer.info("%s.postTakeover method: userkey: %s, port: %s" % (self.__class__.__name__, myKey, myPort))
if rc in (0, 1):
# rc == 0: normal takeover succeeded
# rc == 1: waiting for force takeover
conn = dbapi.connect(userkey=myKey, address='localhost', port=myPort)
self.tracer.info("%s: Connect using userkey %s - %s" % (self.__class__.__name__, myKey,
conn.isconnected()))
cursor = conn.cursor()
rc1 = cursor.execute(stmnt1)
self.tracer.info("%s: (%s) - %s" % (self.__class__.__name__, stmnt1, rc1))
rc2 = cursor.execute(stmnt2)
self.tracer.info("%s: (%s) - %s" % (self.__class__.__name__, stmnt2, rc2))
return 0
elif rc == 2:
# rc == 2: error, something went wrong
return 0

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 470

Activating the cost optimized hook
Use the following steps to activate the cost optimized hook.
1. Stop the cluster.
On any cluster node, run the following command.
$ pcs cluster stop --all

2. Set the file ownership of the hook script.
On NODE2, run the following command.
$ chown -R ${sid}adm:sapsys /hana/shared/myHooks

3. Update the global.ini configuration file on NODE2 to enable the hook script.
On NODE2, run the following command to add the required parameters to the global.ini file.
$ sudo -i -u ${sid}adm -- <<EOT
python \$DIR_INSTANCE/exe/python_support/setParameter.py \
-set SYSTEM/global.ini/ha_dr_provider_SAPHanaCostOptSR/provider=SAPHanaCostOptSR \
-set SYSTEM/global.ini/ha_dr_provider_SAPHanaCostOptSR/path=/hana/shared/myHooks \
-set SYSTEM/global.ini/ha_dr_provider_SAPHanaCostOptSR/userkey=HA_HOOK_KEY \
-set SYSTEM/global.ini/ha_dr_provider_SAPHanaCostOptSR/execution_order=2 \
-set SYSTEM/global.ini/trace/ha_dr_saphanacostoptsr=info
EOT

4. Check the content of the global.ini file.
$ cat /hana/shared/${SID}/global/hdb/custom/config/global.ini

5. Verify that the hook functions.
Restart the HANA instance on NODE2 and verify that the hook script works as expected.
Trigger the hook with an SAP HANA takeover operation.
Check whether the hook logged anything in the trace files.
$ sudo -i -u ${sid}adm -- \
sh -c 'grep SAPHanaCostOptSR $DIR_INSTANCE/$VTHOSTNAME/trace/nameserver_*.trc'

After you verify that the hook functions, you can restart the HA cluster.
6. Start the HA cluster.
On any cluster node, run the following command.
$ pcs cluster start --all

Check the status of the cluster.
$ pcs status --full

Defining limits for SAP HANA resource usage on the secondary node
All SAP HANA systems that are running on NODE2 share the avaible memory of the node. Memory configuration of the secondary system SAP
HANA ${SID} must be limited to the amount required for system replication so that the nonproduction systems can use the remaining memory.
SAP documentation Secondary System Usage describes the different scenarios and provideds parameter recommendations.
The preload of column tables on the secondary system is disabled to restrict its memory consumption by setting the database configuration
parameter preload_column_tables = false . This parameter is found in the [system_replication] section of the instance configuration
file for SAP HANA production system on NODE2.
The global_allocation_limit is set in the [memorymanager] section to limit memory allocation for the SAP HANA production system and

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 471

the nonproduction system that is running on NODE2.
On NODE2, define an environment variable with the wanted memory limit for the secondary HANA production instance.
$ export GLOBAL_ALLOCATION_LIMIT=<memory_size_in_mb_for_hana_secondary>

Then, run the following command to update the global.ini configuration file.
$ sudo -i -u ${sid}adm -- <<EOT
python \$DIR_INSTANCE/exe/python_support/setParameter.py \
-set SYSTEM/global.ini/system_replication/preload_column_tables=false \
-set SYSTEM/global.ini/memorymanager/global_allocation_limit=$GLOBAL_ALLOCATION_LIMIT
EOT

Verify the configuration file.
$ cat /hana/shared/${SID}/global/hdb/custom/config/global.ini

You cannot use hdbsql and ALTER SYSTEM ALTER CONFIGURATION ... statements on the secondary, no SQL connect is possible in this
state. Activate the change by using the hdbnsutil –reconfig command.
$ sudo -i -u ${sid}adm -- hdbnsutil -reconfig

Update the global.ini configuration file of the nonproduction instance to allow for the memory resource usage of the secondary.
On NODE2, define an environment variable with the wanted memory limit for the nonproduction HANA instance.
$ export NON_PROD_GLOBAL_ALLOCATION_LIMIT=<memory_size_in_mb_for_non_prod_hana>

Then, run the following command to update the global.ini configuration file.
$ sudo -i -u ${sid_np}adm -- <<EOT
python \$DIR_INSTANCE/exe/python_support/setParameter.py \
-set SYSTEM/global.ini/memorymanager/global_allocation_limit=$NON_PROD_GLOBAL_ALLOCATION_LIMIT \
-reconfigure
EOT

Verify the configuration file.
$ cat /hana/shared/${SID_np}/global/hdb/custom/config/global.ini

Run the following command to check the current database memory limit.
$ sudo -i -u ${sid_np}adm -- hdbcons "mm globallimit" | grep limit

Configuring cluster resources for the nonproduction instance
Use the following information to configure cluster resources for the nonproduction instance.

Installing the SAPInstance resource agent
The resource-agents-sap package includes the SAPInstance cluster resource agent, which is used to manage the additional nonproduction
SAP HANA instance.
On NODE2, run the following command to install the resource agent.
$ dnf install -y resource-agents-sap

If needed, use subscription-manager to enable the SAP NetWeaver repository.
$ subscription-manager repos --enable="rhel-8-for-ppc64le-sap-netweaver-e4s-rpms"

Creating the cluster resource for managing the nonproduction instance
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 472

On NODE2, run the following command.
$ pcs resource create SAPHana_np_${SID_np}_HDB${INSTNO_np} SAPInstance \
InstanceName="${SID_np}_HDB${INSTNO_np}_${NODE2}" \
MONITOR_SERVICES="hdbindexserver|hdbnameserver" \
START_PROFILE="/usr/sap/${SID_np}/SYS/profile/${SID_np}_HDB${INSTNO_np}_${NODE2}" \
op start timeout=600 op stop timeout=600 op monitor interval=60 timeout=600 \
--group group_${sid_np}_non_prod

If you want to assign a virtual IP address to the nonproduction instance, add a IPaddr2 cluster resource.
$ pcs resource create vip_np IPaddr2 \
ip="${vIP_np}" \
--group group_${sid_np}_non_prod

Create a cluster constraint to prevent that the nonproduction system starts on NODE1.
$ pcs constraint location add loc-${sid_np}-avoid-${NODE1} \
group_${sid_np}_non_prod ${NODE1} -INFINITY resource-discovery=never

When the production system assumes the PRIMARY role on NODE2 if a takeover occurs, the nonproduction system stops and its memory
resources are released. The following cluster constraints make sure that the primary production instance and the nonproduction instance
never run together on one node, and that the nonproduction instance stops before the production instance is promoted.
$ pcs constraint colocation add group_${sid_np}_non_prod with master SAPHana_${SID}_${INSTNO}-clone score=-INFINITY

$ pcs constraint order stop group_${sid_np}_non_prod then promote SAPHana_${SID}_${INSTNO}-clone

The cluster configuration is complete.
Run the following command to check the status of the defined cluster resources.
$ pcs status --full

Sample output:
# pcs status --full
Cluster name: SAP_PRD
Cluster Summary:
* Stack: corosync
* Current DC: cl-prd-2 (2) (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Fri Apr 28 16:38:00 2023
* Last change:

Fri Apr 28 16:37:49 2023 by hacluster via crmd on cl-prd-1

* 2 nodes configured
* 8 resource instances configured
Node List:
* Online: [ cl-prd-1 (1) cl-prd-2 (2) ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-prd-2

* Clone Set: SAPHanaTopology_PRD_00-clone [SAPHanaTopology_PRD_00]:
* SAPHanaTopology_PRD_00 (ocf::heartbeat:SAPHanaTopology):

Started cl-prd-2

* SAPHanaTopology_PRD_00 (ocf::heartbeat:SAPHanaTopology):

Started cl-prd-1

* Clone Set: SAPHana_PRD_00-clone [SAPHana_PRD_00] (promotable):
* SAPHana_PRD_00 (ocf::heartbeat:SAPHana):

Slave cl-prd-2

* SAPHana_PRD_00 (ocf::heartbeat:SAPHana):

Master cl-prd-1

* vip_PRD_00 (ocf::heartbeat:IPaddr2):

Started cl-prd-1

* Resource Group: group_dev_non_prod:
* vip_np (ocf::heartbeat:IPaddr2):

Started cl-prd-2

* SAPHana_np_DEV_HDB10 (ocf::heartbeat:SAPInstance):

Started cl-prd-2

Node Attributes:
* Node: cl-prd-1 (1):
* hana_prd_clone_state

: PROMOTED

* hana_prd_op_mode

: logreplay

* hana_prd_remoteHost

: cl-prd-2
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 473

* hana_prd_roles

: 4:P:master1:master:worker:master

* hana_prd_site

: SiteA

* hana_prd_srmode

: syncmem

* hana_prd_sync_state

: PRIM

* hana_prd_version

: 2.00.070.00.1679989823

* hana_prd_vhost

: cl-prd-1

* lpa_prd_lpt

: 1682692638

* master-SAPHana_PRD_00

: 150

* Node: cl-prd-2 (2):
* hana_prd_clone_state

: DEMOTED

* hana_prd_op_mode

: logreplay

* hana_prd_remoteHost

: cl-prd-1

* hana_prd_roles

: 4:S:master1:master:worker:master

* hana_prd_site

: SiteB

* hana_prd_srmode

: syncmem

* hana_prd_sync_state

: SOK

* hana_prd_version

: 2.00.070.00.1679989823

* hana_prd_vhost

: cl-prd-2

* lpa_prd_lpt

: 30

* master-SAPHana_PRD_00

: 100

Migration Summary:
Tickets:
PCSD Status:
cl-prd-1: Online
cl-prd-2: Online
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Run the following command to check the defined constraints.
Sample output:
# pcs constraint --full
Location Constraints:
Resource: group_dev_non_prod
Disabled on:
Node: cl-prd-1 (score:-INFINITY) (resource-discovery=never) (id:loc-dev-avoid-cl-prd-1)
Ordering Constraints:
start SAPHanaTopology_PRD_00-clone then start SAPHana_PRD_00-clone (kind:Mandatory) (non-symmetrical) (id:orderSAPHanaTopology_PRD_00-clone-SAPHana_PRD_00-clone-mandatory)
stop group_dev_non_prod then promote SAPHana_PRD_00-clone (kind:Mandatory) (id:order-group_dev_non_prodSAPHana_PRD_00-clone-mandatory)
Colocation Constraints:
vip_PRD_00 with SAPHana_PRD_00-clone (score:2000) (rsc-role:Started) (with-rsc-role:Master) (id:colocationvip_PRD_00-SAPHana_PRD_00-clone-2000)
group_dev_non_prod with SAPHana_PRD_00-clone (score:-INFINITY) (rsc-role:Started) (with-rsc-role:Master)
(id:colocation-group_dev_non_prod-SAPHana_PRD_00-clone-INFINITY)
Ticket Constraints:

Enabling the automated registration of the secondary instance
You need to set the parameter AUTOMATED_REGISTER according to your operational requirements. If you want to keep the ability to revert to
the state of the previous primary SAP HANA instance, then AUTOMATED_REGISTER=false avoids an automatic registration of the previous
primary as a new secondary.
If you experience an issue with the data after a takeover that was triggered by the cluster, you can manually revert if

AUTOMATED_REGISTER is

set to false .
If AUTOMATED_REGISTER is set to true , the previous primary SAP HANA instance automatically registers as secondary, and cannot be
activated on its previous history. The advantage of AUTOMATED_REGISTER=true is that high-availability is automatically reestablished after the
failed node reappears in the cluster.
For now, it is recommended to keep AUTOMATED_REGISTER on default value false until the cluster is fully tested and that you verify that the

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 474

failover scenarios work as expected.
Tip: The pcs resource update command is used to modify resource attributes and pcs resource update
SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=true sets the attribute to true .

Testing the SAP HANA System Replication cluster
It is vital to thoroughly test the cluster configuration to make sure that the cluster is working correctly. The following information provides a few
sample failover test scenarios, but is not a complete list of test scenarios.
For example, the description of each test case includes the following information.
Which component is being tested
Description of the test
Prerequisites and the initial state before you start the failover test
Test procedure
Expected behavior and results
Recovery procedure

Test1 - Testing the failure of the primary database instance
Use the following information to test the failure of the primary database instance.

Test1 - Description
Simulate a crash of the primary HANA database instance that is running on NODE1.

Test1 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false .
Check SAP HANA System Replication status:
The primary SAP HANA database is running on NODE1.
The secondary SAP HANA database is running on NODE2.
HANA System Replication is activated and in sync.
The secondary SAP HANA database on NODE2 is running with reduced memory configuration.
The global_allocation_limit is reduced.
Preload of column tables is disabled ( preload_column_tables = false ).
A nonproduction SAP HANA system ${SID_np} is running on NODE2.

Test1 - Test procedure
Crash SAP HANA primary by sending a SIGKILL signal as user ${sid}adm .
On NODE1, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test1 - Expected behavior
SAP HANA primary instance on NODE1 crashes.
The cluster detects the stopped primary HANA database and marks the resource as failed .
The cluster promotes the secondary HANA database on NODE2 to take over as new primary.
The cluster stops the nonproduction database ${SID_np} on NODE2.
During activation, the global_allocation_limit and preload_column_tables parameters are reset to default.
The cluster releases the virtual IP address on NODE1, and acquires it on the new primary on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 475

On NODE2, run the following commands to check that the global_allocation_limit and preload_column_tables are unset.
$ sudo -i -u ${sid}adm -- hdbcons "mm globallimit" | grep limit

$ grep -E "global_allocation_limit|preload_column_tables" \
/hana/shared/${SID}/global/hdb/custom/config/global.ini

Test1 - Recovery procedure
As the cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false , the cluster doesn't restart the failed
HANA database, and doesn't register it against the new primary. The status on the new primary (NODE2) shows the secondary in status
'CONNECTION TIMEOUT'.
On NODE1, run the following commands to register the previous primary as new secondary.
$ sudo -i -u ${sid}adm -- <<EOT
hdbnsutil -sr_register \
--name=${DC1} \
--remoteHost=${NODE2} \
--remoteInstance=${INSTNO} \
--replicationMode=sync \
--operationMode=logreplay \
--online
EOT

Verify the system replication status.
$ sudo -i -u ${sid}adm -- <<EOT
hdbnsutil -sr_state
HDBSettings.sh systemReplicationStatus.py
EOT

On NODE1, run the following command to start the cluster node.
$ pcs cluster start

The new secondary instance restarts and shows up in status synced ( SOK ).
$ pcs status --full

Configure cluster resource SAPHana_${SID}_${INSTNO} with AUTOMATED_REGISTER=true .
On NODE1, run the following command.
$ pcs resource update SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=true

$ pcs resource config SAPHana_${SID}_${INSTNO}

Test2 - Testing the manual move of SAPHana resource to another node
Use the following information to test the manual move of SAPHana resource to another node.

Test2 - Description
Use cluster commands to move the primary instance back to the other node.

Test2 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA System Replication status:
The primary SAP HANA database is running on NODE2.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 476

The secondary SAP HANA database is running on NODE1.
HANA System Replication is activated and in sync.
The nonproduction SAP HANA system ${SID_np} is stopped on NODE2.

Test2 - Test Preparation
Unmanage the cluster resource for the nonproduction SAP HANA system to prevent that it starts when the memory resources of the secondary
are not restricted.
On NODE1, run the following command.
$ pcs resource unmanage group_${sid_np}_non_prod

Test2 - Test Procedure
On NODE1, run the following command to move the SAP HANA primary back to NODE1.
$ pcs resource move SAPHana_${SID}_${INSTNO}-clone

Test2 - Expected behavior
The cluster creates a location constraint to move the resource.
The cluster triggers a takeover to the secondary HANA database on NODE1.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
The resource of the nonproduction SAP HANA system ${SID_np} is in the unmanaged state and isn't started automatically.

Test2 - Recovery procedure
Several steps need to be followed to reestablish the complete HA scenario.
1. Wait until the primary HANA instance is active. Then, reduce the memory footprint of the secondary.
On NODE2, run the following commands to reduce the memory.
$ export GLOBAL_ALLOCATION_LIMIT=<size_in_mb_for_hana_secondary>

$ sudo -i -u ${sid}adm -- <<EOT
python \$DIR_INSTANCE/exe/python_support/setParameter.py \
-set SYSTEM/global.ini/system_replication/preload_column_tables=false \
-set SYSTEM/global.ini/memorymanager/global_allocation_limit=$GLOBAL_ALLOCATION_LIMIT
EOT

2. Remove the location constraint, which triggers the start of the secondary instance.
$ pcs resource clear SAPHana_${SID}_${INSTNO}-clone

Verify that the constraint is cleared.
$ pcs constraint

Check the cluster status.
$ pcs status --full

3. On NODE2, run the following commands to check that the global_allocation_limit and preload_column_tables are set.
$ sudo -i -u ${sid}adm -- hdbcons "mm globallimit" | grep limit

$ grep -E "global_allocation_limit|preload_column_tables" \
/hana/shared/${SID}/global/hdb/custom/config/global.ini

4. Reactivate the resource for the nonproduction SAP HANA system.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 477

On NODE2, run the following command.
$ pcs resource manage group_${sid_np}_non_prod

The resource of the nonproduction SAP HANA system ${SID_np} is managed and the nonproduction system starts on NODE2.
$ pcs status --full

Test3 - Testing failure of node that is running the primary database
Use the following information to test the failure of node that is running the primary database.

Test3 - Description
Simulate a crash of the node that is running the primary HANA database.

Test3 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA System Replication status:
The primary SAP HANA database is running on NODE1.
The secondary SAP HANA database is running on NODE2.
HANA System Replication is activated and in sync.
The secondary SAP HANA database on NODE2 is running with reduced memory configuration.
The global_allocation_limit is reduced.
Preload of column tables is disabled ( preload_column_tables = false ).
A nonproduction SAP HANA system ${SID_np} is running on NODE2.

Test3 - Test procedure
Crash primary on NODE1 by sending a shutoff system request.
On NODE1, run the following command.
$ sync; echo o > /proc/sysrq-trigger

Test3 - Expected behavior
NODE1 shuts down.
The cluster detects the failed node and sets its state to OFFLINE .
The cluster promotes the secondary HANA database on NODE2 to take over as new primary.
The cluster stops the nonproduction database ${SID_np} on NODE2.
During activation, the global_allocation_limit and preload_column_tables parameters of SAP HANA ${SID} are reset.
The cluster acquires the virtual IP address on NODE2 on the new primary.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.

Test3 - Recovery procedure
Log in to the IBM Cloud® console and start NODE1. Wait until NODE1 is available again, then restart the cluster framework.
On NODE1, run the following command.
$ pcs cluster start

$ pcs status --full

As cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true , SAP HANA restarts when NODE1 joins the

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 478

cluster and the former primary is registered as secondary.
Then, rerun the steps in Test2 - Test the manual move of SAPHana resource to another node to revert to the initial situation.

Test4 - Testing failure of the secondary database instance
Use the following information to test the failure of the secondary database instance.

Test4 - Description
Simulate a crash of the secondary HANA database.

Test4 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both nodes active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA System Replication status:
The primary SAP HANA database is running on NODE1.
The secondary SAP HANA database is running on NODE2.
HANA System Replication is activated and sync.

Test4 - Test Procedure
Crash SAP HANA secondary by sending a SIGKILL signal as user ${sid}adm .
On NODE2, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test4 - Expected behavior
SAP HANA secondary on NODE2 crashes.
The cluster detects the stopped secondary HANA database and marks the resource as failed .
The cluster restarts the secondary HANA database.
The cluster detects that the system replication is in sync again.

Test4 - Recovery Procedure
Wait until the secondary HANA instance starts and synchronized again ( SOK ), then cleanup the failed resource actions as shown in pcs
status .

On NODE2, run the following command.
$ pcs resource refresh SAPHana_${SID}_${INSTNO}

$ pcs status --full

Configuring SAP HANA Active/Active (Read Enabled) System Replication in a RHEL
HA Add-On cluster
The following information describes the configuration of a Red Hat Enterprise Linux (RHEL) HA Add-On cluster for managing SAP HANA&reg
Active-Active (Read Enabled) System Replication. The cluster uses virtual server instances in IBM® Power® Virtual Server as cluster nodes.
In an Active/Active (read enabled) configuration, SAP HANA system replication allows read access to the database content on the secondary
system.
Note: This information is intended for architects and specialists that are planning a high-availability deployment of SAP HANA on Power
Virtual Server.

Before you begin
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 479

Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Prerequisites
A Red Hat High Availability cluster is deployed on two virtual server instances in Power Virtual Server.
Install and set up the RHEL HA Add-On cluster according to Implementing a RHEL HA Add-On cluster on Power Virtual Server .
Configure and verify fencing as described in the preceding document.
The virtual server instances need to fulfill hardware and resource requirements for the SAP HANA systems in scope. Follow the
guidelines in the Planning the Deployment document.
The hostnames of the virtual server instances must meet the SAP HANA requirement.
SAP HANA is installed on both virtual server instances and SAP HANA System Replication is configured. The installation of SAP HANA and
setup of SAP HANA System Replication is not specific to the Power Virtual Server environment, and you need to follow the standard
procedures.

Setting up the Active/Active (read enabled) scenario
The Active/Active (read enabled) system replication scenario is an extension of the setup that is described in

Configure SAP HANA Scale-Up

System Replication in a RHEL HA Add-On cluster.
Complete the setup for the production system System Replication cluster before you continue with the following steps.

Changing the system replication operation mode to Active/Active (read enabled)
On the node that is running the secondary instance, run the following command to change the operation mode.
1. Put the cluster in maintenance mode.
$ pcs property set maintenance-mode=true

2. Stop the secondary SAP HANA instance.
$ sudo -i -u ${sid}adm -- \
HDB stop

3. Change the system replication operation mode.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_changeOperationMode --mode=logreplay_readaccess

4. Start the secondary SAP HANA instance.
$ sudo -i -u ${sid}adm -- \
HDB start

5. Remove the cluster from maintenance mode.
$ pcs property set maintenance-mode=false

Configuring cluster resources for an Active/Active (read enabled) scenario
Use the following information to configure the additional cluster resources that are required for an Active/Active (read enabled) scenario.

Creating a secondary virtual IP address resource
Review the information in Reserving virtual IP addresses and reserve a virtual IP address for the secondary.
Use the reserved IP address to create a virtual IP address resource. This virtual IP address allows clients to connect to the secondary HANA
instance for read-only queries.
On a cluster node, assign the reserved IP address to a VIP_SECONDARY environment variable and create the virtual IP address cluster
resource by running the following commands.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 480

$ export VIP_SECONDARY=<reserved IP address for SAP HANA secondary>

$ echo $VIP_SECONDARY

$ pcs resource create vip_s_${SID}_${INSTNO} IPaddr2 ip=$VIP_SECONDARY

Check the configured virtual IP address and the cluster status.
$ pcs resource config vip_s_${SID}_${INSTNO}

$ pcs status --full

Creating location constraints for the secondary virtual IP address
Create a cluster constraint to make sure that the secondary virtual IP address is placed on the cluster node that is running the secondary
instance.
On a cluster node, run the following commands.
$ pcs constraint location vip_s_${SID}_${INSTNO} rule \
score=INFINITY hana_${sid}_sync_state eq SOK \
and hana_${sid}_roles eq 4:S:master1:master:worker:master

$ pcs constraint location vip_s_${SID}_${INSTNO} rule \
score=2000 hana_${sid}_sync_state eq PRIM \
and hana_${sid}_roles eq 4:P:master1:master:worker:master

These location constraints establish the following behavior for the second virtual IP resource:
If both SAP HANA primary and SAP HANA secondary are available, and SAP HANA system replication state is

SOK , then the secondary

virtual IP address is assigned to the node where SAP HANA secondary is active.
If the SAP HANA secondary node is not available or SAP HANA system replication state is not

SOK , then the secondary virtual IP is

assigned to the node where SAP HANA primary is active. When the SAP HANA secondary becomes available and the SAP HANA system
replication state is SOK again, the second virtual IP address moves back to the node where the SAP HANA secondary is active.
If SAP HANA primary or the node where it is running becomes unavailable then the SAP HANA secondary takes over the primary role. The
second virtual IP remains on the node until the other node turns into SAP HANA secondary role and SAP HANA system replication state is
SOK again.

This behavior maximizes the time that the secondary virtual IP resource is assigned to a node where a healthy SAP HANA instance is running.
The cluster configuration for the Active/Active (read enabled) scenario is complete.

Checking the cluster configuration
On a cluster node, run the following command to check the status of the cluster resources.
$ pcs status --full

Sample output:
# pcs status --full
Cluster name: H4S_cluster
Cluster Summary:
* Stack: corosync
* Current DC: cl-h4s-1 (1) (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Mon Jul 31 11:46:11 2023
* Last change:

Mon Jul 31 11:44:34 2023 by root via crm_attribute on cl-h4s-1

* 2 nodes configured
* 7 resource instances configured
Node List:
* Online: [ cl-h4s-1 (1) cl-h4s-2 (2) ]
Full List of Resources:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 481

* res_fence_ibm_powervs (stonith:fence_ibm_powervs):
* vip_H4S_00_primary (ocf::heartbeat:IPaddr2):

Started cl-h4s-1

Started cl-h4s-1

* Clone Set: SAPHanaTopology_H4S_00-clone [SAPHanaTopology_H4S_00]:
* SAPHanaTopology_H4S_00 (ocf::heartbeat:SAPHanaTopology):

Started cl-h4s-2

* SAPHanaTopology_H4S_00 (ocf::heartbeat:SAPHanaTopology):

Started cl-h4s-1

* Clone Set: SAPHana_H4S_00-clone [SAPHana_H4S_00] (promotable):
* SAPHana_H4S_00 (ocf::heartbeat:SAPHana):

Slave cl-h4s-2

* SAPHana_H4S_00 (ocf::heartbeat:SAPHana):

Master cl-h4s-1

* vip_s_H4S_00 (ocf::heartbeat:IPaddr2):

Started cl-h4s-2

Node Attributes:
* Node: cl-h4s-1 (1):
* hana_h4s_clone_state

: PROMOTED

* hana_h4s_op_mode

: logreplay_readaccess

* hana_h4s_remoteHost

: cl-h4s-2

* hana_h4s_roles

: 4:P:master1:master:worker:master

* hana_h4s_site

: SiteA

* hana_h4s_srmode

: syncmem

* hana_h4s_sync_state

: PRIM

* hana_h4s_version

: 2.00.070.00.1679989823

* hana_h4s_vhost

: cl-h4s-1

* lpa_h4s_lpt

: 1690796675

* master-SAPHana_H4S_00

: 150

* Node: cl-h4s-2 (2):
* hana_h4s_clone_state

: DEMOTED

* hana_h4s_op_mode

: logreplay_readaccess

* hana_h4s_remoteHost

: cl-h4s-1

* hana_h4s_roles

: 4:S:master1:master:worker:master

* hana_h4s_site

: SiteB

* hana_h4s_srmode

: syncmem

* hana_h4s_sync_state

: SOK

* hana_h4s_version

: 2.00.070.00.1679989823

* hana_h4s_vhost

: cl-h4s-2

* lpa_h4s_lpt

: 30

* master-SAPHana_H4S_00

: 100

Migration Summary:
Tickets:
PCSD Status:
cl-h4s-1: Online
cl-h4s-2: Online
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

On a cluster node, run the following command to check the defined constraints.
$ pcs constraint --full

Sample output:
# pcs constraint --full
Location Constraints:
Resource: vip_s_H4S_00
Constraint: location-vip_s_H4S_00
Rule: boolean-op=and score=INFINITY (id:location-vip_s_H4S_00-rule)
Expression: hana_h4s_sync_state eq SOK (id:location-vip_s_H4S_00-rule-expr)
Expression: hana_h4s_roles eq 4:S:master1:master:worker:master (id:location-vip_s_H4S_00-rule-expr-1)
Constraint: location-vip_s_H4S_00-1
Rule: boolean-op=and score=2000 (id:location-vip_s_H4S_00-1-rule)
Expression: hana_h4s_sync_state eq PRIM (id:location-vip_s_H4S_00-1-rule-expr)
Expression: hana_h4s_roles eq 4:P:master1:master:worker:master (id:location-vip_s_H4S_00-1-rule-expr-1)
Ordering Constraints:
promote SAPHana_H4S_00-clone then start vip_H4S_00_primary (kind:Mandatory) (id:order-SAPHana_H4S_00-clonevip_H4S_00_primary-mandatory)
start SAPHanaTopology_H4S_00-clone then start SAPHana_H4S_00-clone (kind:Mandatory) (non-symmetrical) (id:orderIBM Cloud for SAP | IBM Power Virtual Servers for SAP 482

SAPHanaTopology_H4S_00-clone-SAPHana_H4S_00-clone-mandatory)
Colocation Constraints:
vip_H4S_00_primary with SAPHana_H4S_00-clone (score:2000) (rsc-role:Started) (with-rsc-role:Master) (id:colocationvip_H4S_00_primary-SAPHana_H4S_00-clone-2000)
Ticket Constraints:

Checking access to the read enabled secondary SAP HANA instance
You can use SAP HANA system replication Active/Active (read enabled) to connect to the secondary system for improved overall performance.
Two connection methods are available to access the read enabled secondary HANA instance:
Explicit read-only connection The application opens an explicit connection to the secondary HANA instance.
Hint-based statement routing An application, for example SAP S/4HANA, opens a connection to the primary HANA instance. On this
connection, SQL statements with system replication-specific hints are first prepared, and then executed. During their execution, the SQL
statements are automatically routed to the secondary system and processed there. For more information about hints, see the SAP HANA
SQL and System Views Reference Guide.
Set the following two environment variables to the virtual IP addresses for the SAP HANA primary and secondary.
export VIP_PRIMARY=<virtual IP address of SAP HANA primary>
export VIP_SECONDARY=<virtual IP address of SAP HANA secondary>

The commands in the following two sections prompt for the password of the SAP HANA

SYSTEM user. The command output shows the

hostname and the IP addresses of the SAP HANA system that ran the SQL statement.

Checking access by using an explicit read-only connection
Verify the connection to the secondary instance by using an explicit read-only connection.
On a cluster node, run the following command.
$ sudo -i -u ${sid}adm -- \
hdbsql -n $VIP_SECONDARY -i $INSTNO -d SYSTEMDB -u SYSTEM \
"select * from m_host_information \
where key = 'net_hostnames' or key = 'net_ip_addresses'"

The sample output shows that the statement ran on the SAP HANA secondary.
HOST,KEY,VALUE
"cl-h4s-2","net_hostnames","cl-h4s-2"
"cl-h4s-2","net_ip_addresses","10.40.10.132,10.40.10.211"
2 rows selected (overall time 7518 usec; server time 291 usec)

Checking access by using hint-based statement routing
Verify the connection to the secondary instance by using the hint-based statement routing.
1. Run a connection test by using an explicit connection to the SAP HANA primary without an SQL hint.
On a cluster node, run the following command.
$ sudo -i -u ${sid}adm -- \
hdbsql -n $VIP_PRIMARY -i $INSTNO -d SYSTEMDB -u SYSTEM \
"select * from m_host_information \
where key = 'net_hostnames' or key = 'net_ip_addresses'"

The sample output shows that the statement ran on the SAP HANA primary.
HOST,KEY,VALUE
"cl-h4s-1","net_hostnames","cl-h4s-1"
"cl-h4s-1","net_ip_addresses","10.40.10.162,10.40.10.201"
2 rows selected (overall time 5239 usec; server time 361 usec)

2. Run a connection test by using an explicit connection to the SAP HANA primary and the

result_lag SQL hint.

$ sudo -i -u ${sid}adm -- \

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 483

hdbsql -n $VIP_PRIMARY -i $INSTNO -d SYSTEMDB -u SYSTEM \
"select * from m_host_information \
where key = 'net_hostnames' or key = 'net_ip_addresses' \
with hint(result_lag('hana_sr'))"

The sample output shows that the statement ran on the SAP HANA secondary.
HOST,KEY,VALUE
"cl-h4s-2","net_hostnames","cl-h4s-2"
"cl-h4s-2","net_ip_addresses","10.40.10.132,10.40.10.211"
2 rows selected (overall time 40.722 msec; server time 16.428 msec)

Enabling the automated registration of the secondary instance
You need to set the parameter AUTOMATED_REGISTER according to your operational requirements. If you want to keep the ability to revert to
the state of the previous primary SAP HANA instance, then AUTOMATED_REGISTER=false avoids an automatic registration of the previous
primary as a new secondary.
If you experience an issue with the data after a takeover that was triggered by the cluster, you can manually revert if

AUTOMATED_REGISTER is

set to false .
If AUTOMATED_REGISTER is set to true , the previous primary SAP HANA instance automatically registers as secondary, and cannot be
activated on its previous history. The advantage of the setting AUTOMATED_REGISTER=true is that high-availability automatically reestablishes
after the failed node reappears in the cluster.
For now, it is recommended to keep AUTOMATED_REGISTER on default value false until the cluster is fully tested and that you verify that the
failover scenarios work as expected.
Tip: The pcs resource update command is used to modify resource attributes and pcs resource update
SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=true sets the attribute to true .

Testing SAP HANA System Replication cluster
It is important to thoroughly test the cluster configuration to make sure that the cluster is working correctly. The following information provides
a few sample failover test scenarios, but is not a complete list of test scenarios.
For example, the description of each test case includes the following information.
Component that is being tested
Description of the test
Prerequisites and the cluster state before you start the failover test
Test procedure
Expected behavior and results
Recovery procedure

Test1 - Testing failure of the primary database instance
Use the following information to test the failure of the primary database instance.

Test1 - Description
Simulate a crash of the primary SAP HANA database instance that is running on NODE1.

Test1 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP HANA system replication.
Both cluster nodes are active.
Cluster that is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} that is configured with AUTOMATED_REGISTER=false .
Check SAP HANA System Replication status:
Primary SAP HANA database is running on NODE1
Secondary SAP HANA database is running on NODE2

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 484

SAP HANA System Replication is activated and in sync

Test1 - Test procedure
Crash SAP HANA primary by sending a SIGKILL signal as the user ${sid}adm .
On NODE1, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test1 - Expected behavior
SAP HANA primary instance on NODE1 crashes.
The cluster detects the stopped primary SAP HANA database and marks the resource as

failed .

The cluster promotes the secondary SAP HANA database on NODE2 to take over as the new primary.
The cluster releases the virtual IP address on NODE1, and acquires it on the new primary on NODE2.
After the takeover, the secondary SAP HANA instance is unavailable and the secondary virtual IP address stays on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.

Test1 - Recovery procedure
As the cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false , the cluster doesn't restart the failed
SAP HANA database, and doesn't register it against the new primary. Which means that the status on the new primary (NODE2) also shows the
secondary in status 'CONNECTION TIMEOUT'.
To reregister the previous primary as a new secondary use the following commands.
On NODE1, run the following command.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC1} \
--remoteHost=${NODE2} \
--remoteInstance=00 \
--replicationMode=sync \
--operationMode=logreplay_readaccess \
--online

Verify the system replication status:
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_state

On a cluster node, run the following command to refresh the cluster resource. This command starts the secondary instance.
$ pcs resource refresh SAPHana_${SID}_${INSTNO}

When the secondary reaches the synced state ( SOK ), the secondary virtual IP address moves to NODE1.
On a cluster node, run the following command to check the cluster status.
$ pcs status --full

Test2 - Testing failure of the node that is running the primary database
Use the following information to test the failure of the node that is running the primary database.

Test2 - Description
Simulate a crash of the node that is running the primary SAP HANA database.

Test2 - Preparation
Make sure that the Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 485

On NODE1, run the following command.
$ pcs resource update SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=true

Verify the AUTOMATED_REGISTER setting in the resource configuration.
$ pcs resource config SAPHana_${SID}_${INSTNO} | grep Attributes

Test2 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP HANA system replication.
Both nodes are active.
Cluster is started on NODE1 and NODE2.
Check SAP HANA System Replication status.
Primary SAP HANA database is running on NODE2
Secondary SAP HANA database is running on NODE1
SAP HANA System Replication is activated and in sync
Secondary virtual IP address is active on NODE1

Test2 - Test procedure
Crash primary on NODE2 by sending a shutoff system request.
On NODE2, run the following command.
$ sync; echo o > /proc/sysrq-trigger

Test2 - Expected behavior
NODE2 shuts down.
The cluster detects the failed node and sets its state to OFFLINE .
The cluster promotes the secondary SAP HANA database on NODE1 to take over as the new primary.
The cluster acquires the virtual IP address on NODE1 on the new primary.
After the takeover, the secondary SAP HANA instance is unavailable and the secondary virtual IP address stays on NODE1.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.

Test2 - Recovery procedure
Log in to the IBM Cloud® Console and start the NODE2 instance. Wait until NODE2 is available again, then restart the cluster framework.
On NODE2, run the following command.
$ pcs cluster start

$ pcs status --full

As a cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true , SAP HANA restarts when NODE2 rejoins
the cluster and the former primary reregisters as a secondary. When the secondary reaches the synced state ( SOK ), the secondary virtual IP
address moves to NODE2.

Test3 - Testing the failure of the secondary database instance
Use the following information to test the failure of the secondary database instance.

Test3 - Description
Simulate a crash of the secondary SAP HANA database.

Test3 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP HANA system replication.
Both nodes are active.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 486

Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA System Replication status:
Primary SAP HANA database is running on NODE1
Secondary SAP HANA database is running on NODE2
SAP HANA System Replication is activated and in sync
Secondary virtual IP address is active on NODE2

Test3 - Test procedure
Crash SAP HANA secondary by sending a SIGKILL signal as the user ${sid}adm .
On NODE2, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test3 - Expected behavior
SAP HANA secondary on NODE2 crashes.
The cluster detects the stopped secondary SAP HANA database and marks the resource as failed .
The cluster moves the secondary virtual IP address to NODE1.
The cluster restarts the secondary SAP HANA database.
The cluster detects that the system replication is in sync again.
The cluster moves the secondary virtual IP address back to NODE2.

Test3 - Recovery procedure
Wait until the secondary SAP HANA instance starts and syncs again ( SOK ), then cleanup the failed resource actions as shown in pcs status .
On a cluster node, run the following commands.
$ pcs resource refresh SAPHana_${SID}_${INSTNO}

$ pcs status --full

Test4 - Testing the manual move of a SAPHana resource to another node
Use the following information to test the manual move of a SAPHana resource to another node.

Test4 - Description
Use cluster commands to move the primary instance to the other node for maintenance purposes.

Test4 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP HANA system replication.
Both nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA System Replication status:
Primary SAP HANA database is running on NODE1
Secondary SAP HANA database is running on NODE2
SAP HANA System Replication is activated and in sync
Secondary virtual IP address is active on NODE2

Test4 - Test procedure
Move SAP HANA primary to other node by using the pcs resource move command.
On a cluster node, run the following command.
$ pcs resource move SAPHana_${SID}_${INSTNO}-clone

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 487

Sample output:
# pcs resource move SAPHana_H4S_00-clone
Warning: Creating location constraint 'cli-ban-SAPHana_H4S_00-clone-on-cl-hdb-1' with a score of -INFINITY for resource
SAPHana_H4S_00-clone on cl-hdb-1.
This will prevent SAPHana_H4S_00-clone from running on cl-hdb-1 until the constraint is removed
This will be the case even if cl-hdb-1 is the last node in the cluster

Test4 - Expected behavior
The cluster creates location constraints to move the resource.
The cluster triggers a takeover to the secondary SAP HANA database.
The secondary virtual IP address stays on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.

Test4 - Recovery procedure
The automatically created location constraints must be removed to allow automatic failover in the future.
Wait until the primary SAP HANA instance is active and remove the constraints.
On a cluster node, run the following command.
$ pcs constraint

$ pcs resource clear SAPHana_${SID}_${INSTNO}-clone

$ pcs constraint

The cluster registers and starts the SAP HANA database as a new secondary instance. After system replication status is in sync again (

SOK ),

the cluster moves the secondary virtual IP address to NODE1.
$ pcs status --full

Configuring SAP HANA multitier system replication in a RHEL HA Add-On cluster
The following information describes the configuration of a Red Hat Enterprise Linux (RHEL) HA add-on cluster for managing SAP HANA&reg
system replication in a multitier replication scenario. The cluster uses virtual server instances in IBM® Power® Virtual Server as cluster nodes.
You can connect multiple systems in an SAP HANA multitier system replication topology to achieve a higher level of availability. The tertiary
SAP HANA instance runs on a third virtual server instance in IBM Power Virtual Server in another workspace. The resource agents for SAP
HANA in the Red Hat Enterprise Linux 8 (RHEL) HA add-on require that the tertiary SAP HANA instance is managed manually. The tertiary SAP
HANA system is installed on a virtual server instance outside the cluster. After a takeover in the cluster, the tertiary SAP HANA instance must
be reregistered manually.
In a multitier system replication scenario, a tertiary SAP HANA system runs on a third virtual server instance. The third virtual server instance is
deployed in a different IBM Power Virtual Server workspace in another geographical location or zone. The SAP HANA system replication
operation mode must be identical for all multitier replication levels. The only exception is logreplay_readaccess between the primary and
secondary combined with logreplay between the secondary and tertiary.
A takeover to the tertiary system on the Disaster Recovery (DR) site must be triggered manually.
Note: This information is intended for architects and specialists that are planning a high-availability deployment of SAP HANA on Power
Virtual Server.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Prerequisites
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 488

A Red Hat High Availability cluster is deployed on two virtual server instances in one workspace in Power Virtual Server. Use the
instructions in the following documents.
Implementing a RHEL HA Add-On cluster on Power Virtual Server .
Configuring SAP HANA Scale-Up System Replication in a RHEL HA Add-On cluster .
A third virtual server instance is deployed in another workspace in Power Virtual Server.
SAP HANA is installed on the third virtual server instance with the same

SID and Instance Number .

Optional - you can reserve a virtual IP address for the system on NODE3 as described in

Reserving virtual IP addresses. Assigning and

unassigning this virtual IP address on NODE3 is a manual task and not part of a cluster operation.

Setting up the multitier scenario
The multitier scenario is an extension of the setup that is described in Configuring SAP HANA Scale-Up System Replication in a RHEL HA AddOn cluster. Complete the setup for the system replication cluster before you continue with the following steps.
If the AUTOMATED_REGISTER cluster attribute is set to true , the reintegration of a failed node in the cluster can lead to a setup with a wrong
SAP HANA system replication mode or an undesired SAP HANA system replication topology. To avoid these problems, disable the automatic
registration and use the hdbnsutil command to register the SAP HANA system manually before you start the cluster on a failed node.
On a cluster node, run the following command to disable the automatic registration.
$ pcs resource update SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=false

Providing network connectivity between the workspaces
1. Use the information in Creating the workspace to create another workspace in a different geographic location or region.
2. Create subnets and make sure that the IP ranges don't overlap with any subnet of the workspace that hosts the virtual server instances
for the cluster. For more information, see Creating subnets.
3. Set up IBM Cloud® connections up in both workspaces and activate Enable IBM Transit Gateway . For more information, see Creating
IBM Cloud® connections.
4. Deploy an IBM Cloud® Transit Gateway to interconnect the two IBM Power Virtual Server workspaces.
Note: IBM Cloud® Transit Gateway enables the interconnection of IBM Power Virtual Server, IBM Cloud® classic, and Virtual
Private Cloud (VPC) infrastructures and keeps data within the IBM Cloud® networks. For more information about planning and
deploying IBM Cloud® Transit Gateway, see Planning for IBM Cloud® Transit Gateway and Ordering IBM Cloud® Transit Gateway .
5. To add the connections to your transit gateway to establish network connectivity between your IBM Power Virtual Server, open IBM
Cloud console and log in to your account.
6. Select the Menu icon

on the upper left and click Interconnectivity.

7. Click Transit Gateway on the left navigation pane.
8. Select the name of your transit gateway.
Tip: In the expanded view, click View details.
9. Click Add connection.
10. Choose and configure the specific network connections that you want to add to the transit gateway.
11. Choose Direct Link, and select the names of your IBM Cloud® connections.
12. Click Add to create a connection.

Preparing environment variables on NODE3
To simplify the setup, prepare the following environment variables for user ID root on NODE3. These environment variables are used in
subsequent commands in the remainder of the instructions.
On NODE3, create a file with the following environment variables. Then, adapt them according to the configuration of your SAP HANA system.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 489

export SID=<SID>

# SAP HANA System ID (uppercase)

export sid=<sid>

# SAP HANA System ID (lowercase)

export INSTNO=<INSTNO>

# SAP HANA Instance Number

export DC3=<Site3>

# HANA System Replication Site Name 3

export NODE1=<Hostname 1>

# Hostname of virtual server instance 1 (production primary)

export NODE2=<Hostname 2>

# Hostname of virtual server instance 2 (production secondary)

export NODE3=<Hostname 3>

# Hostname of virtual server instance 3 (production tertiary)

You must source this file before you use the sample commands in the remainder of this document.
For example, if you created a file that is called sap_tier3.sh , run the following command on NODE3 to set the environment variables.
$ source sap_tier3.sh

Important: Every time that you start a new terminal session, you must run the previous

source command. As an alternative, you can

move add the environment variables file to the /etc/profile.d directory during the cluster configuration. In this example, the file is
sourced automatically each time you log in to the server.

Verifying network connectivity between the virtual server instances
Verify the network connectivity between the two cluster nodes (NODE1 and NODE2) and NODE3.
1. Log in to both NODE1 and NODE2, and ping NODE3.
$ ping -c 3 ${NODE3}

Sample output:
$ # ping -c 3 cl-hdb-3
PING cl-hdb-3 (10.40.20.70) 56(84) bytes of data.
64 bytes from 10.40.20.70 (10.40.20.70): icmp_seq=1 ttl=46 time=78.2 ms
64 bytes from 10.40.20.70 (10.40.20.70): icmp_seq=2 ttl=46 time=78.3 ms
64 bytes from 10.40.20.70 (10.40.20.70): icmp_seq=3 ttl=46 time=78.2 ms
--- cl-hdb-3 ping statistics --3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 78.197/78.233/78.264/0.027 ms

2. Log in to NODE3 and ping NODE1.
$ ping -c 3 ${NODE1}

Sample output:
$ # ping -c 3 cl-hdb-1
PING cl-hdb-1 (10.40.10.60) 56(84) bytes of data.
64 bytes from cl-hdb-1 (10.40.10.60): icmp_seq=1 ttl=46 time=78.3 ms
64 bytes from cl-hdb-1 (10.40.10.60): icmp_seq=2 ttl=46 time=78.2 ms
64 bytes from cl-hdb-1 (10.40.10.60): icmp_seq=3 ttl=46 time=78.3 ms
--- cl-hdb-1 ping statistics --3 packets transmitted, 3 received, 0% packet loss, time 2002ms
rtt min/avg/max/mdev = 78.245/78.268/78.287/0.229 ms

3. Log in to NODE3 and ping NODE2.
$ ping -c 3 ${NODE2}

Sample output:
$ # ping -c 3 cl-hdb-2
PING cl-hdb-2 (10.40.10.194) 56(84) bytes of data.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 490

64 bytes from cl-hdb-2 (10.40.10.194): icmp_seq=1 ttl=46 time=77.6 ms
64 bytes from cl-hdb-2 (10.40.10.194): icmp_seq=2 ttl=46 time=79.1 ms
64 bytes from cl-hdb-2 (10.40.10.194): icmp_seq=3 ttl=46 time=77.7 ms
--- cl-hdb-2 ping statistics --3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 77.649/78.129/79.071/0.703 ms

Copying PKI SSFS storage certificate files to NODE3
The SAP HANA 2.0 data and log transmission channels for the replication process require authentication by using the system PKI SSFS storage
certificate files.
2369981 - Required configuration steps for authentication with HANA System Replication )
The system PKI SSFS storage certificate files are stored in /usr/sap/${SID}/SYS/global/security/rsecssfs/ in subdirectories data and
key .

On NODE3, run the following commands to copy files SSFS_${SID}.DAT and SSFS_${SID}.KEY from NODE2.
$ scp ${NODE2}:/usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT
/usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT

$ scp ${NODE2}:/usr/sap/${SID}/SYS/global/security/rsecssfs/key/SSFS_${SID}.KEY
/usr/sap/${SID}/SYS/global/security/rsecssfs/key/SSFS_${SID}.KEY

The copied PKI SSFS storage certificates on NODE3 become active during start of the SAP HANA system. Therefore, it is recommended to copy
the files when the SAP HANA system on NODE3 is stopped.

Registering NODE3 as tertiary SAP HANA system replication system
Register the SAP HANA system as a tertiary system replication instance.
1. On NODE2, run the following command to enable this site as a system replication source system.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_enable

Sample output:
$ $ hdbnsutil -sr_enable
nameserver is active, proceeding ...
successfully enabled system as system replication source site
done.

2. On NODE3, stop the SAP HANA system.
$ sudo -i -u ${sid}adm -- HDB stop

3. On NODE3, register the tertiary system with NODE2.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC3} \
--remoteHost=${NODE2} \
--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

4. On NODE3, start the tertiary SAP HANA system.
$ sudo -i -u ${sid}adm -- HDB start

Checking the SAP HANA system replication status

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 491

You can monitor the system replication status by using the following tools.
SAP HANA cockpit
SAP HANA studio
hdbnsutil command-line tool
systemReplicationStatus.py Python script

SQL queries
The full output of the systemReplicationStatus.py script is available on only the primary system, as a database connection is required to
obtain some of the status information.
On NODE1, check the system replication status by using the systemReplicationStatus.py Python script.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|Active Status |Mode

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |--------- |------------ |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-1 |30007 |xsengine

|

|HDB

|SYNCMEM

|YES
|HDB

|SYNCMEM

|ACTIVE

|cl-hdb-1 |30003 |indexserver

|YES

|SYNCMEM

|ACTIVE

|
|

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES
|HDB

|ASYNC

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

2 |

|

1 |SiteA

1 |

2 |SiteB

|cl-hdb-2 |

30007 |

2 |SiteB

|cl-hdb-2 |

30003 |

2 |SiteB

|cl-hdb-3 |

30001 |

3 |SiteC

|cl-hdb-3 |

30007 |

3 |SiteC

|cl-hdb-3 |

30003 |

3 |SiteC

True |
2 |SiteB

|
3 |

2 |SiteB

True |

|
2 |

30001 |

True |

|

|
|

1 |SiteA

3 |

|cl-hdb-2 |

True |

|

|

|YES

1 |SiteA
|

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|ASYNC

1 |

True |
2 |SiteB

|

True |

status system replication site "2": ACTIVE
status system replication site "3": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

An alternative view of the system replication status is available with the

hdbnsutil command.

On all nodes, run the following command to check the system replication status.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output on NODE1:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: primary
operation mode: primary
site id: 1
site name: SiteA

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 492

is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: true
is a takeover active: false
is primary suspended: false
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-1 -> [SiteC] cl-hdb-3
cl-hdb-1 -> [SiteB] cl-hdb-2
cl-hdb-1 -> [SiteA] cl-hdb-1

Site Mappings:
~~~~~~~~~~~~~~
SiteA (primary/primary)
|---SiteB (syncmem/logreplay)
|

|---SiteC (async/logreplay)

Tier of SiteA: 1
Tier of SiteB: 2
Tier of SiteC: 3
Replication mode of SiteA: primary
Replication mode of SiteB: syncmem
Replication mode of SiteC: async
Operation mode of SiteA: primary
Operation mode of SiteB: logreplay
Operation mode of SiteC: logreplay
Mapping: SiteA -> SiteB
Mapping: SiteB -> SiteC
Hint based routing site:
done.

Sample output on NODE2:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: syncmem
operation mode: logreplay
site id: 2
site name: SiteB
is source system: true
is secondary/consumer system: true
has secondaries/consumers attached: true
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 1
primary masters: cl-hdb-1
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-2 -> [SiteC] cl-hdb-3
cl-hdb-2 -> [SiteB] cl-hdb-2
cl-hdb-2 -> [SiteA] cl-hdb-1

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 493

Site Mappings:
~~~~~~~~~~~~~~
SiteA (primary/primary)
|---SiteB (syncmem/logreplay)
|

|---SiteC (async/logreplay)

Tier of SiteA: 1
Tier of SiteB: 2
Tier of SiteC: 3
Replication mode of SiteA: primary
Replication mode of SiteB: syncmem
Replication mode of SiteC: async
Operation mode of SiteA: primary
Operation mode of SiteB: logreplay
Operation mode of SiteC: logreplay
Mapping: SiteA -> SiteB
Mapping: SiteB -> SiteC
Hint based routing site:
done.

Sample output on NODE3:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: async
operation mode: logreplay
site id: 3
site name: SiteC
is source system: false
is secondary/consumer system: true
has secondaries/consumers attached: false
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 2
primary masters: cl-hdb-2
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-3 -> [SiteC] cl-hdb-3
cl-hdb-3 -> [SiteB] cl-hdb-2
cl-hdb-3 -> [SiteA] cl-hdb-1

Site Mappings:
~~~~~~~~~~~~~~
SiteA (primary/primary)
|---SiteB (syncmem/logreplay)
|

|---SiteC (async/logreplay)

Tier of SiteA: 1
Tier of SiteB: 2
Tier of SiteC: 3
Replication mode of SiteA: primary
Replication mode of SiteB: syncmem

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 494

Replication mode of SiteC: async
Operation mode of SiteA: primary
Operation mode of SiteB: logreplay
Operation mode of SiteC: logreplay
Mapping: SiteA -> SiteB
Mapping: SiteB -> SiteC
Hint based routing site:
done.

Testing the SAP HANA system replication cluster
It is vital to thoroughly test the cluster configuration to make sure that the cluster is working correctly. The following information provides a few
sample failover test scenarios, but is not a complete list of test scenarios.
For example, the description of each test case includes the following information.
Component that is tested
Description of the test
Prerequisites and the initial state before the failover test
Test procedure
Expected behavior and results
Recovery procedure

Test1 - Testing the failure of the primary database instance
Use the following information to test the failure of the primary database instance.

Test1 - Description
Simulate a crash of the primary SAP HANA database instance that runs on NODE1.

Test1 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false .
Check SAP HANA system replication status:
SAP HANA multitier system replication is activated and in sync.
The primary SAP HANA system runs on NODE1.
The secondary SAP HANA system runs on NODE2.
The tertiary SAP HANA system runs on NODE3 and is registered with NODE2.
Check the current system replication status on NODE1.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|Active Status |Mode

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |--------- |------------ |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-1 |30007 |xsengine

|

|HDB
|YES
|HDB

|SYNCMEM
|SYNCMEM

|ACTIVE

|cl-hdb-1 |30003 |indexserver

1 |
|
2 |

|
|

1 |SiteA

3 |

30001 |

2 |SiteB

|cl-hdb-2 |

30007 |

2 |SiteB

|cl-hdb-2 |

30003 |

2 |SiteB

True |
1 |SiteA

|

|cl-hdb-2 |

True |
1 |SiteA

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 495

|YES

|SYNCMEM

|ACTIVE

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|ASYNC

|HDB
|YES

|ASYNC

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

|
1 |

2 |SiteB
|

2 |

|
|

True |

|

|

30001 |

3 |SiteC

|cl-hdb-3 |

30007 |

3 |SiteC

|cl-hdb-3 |

30003 |

3 |SiteC

True |
2 |SiteB

3 |

|cl-hdb-3 |

True |
2 |SiteB

|

True |

status system replication site "2": ACTIVE
status system replication site "3": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

Test1 - Test procedure
Crash SAP HANA primary by sending a SIGKILL signal as user ${sid}adm .
On NODE1, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test1 - Expected behavior
SAP HANA primary instance on NODE1 crashes.
The cluster detects the stopped primary and marks the resource as undefined .
The cluster promotes the secondary SAP HANA system on NODE2, which takes over as primary.
The cluster releases the virtual IP address on NODE1, and acquires it on the primary on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
On NODE1, run the following command to check the cluster status.
$ pcs status --full

Sample output:
$ pcs status --full
Cluster name: HDB_cluster
Cluster Summary:
* Stack: corosync
* Current DC: cl-hdb-1 (1) (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Mon Jul 10 16:00:38 2023
* Last change:

Mon Jul 10 15:58:50 2023 by root via crm_attribute on cl-hdb-2

* 2 nodes configured
* 6 resource instances configured
Node List:
* Online: [ cl-hdb-1 (1) cl-hdb-2 (2) ]
Full List of Resources:
* res_fence_ibm_powervs
* vip_HDB_00_primary

(stonith:fence_ibm_powervs):

(ocf::heartbeat:IPaddr2):

Started cl-hdb-1

Started cl-hdb-2

* Clone Set: SAPHanaTopology_HDB_00-clone [SAPHanaTopology_HDB_00]:
* SAPHanaTopology_HDB_00

(ocf::heartbeat:SAPHanaTopology):

Started cl-hdb-1

* SAPHanaTopology_HDB_00

(ocf::heartbeat:SAPHanaTopology):

Started cl-hdb-2

* Clone Set: SAPHana_HDB_00-clone [SAPHana_HDB_00] (promotable):
* SAPHana_HDB_00

(ocf::heartbeat:SAPHana):

Master cl-hdb-2

* SAPHana_HDB_00

(ocf::heartbeat:SAPHana):

Stopped

Node Attributes:
* Node: cl-hdb-1 (1):

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 496

* hana_hdb_clone_state

: UNDEFINED

* hana_hdb_op_mode

: logreplay

* hana_hdb_remoteHost

: cl-hdb-2

* hana_hdb_roles

: 1:P:master1::worker:

* hana_hdb_site

: SiteA

* hana_hdb_srah

: -

* hana_hdb_srmode

: sync

* hana_hdb_sync_state

: SFAIL

* hana_hdb_version

: 2.00.070.00.1679989823

* hana_hdb_vhost

: cl-hdb-1

* lpa_hdb_lpt

: 10

* master-SAPHana_HDB_00

: -9000

* Node: cl-hdb-2 (2):
* hana_hdb_clone_state

: PROMOTED

* hana_hdb_op_mode

: logreplay

* hana_hdb_remoteHost

: cl-hdb-1

* hana_hdb_roles

: 4:P:master1:master:worker:master

* hana_hdb_site

: SiteB

* hana_hdb_sra

: -

* hana_hdb_srah

: -

* hana_hdb_srmode

: sync

* hana_hdb_sync_state

: PRIM

* hana_hdb_version

: 2.00.070.00.1679989823

* hana_hdb_vhost

: cl-hdb-2

* lpa_hdb_lpt

: 1688997529

* master-SAPHana_HDB_00

: 150

Migration Summary:
* Node: cl-hdb-1 (1):
* SAPHana_HDB_00: migration-threshold=5000 fail-count=1000000 last-failure='Mon Jul 10 15:56:06 2023'
Failed Resource Actions:
* SAPHana_HDB_00_start_0 on cl-hdb-1 'not running' (7): call=51, status='complete', exitreason='', last-rcchange='2023-07-10 15:56:04 +02:00', queued=0ms, exec=1527ms
Tickets:
PCSD Status:
cl-hdb-1: Online
cl-hdb-2: Online
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

On NODE2, run the following command to check the system replication status.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|Active Status |Mode

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |--------- |------------ |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES
|HDB
|YES

|ASYNC
|ASYNC

|ACTIVE

|cl-hdb-2 |30003 |indexserver
|ASYNC

|ACTIVE

1 |
|
2 |

|
|
|

2 |SiteB

3 |

3 |SiteC

|cl-hdb-3 |

30007 |

3 |SiteC

|cl-hdb-3 |

30003 |

3 |SiteC

True |
2 |SiteB

|

30001 |

True |
2 |SiteB

|

|cl-hdb-3 |

True |

status system replication site "3": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 497

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 2
site name: SiteB

Test1 - Recovery procedure
As the cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false , you need to register the SAP HANA
system on NODE1 manually with the primary on NODE2.
Important: When you register SAP HANA on NODE1 as a secondary, the SAP HANA system replication topology changes. Both SAP
HANA systems on NODE3 at SiteC and NODE1 at SiteA are then registered as secondaries to the primary SAP HANA database that
runs on NODE2 at SiteB .

Important: If you want to stay with a multitier topology, you need to unregister the SAP HANA system on NODE3 at

SiteC first. Then,

you register the SAP HANA system on NODE1 at SiteA with the primary on NODE2 at SiteB . Finally, you register the SAP HANA
system on NODE3 at SiteC with secondary on NODE1 at SiteA .
On NODE1, run the following command to register the system with the primary on NODE2.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC1} \
--remoteHost=${NODE2} \
--remoteInstance=${INSTNO} \
--replicationMode=syncmem \
--operationMode=logreplay \
--online

On NODE1, run the following command to verify the resource status.
$ pcs resource status

The cluster resource SAPHana_${SID}_${INSTNO}-clone remains in status Stopped on NODE1.
Sample output:
$ # pcs resource status
* vip_HDB_00_primary

(ocf::heartbeat:IPaddr2):

Started cl-hdb-2

* Clone Set: SAPHanaTopology_HDB_00-clone [SAPHanaTopology_HDB_00]:
* Started: [ cl-hdb-1 cl-hdb-2 ]
* Clone Set: SAPHana_HDB_00-clone [SAPHana_HDB_00] (promotable):
* Masters: [ cl-hdb-2 ]
* Stopped: [ cl-hdb-1 ]

On a cluster node, run the following command to clear the failure status of the resource.
$ pcs resource cleanup SAPHana_${SID}_${INSTNO}-clone

Sample output:
$ # pcs resource cleanup SAPHana_HDB_00-clone
Cleaned up SAPHana_HDB_00:0 on cl-hdb-2
Cleaned up SAPHana_HDB_00:0 on cl-hdb-1
Cleaned up SAPHana_HDB_00:1 on cl-hdb-2
Cleaned up SAPHana_HDB_00:1 on cl-hdb-1
Waiting for 1 reply from the controller
... got reply (done)

After a while, verify the system replication status on NODE2.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 498

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|Active Status |Mode

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |--------- |------------ |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|ASYNC

|HDB
|YES

|ASYNC

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES

|SYNCMEM

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|SYNCMEM

|ACTIVE

2 |

2 |SiteB

1 |
|
|

|

|cl-hdb-3 |

30007 |

3 |SiteC

|cl-hdb-3 |

30003 |

3 |SiteC

|cl-hdb-1 |

30001 |

1 |SiteA

|cl-hdb-1 |

30007 |

1 |SiteA

|cl-hdb-1 |

30003 |

1 |SiteA

True |
2 |SiteB

3 |

3 |SiteC

True |
2 |SiteB

2 |

30001 |

True |

|

|
|

2 |SiteB

3 |

|cl-hdb-3 |

True |

|

|
|

2 |SiteB
|

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|SYNCMEM

1 |

True |
2 |SiteB

|

True |

status system replication site "3": ACTIVE
status system replication site "1": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 2
site name: SiteB

Important: The SAP HANA system replication topology that is changed to a multitarget environment. The primary runs on NODE2 at
SiteB . Both NODE3 at SiteC and NODE1 at SiteA are registered as secondaries. If another takeover occurs and NODE1 at SiteA

is promoted to primary again, NODE3 at SiteC is decoupled.
To create a multitier landscape with NODE3 at SiteC as a tertiary system, repeat the steps similar to Registering NODE3 as tertiary SAP
HANA system replication system and register NODE3 to the secondary on NODE1.
1. On NODE1, run the following command to enable this site as a system replication source system.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_enable

Sample output:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_enable
nameserver is active, proceeding ...
successfully enabled system as system replication source site
done.

2. On NODE3, register the system with NODE1 at SiteA .
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC3} \
--remoteHost=${NODE1} \
--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

$ # sudo -i -u hdbadm -- hdbnsutil -sr_register --name=SiteC --remoteHost=cl-hdb-1 --remoteInstance=00 -replicationMode=async --operationMode=logreplay --online
adding site ...
collecting information ...
updating local ini files ...
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 499

done.

3. Verify the system replication status on all three nodes as described in Checking the SAP HANA system replication status .

Test2 - Testing the manual move of a SAPHana resource to another node
Use the following information to test the manual move of the SAPHana resource to another node.

Test2 - Description
Use cluster commands to move the primary instance to the other cluster node.

Test2 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false .
Check SAP HANA system replication status:
HANA system replication is activated and in sync.
The primary SAP HANA system runs on NODE2.
The secondary SAP HANA system runs on NODE1.
The tertiary SAP HANA system runs on NODE3 and is registered with NODE1.

Test2 - Test procedure
1. On NODE3, stop the tertiary HANA system before you perform the controlled move of the primary to NODE1.
$ sudo -i -u ${sid}adm -- HDB stop

2. On a cluster node, run the following command to move the primary back to NODE1.
$ pcs resource move SAPHana_${SID}_${INSTNO}-clone

3. Wait until the primary is up on NODE1. Then, register NODE2 with the primary on NODE1.
On NODE2, run the following command.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC2} \
--remoteHost=${NODE1} \
--remoteInstance=${INSTNO} \
--replicationMode=syncmem \
--operationMode=logreplay \
--online

4. On a cluster node, run the following commend to clear the resource.
$ pcs resource clear SAPHana_${SID}_${INSTNO}-clone

This command clears the location constraint, which was created by the move command. The cluster starts the SAP HANA system on
NODE2.
5. On NODE2, run the following command to enable this site as a system replication source system.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_enable

6. On NODE3, run the following command to register the system with NODE2.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC3} \
--remoteHost=${NODE2} \

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 500

--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

7. On NODE3, start the tertiary HANA system.
$ sudo -i -u ${sid}adm -- HDB start

8. Verify the system replication status on all three nodes as described in Checking the SAP HANA system replication status .

Test2 - Expected behavior
The cluster creates a location constraint to move the resource.
The cluster triggers a takeover to the secondary HANA system on NODE1.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
Register NODE2 with the primary on NODE1.
Run pcs resource clear command to remove the location constraint. This command triggers the start of the secondary instance on
NODE2.
After you register and start the HANA system on NODE3 at

SiteC , the tertiary HANA system is registered with NODE2.

Test2 - Recovery procedure
No recovery procedure is required. The test sequence reestablished the initial SAP HANA multitier system replication topology.

Test3 - Testing failure of node that runs the primary database
Use the following information to test the failure of node that runs the primary database.

Test3 - Description
Simulate a crash of the node that runs the primary HANA database.

Test3 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false .
Check SAP HANA system replication status:
HANA system replication is activated and in sync.
The primary SAP HANA system runs on NODE1.
The secondary SAP HANA system runs on NODE2.
The secondary SAP HANA system runs on NODE3 and is registered with NODE2.

Test3 - Test procedure
Crash the primary on NODE1 by sending a crash system request.
On NODE1, run the following command.
$ sync; echo c > /proc/sysrq-trigger

Test3 - Expected behavior
NODE1 shuts down.
The cluster detects the failed node and sets its state to OFFLINE .
The cluster promotes the secondary HANA database on NODE2 to take over as new primary.
The cluster acquires the virtual IP address on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
The tertiary SAP HANA system that runs on NODE3 is still registered with NODE2.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 501

Verify the SAP HANA system replication status on NODE2.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|

|Active Status |Mode

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |--------- |------------ |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|ASYNC

|HDB
|YES

|ASYNC

|HDB

|ACTIVE

|ASYNC

|ACTIVE

2 |SiteB
|

2 |

|

|cl-hdb-2 |30003 |indexserver

|YES

1 |

2 |SiteB

3 |

|

30001 |

3 |SiteC

|cl-hdb-3 |

30007 |

3 |SiteC

|cl-hdb-3 |

30003 |

3 |SiteC

True |

|

|

|cl-hdb-3 |

True |
2 |SiteB

|

True |

status system replication site "3": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 2
site name: SiteB

Test3 - Recovery procedure
Log in to the IBM Cloud® console and start NODE1.
1. On NODE1, run the following command to register the system with the primary on NODE2.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC1} \
--remoteHost=${NODE2} \
--remoteInstance=${INSTNO} \
--replicationMode=syncmem \
--operationMode=logreplay \
--online

2. On NODE1, run the following command to start the cluster services.
$ pcs cluster start

3. On a cluster node, run the following command to check the cluster status.
$ pcs status --full

4. On NODE2, verify the SAP HANA system replication status.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

Name |Active Status |Mode

|

|
|Status

|

|Secondary
|

|
|Host

|Port

|Site ID

|Site

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 502

|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|ASYNC

|HDB
|YES

|ASYNC

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES

|SYNCMEM

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|SYNCMEM

|ACTIVE

2 |

2 |SiteB

1 |
|
|

|

|cl-hdb-3 |

30007 |

3 |SiteC

|cl-hdb-3 |

30003 |

3 |SiteC

|cl-hdb-1 |

30001 |

1 |SiteA

|cl-hdb-1 |

30007 |

1 |SiteA

|cl-hdb-1 |

30003 |

1 |SiteA

True |
2 |SiteB

3 |

3 |SiteC

True |
2 |SiteB

2 |

30001 |

True |

|

|
|

2 |SiteB

3 |

|cl-hdb-3 |

True |

|

|
|

2 |SiteB
|

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|SYNCMEM

1 |

True |
2 |SiteB

|

True |

status system replication site "3": ACTIVE
status system replication site "1": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 2
site name: SiteB

5. Run the steps in Test1 - Recovery procedure to rebuild the SAP HANA system replication multitier topology for NODE3 at SiteC .
6. Run the steps in Test2 - Test the manual move of SAPHana resource to another node to revert to the initial topology.

Test4 - Testing failure of the secondary database instance
Use the following information to test the failure of the secondary database instance.

Test4 - Description
Simulate a crash of the secondary HANA database.

Test4 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false .
Check SAP HANA system replication status:
HANA system replication is active and in sync.
The primary SAP HANA system runs on NODE1.
The secondary SAP HANA system runs on NODE2.
The tertiary SAP HANA system runs on NODE3 and is registered with NODE2.

Test4 - Test procedure
Crash SAP HANA secondary by sending a SIGKILL signal as user ${sid}adm .
On NODE2, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test4 - Expected behavior
SAP HANA secondary on NODE2 crashes.
The cluster detects the stopped secondary HANA system and marks the resource as failed .
The cluster restarts the secondary HANA system.
The cluster detects that the system replication is in sync again.
The tertiary SAP HANA system that runs on NODE3 gets in sync again.
On NODE1, check the SAP HANA system replication status periodically to observe the recovery steps.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 503

$ watch -n 5 sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Secondary

|Replication |Replication |Replication

|

|

|

|Active Status

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary
|

|Mode

|
|Status

|Secondary

|

|

|Host

|Status Details

|Port

|
|Site ID

|Site Name

|Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |--------- |----------------- |----------- |----------- |--------------------------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver
|CONNECTION TIMEOUT |SYNCMEM
|HDB

|ERROR

|cl-hdb-1 |30007 |xsengine

|CONNECTION TIMEOUT |SYNCMEM
|HDB

|UNKNOWN

|UNKNOWN

|HDB

|UNKNOWN

|HDB

|UNKNOWN

2 |

|cl-hdb-2 |

1 |SiteA

|

3 |

1 |SiteA

|

1 |

2 |SiteB

|

2 |

|

3 |

2 |SiteB

False |
30003 |

2 |SiteB

False |
30001 |

3 |SiteC

|

30007 |

3 |SiteC

|

30003 |

3 |SiteC

|

False |

2 |SiteB

|cl-hdb-3 |
False |

2 |SiteB

|Site with id '2' is not reachable |

30007 |

|

|cl-hdb-3 |

2 |SiteB

False |

|

|cl-hdb-2 |

|Communication channel closed

30001 |

|

|cl-hdb-2 |

|Communication channel closed

|Site with id '2' is not reachable |

|cl-hdb-2 |30003 |indexserver

|UNKNOWN

1 |SiteA

|Site with id '2' is not reachable |

|cl-hdb-2 |30007 |xsengine

|UNKNOWN

|

|ERROR

|SYSTEMDB |cl-hdb-2 |30001 |nameserver

1 |

|Communication channel closed

|ERROR

|cl-hdb-1 |30003 |indexserver

|CONNECTION TIMEOUT |SYNCMEM

|

|cl-hdb-3 |
False |

status system replication site "2": ERROR
status system replication site "3": UNKNOWN
overall system replication status: ERROR
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

Test4 - Recovery procedure
Wait until the secondary HANA instance starts and synchronized again ( SOK ), then cleanup the failed resource actions that are shown in the
pcs status output.

1. On a cluster node, run the following command.
$ pcs resource refresh SAPHana_${SID}_${INSTNO}

2. Check the cluster status.
$ pcs status --full

Test5 - Testing DR activation on the node that runs the tertiary database
Use the following information to test the failure of both nodes in the primary workspace.

Test5 - Description
Simulate a crash of the nodes that run the primary and secondary SAP HANA database.

Test5 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Cluster Resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=false .
Check SAP HANA system replication status:
HANA system replication is active and in sync.
The primary SAP HANA system runs on NODE1.
The secondary SAP HANA system runs on NODE2.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 504

The tertiary SAP HANA system runs on NODE3 and is registered with NODE2.

Test5 - Test procedure
Crash primary on NODE1 and secondary on NODE2 by sending a crash system request on both nodes.
1. On NODE1, run the following command.
$ sync; echo c > /proc/sysrq-trigger

2. On NODE2, run the following command.
$ sync; echo c > /proc/sysrq-trigger

3. On NODE3, run the following command to activate the HANA system as the new primary.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_takeover

Sample output:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_takeover
done.

Test5 - Expected behavior
NODE1 and NODE2 halt immediately.
After the manual takeover, NODE3 runs the primary SAP HANA system.
An application, such as SAP NetWeaver, can connect to the SAP HANA system on NODE3.
On NODE3, run the following command to verify that the SAP HANA system runs as primary.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: primary
operation mode: primary
site id: 3
site name: SiteC
is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: false
is a takeover active: false
is primary suspended: false
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-3 -> [SiteC] cl-hdb-3

Site Mappings:
~~~~~~~~~~~~~~
SiteC (primary/primary)
Tier of SiteC: 1
Replication mode of SiteC: primary

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 505

Operation mode of SiteC: primary

Hint based routing site:
done.

Test5 - Recovery procedure
The recovery procedure after a takeover to the tertiary SAP HANA system is complex and is documented as a separate test in the

Test6 section.

Test6 - Restoring the original SAP HANA multitier system replication topology
Use the following information to revert to the original system replication topology after a takeover to the tertiary SAP HANA system.
Check the following SAP documentation.
Restore the Original SAP HANA Multitier System Replication Configuration

Test6 - Description
Reactivate the cluster in the primary workspace and restore the original system replication topology.

Test6 - Prerequisites
A two-node RHEL HA Add-On cluster for HANA system replication in the primary workspace.
Both virtual server instances of the cluster are stopped.
The primary SAP HANA system runs on NODE3.

Test6 - Test procedure
1. Log in to the IBM Cloud® console and start both NODE1 and NODE2.
2. Wait until both nodes are available again.
3. Ensure that the Red Hat HA Add-On cluster services are stopped on both cluster nodes NODE1 and NODE2.
4. On NODE3, verify that SAP HANA system replication is enabled.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

5. On NODE1, run the following command to set an environment variable with the hostname of NODE3.
$ export NODE3=<Hostname 3>

# Hostname of virtual server instance 3 (production tertiary)

6. On NODE1, run the following command to register the SAP HANA system with the primary on NODE3.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC1} \
--remoteHost=${NODE3} \
--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

7. On NODE1, check the system replication configuration.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output:
$
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: false
mode: async
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 506

operation mode: unknown
site id: 1
site name: SiteA
is source system: unknown
is secondary/consumer system: true
has secondaries/consumers attached: unknown
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 3
primary masters: cl-hdb-3
done.

8. On NODE1, start the SAP HANA system to start the system replication.
$ sudo -i -u ${sid}adm -- HDB start

9. On NODE3, check the system replication status and wait until the secondary on NODE1 is fully synchronized.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

|

Name |Active Status |Mode

|Status

|

|Secondary

|

|Host

|
|Port

|Site ID

|Site

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-3 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-3 |30007 |xsengine

|

|HDB

|ASYNC

|YES
|HDB

|ASYNC

|ACTIVE

|cl-hdb-3 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

1 |
|
2 |

|
|

3 |SiteC

|

|

|

30001 |

1 |SiteA

|cl-hdb-1

|

30007 |

1 |SiteA

|cl-hdb-1

|

30003 |

1 |SiteA

True |
3 |SiteC

3 |

|cl-hdb-1

True |
3 |SiteC

|

True |

status system replication site "1": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 3
site name: SiteC

Important: You need a downtime window to perform the move of the primary role back to NODE1. All application servers that are
connected to NODE3 must be stopped.
A takeover with handshake suspends all transactions on the primary system on NODE3 and the takeover is only executed when all remaining
redo log is available on NODE1.
1. On NODE1, run the following command to takeover the primary role.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_takeover --suspendPrimary

2. On NODE1, check that the HANA system runs as primary.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

3. On NODE3, run the following command to verify the system replication status.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 507

$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|

|

Name |Active Status |Mode

|Status

|Secondary

|

|

|Host

|Status Details

|

|Port

|Site ID

|Site

|Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------------------------- |------------ |
|SYSTEMDB |cl-hdb-3 |30001 |nameserver

|

|PRIMARY

|IS PRIMARY (e.g. after takeover) |

|HDB

|

|

|cl-hdb-3 |30007 |xsengine

|PRIMARY
|HDB

|

|

|

|

3 |SiteC

2 |

|cl-hdb-1 |

3 |SiteC

|

|

3 |

30001 |

|cl-hdb-1 |

3 |SiteC

1 |

False |

|IS PRIMARY (e.g. after takeover) |

|cl-hdb-3 |30003 |indexserver

|PRIMARY

1 |

30007 |

1 |

False |

|cl-hdb-1 |

|IS PRIMARY (e.g. after takeover) |

30003 |

1 |

False |

status system replication site "1": ERROR
overall system replication status: ERROR
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 3
site name: SiteC

The following summary shows the status after these steps.
NODE1 runs as primary, but no application is connected.
NODE2 is up, but SAP HANA is not started.
NODE3 is up and SAP HANA is blocked in suspendPrimary mode.
Red Hat HA Add-On cluster services are stopped on NODE1 and NODE2.
1. On NODE2, run the following command to register with the primary on NODE1.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC2} \
--remoteHost=${NODE1} \
--remoteInstance=${INSTNO} \
--replicationMode=syncmem \
--operationMode=logreplay \
--online

2. On NODE2, start SAP HANA to start the replication.
$ sudo -i -u ${sid}adm -- HDB start

3. On NODE1, check the system replication status and wait until the secondary on NODE2 is fully synchronized.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

Name |Active Status |Mode

|
|Status

|

|Secondary

|

|Host

|
|Port

|Site ID

|Site

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-1 |30007 |xsengine

|

|HDB
|YES
|HDB
|YES

|SYNC
|SYNC

|ACTIVE

|cl-hdb-1 |30003 |indexserver
|SYNC

|ACTIVE

1 |
|
2 |

|
|
|

1 |SiteA

3 |

30001 |

2 |SiteB

|cl-hdb-2

|

30007 |

2 |SiteB

|cl-hdb-2

|

30003 |

2 |SiteB

True |
1 |SiteA

|

|

True |
1 |SiteA

|

|cl-hdb-2

True |
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 508

status system replication site "2": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

The following summary shows the status after these steps.
NODE1 runs as primary, but no application is connected.
NODE2 runs as secondary.
NODE3 is up and SAP HANA is blocked in suspendPrimary mode.
Red Hat HA Add-On cluster services are stopped on NODE1 and NODE2.
1. On a cluster node, run the following command to start the cluster.
$ pcs cluster start --all

2. Check the cluster status and verify that it is fully operational again.
$ pcs status --full

The following summary shows the status after these steps.
NODE1 runs as primary.
NODE2 runs as secondary.
Red Hat HA Add-On cluster services are started and the cluster manages SAP HANA system replication on NODE1 and NODE2.
NODE3 is up and SAP HANA is blocked in suspendPrimary mode.
1. On NODE2, run the following command to enable it as system replication source site.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_enable

Sample output:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_enable
nameserver is active, proceeding ...
successfully enabled system as system replication source site
done.

2. On NODE2, check the system replication configuration.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output:
$ # sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: sync
operation mode: logreplay
site id: 2
site name: SiteB
is source system: true
is secondary/consumer system: true
has secondaries/consumers attached: false
is a takeover active: false
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 509

is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 1
primary masters: cl-hdb-1
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-2 -> [SiteB] cl-hdb-2
cl-hdb-2 -> [SiteA] cl-hdb-1

Site Mappings:
~~~~~~~~~~~~~~
SiteA (primary/primary)
|---SiteB (sync/logreplay)
Tier of SiteA: 1
Tier of SiteB: 2
Replication mode of SiteA: primary
Replication mode of SiteB: sync
Operation mode of SiteA: primary
Operation mode of SiteB: logreplay
Mapping: SiteA -> SiteB
Hint based routing site:
done.

3. On NODE3, run the following command to register the system with NODE2.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC3} \
--remoteHost=${NODE2} \
--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

4. On NODE1, run the following command to verify the new SAP HANA system replication topology.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

The SAP HANA system on NODE3 at SiteC reappears in the SAP HANA system replication topology. When you run the

hdbnsutil -

sr_register command, the system stops and CONNECTION TIMEOUT is shown in the output.

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Secondary

|Replication |Replication |Replication

|

|

Name |Active Status

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary |Secondary

|

|

|

|Mode

|Status

|

|Secondary
|

|
|Host

|Port

|Site ID

|Site

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |-------- |------------------ |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver
|YES

|SYNCMEM

|HDB

|cl-hdb-1 |30007 |xsengine

|YES

|SYNCMEM

|HDB

|cl-hdb-1 |30003 |indexserver

|YES

|SYNCMEM

|HDB

|

2 |

|
|

|UNKNOWN

1 |SiteA
|

1 |
|

|

1 |SiteA
|

3 |

|

1 |SiteA
|

|

|ACTIVE

|cl-hdb-2 |30007 |xsengine

1 |
|

|ACTIVE

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|CONNECTION TIMEOUT |ASYNC

|

|ACTIVE

2 |SiteB
|

2 |

2 |SiteB

|cl-hdb-2 |

30001 |

2 |SiteB

30007 |

2 |SiteB

30003 |

2 |SiteB

30001 |

3 |SiteC

30007 |

3 |SiteC

True |
|cl-hdb-2 |
True |
|cl-hdb-2 |
True |
|cl-hdb-3 |
False |
|cl-hdb-3 |

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 510

|CONNECTION TIMEOUT |ASYNC
|HDB

|UNKNOWN

|cl-hdb-2 |30003 |indexserver

|CONNECTION TIMEOUT |ASYNC

|
|

|UNKNOWN

|
3 |

False |

2 |SiteB

|

|

|cl-hdb-3 |

30003 |

3 |SiteC

False |

status system replication site "2": ACTIVE
status system replication site "3": UNKNOWN
overall system replication status: UNKNOWN
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

5. On NODE3, run the following command to start the tertiary HANA system.
$ sudo -i -u ${sid}adm -- HDB start

The following summary shows the final status after these steps.
NODE1 runs as primary.
NODE2 runs as secondary.
Red Hat HA Add-On cluster services are started and the cluster manages SAP HANA system replication on NODE1 and NODE2.
NODE3 runs as tertiary.
On NODE1, run the following command to verify the SAP HANA system replication topology.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|Active Status |Mode

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |---------|----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |--------|------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-1 |30007 |xsengine

|

|HDB

|SYNC

|YES
|HDB

|SYNC

|ACTIVE

|cl-hdb-1 |30003 |indexserver

|YES

|SYNC

|ACTIVE

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES
|HDB

|ASYNC

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

2 |
3 |
1 |
2 |

|
|
|

3 |

|cl-hdb-2

|

30007 |

2 |SiteB

|cl-hdb-2

|

30003 |

2 |SiteB

|cl-hdb-3

|

30001 |

3 |SiteC

|cl-hdb-3

|

30007 |

3 |SiteC

|cl-hdb-3

|

30003 |

3 |SiteC

True |
2 |SiteB

|

2 |SiteB

True |
2 |SiteB

|

30001 |

True |
2 |SiteB

|

|

True |
1 |SiteA

|

|cl-hdb-2

True |
1 |SiteA

|

|
|

1 |SiteA
|

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|ASYNC

1 |

True |

status system replication site "2": ACTIVE
status system replication site "3": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

sap-power-virtual-server-ha-rhel-hana-sr-multitarget.md

Configuring SAP HANA Multitarget System Replication in a RHEL HA Add-On
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 511

cluster
The following information describes the configuration of a Red Hat Enterprise Linux (RHEL) HA add-on cluster for managing SAP HANA&reg
system replication in a multitarget replication scenario. The cluster uses virtual server instances in IBM® Power® Virtual Server as cluster
nodes.
You can connect multiple systems in an SAP HANA multitarget system replication topology to achieve a higher level of availability. A third SAP
HANA instance runs on a virtual server instance in IBM Power Virtual Server in another workspace. The resource agents for SAP HANA in the
Red Hat Enterprise Linux 8 (RHEL) HA add-on require that the third SAP HANA instance is managed manually and is installed on a virtual server
instance outside the cluster.
In a multitarget system replication scenario, one secondary SAP HANA system runs on a virtual server instance in the cluster and another
secondary HANA system runs on a virtual server instance that is deployed in a Disaster Recovery (DR) site . The DR site is implemented in a
different IBM Power Virtual Server workspace in another geographical location or zone. The SAP HANA system replication operation mode
must be identical for all multitarget replication levels.
A takeover of the secondary system in the DR site must be triggered manually.
Note: This information is intended for architects and specialists that are planning a high-availability deployment of SAP HANA on Power
Virtual Server.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Prerequisites
A Red Hat High Availability cluster is deployed on two virtual server instances in one workspace in Power Virtual Server. Follow the
instructions in the following documents.
Implementing a RHEL HA Add-On cluster on Power Virtual Server .
Configuring SAP HANA Scale-Up System Replication in a RHEL HA Add-On cluster .
A third virtual server instance is deployed in another workspace in Power Virtual Server.
SAP HANA is installed on the third virtual server instance with the same

SID and Instance Number .

Optional - you can reserve a virtual IP address for the system on NODE3 as described in

Reserving virtual IP addresses. Assigning and

unassigning this virtual IP address on NODE3 is a manual task and not part of a cluster operation.

Setting up a multitarget scenario
A multitarget scenario is an extension of the setup that is described in Configuring SAP HANA Scale-Up System Replication in a RHEL HA AddOn cluster. Make sure that you complete the setup for the system replication cluster before you continue with the following steps.
To simplify the cluster operations, you can set the AUTOMATED_REGISTER cluster attribute of the SAPHana resource to true . With
AUTOMATED_REGISTER=true , the cluster performs an automatic registration of the previous primary as a new secondary after the failed node

reappears in the cluster.
On a cluster node, run the following command to verify the AUTOMATED_REGISTER cluster attribute of the resource.
$ pcs resource config SAPHana_${SID}_${INSTNO}

Sample output:
# pcs resource config SAPHana_${SID}_${INSTNO}
Resource: SAPHana_HDB_00 (class=ocf provider=heartbeat type=SAPHana)
Attributes: AUTOMATED_REGISTER=true DUPLICATE_PRIMARY_TIMEOUT=900 InstanceNumber=00 PREFER_SITE_TAKEOVER=True SID=HDB
Operations: demote interval=0s timeout=3600 (SAPHana_HDB_00-demote-interval-0s)
methods interval=0s timeout=5 (SAPHana_HDB_00-methods-interval-0s)
monitor interval=121 role=Slave timeout=700 (SAPHana_HDB_00-monitor-interval-121)
monitor interval=119 role=Master timeout=700 (SAPHana_HDB_00-monitor-interval-119)
promote interval=0s timeout=3600 (SAPHana_HDB_00-promote-interval-0s)
reload interval=0s timeout=5 (SAPHana_HDB_00-reload-interval-0s)
start interval=0s timeout=3600 (SAPHana_HDB_00-start-interval-0s)
stop interval=0s timeout=3600 (SAPHana_HDB_00-stop-interval-0s)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 512

If the AUTOMATED_REGISTER cluster attribute is currently set to false , use the following command to enable the automatic registration.
$ pcs resource update SAPHana_${SID}_${INSTNO} AUTOMATED_REGISTER=true

Providing network connectivity between the workspaces
1. Use the information in Creating the workspace to create another workspace in a different geographic location or region.
2. Create subnets and make sure that the IP ranges don't overlap with any subnet of the workspace that hosts the virtual server instances
for the cluster. For more information, see Creating subnets.
3. Set up IBM Cloud® connections up in both workspaces and activate Enable IBM Transit Gateway . For more information, see Creating
IBM Cloud® connections.
4. Deploy an IBM Cloud® Transit Gateway to interconnect the two IBM Power Virtual Server workspaces.
Note: IBM Cloud® Transit Gateway enables the interconnection of IBM Power Virtual Server, IBM Cloud® classic, and Virtual
Private Cloud (VPC) infrastructures and keeps data within the IBM Cloud® networks. For more information about planning and
deploying IBM Cloud® Transit Gateway, see Planning for IBM Cloud® Transit Gateway and Ordering IBM Cloud® Transit Gateway .
5. To add the connections to your transit gateway to establish network connectivity between your IBM Power Virtual Server, open IBM
Cloud console and log in to your account.
6. Select the Menu icon

on the upper left and click Interconnectivity.

7. Click Transit Gateway on the left navigation pane.
8. Select the name of your transit gateway.
Tip: In the expanded view, click View details.
9. Click Add connection.
10. Choose and configure the specific network connections that you want to add to the transit gateway.
11. Choose Direct Link, and select the names of your IBM Cloud® connections.
12. Click Add to create a connection.

Preparing environment variables on NODE3
To simplify the setup, prepare the following environment variables for user ID root on NODE3. These environment variables are used in
subsequent commands in the remainder of the instructions.
On NODE3, create a file with the following environment variables. Then, adapt the variables according to the configuration of your SAP HANA
system.
export SID=<SID>

# SAP HANA System ID (uppercase)

export sid=<sid>

# SAP HANA System ID (lowercase)

export INSTNO=<INSTNO>

# SAP HANA Instance Number

export DC3=<Site3>

# HANA System Replication Site Name 3

export NODE1=<Hostname 1>

# Hostname of virtual server instance 1 (production primary)

export NODE2=<Hostname 2>

# Hostname of virtual server instance 2 (production secondary)

export NODE3=<Hostname 3>

# Hostname of virtual server instance 3 (production tertiary)

You must source this file before you can use the sample commands in the remainder of this document.
For example, if you created a file that is named sap_dr_site.sh , run the following command on NODE3 to set the environment variables.
$ source sap_dr_site.sh

Important: Every time that you start a new terminal session, you must run the previous

source command. Alternatively, you can move

the environment variables file to the /etc/profile.d directory for the duration of the cluster configuration. In this example, the file is
sourced automatically each time you log in to the server.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 513

Verifying network connectivity between the virtual server instances
Verify the network connectivity between the two cluster nodes (NODE1 and NODE2) and NODE3.
1. Log in to both NODE1 and NODE2, and ping NODE3.
$ ping -c 3 ${NODE3}

Sample output:
# ping -c 3 cl-hdb-3
PING cl-hdb-3 (10.40.20.70) 56(84) bytes of data.
64 bytes from 10.40.20.70 (10.40.20.70): icmp_seq=1 ttl=46 time=78.2 ms
64 bytes from 10.40.20.70 (10.40.20.70): icmp_seq=2 ttl=46 time=78.3 ms
64 bytes from 10.40.20.70 (10.40.20.70): icmp_seq=3 ttl=46 time=78.2 ms
--- cl-hdb-3 ping statistics --3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 78.197/78.233/78.264/0.027 ms

2. Log in to NODE3 and ping NODE1.
$ ping -c 3 ${NODE1}

Sample output:
# ping -c 3 cl-hdb-1
PING cl-hdb-1 (10.40.10.60) 56(84) bytes of data.
64 bytes from cl-hdb-1 (10.40.10.60): icmp_seq=1 ttl=46 time=78.3 ms
64 bytes from cl-hdb-1 (10.40.10.60): icmp_seq=2 ttl=46 time=78.2 ms
64 bytes from cl-hdb-1 (10.40.10.60): icmp_seq=3 ttl=46 time=78.3 ms
--- cl-hdb-1 ping statistics --3 packets transmitted, 3 received, 0% packet loss, time 2002ms
rtt min/avg/max/mdev = 78.245/78.268/78.287/0.229 ms

3. Log in to NODE3 and ping NODE2.
$ ping -c 3 ${NODE2}

Sample output:
# ping -c 3 cl-hdb-2
PING cl-hdb-2 (10.40.10.194) 56(84) bytes of data.
64 bytes from cl-hdb-2 (10.40.10.194): icmp_seq=1 ttl=46 time=77.6 ms
64 bytes from cl-hdb-2 (10.40.10.194): icmp_seq=2 ttl=46 time=79.1 ms
64 bytes from cl-hdb-2 (10.40.10.194): icmp_seq=3 ttl=46 time=77.7 ms
--- cl-hdb-2 ping statistics --3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 77.649/78.129/79.071/0.703 ms

Copying PKI SSFS storage certificate files to NODE3
The SAP HANA 2.0 data and log transmission channels for the replication process require authentication by using the system PKI SSFS storage
certificate files.
2369981 - Required configuration steps for authentication with HANA System Replication )
The system PKI SSFS storage certificate files are stored in /usr/sap/${SID}/SYS/global/security/rsecssfs/ in subdirectories data and
key .

On NODE3, run the following commands to copy files SSFS_${SID}.DAT and SSFS_${SID}.KEY from NODE1.
$ scp ${NODE1}:/usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 514

/usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT

$ scp ${NODE1}:/usr/sap/${SID}/SYS/global/security/rsecssfs/key/SSFS_${SID}.KEY
/usr/sap/${SID}/SYS/global/security/rsecssfs/key/SSFS_${SID}.KEY

The copied PKI SSFS storage certificates on NODE3 become active during the start of the SAP HANA system. Therefore, it is recommended to
copy the files when the SAP HANA system on NODE3 is stopped.

Registering NODE3 as a secondary SAP HANA DR system replication system
Register the SAP HANA system as a secondary DR system replication instance.
1. On NODE3, stop the SAP HANA system.
$ sudo -i -u ${sid}adm -- HDB stop

2. On NODE3, register the secondary SAP HANA instance with NODE1.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC3} \
--remoteHost=${NODE1} \
--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

3. On NODE3, start the secondary SAP HANA instance.
$ sudo -i -u ${sid}adm -- HDB start

Checking the SAP HANA system replication status
You can monitor the system replication status by using the following tools.
SAP HANA cockpit
SAP HANA studio
hdbnsutil command-line tool
systemReplicationStatus.py Python script

SQL queries
The full output of the systemReplicationStatus.py script is available on only the primary system, as a database connection is required to
obtain some of the status information.
On NODE1, check the system replication status by using the systemReplicationStatus.py Python script.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
# sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|Active Status |Mode

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |--------|------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-1 |30007 |xsengine

|

|HDB
|YES
|HDB
|YES

|ASYNC
|ASYNC

|ACTIVE

|cl-hdb-1 |30003 |indexserver
|ASYNC

|ACTIVE

|

|YES

|

|ACTIVE

2 |
|

1 |

30001 |

3 |SiteC

|cl-hdb-3

|

30007 |

3 |SiteC

|cl-hdb-3

|

30003 |

3 |SiteC

|cl-hdb-2

|

30001 |

2 |SiteB

True |
1 |SiteA

|

|

True |
1 |SiteA

|

|cl-hdb-3

True |
1 |SiteA

3 |

|
|

1 |SiteA
|

|

|SYSTEMDB |cl-hdb-1 |30001 |nameserver
|SYNCMEM

1 |

True |

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 515

|HDB

|cl-hdb-1 |30007 |xsengine

|YES

|SYNCMEM

|HDB

|ACTIVE

|cl-hdb-1 |30003 |indexserver

|YES

|SYNCMEM

|ACTIVE

|

2 |

|
|
|

1 |SiteA
|

3 |

|cl-hdb-2

|

30007 |

2 |SiteB

|cl-hdb-2

|

30003 |

2 |SiteB

True |
1 |SiteA

|

True |

status system replication site "3": ACTIVE
status system replication site "2": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

An alternative view of the system replication status is available with the

hdbnsutil command.

On all nodes, run the following command to check the system replication status.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output on NODE1:
# sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: primary
operation mode: primary
site id: 1
site name: SiteA
is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: true
is a takeover active: false
is primary suspended: false
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-1 -> [SiteC] cl-hdb-3
cl-hdb-1 -> [SiteB] cl-hdb-2
cl-hdb-1 -> [SiteA] cl-hdb-1

Site Mappings:
~~~~~~~~~~~~~~
SiteA (primary/primary)
|---SiteC (async/logreplay)
|---SiteB (syncmem/logreplay)
Tier of SiteA: 1
Tier of SiteC: 2
Tier of SiteB: 2
Replication mode of SiteA: primary
Replication mode of SiteC: async
Replication mode of SiteB: syncmem
Operation mode of SiteA: primary
Operation mode of SiteC: logreplay
Operation mode of SiteB: logreplay
Mapping: SiteA -> SiteC
Mapping: SiteA -> SiteB
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 516

Hint based routing site:
done.

Sample output on NODE2:
# sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: syncmem
operation mode: logreplay
site id: 2
site name: SiteB
is source system: true
is secondary/consumer system: true
has secondaries/consumers attached: false
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 1
primary masters: cl-hdb-1
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-2 -> [SiteC] cl-hdb-3
cl-hdb-2 -> [SiteB] cl-hdb-2
cl-hdb-2 -> [SiteA] cl-hdb-1

Site Mappings:
~~~~~~~~~~~~~~
SiteA (primary/primary)
|---SiteC (async/logreplay)
|---SiteB (syncmem/logreplay)
Tier of SiteA: 1
Tier of SiteC: 2
Tier of SiteB: 2
Replication mode of SiteA: primary
Replication mode of SiteC: async
Replication mode of SiteB: syncmem
Operation mode of SiteA: primary
Operation mode of SiteC: logreplay
Operation mode of SiteB: logreplay
Mapping: SiteA -> SiteC
Mapping: SiteA -> SiteB
Hint based routing site:
done.

Sample output on NODE3:
# sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 517

mode: async
operation mode: logreplay
site id: 3
site name: SiteC
is source system: false
is secondary/consumer system: true
has secondaries/consumers attached: false
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 1
primary masters: cl-hdb-1
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-3 -> [SiteC] cl-hdb-3
cl-hdb-3 -> [SiteB] cl-hdb-2
cl-hdb-3 -> [SiteA] cl-hdb-1

Site Mappings:
~~~~~~~~~~~~~~
SiteA (primary/primary)
|---SiteC (async/logreplay)
|---SiteB (syncmem/logreplay)
Tier of SiteA: 1
Tier of SiteC: 2
Tier of SiteB: 2
Replication mode of SiteA: primary
Replication mode of SiteC: async
Replication mode of SiteB: syncmem
Operation mode of SiteA: primary
Operation mode of SiteC: logreplay
Operation mode of SiteB: logreplay
Mapping: SiteA -> SiteC
Mapping: SiteA -> SiteB
Hint based routing site:
done.
done.

On all nodes, run the following command to check the replication mode and the operation mode.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_state \
--sapcontrol=1 2>/dev/null | grep -E "site(Operation|Replication)Mode"

Sample output:
# sudo -i -u ${sid}adm -- hdbnsutil -sr_state --sapcontrol=1 2>/dev/null | grep -E "site(Operation|Replication)Mode"
siteReplicationMode/SiteA=primary
siteReplicationMode/SiteB=syncmem
siteOperationMode/SiteA=primary
siteOperationMode/SiteB=logreplay

Enabling automatic registration of secondaries after a takeover
In multitarget replication scenarios, SAP HANA can automatically reregister the secondaries that were previously registered before a takeover.
To enable this feature, set the parameter register_secondaries_on_takeover in the [system_replication] section in the global.ini
file to true . After a failover of an SAP HANA primary system to a secondary, the other secondary system reregisters automatically to the new

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 518

primary system.
This option must be added to the global.ini file on all potential primary sites.
On all three nodes, run the following command to change the parameter.
$ sudo -i -u ${sid}adm -- <<EOT
python \$DIR_INSTANCE/exe/python_support/setParameter.py \
-set SYSTEM/global.ini/system_replication/register_secondaries_on_takeover=true
EOT

Verify the [system_replication] section in the global.ini configuration file.
$ cat /hana/shared/${SID}/global/hdb/custom/config/global.ini

Testing the SAP HANA system replication cluster
It is vital to thoroughly test the cluster configuration to make sure that the cluster is working correctly. The following information provides a few
sample failover test scenarios, but is not a complete list of test scenarios.
For example, the description of each test case includes the following information.
Component that is tested
Description of the test
Prerequisites and the initial state before the failover test
Test procedure
Expected behavior and results
Recovery procedure

Test1 - Testing the failure of the primary database instance
Use the following information to test the failure of the primary database instance.

Test1 - Description
Simulate a crash of the primary SAP HANA database instance that runs on NODE1.

Test1 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
The cluster is started on NODE1 and NODE2.
The cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA system replication status:
SAP HANA multitarget system replication is activated and in sync.
The primary SAP HANA system runs on NODE1.
The secondary SAP HANA system runs on NODE2.
Another secondary SAP HANA system runs on NODE3 at the DR site and is registered with NODE1.
Check the current system replication status on NODE1.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
# sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|Active Status |Mode

|

|

|
|Status

|

|Secondary

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |--------|------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

1 |

1 |SiteA

|cl-hdb-3

|

30001 |

3 |SiteC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 519

|YES

|ASYNC

|HDB

|ACTIVE

|

|cl-hdb-1 |30007 |xsengine

|

|YES

|ASYNC

|HDB

|ACTIVE

|cl-hdb-1 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|YES

|SYNCMEM

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|SYNCMEM

|ACTIVE

1 |SiteA

3 |

1 |SiteA

1 |
|
|

|

30007 |

3 |SiteC

|cl-hdb-3

|

30003 |

3 |SiteC

|cl-hdb-2

|

30001 |

2 |SiteB

|cl-hdb-2

|

30007 |

2 |SiteB

|cl-hdb-2

|

30003 |

2 |SiteB

True |
2 |SiteA

3 |

|

True |
2 |SiteA

2 |

|cl-hdb-3

True |

|

|
|

True |

|

|
|

|HDB

2 |

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|SYNCMEM

|

True |
2 |SiteA

|

True |

status system replication site "3": ACTIVE
status system replication site "2": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

Test1 - Test procedure
Crash SAP HANA primary by sending a SIGKILL signal as user ${sid}adm .
On NODE1, run the following command.
$ sudo -i -u ${sid}adm -- HDB kill-9

Test1 - Expected behavior
The SAP HANA primary instance on NODE1 crashes.
The cluster detects the stopped primary and marks the resource as undefined .
The cluster promotes the secondary SAP HANA system on NODE2, which takes over as primary.
The cluster releases the virtual IP address on NODE1, and acquires it on the primary on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
The secondary HANA system that runs on NODE3 at the DR site is automatically reregistered to the new primary that runs on NODE2.
The cluster waits until the primary on NODE2 is fully active and registers the failed instance on NODE1 as a secondary.
The cluster starts the secondary HANA instance on NODE1.
On NODE1, run the following command to check the cluster status.
$ pcs status --full

Sample output:
pcs status --full
Cluster name: HDB_cluster
Cluster Summary:
* Stack: corosync
* Current DC: cl-hdb-1 (1) (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Mon Oct

9 10:46:59 2023

* Last change:

9 10:46:54 2023 by root via crm_attribute on cl-hdb-2

Mon Oct

* 2 nodes configured
* 6 resource instances configured
Node List:
* Online: [ cl-hdb-1 (1) cl-hdb-2 (2) ]
Full List of Resources:
* res_fence_ibm_powervs
* vip_HDB_00_primary

(stonith:fence_ibm_powervs):

(ocf::heartbeat:IPaddr2):

Started cl-hdb-1

Started cl-hdb-2

* Clone Set: SAPHanaTopology_HDB_00-clone [SAPHanaTopology_HDB_00]:
* SAPHanaTopology_HDB_00

(ocf::heartbeat:SAPHanaTopology):

Started cl-hdb-1

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 520

* SAPHanaTopology_HDB_00

(ocf::heartbeat:SAPHanaTopology):

Started cl-hdb-2

* Clone Set: SAPHana_HDB_00-clone [SAPHana_HDB_00] (promotable):
* SAPHana_HDB_00

(ocf::heartbeat:SAPHana):

Slave cl-hdb-1

* SAPHana_HDB_00

(ocf::heartbeat:SAPHana):

Master cl-hdb-2

Node Attributes:
* Node: cl-hdb-1 (1):
* hana_hdb_clone_state

: DEMOTED

* hana_hdb_op_mode

: logreplay

* hana_hdb_remoteHost

: cl-hdb-2

* hana_hdb_roles

: 4:S:master1:master:worker:master

* hana_hdb_site

: SiteA

* hana_hdb_sra

: -

* hana_hdb_srah

: -

* hana_hdb_srmode

: syncmem

* hana_hdb_sync_state

: SOK

* hana_hdb_version

: 2.00.070.00

* hana_hdb_vhost

: cl-hdb-1

* lpa_hdb_lpt

: 30

* master-SAPHana_HDB_00

: 100

* Node: cl-hdb-2 (2):
* hana_hdb_clone_state

: PROMOTED

* hana_hdb_op_mode

: logreplay

* hana_hdb_remoteHost

: cl-hdb-1

* hana_hdb_roles

: 4:P:master1:master:worker:master

* hana_hdb_site

: SiteB

* hana_hdb_sra

: -

* hana_hdb_srah

: -

* hana_hdb_srmode

: syncmem

* hana_hdb_sync_state

: PRIM

* hana_hdb_version

: 2.00.070.00

* hana_hdb_vhost

: cl-hdb-2

* lpa_hdb_lpt

: 1696841214

* master-SAPHana_HDB_00

: 150

Migration Summary:
* Node: cl-hdb-1 (1):
* SAPHana_HDB_00: migration-threshold=5000 fail-count=1 last-failure='Mon Oct

9 10:39:58 2023'

Failed Resource Actions:
* SAPHana_HDB_00_monitor_119000 on cl-hdb-1 'master (failed)' (9): call=31, status='complete', exitreason='', lastrc-change='2023-10-09 10:39:58 +02:00', queued=0ms, exec=0ms
Tickets:
PCSD Status:
cl-hdb-1: Online
cl-hdb-2: Online
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

On NODE2, run the following command to check the system replication status.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
# sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|Active Status |Mode

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |--------|------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB

|ASYNC

1 |

2 |SiteB
|

2 |

|cl-hdb-3

|

30001 |

3 |SiteC

|cl-hdb-3

|

30007 |

3 |SiteC

True |
2 |SiteB

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 521

|YES

|ASYNC

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

|
|
|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES

|SYNCMEM

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|SYNCMEM

|ACTIVE

3 |

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|SYNCMEM

|

2 |SiteB
|

1 |

2 |SiteB

2 |
|

|

|

30003 |

3 |SiteC

|cl-hdb-1

|

30001 |

1 |SiteA

|cl-hdb-1

|

30007 |

1 |SiteA

|cl-hdb-1

|

30003 |

1 |SiteA

True |
2 |SiteB

3 |

|cl-hdb-3

True |

|

|
|

True |

True |
2 |SiteB

|

True |

status system replication site "3": ACTIVE
status system replication site "1": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 2
site name: SiteB

The SAP HANA primary runs on NODE2 at SiteB . The secondary on NODE3 is automatically reregistered to the new primary that runs on
NODE2. As the cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true , the cluster registers the SAP
HANA system on NODE1 automatically as a secondary to the primary on NODE2.

Test2 - Testing the manual move of a SAPHana resource to another node
Use the following information to test the manual move of the SAPHana resource to another node.

Test2 - Description
Use cluster commands to move the primary instance to the other cluster node.

Test2 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
The cluster is started on NODE1 and NODE2.
The cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA system replication status:
HANA system replication is activated and in sync.
The primary SAP HANA system runs on NODE2.
The secondary SAP HANA system runs on NODE1.
Another secondary SAP HANA system runs on NODE3 at the DR site and is registered with NODE2.

Test2 - Test procedure
1. On a cluster node, run the following command to move the primary back to NODE1.
$ pcs resource move SAPHana_${SID}_${INSTNO}-clone

Sample output:
# pcs resource move SAPHana_${SID}_${INSTNO}-clone
Warning: Creating location constraint 'cli-ban-SAPHana_HDB_00-clone-on-cl-hdb-2' with a score of -INFINITY for
resource SAPHana_HDB_00-clone on cl-hdb-2.
This will prevent SAPHana_HDB_00-clone from running on cl-hdb-2 until the constraint is removed
This will be the case even if cl-hdb-2 is the last node in the cluster

After the primary is active on NODE1, SAP HANA automatically reregisters the instance on NODE3 as a secondary to NODE1.
2. Wait until the primary is up on NODE1. Then, remove the location constraint.
$ pcs resource clear SAPHana_${SID}_${INSTNO}-clone

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 522

Sample output:
# pcs resource clear SAPHana_${SID}_${INSTNO}-clone
Removing constraint: cli-ban-SAPHana_HDB_00-clone-on-cl-hdb-2

This command clears the location constraint that was created by the move command. The cluster starts the SAP HANA system on
NODE2.
3. Verify the system replication status on all three nodes as described in Checking the SAP HANA system replication status .

Test2 - Expected behavior
The cluster creates a location constraint to move the resource.
The cluster triggers a takeover to the secondary HANA system on NODE1.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
Register NODE2 with the primary on NODE1.
Run pcs resource clear command to remove the location constraint. This command triggers the start of the secondary instance on
NODE2.
The secondary HANA system that runs on NODE3 at the DR site is automatically reregistered to the new primary that runs on NODE1.

Test2 - Recovery procedure
No recovery procedure is required. The test sequence reestablished the initial SAP HANA multitarget system replication topology.

Test3 - Testing failure of node that runs the primary database
Use the following information to test the failure of the node that runs the primary database.

Test3 - Description
Simulate a crash of the node that runs the primary HANA database.

Test3 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
The cluster is started on NODE1 and NODE2.
The cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA system replication status:
HANA system replication is activated and in sync.
The primary SAP HANA system runs on NODE1.
The secondary SAP HANA system runs on NODE2.
Another secondary SAP HANA system runs on NODE3 at the DR site and is registered with NODE1.

Test3 - Test procedure
Crash the primary on NODE1 by sending a crash system request.
On NODE1, run the following command.
$ sync; echo c > /proc/sysrq-trigger

Test3 - Expected behavior
NODE1 crashes.
The cluster detects the failed node and sets its state to OFFLINE .
The cluster promotes the secondary HANA database on NODE2 to take over as the new primary.
The cluster acquires the virtual IP address on NODE2.
If an application, such as SAP NetWeaver, is connected to a tenant database of SAP HANA, the application automatically reconnects to
the new primary.
The secondary SAP HANA system that runs on NODE3 at the DR site is automatically reregistered to NODE2.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 523

Verify the SAP HANA system replication status on NODE2.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
# sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|

|

|Active Status |Mode

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |--------|------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|ASYNC

|HDB
|YES

|ASYNC

|HDB

|ACTIVE

|ASYNC

|ACTIVE

2 |SiteB
|

2 |

|

|cl-hdb-2 |30003 |indexserver

|YES

1 |

2 |SiteB

3 |

|

|

30001 |

3 |SiteC

|cl-hdb-3

|

30007 |

3 |SiteC

|cl-hdb-3

|

30003 |

3 |SiteC

True |

|

|

|cl-hdb-3

True |
2 |SiteB

|

True |

status system replication site "3": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 2
site name: SiteB

Test3 - Recovery procedure
1. Log in to the IBM Cloud® console and start NODE1.
2. On NODE1, run the following command to start the cluster services.
$ pcs cluster start

3. On a cluster node, run the following command to check the cluster status.
$ pcs status --full

4. On NODE2, verify the SAP HANA system replication status.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
# sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

Name |Active Status |Mode

|
|Status

|

|Secondary

|

|Host

|
|Port

|Site ID

|Site

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES
|HDB
|YES

|ASYNC
|ASYNC

|ACTIVE

|cl-hdb-2 |30003 |indexserver
|ASYNC

|ACTIVE

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|HDB
|YES
|HDB
|YES

|SYNCMEM

|ACTIVE

|cl-hdb-2 |30003 |indexserver
|SYNCMEM

|ACTIVE

2 |
3 |
1 |
2 |

|
|
|

3 |

|cl-hdb-3

|

30007 |

3 |SiteC

|cl-hdb-3

|

30003 |

3 |SiteC

|cl-hdb-1

|

30001 |

1 |SiteA

|cl-hdb-1

|

30007 |

1 |SiteA

|cl-hdb-1

|

30003 |

1 |SiteA

True |
2 |SiteB

|

3 |SiteC

True |
2 |SiteB

|

30001 |

True |
2 |SiteB

|

|

True |
2 |SiteB

|

|cl-hdb-3

True |
2 |SiteB

|

|
|

2 |SiteB
|

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver
|SYNCMEM

1 |

True |
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 524

status system replication site "3": ACTIVE
status system replication site "1": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 2
site name: SiteB

5. Run the steps in Test2 - Test the manual move of SAP Hana resource to another node to revert to the initial topology.

Test4 - Testing DR activation on the node that runs at the DR site
Use the following information to test the failure of both nodes in the primary workspace.

Test4 - Description
Simulate a crash of the nodes that run the primary and secondary SAP HANA databases.

Test4 - Prerequisites
A functional two-node RHEL HA Add-On cluster for HANA system replication.
Both cluster nodes are active.
The cluster is started on NODE1 and NODE2.
The cluster resource SAPHana_${SID}_${INSTNO} is configured with AUTOMATED_REGISTER=true .
Check SAP HANA system replication status:
SAP HANA multitarget system replication is activated and in sync.
The primary SAP HANA system runs on NODE1.
The secondary SAP HANA system runs on NODE2.
Another secondary SAP HANA system runs on NODE3 at the DR site and is registered with NODE1.

Test4 - Test procedure
Crash primary on NODE1 and secondary on NODE2 by sending a crash system request on both nodes.
1. On NODE1, run the following command.
$ sync; echo c > /proc/sysrq-trigger

2. On NODE2, run the following command.
$ sync; echo c > /proc/sysrq-trigger

3. On NODE3, run the following command to activate the HANA system as primary.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_takeover

Sample output:
# sudo -i -u hdbadm -- hdbnsutil -sr_takeover
done.

Test4 - Expected behavior
NODE1 and NODE2 halt immediately.
After the manual takeover, NODE3 runs the primary SAP HANA system.
An application, such as SAP NetWeaver, can connect to the SAP HANA system on NODE3.
Important: NODE3 is not part of the cluster and does not takeover the virtual IP address after a HANA system replication takeover. The
start up of application servers that connect to NODE3 at the DR site requires extra effort, which is not described in this document.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 525

On NODE3, run the following command to verify that the SAP HANA system runs as primary.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output:
# sudo -i -u hdbadm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: primary
operation mode: primary
site id: 3
site name: SiteC
is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: false
is a takeover active: false
is primary suspended: false
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-3 -> [SiteC] cl-hdb-3
cl-hdb-3 -> [SiteB] cl-hdb-2

Site Mappings:
~~~~~~~~~~~~~~
SiteC (primary/primary)
Tier of SiteC: 1
Replication mode of SiteC: primary
Operation mode of SiteC: primary

Hint based routing site:
done.

Test4 - Recovery procedure
The recovery procedure after a takeover to the DR site is complex and is documented as a separate test in the Test5 section.

Test5 - Restoring the original SAP HANA multitarget system replication topology
Use the following information to revert to the original system replication topology after a takeover to the SAP HANA system that runs at the

DR

site.
Check the following SAP documentation.
Restore the Original SAP HANA multitarget System Replication Configuration

Test5 - Description
Restore the original system replication topology and reactivate the cluster in the primary workspace.

Test5 - Prerequisites
A two-node RHEL HA Add-On cluster for HANA system replication in the primary workspace.
Both virtual server instances of the cluster are stopped.
The primary SAP HANA system runs on NODE3 at the DR site.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 526

Test5 - Test procedure
1. Restart virtual server instances in the primary workspace.
a. Log in to the IBM Cloud® console and start both NODE1 and NODE2.
b. Wait until both nodes are available.
c. Make sure that the Red Hat HA Add-On cluster services are stopped on both cluster nodes.
2. Register the SAP HANA system on NODE1 as a secondary.
a. On NODE3, verify that SAP HANA system replication is enabled.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

b. On NODE1, run the following command to set an environment variable with the hostname of NODE3.
$ export NODE3=<Hostname 3>

# Hostname of virtual server instance 3 (production tertiary)

c. On NODE1, run the following command to register the SAP HANA system with the primary on NODE3.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC1} \
--remoteHost=${NODE3} \
--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

d. On NODE1, check the system replication configuration.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output:

System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: false
mode: async
operation mode: unknown
site id: 1
site name: SiteA
is source system: unknown
is secondary/consumer system: true
has secondaries/consumers attached: unknown
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 3
primary masters: cl-hdb-3
done.

e. On NODE1, start the SAP HANA system to start the system replication.
$ sudo -i -u ${sid}adm -- HDB start

f. On NODE3, check the system replication status and wait until the secondary on NODE1 is fully synchronized.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 527

Sample output:
# sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

|Site Name |Active Status |Mode

|
|Status

|

|Secondary

|

|

|Host

|Port

|Site ID

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-3 |30001 |nameserver
|SiteA

|YES

|ASYNC

|HDB

|cl-hdb-3 |30007 |xsengine

|SiteA

|YES

|HDB

|cl-hdb-3 |30003 |indexserver

|SiteA

|YES

|ASYNC
|ASYNC

|

1 |

|ACTIVE

|

|

2 |

|ACTIVE

|

|

3 |

|ACTIVE

|

3 |SiteC

|cl-hdb-1
|

3 |SiteC

|cl-hdb-1
|

3 |SiteC

30001 |

1

|

30007 |

1

|

30003 |

1

True |
|cl-hdb-1

|

|

True |

True |

status system replication site "1": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 3
site name: SiteC

3. Initiate a fallback to the primary workspace.
Important: You need a downtime window to perform the move of the primary role back to NODE1.
To optimize the downtime window, the SAP HANA system on NODE2 can be registered as secondary to NODE3 now before the downtime
window. The drawback is that a higher amount of data is transferred between the two Power Virtual Server workspaces.
In the following, the SAP HANA system on NODE2 is registered as secondary to NODE1 after NODE1 becomes primary again.
a. Stop all applications and SAP application servers that are connected to NODE3.
b. On NODE1, run the following command to takeover the primary role.
A takeover with handshake suspends all transactions on the primary system on NODE3 and the takeover is only executed when all
remaining redo log is available on NODE1.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_takeover --suspendPrimary

c. On NODE1, check that the HANA system runs as primary.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

d. On NODE3, run the following command to verify the system replication status.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

Sample output:
# sudo -i -u ${sid}adm -- hdbnsutil -sr_state
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
SUSPEND PRIMARY ACTIVE
mode: primary
operation mode: primary
site id: 3
site name: SiteC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 528

is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: true
is a takeover active: false
is primary suspended: true
Host Mappings:
~~~~~~~~~~~~~~
cl-hdb-3 -> [SiteC] cl-hdb-3
cl-hdb-3 -> [SiteB] cl-hdb-2
cl-hdb-3 -> [SiteA] cl-hdb-1

Site Mappings:
~~~~~~~~~~~~~~
SiteC (primary/primary)
|---SiteA (async/logreplay)
Tier of SiteC: 1
Tier of SiteA: 2
Replication mode of SiteC: primary
Replication mode of SiteA: async
Operation mode of SiteC: primary
Operation mode of SiteA: logreplay
Mapping: SiteC -> SiteA
Hint based routing site:
done.

The following summary shows the status after these steps.
NODE1 runs as primary, but no application is connected.
NODE2 is up, but SAP HANA is not started.
NODE3 is up and SAP HANA is blocked in suspendPrimary mode.
Red Hat HA Add-On cluster services are stopped on NODE1 and NODE2.
4. Register the SAP HANA system on NODE2 as a secondary.
a. On NODE2, run the following command to register the SAP HANA instance with the primary on NODE1.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC2} \
--remoteHost=${NODE1} \
--remoteInstance=${INSTNO} \
--replicationMode=syncmem \
--operationMode=logreplay \
--online

b. On NODE2, start SAP HANA to start the replication.
$ sudo -i -u ${sid}adm -- HDB start

c. On NODE1, check the system replication status and wait until the secondary on NODE2 is fully synchronized.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
# sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

|Site Name |Active Status |Mode

|
|Status

|

|

|Secondary

|

|Host

|Port

|Site ID

|Status Details |Fully Synced |
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 529

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver
|SiteB

|YES

|SYNCMEM

|HDB

|cl-hdb-1 |30007 |xsengine

|SiteB

|YES

|HDB

|cl-hdb-1 |30003 |indexserver

|SiteB

|YES

|SYNCMEM
|SYNCMEM

|

1 |

|ACTIVE

|

|

2 |

|ACTIVE

|

|

3 |

|ACTIVE

|

1 |SiteA

|cl-hdb-2
|

1 |SiteA

30001 |

2

|

30007 |

2

|

30003 |

2

True |
|cl-hdb-2

|
1 |SiteA

|

True |
|cl-hdb-2

|

True |

status system replication site "2": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

The following summary shows the status after these steps.
NODE1 runs as primary, but no application is connected.
NODE2 runs as secondary.
NODE3 is up and SAP HANA is blocked in suspendPrimary mode.
Red Hat HA Add-On cluster services are stopped on NODE1 and NODE2.
5. Restart the cluster on NODE1 and NODE2.
a. Stop the SAP HANA systems on NODE1 and NODE2.
On NODE1, run
$ sudo -i -u ${sid}adm -- HDB stop

On NODE2, run
$ sudo -i -u ${sid}adm -- HDB stop

b. On a cluster node, run the following command to start the cluster.
$ pcs cluster start --all

c. Check the cluster status and verify that it is fully operational again.
$ pcs status --full

d. On NODE1, check the system replication status.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
# sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

|Site Name |Active Status |Mode

|
|Status

|

|Secondary

|

|

|Host

|Port

|Site ID

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver
|SiteB

|YES

|SYNCMEM

|HDB

|cl-hdb-1 |30007 |xsengine

|SiteB

|YES

|HDB

|cl-hdb-1 |30003 |indexserver

|SiteB

|YES

|SYNCMEM
|SYNCMEM

|

1 |

|ACTIVE

|

|

2 |

|ACTIVE

|

|

3 |

|ACTIVE

|

1 |SiteA

|cl-hdb-2
|

1 |SiteA
1 |SiteA

2

|

30007 |

2

|

30003 |

2

True |
|cl-hdb-2

|

30001 |

True |
|cl-hdb-2

|

|

True |

status system replication site "2": ACTIVE
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 530

overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

The following summary shows the status after these steps.
NODE1 runs as primary.
NODE2 runs as secondary.
Red Hat HA Add-On cluster services are started and the cluster manages SAP HANA system replication on NODE1 and NODE2.
NODE3 is up and SAP HANA is blocked in suspendPrimary mode.
6. Register the SAP HANA system on NODE3 as a secondary.
a. On NODE3, run the following command to register the system with NODE1.
$ sudo -i -u ${sid}adm -- \
hdbnsutil -sr_register \
--name=${DC3} \
--remoteHost=${NODE1} \
--remoteInstance=${INSTNO} \
--replicationMode=async \
--operationMode=logreplay \
--online

b. On NODE1, run the following command to verify the new SAP HANA system replication topology.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

The previous hdbnsutil -sr_register command triggers a restart of the SAP HANA system. During this restart, you might
observe a CONNECTION TIMEOUT status in the output.
Sample output:
# sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary

|Secondary |Secondary
|

|

|

|Replication |Replication |Replication
|

|Site Name |Active Status

|
|Mode

|
|Status

|

|Secondary
|Host

|

|Port

|Site ID

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |-------- |------------------ |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver
|SiteB

|YES

|HDB

|cl-hdb-1 |30007 |xsengine

|

|SYNCMEM

|SiteB

|YES

|HDB

|cl-hdb-1 |30003 |indexserver

|SiteB

|YES

|ACTIVE
|

|SYNCMEM

|SiteC

|CONNECTION TIMEOUT |ASYNC

|HDB

|cl-hdb-2 |30007 |xsengine

|SiteC

|CONNECTION TIMEOUT |ASYNC

|HDB

|cl-hdb-2 |30003 |indexserver

|SiteC

|CONNECTION TIMEOUT |ASYNC

|UNKNOWN
|

1 |SiteA

|cl-hdb-2 |
|

2 |SiteB
|
|
2 |SiteB
|

2

30003 |

2

30001 |

3

False |
30007 |

3

False |

|cl-hdb-3 |
|

30007 |

True |

|cl-hdb-3 |
|

2

True |

|cl-hdb-3 |
|

2 |SiteB

3 |
|UNKNOWN

|cl-hdb-2 |
|

30001 |

True |

1 |SiteA

|

2 |

|cl-hdb-2 |
|

|

1 |
|UNKNOWN

|

|

3 |
|ACTIVE

|

1 |SiteA

2 |
|ACTIVE

|

|SYNCMEM

|SYSTEMDB |cl-hdb-2 |30001 |nameserver

1 |

30003 |

3

False |

status system replication site "2": ACTIVE
status system replication site "3": UNKNOWN
overall system replication status: UNKNOWN
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 531

In case the system does not automatically restart after the

hdbnsutil -sr_register command, you need to stop and start it

manually.
The following is a sample output of such a situation. The replication status of NODE3 shows

IS PRIMARY (e.g. after

takeover) and it does not change when you check the status multiple times.
# sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary|Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

|

|Site Name |Active Status |Mode

|

|Status

|Secondary

|

|Host

|Port

|Status Details

|

|Site ID

|Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |-------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------------------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

|PRIMARY

|IS PRIMARY (e.g. after takeover) |

|

|HDB

|

|cl-hdb-1 |30007 |xsengine

|PRIMARY

|

|HDB

|

|

|

1 |SiteA

2 |

1 |SiteA

|cl-hdb-3 |

|

|

3 |

1 |SiteA

|cl-hdb-3 |

|SiteB

|YES

|SYNCMEM

|HDB

|cl-hdb-1 |30007 |xsengine

|SiteB

|YES

|HDB

|cl-hdb-1 |30003 |indexserver

|SiteB

|YES

|SYNCMEM
|SYNCMEM

|

1 |

|ACTIVE

|

|

2 |

|ACTIVE

|

|

3 |

|ACTIVE

|

1 |SiteA

30007 |

|cl-hdb-3 |

3 |

False |

|cl-hdb-2 |

30001 |

|cl-hdb-2 |

2
True |

30007 |
|

1 |SiteA

3 |

30003 |

|
1 |SiteA

3 |

False |

|IS PRIMARY (e.g. after takeover) |

|SYSTEMDB |cl-hdb-1 |30001 |nameserver

30001 |
False |

|IS PRIMARY (e.g. after takeover) |

|cl-hdb-1 |30003 |indexserver

|PRIMARY

1 |

|cl-hdb-2 |

2
True |

30003 |
|

2
True |

status system replication site "3": ERROR
status system replication site "2": ACTIVE
overall system replication status: ERROR
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

On NODE3, run the following command to restart the secondary HANA system.
$ sudo -i -u ${sid}adm -- HDB restart

The following summary shows the final status after these steps.
NODE1 runs as primary.
NODE2 runs as secondary.
NODE3 runs as another secondary at the DR site.
NODE2 and NODE3 are both registered to NODE1.
Red Hat HA Add-On cluster services are started and the cluster manages SAP HANA system replication on NODE1 and NODE2.
On NODE1, run the following command to verify the SAP HANA system replication topology.
$ sudo -i -u ${sid}adm -- HDBSettings.sh systemReplicationStatus.py

Sample output:
$ # sudo -i -u hdbadm -- HDBSettings.sh systemReplicationStatus.py
|Database |Host

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary

|Secondary |Secondary

|Replication |Replication |Replication

|

|

|

|

Name |Active Status |Mode

|
|Status

|

|Secondary

|

|Host

|
|Port

|Site ID

|Site

|Status Details |Fully Synced |

|-------- |---------|----- |------------ |--------- |------- |--------- |--------- |--------- |--------- |-------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |cl-hdb-1 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-1 |30007 |xsengine

|

|HDB
|YES
|HDB

|SYNCMEM
|SYNCMEM

|ACTIVE

|cl-hdb-1 |30003 |indexserver

1 |
|
2 |

|
|

1 |SiteA

3 |

|

30001 |

2 |SiteB

|cl-hdb-2

|

30007 |

2 |SiteB

|cl-hdb-2

|

30003 |

2 |SiteB

True |
1 |SiteA

|

|cl-hdb-2

True |
1 |SiteA

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 532

|YES

|SYNCMEM

|ACTIVE

|

|SYSTEMDB |cl-hdb-2 |30001 |nameserver

|

|YES

|ACTIVE

|

|cl-hdb-2 |30007 |xsengine

|

|ASYNC

|HDB
|YES

|ASYNC

|HDB

|ACTIVE

|cl-hdb-2 |30003 |indexserver

|YES

|ASYNC

|ACTIVE

|
1 |

|

2 |SiteB
|

2 |

|
3 |

|

30001 |

3 |SiteC

|cl-hdb-3

|

30007 |

3 |SiteC

|cl-hdb-3

|

30003 |

3 |SiteC

True |
2 |SiteB

|

|cl-hdb-3

True |
2 |SiteB

|

|

True |

True |

status system replication site "2": ACTIVE
status system replication site "3": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode: PRIMARY
site id: 1
site name: SiteA

Configuring high availability for SAP S/4HANA (ASCS and ERS) in a RHEL HA AddOn cluster
The following information describes the configuration of ABAP SAP Central Services (ASCS) and Enqueue Replication Service (ERS) with Red Hat
Enterprise Linux (RHEL) in a RHEL HA Add-On cluster. The cluster uses virtual server instances in IBM® Power® Virtual Server as cluster nodes.
The focus of this example configuration is on the second generation of the Standalone Enqueue Server, or ENSA2.
Starting with the release of SAP S/4HANA 1809, ENSA2 is installed by default, and can be configured in a two-node or multi-node cluster. This
example uses the ENSA2 setup for a two-node RHEL HA Add-On cluster. If the ASCS service fails in a two-node cluster, it restarts on the node
where ERS is running. The lock entries for the SAP application are protected when they rebuild from the copy of the lock table that's available
in the ERS. When the failed cluster node reactivates, the ERS instance moves to the other node (anti-collocation) to protect the lock table copy.
It is recommended that you install the SAP database instance and other SAP application server instances on virtual server instances outside
the two-node cluster for ASCS and ERS.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Prerequisites
The virtual server instances must meet the hardware and resource requirements of the SAP instances installed on them. Follow the
guidelines on instance types, storage, and memory sizing in the Planning the Deployment document.
This information describes a setup that uses shareable storage volumes accessible on both cluster nodes. Certain file systems are
created on shareable storage volumes so that they can be mounted on both cluster nodes. This setup applies to both instance
directories.
/usr/sap/<SID>/ASCS<Inst#> of the ASCS instance.
/usr/sap/<SID>/ERS<Inst#> of the ERS instance.

Make sure that the storage volumes that were created for these file systems are attached to both virtual server instances. During SAP
instance installation and RHEL HA Add-On cluster configuration, each instance directory must be mounted on its appropriate node. HALVM ensures that each of the two instance directories is mounted on only one node at a time.
Important: Different storage setups for the instance directories, such as NFS mounts, are possible. General storage setup steps
or creation of cluster file system resources are not described in this document and must be adapted.
The virtual hostname for ASCS instance and ERS instance must meet the requirements as documented in Hostnames of SAP ABAP
Platform servers. Make sure that the virtual IP addresses for the SAP instances are assigned to a network adapter and that they can
communicate in the network.
SAP application server instances require a common shared file system SAPMNT /sapmnt/<SID> with read and write access, and other
shared file systems such as SAPTRANS /usr/sap/trans . These file systems are typically provided by an external NFS server. The NFS
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 533

server must be installed on virtual servers that are not part of the ENSA2 cluster.
Configuring an active-passive NFS server in a Red Hat High Availability cluster describes the implementation of an active-passive NFS
server in a RHEL HA Add-On cluster with Red Hat Enterprise Linux 8 by using virtual server instances in Power Virtual Server.
Ensure that all SAP installation media is available.

Preparing nodes for SAP installation
The following information describes how to prepare the nodes for an SAP installation.

Preparing environment variables
To simplify the setup, prepare the following environment variables for user root on both cluster nodes. These environment variables are
used in subsequent commands in the remainder of the instructions.
On both nodes, create a file with the following environment variables. Then, you need to adapt them to your configuration.
export SID=<SID>

# SAP System ID (uppercase)

export sid=<sid>

# SAP System ID (lowercase)

export ASCS_nr=<INSTNO>

# Instance Number for ASCS

export ERS_nr=<INSTNO>

# Instance Number for ERS

# virtual hostnames
export ASCS_vh=<virtual hostname>

# virtual hostname for ASCS

export ERS_vh=<virtual hostname>

# virtual hostname for ERS

export ASCS_ip=<IP address>

# virtual IP address for ASCS

export ERS_ip=<IP address>

# virtual IP address for ERS

# LVM storage for instance file systems
export ASCS_vg=<vg name>

# volume group name for ASCS

export ERS_vg=<vg name>

# volume group name for ERS

export ASCS_lv=<lv name>

# logical volume name for ASCS

export ERS_lv=<lv name>

# logical volume name for ERS

It is recommended to use meaningful names for the volume groups and logical volumes that designate their content. For example, include the
SID and ascs or ers in the name Don't use hyphens in the volume group or logical volume names.
s01ascsvg and s01ascslv
s01ersvg and s01erslv
You must source this file before you use the sample commands in the remainder of the instructions.
For example, if you created a file that is named sap_envs.sh , run the following command on both nodes to set the environment variables.
$ source sap_envs.sh

Important: Every time that you start a new terminal session, you must run the previous

source command. As an alternative, you can

move the environment variables file to the /etc/profile.d directory during the cluster configuration. In this example, the file is
sourced automatically each time you log in to the server.

Assigning virtual IP addresses
Review the information in Reserving virtual IP addresses.
Check whether the virtual IP address for the SAP instance is present. Otherwise, you need to identify the correct network adapter to assign the
IP address.
On both nodes, check the list of currently active IP addresses.
$ ip -o -f inet address show | '/scope global/ {print $2, $4}'

Sample output of the previous command.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 534

# ip -o -f inet address show | awk '/scope global/ {print $2, $4}'
env2 10.51.0.66/24
env3 10.52.0.41/24
env4 10.111.1.28/24

The device name of the network adapter appears in the first column. The second column lists the active IP addresses and the number of bits
that are reserved for the netmask - which are separated by a slash.
If the virtual IP address for the SAP instance is not present, make sure that it isn't erroneously set on another virtual server instance.
On NODE1, run the following command.
$ ping -c 3 ${ASCS_vh}

Sample output:
# ping -c 2 cl-sap-scs
PING cl-sap-scs (10.111.1.248) 56(84) bytes of data.
From cl-sap-1.tst.ibm.com (10.111.1.28) icmp_seq=1 Destination Host Unreachable
From cl-sap-1.tst.ibm.com (10.111.1.28) icmp_seq=2 Destination Host Unreachable
--- cl-sap-ers ping statistics --2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 2112ms
pipe 3

If the ping output shows Destination Host Unreachable , the IP address is available, and you can assign the IP alias to the virtual server
instance. Use the correct device name env of the network adapter that matches the subnet of the IP address.
Example command on NODE1:
$ ip addr add ${ASCS_ip} dev env4

Example command on NODE2:
$ ip addr add ${ERS_ip} dev env4

Note: According to your specific network configuration, the device name for the network adapter might be different.
The IP address is required for the SAP installation, and is set manually. Later, the virtual IP addresses are controlled by the Red Hat HA Cluster
Add-on.

Preparing volume groups, logical volumes, and shared file systems
Shared storage is an important resource in an ENSA2 cluster. ASCS and ERS must be able to run on both nodes, and their runtime environment
is stored in the shared storage volumes. All cluster nodes need to access the shared storage volumes, but only one node has exclusive read
and write access to a volume.

Preparing High Availability Logical Volume Manager settings
Edit the file /etc/lvm/lvm.conf to include the system ID in the volume group.
On both nodes, edit the lvm.conf file.
$ vi /etc/lvm/lvm.conf

Search for the system_id_source parameter and change its value to uname .
Sample setting for the system_id_source parameter in etc/lvm/lvm.conf .
system_id_source = "uname"

Identifying World Wide Names of shared storage volumes
Determine the World Wide Name (WWN) for each storage volume that is part of one of the shared volume groups.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 535

1. Log in to IBM Cloud® to the Storage volumes view of Power Virtual Server.
2. Select your workspace.
3. Filter on the volume prefix in the Storage volumes list, and identify all the World Wide Names of the volumes that are in scope for ASCS
and ERS instances. The World Wide Name is a 32-digit hexadecimal number.
Tip: Make sure that the attribute Shareable is On for those volumes.
In the Virtual server instances view, go to both virtual server instances of the cluster. Verify that all volumes that are in scope for ASCS and ERS
are attached to both virtual server instances.
When you attach a new storage volume to a virtual server instance, make sure that you rescan the SCSI bus to detect the new volume.
Afterward, update the multipath configuration of the virtual server instance.
On the nodes with new storage volume attachments, run the following command.
$ rescan-scsi-bus.sh && sleep 10 && multipathd reconfigure

Log in to both cluster nodes, and add the WWN to the environment variables of user root .
Tip: Use the pvs --all command to determine the appropriate WWN values.
On NODE1, run the following command.
export ASCS_pvid=3<WWN>

# WWN of shared storage volume for ASCS

On NODE2, run the following command.
export ERS_pvid=3<WWN>

# WWN of shared storage volume for ERS

Tip: Make sure that you set the environment variable by using the hexadecimal number with lowercase letters.

Creating physical volumes
On NODE1, run the following command.
$ pvcreate /dev/mapper/${ASCS_pvid}

Sample output:
# pvcreate /dev/mapper/${ASCS_pvid}
Physical volume "/dev/mapper/360050768108103357000000000002ddc" successfully created.

On NODE2, run the following command.
$ pvcreate /dev/mapper/${ERS_pvid}

Sample output:
# pvcreate /dev/mapper/${ERS_pvid}
Physical volume "/dev/mapper/360050768108103357000000000002e31" successfully created.

Creating volume groups
Create the volume group for the ASCS.
On NODE1, run the following command.
$ vgcreate ${ASCS_vg} /dev/mapper/${ASCS_pvid}

Verify that the System ID is set.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 536

$ vgs -o+systemid

Sample output:
# vgs -o+systemid
VG

#PV #LV #SN Attr

s01ascsvg

1

0

VSize

VFree

System ID

0 wz--n- <50.00g <50.00g cl-sap-1

Create the volume group for the ERS.
On NODE2, run the following command.
$ vgcreate ${ERS_vg} /dev/mapper/${ERS_pvid}

Verify that the System ID is set.
Sample output:
# vgs -o+systemid
VG

#PV #LV #SN Attr

s01ersvg

1

0

VSize

VFree

System ID

0 wz--n- <50.00g <50.00g cl-sap-2

Creating logical volumes and file systems
Create the logical volume for the ASCS and format it as XFS file system.
On NODE1, run the following commands.
$ lvcreate -l 100%FREE -n ${ASCS_lv} ${ASCS_vg}

$ mkfs.xfs /dev/${ASCS_vg}/${ASCS_lv}

Create the logical volume for the ERS and format it as XFS file system.
On NODE2, run the following commands.
$ lvcreate -l 100%FREE -n ${ERS_lv} ${ERS_vg}

$ mkfs.xfs /dev/${ERS_vg}/${ERS_lv}

Making sure that a volume group is not activated on multiple cluster nodes
Volume groups that are managed by the cluster must not activate automatically on startup.
Tip: For RHEL 8.5 and later, disable autoactivation when creating the volume group by specifying the

--setautoactivation n flag on

the vgcreate command.
On both nodes, edit the /etc/lvm/lvm.conf file and modify the auto_activation_volume_list entry to limit autoactivation to specific
volume groups.
$ vi /etc/lvm/lvm.conf

Locate the auto_activation_volume_list parameter and add all volume groups except the one you defined for the NFS cluster to this list.
See an example of how to set the auto_activation_volume_list entry in /etc/lvm/lvm.conf :
auto_activation_volume_list = [ "rhel_root" ]

Rebuild the initramfs boot image to make sure that the boot image does not activate a volume group that is controlled by the cluster.
On both nodes, run the following command.
$ dracut -H -f /boot/initramfs-$(uname -r).img $(uname -r)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 537

Reboot both nodes.

Mounting the file systems for SAP installation
Activate the volume groups and mount the SAP instance file systems.
On NODE1 (ASCS), run the following commands.
$ vgchange -a y ${ASCS_vg}

$ mkdir -p /usr/sap/${SID}/ASCS${ASCS_nr}

$ mount /dev/${ASCS_vg}/${ASCS_lv} /usr/sap/${SID}/ASCS${ASCS_nr}

On NODE2 (ERS), run the following commands.
$ vgchange -a y ${ERS_vg}

$ mkdir -p /usr/sap/${SID}/ERS${ERS_nr}

$ mount /dev/${ERS_vg}/${ERS_lv} /usr/sap/${SID}/ERS${ERS_nr}

Mounting the required NFS file systems
On both nodes, make sure that the NFS file systems /sapmnt and /usr/sap/trans are mounted.
$ mount | grep nfs

Installing SAP instances
Use the SAP Software Provisioning Manager (SWPM) to install all instances.
Install SAP instances on the cluster nodes.
Install an ASCS instance on NODE1 by using the virtual hostname ${ASCS_vh} that is associated with the virtual IP address for
ASCS:
<swpm>/sapinst SAPINST_USE_HOSTNAME=${ASCS_vh}

Install an ERS instance on NODE2 by using the virtual hostname ${ERS_vh} that is associated with the virtual IP address for ERS:
<swpm>/sapinst SAPINST_USE_HOSTNAME=${ERS_vh}

Install instances outside the cluster.
DB instance
PAS instance
AAS instances

Installing and setting up the RHEL HA Add-On cluster
Install and set up the RHEL HA Add-On cluster according to Implement RHEL HA Add-On cluster on Power Virtual Server .
Configure and test fencing as described in Creating the fencing device .

Preparing ASCS and ERS instances for the cluster integration
Use the following steps to prepare the SAP instances for the cluster integration.

Removing the ASCS and ERS entries from the SAP services files
Adjust the SAP services file /usr/sap/sapservices to prevent automatic start of the sapstartsrv instance agent for both ASCS and ERS

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 538

instances after a reboot.
On both nodes, edit the SAP services file and remove or comment out the sapstartsrv entries for both ASCS and ERS.
$ vi /usr/sap/sapservices

Example:
#LD_LIBRARY_PATH=/usr/sap/S01/ASCS01/exe:$LD_LIBRARY_PATH;export LD_LIBRARY_PATH;/usr/sap/S01/ASCS01/exe/sapstartsrv
pf=/usr/sap/S01/SYS/profile/S01_ASCS01_cl-sap-scs -D -u s01adm

Creating mount points for the instance file systems on the takeover node
Create the mount points for the instance file systems and adjust their ownership.
On NODE1, run the following commands.
$ mkdir /usr/sap/${SID}/ERS${ERS_nr}

$ chown ${sid}adm:sapsys /usr/sap/${SID}/ERS${ERS_nr}

On NODE2, run the following commands.
$ mkdir /usr/sap/${SID}/ASCS${ASCS_nr}

$ chown ${sid}adm:sapsys /usr/sap/${SID}/ASCS${ASCS_nr}

Installing permanent SAP license keys
When the SAP ASCS instance is installed on a Power Virtual Server instance, the SAP license mechanism relies on the partition UUID. For more
information, see SAP note 2879336 - Hardware key based on unique ID .
On both nodes, run the following command as user <sid>adm to identify the HARDWARE KEY of the node.
$ sudo -i -u ${sid}adm -- sh -c 'saplikey -get'

Sample output:
$ sudo -i -u ${sid}adm -- sh -c 'saplikey -get'
saplikey: HARDWARE KEY = H1428224519

Note the HARDWARE KEY of each node.
You need both hardware keys to request two different SAP license keys. Check the following SAP notes for more information about requesting
SAP license keys:
2879336 - Hardware key based on unique ID
2662880 - How to request SAP license keys for failover systems

Installing SAP resource agents
Install the required software packages. The resource-agents-sap includes the SAPInstance cluster resource agent for managing the SAP
instances.
Unless sap_cluster_connector is configured for the SAP instance, the RHEL HA Add-On cluster considers any state change of the instance
as an issue. If other SAP tools such as sapcontrol are used to manage the instance, then sap_cluster_connector grants permission to
control SAP instances that are running inside the cluster. If the SAP instances are managed by only cluster tools, the implementation of
sap_cluster_connector is not necessary.

Install the packages for the resource agent and the SAP Cluster Connector library. For more information, see How to enable the SAP HA
Interface for SAP ABAP application server instances managed by the RHEL HA Add-On
On both nodes, run the following commands.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 539

If needed, use subscription-manager to enable the SAP NetWeaver repository. The RHEL for SAP Subscriptions and Repositories
documentation describes how to enable the required repositories.
$ subscription-manager repos --enable="rhel-8-for-ppc64le-sap-netweaver-e4s-rpms"

Install the required packages.
$ dnf install -y resource-agents-sap

sap-cluster-connector

Configuring SAP Cluster Connector
Add user ${sid}adm to the haclient group.
On both nodes, run the following command.
$ usermod -a -G haclient ${sid}adm

Adapting the SAP instance profiles
Modify the start profiles of all SAP instances that are managed by SAP tools outside the cluster. Both ASCS and ERS instances can be controlled
by the RHEL HA Add-On cluster and its resource agents. Adjust the SAP instance profiles to prevent an automatic restart of instance processes.
On NODE1, navigate to the SAP profile directory.
$ cd /sapmnt/${SID}/profile

Change all occurrences of Restart_Program to Start_Program in the instance profile of both ASCS and ERS.
$ sed -i -e 's/Restart_Program_\([0-9][0-9]\)/Start_Program_\1/' ${SID}_ASCS${ASCS_nr}_${ASCS_vh}

$ sed -i -e 's/Restart_Program_\([0-9][0-9]\)/Start_Program_\1/' ${SID}_ERS${ERS_nr}_${ERS_vh}

Add the following two lines at the end of the SAP instance profile to configure

sap_cluster_connector for the ASCS and ERS instances.

service/halib = $(DIR_EXECUTABLE)/saphascriptco.so
service/halib_cluster_connector = /usr/bin/sap_cluster_connector

Configuring ASCS and ERS cluster resources
Up to this point, the following are assumed:
A RHEL HA Add-On cluster is running on both virtual server instances and fencing of the nodes was tested.
The SAP System is running.
SAP ASCS is installed and active on node 1 of the cluster.
SAP ERS is installed and active on node 2 of the cluster.
All steps in Prepare ASCS and ERS instances for the cluster integration are complete.

Configuring resource for sapmnt share
Create a cloned Filesystem cluster resource to mount the SAPMNT share from an external NFS server to all cluster nodes.
Make sure that the environment variable ${NFS_vh} is set to the virtual hostname of your NFS server ${NFS_vh} , and ${NFS_options}
according to your mount options.
Example mount options:
export NFS_options="rw,sec=sys"

Note: Check SAP recommendations for NFS mount options at the Recommended mount options for read-write directories wiki page.
On NODE1, run the following command.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 540

$ pcs resource create fs_sapmnt Filesystem \
device="${NFS_vh}:/${SID}" \
directory="/sapmnt/${SID}" \
fstype='nfs' \
"options=${NFS_options}" \
clone interleave=true

Configuring ASCS resource group
Create a resource for the virtual IP address of the ASCS.
On NODE1, run the following commands.
$ pcs resource create ${sid}_vip_ascs${ASCS_nr} IPaddr2 \
ip=${ASCS_ip} \
--group ${sid}_ascs${ASCS_nr}_group

In this example of creating resources for an HA-LVM file system on a shared storage volume, you create resources for LVM-activate and for the
instance file system of the ASCS.
$ pcs resource create ${sid}_fs_ascs${ASCS_nr}_lvm LVM-activate \
vgname="${ASCS_vg}" \
vg_access_mode=system_id \
--group ${sid}_ascs${ASCS_nr}_group

$ pcs resource create ${sid}_fs_ascs${ASCS_nr} Filesystem \
device="/dev/mapper/${ASCS_vg}-${ASCS_lv}" \
directory=/usr/sap/${SID}/ASCS${ASCS_nr} \
fstype=xfs \
--group ${sid}_ascs${ASCS_nr}_group

In the alternative example that the instance file system of the ASCS is provided by an HA NFS server, only the file system resource is required.
Make sure that you defined the environment variable ${NFS_vh} according to your NFS server, and that you created a directory ${SID}/ASCS
under the NFS root directory during the SAP installation of the ASCS instance.
$ pcs resource create ${sid}_fs_ascs${ASCS_nr} Filesystem \
device="${NFS_vh}:${SID}/ASCS" \
directory=/usr/sap/${SID}/ASCS${ASCS_nr} \
fstype=nfs \
force_unmount=safe \
op start interval=0 timeout=60 \
op stop interval=0 timeout=120 \
--group ${sid}_ascs${ASCS_nr}_group

Create a resource for managing the ASCS instance.
$ pcs resource create ${sid}_ascs${ASCS_nr} SAPInstance \
InstanceName="${SID}_ASCS${ASCS_nr}_${ASCS_vh}" \
START_PROFILE=/sapmnt/${SID}/profile/${SID}_ASCS${ASCS_nr}_${ASCS_vh} \
AUTOMATIC_RECOVER=false \
meta resource-stickiness=5000 \
migration-threshold=1 failure-timeout=60 \
op monitor interval=20 on-fail=restart timeout=60 \
op start interval=0 timeout=600 \
op stop interval=0 timeout=600 \
--group ${sid}_ascs${ASCS_nr}_group

Note: The meta resource-stickiness=5000 option is used to balance the failover constraint with ERS so that the resource stays on
the node where it started and doesn't migrate uncontrollably in the cluster.
Add a resource stickiness to the group to make sure that the ASCS remains on the node.
$ pcs resource meta ${sid}_ascs${ASCS_nr}_group \
resource-stickiness=3000

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 541

Configuring the ERS resource group
Create a resource for the virtual IP address of the ERS.
On NODE1, run the following command.
$ pcs resource create ${sid}_vip_ers${ERS_nr} IPaddr2 \
ip=${ERS_ip} \
--group ${sid}_ers${ERS_nr}_group

In the example of creating resources for an HA-LVM file system on a shared storage volume, you create resources for LVM-activate and for the
instance file system of the ERS.
$ pcs resource create ${sid}_fs_ers${ERS_nr}_lvm LVM-activate \
vgname="${ERS_vg}" \
vg_access_mode=system_id \
--group ${sid}_ers${ERS_nr}_group

$ pcs resource create ${sid}_fs_ers${ERS_nr} Filesystem \
device="/dev/mapper/${ERS_vg}-${ERS_lv}" \
directory=/usr/sap/${SID}/ERS${ERS_nr} \
fstype=xfs \
--group ${sid}_ers${ERS_nr}_group

In the alternative example that the instance file system of the ERS is provided by an HA NFS server, only the file system resource is required.
Make sure that you defined the environment variable ${NFS_vh} according to your NFS server, and that you created a directory ${SID}/ERS
under the NFS root directory during the SAP installation of the ERS instance.
$ pcs resource create ${sid}_fs_ers${ERS_nr} Filesystem \
device="${NFS_vh}:${SID}/ERS" \
directory=/usr/sap/${SID}/ERS${ERS_nr} \
fstype=nfs \
force_unmount=safe \
op start interval=0 timeout=60 \
op stop interval=0 timeout=120 \
--group ${sid}_ers${ERS_nr}_group

Create a resource for managing the ERS instance.
$ pcs resource create ${sid}_ers${ERS_nr} SAPInstance \
InstanceName="${SID}_ERS${ERS_nr}_${ERS_vh}" \
START_PROFILE=/sapmnt/${SID}/profile/${SID}_ERS${ERS_nr}_${ERS_vh} \
AUTOMATIC_RECOVER=false \
IS_ERS=true \
op monitor interval=20 on-fail=restart timeout=60 \
op start interval=0 timeout=600 \
op stop interval=0 timeout=600 \
--group ${sid}_ers${ERS_nr}_group

Configuring constraints
A colocation constraint prevents resource groups ${sid}_ascs${ASCS_nr}_group and ${sid}_ers${ERS_nr}_group from being active on
the same node whenever possible. The stickiness score of -5000 makes sure that they run on the same node if only a single node is available.
$ pcs constraint colocation add \
${sid}_ers${ERS_nr}_group with ${sid}_ascs${ASCS_nr}_group -5000

An order constraint controls that resource group ${sid}_ascs${ASCS_nr}_group starts before ${sid}_ers${ERS_nr}_group .
$ pcs constraint order start \
${sid}_ascs${ASCS_nr}_group then stop ${sid}_ers${ERS_nr}_group \
symmetrical=false \
kind=Optional

The following two order constraints make sure that the file system SAPMNT mounts before resource groups ${sid}_ascs${ASCS_nr}_group

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 542

and ${sid}_ers${ERS_nr}_group start.
$ pcs constraint order fs_sapmnt-clone then ${sid}_ascs${ASCS_nr}_group

$ pcs constraint order fs_sapmnt-clone then ${sid}_ers${ERS_nr}_group

The cluster setup is complete.

Testing SAP ENSA2 clusters
It is vital to thoroughly test the cluster configuration to make sure that the cluster is working correctly. The following information provides a few
sample failover test scenarios, but is not a complete list of test scenarios.
For example, the description of each test case includes the following information.
Component under test
Description of the test
Prerequisites and the initial state before failover test
Test procedure
Expected behavior and results
Recovery procedure

Test1 - Testing failure of the ASCS instance
Test1 - Description
Simulate a crash of the SAP ASCS instance that is running on NODE1.

Test1 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP ENSA2.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Resource group ${sid}_ascs${ASCS_nr}_group is active on NODE1.
Resources ${sid}_vip_ascs${ASCS_nr}, ${sid}_fs_ascs${ASCS_nr}_lvm, ${sid}_fs_ascs${ASCS_nr} and ${sid}_ascs${ASCS_nr} are
Started on NODE1.

Resource group ${sid}_ers${ERS_nr}_group is active on NODE2.
Resources ${sid}_vip_ers${ERS_nr}, ${sid}_fs_ers${ERS_nr}_lvm, ${sid}_fs_ers${ERS_nr} and ${sid}_ers${ERS_nr} are Started
on NODE2.
Check SAP instance processes:
ASCS instance is running on NODE1.
ERS instance is running on NODE2.
$ pcs status

Sample output:
# pcs status
Cluster name: SAP_ASCS
Cluster Summary:
* Stack: corosync
* Current DC: cl-sap-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Tue Feb 14 07:59:16 2023
* Last change:

Tue Feb 14 05:02:22 2023 by hacluster via crmd on cl-sap-1

* 2 nodes configured
* 11 resource instances configured
Node List:
* Online: [ cl-sap-1 cl-sap-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-sap-2

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 543

* Resource Group: s01_ascs01_group:
* s01_vip_ascs01 (ocf::heartbeat:IPaddr2):

Started cl-sap-1

* s01_fs_ascs01_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ascs01 (ocf::heartbeat:Filesystem):
* s01_ascs01 (ocf::heartbeat:SAPInstance):

Started cl-sap-1

Started cl-sap-1
Started cl-sap-1

* Resource Group: s01_ers02_group:
* s01_vip_ers02 (ocf::heartbeat:IPaddr2):

Started cl-sap-2

* s01_fs_ers02_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ers02 (ocf::heartbeat:Filesystem):
* s01_ers02 (ocf::heartbeat:SAPInstance):

Started cl-sap-2

Started cl-sap-2
Started cl-sap-2

* Clone Set: fs_sapmnt-clone [fs_sapmnt]:
* Started: [ cl-sap-1 cl-sap-2 ]
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Test1 - Test Procedure
To crash the SAP ASCS instance, send a SIGKILL signal to the enque server as user ${sid}adm .
On NODE1, identify the PID of the enque server.
$ pgrep -af "(en|enq).sap"

Send a SIGKILL signal to the identified process.
Sample output:
# pgrep -af "(en|enq).sap"
30186 en.sapS01_ASCS01 pf=/usr/sap/S01/SYS/profile/S01_ASCS01_cl-sap-scs
# kill -9 30186

Test1 - Expected behavior
SAP ASCS instance on NODE1 crashes.
The cluster detects the crashed ASCS instance.
The cluster stops the dependent resources on NODE1 (virtual IP address, file system /usr/sap/${SID}/ASCS${ASCS_nr} , and the LVM
resources), and acquires them on NODE2.
The cluster starts the ASCS on NODE2.
The cluster stops the ERS instance on NODE2.
The cluster stops the dependent resources on NODE1 (virtual IP address, file system /usr/sap/${SID}/ERS${ERS_nr} , and the LVM
resources), and acquires them on NODE1.
The cluster starts the ERS on NODE1.
After a few seconds, check the status with the following command.
$ pcs status

Sample output:
# pcs status
Cluster name: SAP_ASCS
Cluster Summary:
* Stack: corosync
* Current DC: cl-sap-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Tue Feb 14 08:10:18 2023
* Last change:

Tue Feb 14 05:02:22 2023 by hacluster via crmd on cl-sap-1

* 2 nodes configured
* 11 resource instances configured
Node List:
* Online: [ cl-sap-1 cl-sap-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-sap-2
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 544

* Resource Group: s01_ascs01_group:
* s01_vip_ascs01 (ocf::heartbeat:IPaddr2):

Started cl-sap-2

* s01_fs_ascs01_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ascs01 (ocf::heartbeat:Filesystem):
* s01_ascs01 (ocf::heartbeat:SAPInstance):

Started cl-sap-2

Started cl-sap-2
Started cl-sap-2

* Resource Group: s01_ers02_group:
* s01_vip_ers02 (ocf::heartbeat:IPaddr2):

Started cl-sap-1

* s01_fs_ers02_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ers02 (ocf::heartbeat:Filesystem):
* s01_ers02 (ocf::heartbeat:SAPInstance):

Started cl-sap-1

Started cl-sap-1
Started cl-sap-1

* Clone Set: fs_sapmnt-clone [fs_sapmnt]:
* Started: [ cl-sap-1 cl-sap-2 ]
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Test2 - Testing failure of the node that is running the ASCS instance
Use the folling information to test a failure of the node that is running the ASCS instance.

Test2 - Description
Simulate a crash of the node where the ASCS instance is running.

Test2 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP ENSA2.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Resource group ${sid}_ascs${ASCS_nr}_group is active on NODE2.
Resources ${sid}_vip_ascs${ASCS_nr}, ${sid}_fs_ascs${ASCS_nr}_lvm, ${sid}_fs_ascs${ASCS_nr} and ${sid}_ascs${ASCS_nr} are
Started on NODE2.

Resource group ${sid}_ers${ERS_nr}_group is active on NODE1.
Resources ${sid}_vip_ers${ERS_nr}, ${sid}_fs_ers${ERS_nr}_lvm, ${sid}_fs_ers${ERS_nr} and ${sid}_ers${ERS_nr} are Started
on NODE1.
Check SAP instance processes:
ASCS instance is running on NODE2.
ERS instance is running on NODE1.

Test2 - Test procedure
Crash NODE2 by sending a fast-restart system request.
On NODE2, run the following command.
$ sync; echo b > /proc/sysrq-trigger

Test2 - Expected behavior
NODE2 restarts.
The cluster detects the failed node and sets its state to offline (UNCLEAN).
The cluster acquires the ASCS resources (virtual IP address, file system /usr/sap/${SID}/ASCS${ASCS_nr} , and the LVM items) on
NODE1.
The cluster starts the ASCS on NODE1.
The cluster stops the ERS instance on NODE1.
The cluster stops the dependent resources on NODE1 (virtual IP address, file system /usr/sap/${SID}/ERS${ERS_nr} , and the LVM
resources), and releases them.
After a while, check the status with the following command.
Note: The second node is offline and both resource groups are running on the first node.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 545

$ pcs status

Sample output:
# pcs status
Cluster name: SAP_ASCS
Cluster Summary:
* Stack: corosync
* Current DC: cl-sap-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Tue Feb 14 08:34:16 2023
* Last change:

Tue Feb 14 08:34:04 2023 by hacluster via crmd on cl-sap-1

* 2 nodes configured
* 11 resource instances configured
Node List:
* Online: [ cl-sap-1 ]
* OFFLINE: [ cl-sap-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-sap-1

* Resource Group: s01_ascs01_group:
* s01_vip_ascs01 (ocf::heartbeat:IPaddr2):

Started cl-sap-1

* s01_fs_ascs01_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ascs01 (ocf::heartbeat:Filesystem):
* s01_ascs01 (ocf::heartbeat:SAPInstance):

Started cl-sap-1

Started cl-sap-1
Started cl-sap-1

* Resource Group: s01_ers02_group:
* s01_vip_ers02 (ocf::heartbeat:IPaddr2):

Started cl-sap-1

* s01_fs_ers02_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ers02 (ocf::heartbeat:Filesystem):
* s01_ers02 (ocf::heartbeat:SAPInstance):

Started cl-sap-1

Started cl-sap-1
Started cl-sap-1

* Clone Set: fs_sapmnt-clone [fs_sapmnt]:
* Started: [ cl-sap-1 ]
* Stopped: [ cl-sap-2 ]
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Test2 - Recovery procedure
Wait until NODE2 restarts, then restart the cluster framework.
On NODE1, run the following command.
$ pcs cluster start

The cluster starts on NODE2 and acquires the ERS resources (virtual IP address, file system /usr/sap/${SID}/ERS${ERS_nr} , and the
LVM resources) on NODE2.
The cluster starts the ERS instance on NODE2.
Wait a moment and check the status with the following command. The ERS resource group moved to the second node.
$ pcs status

Sample output:
# pcs status
Cluster name: SAP_ASCS
Cluster Summary:
* Stack: corosync
* Current DC: cl-sap-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Tue Feb 14 08:41:23 2023
* Last change:

Tue Feb 14 08:34:04 2023 by hacluster via crmd on cl-sap-1

* 2 nodes configured
* 11 resource instances configured
Node List:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 546

* Online: [ cl-sap-1 cl-sap-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-sap-1

* Resource Group: s01_ascs01_group:
* s01_vip_ascs01 (ocf::heartbeat:IPaddr2):

Started cl-sap-1

* s01_fs_ascs01_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ascs01 (ocf::heartbeat:Filesystem):
* s01_ascs01 (ocf::heartbeat:SAPInstance):

Started cl-sap-1

Started cl-sap-1
Started cl-sap-1

* Resource Group: s01_ers02_group:
* s01_vip_ers02 (ocf::heartbeat:IPaddr2):

Started cl-sap-2

* s01_fs_ers02_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ers02 (ocf::heartbeat:Filesystem):
* s01_ers02 (ocf::heartbeat:SAPInstance):

Started cl-sap-2

Started cl-sap-2
Started cl-sap-2

* Clone Set: fs_sapmnt-clone [fs_sapmnt]:
* Started: [ cl-sap-1 cl-sap-2 ]
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Test3 - Testing failure of the ERS instance
Use the following information to test the failure of an ERS instance.

Test3 - Description
Simulate a crash of the ERS instance.

Test3 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP ENSA2.
Both cluster nodes are active.
Cluster starts on NODE1 and NODE2.
Resource group ${sid}_ascs${ASCS_nr}_group is active on NODE1.
Resources ${sid}_vip_ascs${ASCS_nr}, ${sid}_fs_ascs${ASCS_nr}_lvm, ${sid}_fs_ascs${ASCS_nr} and ${sid}_ascs${ASCS_nr} are
Started on NODE1.

Resource group ${sid}_ers${ERS_nr}_group is active on NODE2.
Resources ${sid}_vip_ers${ERS_nr}, ${sid}_fs_ers${ERS_nr}_lvm, ${sid}_fs_ers${ERS_nr} and ${sid}_ers${ERS_nr} are Started
on NODE2.
Check SAP instance processes:
ASCS instance is running on NODE1.
ERS instance is running on NODE2.

Test3 - Test Procedure
Crash the SAP ERS instance by sending a SIGKILL signal.
On NODE2, identify the PID of the enque replication server.
$ pgrep -af "(er|enqr).sap"

Send a SIGKILL signal to the identified process.
Sample output:
# pgrep -af "(er|enqr).sap"
2527198 er.sapS01_ERS02 pf=/usr/sap/S01/ERS02/profile/S01_ERS02_cl-sap-ers NR=01
# kill -9 2527198

Test3 - Expected behavior
SAP Enqueue Replication Server on NODE2 crashes immediately.
The cluster detects the stopped ERS and marks the resource as failed.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 547

The cluster restarts the ERS on NODE2.
Check the status with the following command.
$ pcs status

The ${sid}_ers${ERS_nr} ERS resource restarted on the second node. If you run the pcs status command too soon, you might see the
ERS resource briefly in status FAILED .
Sample output:
# pcs status
Cluster name: SAP_ASCS
Cluster Summary:
* Stack: corosync
* Current DC: cl-sap-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Tue Feb 14 08:50:53 2023
* Last change:

Tue Feb 14 08:50:50 2023 by hacluster via crmd on cl-sap-2

* 2 nodes configured
* 11 resource instances configured
Node List:
* Online: [ cl-sap-1 cl-sap-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-sap-1

* Resource Group: s01_ascs01_group:
* s01_vip_ascs01 (ocf::heartbeat:IPaddr2):

Started cl-sap-1

* s01_fs_ascs01_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ascs01 (ocf::heartbeat:Filesystem):
* s01_ascs01 (ocf::heartbeat:SAPInstance):

Started cl-sap-1

Started cl-sap-1
Started cl-sap-1

* Resource Group: s01_ers02_group:
* s01_vip_ers02 (ocf::heartbeat:IPaddr2):

Started cl-sap-2

* s01_fs_ers02_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ers02 (ocf::heartbeat:Filesystem):
* s01_ers02 (ocf::heartbeat:SAPInstance):

Started cl-sap-2

Started cl-sap-2
Started cl-sap-2

* Clone Set: fs_sapmnt-clone [fs_sapmnt]:
* Started: [ cl-sap-1 cl-sap-2 ]
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Test3 - Recovery Procedure
On NODE2, run the following commands.
$ pcs resource refresh

$ pcs status --full

Test4 - Testing the manual move of the ASCS instance
Use the following information to test a manual move of an ASCS instance.

Test4 - Description
Use SAP Control commands to move the ASCS instance to the other node for maintenance purposes.

Test4 - Prerequisites
A functional two-node RHEL HA Add-On cluster for SAP ENSA2.
The sap_cluster_connector is installed and configured.
Both cluster nodes are active.
Cluster is started on NODE1 and NODE2.
Resource group ${sid}_ascs${ASCS_nr}_group is active on NODE1.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 548

Resources ${sid}_vip_ascs${ASCS_nr}, ${sid}_fs_ascs${ASCS_nr}_lvm, ${sid}_fs_ascs${ASCS_nr} and ${sid}_ascs${ASCS_nr} are
Started on NODE1.

Resource group ${sid}_ers${ERS_nr}_group is active on NODE2.
Resources ${sid}_vip_ers${ERS_nr}, ${sid}_fs_ers${ERS_nr}_lvm, ${sid}_fs_ers${ERS_nr} and ${sid}_ers${ERS_nr} are Started
on NODE2.
Check SAP instance processes:
ASCS instance is running on NODE1.
ERS instance is running on NODE2.

Test4 - Test Procedure
Log in to NODE1 and run sapcontrol to move the ASCS instance to the other node.
$ sudo -i -u ${sid}adm -- sh -c "sapcontrol -nr ${ASCS_nr} -function HAFailoverToNode"

Test4 - Expected behavior
sapcontrol interacts with the cluster through the sap-cluster-connector .

The cluster creates location constraints to move the resource.
Check the status with the following command. Keep in mind that the ASCS resource group moved to the second node. If you run the pcs
status command too soon, you might see some resources stopping and starting .
$ pcs status

Sample output:
# pcs status
Cluster name: SAP_ASCS
Cluster Summary:
* Stack: corosync
* Current DC: cl-sap-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Tue Feb 14 09:03:19 2023
* Last change:

Tue Feb 14 09:01:40 2023 by s01adm via crm_resource on cl-sap-1

* 2 nodes configured
* 11 resource instances configured
Node List:
* Online: [ cl-sap-1 cl-sap-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-sap-1

* Resource Group: s01_ascs01_group:
* s01_vip_ascs01 (ocf::heartbeat:IPaddr2):

Started cl-sap-2

* s01_fs_ascs01_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ascs01 (ocf::heartbeat:Filesystem):
* s01_ascs01 (ocf::heartbeat:SAPInstance):

Started cl-sap-2

Started cl-sap-2
Started cl-sap-2

* Resource Group: s01_ers02_group:
* s01_vip_ers02 (ocf::heartbeat:IPaddr2):

Started cl-sap-1

* s01_fs_ers02_lvm (ocf::heartbeat:LVM-activate):
* s01_fs_ers02 (ocf::heartbeat:Filesystem):
* s01_ers02 (ocf::heartbeat:SAPInstance):

Started cl-sap-1

Started cl-sap-1
Started cl-sap-1

* Clone Set: fs_sapmnt-clone [fs_sapmnt]:
* Started: [ cl-sap-1 cl-sap-2 ]
Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Test4 - Recovery Procedure
Wait until the ASCS instance is active on NODE2. After five minutes, the cluster removes the created location constraints automatically.
The following instructions show how to remove the constraints manually.
On NODE2, run the following command.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 549

$ pcs constraint

Sample output:
# pcs constraint
Location Constraints:
Resource: s01_ascs01_group
Constraint: cli-ban-s01_ascs01_group-on-cl-sap-1
Rule: boolean-op=and score=-INFINITY
Expression: #uname eq string cl-sap-1
Expression: date lt 2023-02-08 09:33:50 -05:00
Ordering Constraints:
start s01_ascs01_group then stop s01_ers02_group (kind:Optional) (non-symmetrical)
start fs_sapmnt-clone then start s01_ascs01_group (kind:Mandatory)
start fs_sapmnt-clone then start s01_ers02_group (kind:Mandatory)
Colocation Constraints:
s01_ers02_group with s01_ascs01_group (score:-5000)
Ticket Constraints:

$ pcs resource clear ${sid}_ascs${ASCS_nr}_group

The Location constraints are removed:
$ pcs constraint

Sample output:
# pcs constraint
Location Constraints:
Ordering Constraints:
start s01_ascs01_group then stop s01_ers02_group (kind:Optional) (non-symmetrical)
start fs_sapmnt-clone then start s01_ascs01_group (kind:Mandatory)
start fs_sapmnt-clone then start s01_ers02_group (kind:Mandatory)
Colocation Constraints:
s01_ers02_group with s01_ascs01_group (score:-5000)
Ticket Constraints:

Configuring an active-passive NFS server in a Red Hat High Availability cluster
The following information describes the configuration of an active-passive NFS server in a Red Hat Enterprise Linux (RHEL) HA Add-On cluster.
The cluster uses virtual server instances in IBM® Power® Virtual Server as cluster nodes.
The described setup uses shareable storage volumes that are accessible on both cluster nodes. The file systems for the NFS exports are
created on those shareable storage volumes. HA-LVM makes sure that the volume group is active on one node at a time.
In the example setup, one shared volume group nfssharevg contains three logical volumes nfssharelv , sap${SID}lv , and saptranslv .
XFS file systems are created on those logical volumes and are mounted on /nfsshare , /nfshare/export/sap${SID} ,
/nfsshare/export/saptrans .

The instructions are based on the Red Hat product documentation and articles that are listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Before you begin
Review the general requirements, product documentation, support articles, and SAP notes listed in Implementing High Availability for SAP
Applications on IBM Power Virtual Server References.

Prerequisites
A virtual hostname and IP address is required for the NFS server. Make sure that the virtual IP address is defined on the network interface, and
reachable in the network.
Name resolution and reverse lookup for physical and virtual IP names and addresses must be unique and consistent on all NFS server and
client nodes. Details of the NFS clients (subnet, required NFS export options) must be available. You need to enter them during the cluster
setup.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 550

Preparing for a highly available NFS server
Use the following information to prepare the environment for a highly available NFS server.

Installing NFS software packages
On both nodes, run the following commands.
$ dnf install -y nfs-utils

Preparing LVM objects
All cluster nodes need access to the shared storage volumes, but only one node has exclusive read and write access to a volume.

Preparing active-passive HA LVM
On both nodes, edit file /etc/lvm/lvm.conf to include the system ID in the volume group. Search for the configuration setting
system_id_source and change its value to "uname".

Sample setting of system_id_source in /etc/lvm/lvm.conf :
# grep "system_id_source ="

/etc/lvm/lvm.conf

system_id_source = "uname"

Verify that the LVM system ID for the node matches the uname -n output.
$ lvm systemid

$ uname -n

Sample output:
# lvm systemid
system ID: cl-nfs-1
# uname -n
cl-nfs-1

Identifying the World Wide Names of shared storage volumes
Identify the World Wide Names (WWN) for all volumes that are used in the shared volume group.
1. Log in to IBM Cloud® and go to the Storage volumes view of Power Virtual Server.
2. Select your workspace.
3. Filter for the volume prefix in the Storage volumes list, and identify all the World Wide Names of the volumes in scope (the World Wide
Name is a 32-digit hexadecimal number).
Note: Make sure that the attribute Shareable is On for those volumes.
4. In the Virtual server instances view, go to both virtual server instances of the cluster and verify that in scope volumes are attached to
both virtual server instances.

Discovering new SAN volumes on cluster nodes
When you attach a new storage volume to a virtual server instance, you need to rescan the SCSI bus to detect the new volume. Then, update
the multipath configuration of the virtual server instance.
On the nodes with new storage volume attachments, run the following command.
$ rescan-scsi-bus.sh && sleep 10 && multipathd reconfigure

Tip: The WWN value of a volume can also be found with the pvs --all command.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 551

Preparing environment variables
To simplify the setup, prepare the following environment variables for user ID root on both nodes. These environment variables are used in
subsequent commands in the remainder of this document.
On both nodes, create a file with the environment variables. Then, adapt them to your configuration.
Adapt NFS_vh , NFS_ip , NFS_clientspec , and NFS_options to your environment. For NFS_pvid , use the WWN that you identified
previously. In addition to the file system that is used for the NFS share, the example shows two more file systems that are used for an SAP
system landscape with system ID ${SID} and the SAP transport directory. The sample sizes ${NFS_sz1} , ${NFS_sz2} , and ${NFS_sz3}
are percentages of the ${NFS_vg} volume group size and need to be modified according to your requirements. The volume group names and
mount point names are suggestions and need to be changed to match your own naming conventions.
Tip: Make sure that you set the NFS_pvid environment variable by using lowercase letters in the hexadecimal number.

# virtual hostnames
export NFS_vh=<virtual hostname>

# virtual hostname for NFS server

export NFS_ip=<IP address>

# virtual IP address for NFS server

# LVM storage for NFS file systems
export NFS_pvid=3<WWN>

# WWN of shareable storage volume used for NFS

export NFS_vg="nfssharevg"

# volume group name for NFS exported file systems

# NFS share file system
export NFS_lv1="nfssharelv"

# logical volume name export #1

export NFS_sz1="5%VG"

# logical volume size

export NFS_fs1="/nfsshare"

# file system mount point

export NFS_root="${NFS_fs1}/export"

# base export directory

# NFS share file system for SAP system ID <SID>
export SID=<SID>

# SAP system ID

export NFS_lv2="sap${SID}lv"

# logical volume name export #2

export NFS_sz2="40%VG"
export NFS_fs2="${NFS_root}/sap${SID}"

# logical volume size
# file system mount point

# NFS share file system for SAP transport directory
export NFS_lv3="saptranslv"

# logical volume name export #3

export NFS_sz3="40%VG"

# logical volume size

export NFS_fs3="${NFS_root}/saptrans"

# file system mount point

# NFS client options
export NFS_clientspec="10.111.1.0/24"

# client specs (subnet and netmask) for allowed NFS clients

export NFS_options="rw,sync,no_root_squash,no_subtree_check,crossmnt"

# options for NFS export

You must source this file before you use the sample commands in the remainder of this document.
For example, if you created a file that is named nfs_envs.sh , run the following command on both nodes to set the environment variables.
$ source nfs_envs.sh

Note: Every time that you start a new terminal session, you must run the

source command. Alternatively, you can add the

environment variables file to the /etc/profile.d directory during the cluster configuration. In this example, the file is sourced
automatically each time you log in to the server.

Creating LVM objects
Use the following information to create LVM objects.

Creating physical volumes
On NODE1, run the following command.
$ pvcreate /dev/mapper/${NFS_pvid}

Sample output:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 552

pvcreate /dev/mapper/${NFS_pvid}
Physical volume "/dev/mapper/360050768108103357000000000002ddc" successfully created.

Creating a volume group
On NODE1, create the volume group for the NFS export.
$ vgcreate ${NFS_vg} /dev/mapper/${NFS_pvid}

Verify that the System ID is set.
$ vgs -o+systemid

Sample output:
# vgs -o+systemid
VG

#PV #LV #SN Attr

nfssharevg

1

0

VSize

VFree

System ID

0 wz--n- <50.00g <50.00g cl-sap-1

Creating logical volumes
On NODE1, create three logical volumes for the NFS export.
$ lvcreate -l ${NFS_sz1} -n ${NFS_lv1} ${NFS_vg}

$ lvcreate -l ${NFS_sz2} -n ${NFS_lv2} ${NFS_vg}

$ lvcreate -l ${NFS_sz3} -n ${NFS_lv3} ${NFS_vg}

Creating the file systems
On NODE1, create the file systems for NFS exports.
The example uses file system type xfs . Other file system types are possible. Then, the resource definitions need to be changed.
$ mkfs.xfs /dev/${NFS_vg}/${NFS_lv1}

$ mkfs.xfs /dev/${NFS_vg}/${NFS_lv2}

$ mkfs.xfs /dev/${NFS_vg}/${NFS_lv3}

Creating the mount point for the NFS export
On both nodes, run the following command.
$ mkdir -p ${NFS_fs1}

Making sure that a volume group is not activated on multiple cluster nodes
Volume groups that are managed by Pacemaker must not activate automatically on startup.
Tip: For RHEL 8.5 and later, you can disable autoactivation for a volume group when you create the volume group by specifying the

--

setautoactivation n flag for the vgcreate command.

On both nodes, edit file /etc/lvm/lvm.conf and modify the auto_activation_volume_list entry to limit autoactivation to specific volume
groups. Search for parameter auto_activation_volume_list and add the volume groups, other than the volume group that you defined for
the NFS cluster, as entries in that list.
Sample setting of the auto_activation_volume_list entry in /etc/lvm/lvm.conf :
auto_activation_volume_list = [ "rhel_root" ]

Rebuild the initramfs boot image to make sure that the boot image does not activate a volume group that is controlled by the cluster.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 553

On both nodes, run the following command.
$ dracut -H -f /boot/initramfs-$(uname -r).img $(uname -r)

Reboot both nodes.

Installing and setting up the RHEL HA Add-On cluster
Use the following instructions to perform the initial cluster configuration.
Install and set up the RHEL HA Add-On cluster according to Implementing RHEL HA Add-On cluster on Power Virtual Server .
Configure and test fencing as described in Create the fencing device .
Sample output of the cluster status at this stage.
# pcs status
Cluster name: SAP_NFS
Cluster Summary:
* Stack: corosync
* Current DC: cl-nfs-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Fri Mar 10 10:35:42 2023
* Last change:

Fri Mar 10 09:52:08 2023 by root via cibadmin on cl-nfs-1

* 2 nodes configured
* 1 resource instance configured
Node List:
* Online: [ cl-nfs-1 cl-nfs-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-nfs-1

Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

Configuring general cluster properties
To prevent the cluster from moving healthy resources to another node (for example when you restart the cluster on a previously failed node),
you can set the default value for the resource-stickiness meta attribute to 1.
On NODE1, run the following command.
$ pcs resource defaults update resource-stickiness=1

Configuring NFS resource group and resources
Use the following steps to configure the NFS resources in the cluster.

Creating the LVM-activate resource
To make sure that all NFS resources run on the same node, configure them as part of the resource group

nfsgroup .

This resource group is created with the first resource. Resources start in the order in which they are added to the group. The resources stop in
reverse order.
On NODE1, run the following command.
$ pcs resource create nfs_vg ocf:heartbeat:LVM-activate \
vgname=${NFS_vg} \
vg_access_mode=system_id \
--group nfsgroup

To avoid data corruption, don't configure more than one LVM-activate resource that uses the same LVM volume group in an active-passive HA
configuration. Don't configure an LVM-activate resource as a clone resource in an active-passive HA configuration.
Check the status of the cluster and verify that resource nfs_vg is active.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 554

On NODE1, run the following command.
$ pcs resource status

Sample output:
# pcs resource status
* Resource Group: nfsgroup:
* nfs_vg

(ocf::heartbeat:LVM-activate):

Started cl-nfs-1

The following command configures the xfs file system resources for the nfsgroup resource group. The file systems use LVM volume group
${NFS_vg} and the logical volumes ( ${NFS_lv1} , ${NFS_lv2} , ${NFS_lv3} ) that were created before.

On NODE1, run the following command.
$ pcs resource create nfs_fs1 Filesystem \
device=/dev/${NFS_vg}/${NFS_lv1} \
directory=${NFS_fs1} \
fstype=xfs \
--group nfsgroup

You can specify mount options as part of the resource configuration for a file system resource by using the

options=<options> parameter.

Run pcs resource describe filesystem for a complete list of configuration options.
Check the status of the cluster and verify that the resource nfs_fs1 is active.
$ pcs resource status

Sample output:
# pcs resource status
* Resource Group: nfsgroup:
* nfs_vg

(ocf::heartbeat:LVM-activate):

Started cl-nfs-1

* nfs_fs1

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

On the node with the active resource group nfsgroup , create two subdirectories in ${NFS_fs1} . ${NFS_fs1}/stat is used as
nfs_shared_infodir for NFS lock information and ${NFS_fs1}/export is used as NFS root.
$ mkdir ${NFS_fs1}/stat ${NFS_fs1}/export

Create the mount points for the other exported file systems.
On both nodes, run the following command.
$ mkdir ${NFS_fs2} ${NFS_fs3}

Create the resources for the other two NFS file systems.
On NODE1, run the following commands.
$ pcs resource create nfs_fs2 Filesystem \
device=/dev/${NFS_vg}/${NFS_lv2} \
directory=${NFS_fs2} \
fstype=xfs \
--group nfsgroup

$ pcs resource create nfs_fs3 Filesystem \
device=/dev/${NFS_vg}/${NFS_lv3} \
directory=${NFS_fs3} \
fstype=xfs \
--group nfsgroup

Check the status of the cluster and verify that all three file system resources ( nfs_fs1 , nfs_fs2 , nfs_fs3 ) are active.
$ pcs resource status

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 555

Sample output:
# pcs resource status
* Resource Group: nfsgroup:
* nfs_vg

(ocf::heartbeat:LVM-activate):

Started cl-nfs-1

* nfs_fs1

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_fs2

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_fs3

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

Creating the nfsserver resource
On NODE1, create a resource for managing the NFS server.
$ pcs resource create nfs_daemon nfsserver \
nfs_shared_infodir=${NFS_fs1}/stat \
nfs_no_notify=true \
--group nfsgroup

The nfs_shared_infodir parameter of the nfsserver resource specifies a directory where the NFS server stores stateful information.
Check the status of the cluster and verify that the NFS server is started.
$ pcs resource status

Sample output:
# pcs resource status
* Resource Group: nfsgroup:
* nfs_vg

(ocf::heartbeat:LVM-activate):

Started cl-nfs-1

* nfs_fs1

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_fs2

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_fs3

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_daemon

(ocf::heartbeat:nfsserver):

Started cl-nfs-1

Creating the exportfs resource
To export the ${NFS_root} directory, add the exportfs resources to the nfsgroup group, which builds a virtual directory for NFSv4 clients.
NFSv3 clients can access these exports too.
On NODE1, run the following command.
$ pcs resource create nfs_export exportfs \
clientspec=${NFS_clientspec} \
options=${NFS_options} \
directory=${NFS_root} \
fsid=0 \
--group nfsgroup

Configuring a floating IP address resource
Review the information in Reserving virtual IP addresses and reserve a virtual IP address for the NFS cluster.
Create a resource for the virtual IP address of the NFS Server. NFS clients access the NFS share by using the floating IP address.
On NODE1, run the following command.
$ pcs resource create nfs_ip IPaddr2 \
ip=${NFS_ip} \
--group nfsgroup

Configuring a notify resource
The nfsnotify resource sends FSv3 reboot notifications after the entire NFS deployment initializes.
On NODE1, run the following command.
$ pcs resource create nfs_notify nfsnotify \
source_host=${NFS_ip} \
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 556

--group nfsgroup

The NFS cluster setup is now complete.
On NODE1, run the following command to check the status.
$ pcs resource status

Sample output:
# pcs resource status
* Resource Group: nfsgroup:
* nfs_vg

(ocf::heartbeat:LVM-activate):

Started cl-nfs-1

* nfs_fs1

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_fs2

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_fs3

(ocf::heartbeat:Filesystem):

Started cl-nfs-1

* nfs_daemon

(ocf::heartbeat:nfsserver):

Started cl-nfs-1

* nfs_export

(ocf::heartbeat:exportfs):

Started cl-nfs-1

* nfs_ip

(ocf::heartbeat:IPaddr2):

* nfs_notify

Started cl-nfs-1

(ocf::heartbeat:nfsnotify):

Started cl-nfs-1

Testing the NFS server cluster
You can validate the NFS resource configuration in a high availability cluster by using the following procedures. You can mount the exported file
system with either NFSv3 or NFSv4. Run the following tests to verify that the NFS cluster functions.

Test1 - Testing the NFS export
Use the following information to test the NFS export.
Run all the commands on an NFS client node outside the HA NFS cluster.
Verify the NFS exports.
$ showmount -e ${NFS_ip}

The showmount command displays information about file systems that are exported by an NFS Server (NFS v3). Verify that the output lists all
the exported directories.
Create a temporary directory on the NFS client node. Then, mount the NFS file system and create the directory structure that is required for the
SAP installation.
In the first example, only /usr/sap/trans and /sapmnt/${SID} are NFS mounted on the SAP application server instance.
Prepare the mount points that are used for the SAP installation.
$ mkdir -p /sapmnt/${SID} \
/usr/sap/trans

Change the attributes of the mount points.
$ chattr +i /sapmnt/${SID} \
/usr/sap/trans

Mount the NFS shares.
$ mount -t nfs -o vers=4,minorversion=1,sec=sys ${NFS_vh}:/saptrans /usr/sap/trans

$ mount -t nfs -o vers=4,minorversion=1,sec=sys ${NFS_vh}:/sap${SID} /sapmnt/${SID}

Change the ownership and the permissions.
$ chown ${sid}adm:sapsys /usr/sap/trans

$ chmod g+w /usr/sap/trans
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 557

$ chown -R ${sid}adm:sapsys /sapmnt/${SID}

Unmount the file systems.
$ umount /usr/sap/trans

$ umount /sapmnt/${SID}

Add the new file systems to /etc/fstab .
$ cat >> /etc/fstab << EOT
​${NFS_vh}:/saptrans /usr/sap/trans

nfs vers=4,minorversion=1,sec=sys

0

0

${NFS_vh}:/sap${SID} /sapmnt/${SID}

nfs vers=4,minorversion=1,sec=sys

0

0

EOT

Check the updated file.
$ cat /etc/fstab

In the second example, /usr/sap/trans , /sapmnt/${SID} , and all instance directories are NFS mounted on the SAP application server
instances.
Export environment variables for the ASCS and ERS system numbers. Change the following numbers to the system numbers that you used
during ASCS and ERS installation.
$ export ASCS_nr=01

$ export ERS_nr=02

Prepare the final mount points that are used for the SAP installation.
$ mkdir -p /sapmnt/${SID} \
/usr/sap/trans \
/usr/sap/${SID}/SYS \
/usr/sap/${SID}/ASCS${ASCS_nr} \
/usr/sap/${SID}/ERS${ERS_nr}

Change the attributes of the mount points.
$ chattr +i /sapmnt/${SID} \
/usr/sap/trans \
/usr/sap/${SID}/SYS \
/usr/sap/${SID}/ASCS${ASCS_nr} \
/usr/sap/${SID}/ERS${ERS_nr}

Mount the NFS shares to create the required subdirectories, change the ownership, and change the permissions.
$ mount -t nfs -o vers=4,minorversion=1,sec=sys ${NFS_vh}:/saptrans /mnt

$ chown ${sid}adm:sapsys /mnt

$ chmod g+w /mnt

$ umount /mnt

$ mount -t nfs -o vers=4,minorversion=1,sec=sys ${NFS_vh}:/sap${SID} /mnt

$ mkdir -p /mnt/sapmnt \
/mnt/ASCS \
/mnt/ERS \
/mnt/SYS \

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 558

/mnt/PAS \
/mnt/AS1

$ chown -R ${sid}adm:sapsys /mnt

$ umount /mnt

Add the new file systems to /etc/fstab .
$ cat >> /etc/fstab < EOT
​${NFS_vh}:/saptrans /usr/sap/trans

nfs vers=4,minorversion=1,sec=sys

${NFS_vh}:/sap${SID}/sapmnt /sapmnt/${SID}

0

0

nfs vers=4,minorversion=1,sec=sys

0

0

${NFS_vh}:/sap${SID}/ASCS /usr/sap/${SID}/ASCS${ASCS_nr} nfs vers=4,minorversion=1,sec=sys

0

${NFS_vh}:/sap${SID}/ERS

/usr/sap/${SID}/ERS${ERS_nr} nfs vers=4,minorversion=1,sec=sys

0

${NFS_vh}:/sap${SID}/SYS

/usr/sap/${SID}/SYS

nfs vers=4,minorversion=1,sec=sys

0

0

0

0

EOT

Check the updated file.
$ cat /etc/fstab

Test2 - Testing the failover of the NFS server
Use the following information to test the failover of the NFS server.

Test2 - Description
Simulate a crash of the cluster node that has the NFS resources.

Test2 - Prerequisites
A functional two-node RHEL HA Add-On cluster for an NFS HA server.
Cluster is started on both nodes.
The file systems are mounted on an NFS client node outside the cluster and the applications can access the content.

Test2 - Test procedure
Crash the cluster node by sending a shutoff system request.
First, check the cluster status and identify the node where the nfsgroup resource group is running.
On NODE1, run the following command.
$ pcs status

Then, log in to the identified cluster node and send a shutoff system request.
$ sync; echo o > /proc/sysrq-trigger

Test2 - Expected behavior
The node with the active nfsgroup resource group shuts down.
The cluster detects the failed node and starts a fencing action.
The fencing operation sets the state of the fenced node to offline.
The cluster acquires the NFS Server resources on the failover node.
Check that all the resources started on the failover node.
$ pcs resource status

Sample output:
# pcs resource status
* Resource Group: nfsgroup:
* nfs_vg

(ocf::heartbeat:LVM-activate):

Started cl-nfs-2

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 559

* nfs_fs1

(ocf::heartbeat:Filesystem):

Started cl-nfs-2

* nfs_fs2

(ocf::heartbeat:Filesystem):

Started cl-nfs-2

* nfs_fs3

(ocf::heartbeat:Filesystem):

Started cl-nfs-2

* nfs_daemon

(ocf::heartbeat:nfsserver):

Started cl-nfs-2

* nfs_export

(ocf::heartbeat:exportfs):

Started cl-nfs-2

* nfs_ip

(ocf::heartbeat:IPaddr2):

* nfs_notify

Started cl-nfs-2

(ocf::heartbeat:nfsnotify):

Started cl-nfs-2

Verify that the file system is still mounted on the NFS client node, and that the applications can still access the content.

Test2 - Recovery procedure
Log in to the IBM Cloud® Console and start the stopped instance. Wait until the cluster node is available again, then restart the cluster
framework.
On the cluster node, run the following command.
$ pcs cluster start

Check the cluster status.
$ pcs status

Sample output:
# pcs status
Cluster name: SAP_NFS
Cluster Summary:
* Stack: corosync
* Current DC: cl-nfs-1 (version 2.0.5-9.el8_4.5-ba59be7122) - partition with quorum
* Last updated: Mon Mar 20 08:11:28 2023
* Last change:

Mon Mar 20 07:56:25 2023 by hacluster via crmd on cl-nfs-1

* 2 nodes configured
* 9 resource instances configured
Node List:
* Online: [ cl-nfs-1 cl-nfs-2 ]
Full List of Resources:
* res_fence_ibm_powervs (stonith:fence_ibm_powervs):

Started cl-nfs-1

* Resource Group: nfsgroup:
* nfs_vg (ocf::heartbeat:LVM-activate):

Started cl-nfs-2

* nfs_fs1 (ocf::heartbeat:Filesystem):

Started cl-nfs-2

* nfs_fs2 (ocf::heartbeat:Filesystem):

Started cl-nfs-2

* nfs_fs3 (ocf::heartbeat:Filesystem):

Started cl-nfs-2

* nfs_daemon (ocf::heartbeat:nfsserver):

Started cl-nfs-2

* nfs_export (ocf::heartbeat:exportfs):

Started cl-nfs-2

* nfs_ip (ocf::heartbeat:IPaddr2):

Started cl-nfs-2

* nfs_notify (ocf::heartbeat:nfsnotify):

Started cl-nfs-2

Daemon Status:
corosync: active/disabled
pacemaker: active/disabled
pcsd: active/enabled

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 560

SAP Migration from on-premises to PowerVS
Overview - Migrating SAP servers between on-premises and IBM Cloud® on IBM
Power Virtual Server
Running SAP S/4HANA or SAP ECC on IBM IBM® Power® Virtual Server in a hybrid cloud environment offers:
A flexible infrastructure
Consistent platform for SAP HANA based and traditional applications
Best-in-class performance and
Freedom to run SAP workload where you need it.
Use the following information to understand how to migrate an SAP system between on-premises and Power Virtual Server.

SAP workload-related hybrid cloud network considerations
The hybrid cloud network connection is the base decision for all migration scenarios.
Deciding on the network connection option and estimating bandwidth requirements are the first steps. A typical SAP database size can be
huge. The network connection must be able to complete intersite data replication in sufficient time. Read the Hybrid Cloud Network
Considerations for SAP applications on IBM® Power® Virtual Server section for details.

Migrating SAP S/4HANA to IBM Power Virtual Server
Multiple options to migrate SAP S/4HANA between sites are possible. The following solution reduces SAP application downtime by using SAP
HANA System Replication (HSR):
1. Check the SAP S/4HANA Pre-Migration Steps section.
2. Install and prepare a target system in Power Virtual Server as described in the Creating the Target SAP HANA System on IBM Power
Systems Virtual Servers pre-step section.
3. Migrate the application data according to SAP HANA System Replication .
4. Perform an SAP HANA System Replication Takeover to activate services on the target site and make sure that clients connect to the new
location.

Hybrid Cloud Network Consideration for SAP applications on IBM Power Virtual
Server
A hybrid cloud environment combines the on-premises site with IBM® Power® Virtual Server. To join SAP S/4HANA systems between both
sites, multiple network connection options are available.
Due to typically huge SAP S/4HANA database sizes, a minimum network bandwidth is mandatory for productive systems.
The following topics are covered in the following sections:
A rough network migration minimum bandwidth considerations for SAP workloads
A brief overview of hybrid cloud connection options that are available that includes links to the setup descriptions
Extra required network services to migrate an SAP system
Test of network connections for SAP workload
Note: This information doesn't replace existing SAP or other vendor documentation.

Network bandwidth considerations
Bandwidth is determined by the required connection speed between on-premises and IBM Cloud® depends on project scenario, network
protocols, migration path, and project target.
A hybrid scenario with collaborating systems in IBM Cloud® and on-premises needs different requirements when compared with a one-time
move of a system to IBM Cloud® for isolated testing.
Network bandwidth is the main limiting factor for
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 561

Full synchronization time of the database servers
Delta replication time
Outage time during takeover
Important: The full synchronization is necessary as well for the initial upload as to fix synchronization issues when they occur.
Discuss bandwidth with your network provider and network specialist, as every connection type is different.

Example - Synchronization time estimation for an IPsec connection
As a rough estimation, consider an example that uses an IPsec VPN connection over a dedicated internet connection. A full synchronization
time can be estimated by using the following formula:
Time = 200% * (data transfer size) / Bandwidth
Estimation example.
Data base size: 922 GB
Expected changes while data transfers: 10%
Data transfer size: 110% * 922 GB = 1024 GB
Bandwidth: 500 MBit/s = 0.061 GB/s
Estimated transfer time is 200% * 1024/0.061 = 33554 sec = 9:19 hours
The calculated +100% overhead is a broad approach for necessary TCP/IP headers, IPsec headers, and extra data transfers. It does not
consider data retransmission or shared network usage. This estimation is intended to help determine the required minimum bandwidth.
The following table lists the calculated transfer times for a 1-Terabyte database:
Data base transfer size

Bandwidth

Overhead

Time for full sync

1024 GB

10 GBps

+100%

00:27 hours

1024 GB

5 GBps

+100%

00:54 hours

1024 GB

2 GBps

+100%

02:16 hours

1024 GB

1 GBps

+100%

04:33 hours

1024 GB

500 MBps

+100%

09:19 hours

1024 GB

250 MBps

+100%

18:38 hours

1024 GB

150 MBps

+100%

31:38 hours

Table 1. Calculated estimated time for IPsec VPN full synchronization

As an example, if an SAP system needs to be productive again within 8 hours after a synchronization error occurred, for a 922 GB database
size, the calculated network bandwidth must be greater than 500 MB/s.
Important: This estimation is based on assumptions. It is not qualified or intended to determine the accurate replication time. Consult
your network provider, or measure the time of a test replication to determine reliable values specific for your network setup.

Network connection option overview
A hybrid cloud setup in general combines the customer network with a customer network segment in IBM Cloud®. It is an extension of the
existing customer network, as if you would connect a remote data center.
Connecting an on-premises network with IBM Power Servers in PowerVS in IBM Cloud® is described in Network architecture diagrams.
If you are new to PowerVS, architectures from the Power Edge Router (PER) use cases are the recommended ones and are the easiest to
implement. If you have an existing PowerVS workspace, you might either consider migrating to the newer PER setup or inspect the Power

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 562

Virtual Server networking environment description.
Both PER and non-PER architectures offer these types of network connection options:

IBM Cloud® Direct Link 2.0
IBM Cloud® Direct Link is a suite of offerings that enables the creation of direct, private connections between your on-premises network and
IBM Cloud®, without traversing the public internet. For more information, see Getting started with IBM Cloud®Direct Link (2.0) and Connecting
an on-premises data center.

Internet VPN
Internet VPN uses the public internet to connect on-premises networks and IBM Cloud® networks through a VPN. At IBM Cloud® the VPN is
either terminated by a gateway device, gateway appliance, or a VPN as a service (VPNaaS). Read the IBM PowerVS specific Creating VPN
connections article.
The easiest way to establish a site-to-site VPN is to start with the VPN-as-a-service (VPNaaS). Read the article FAQs for site-to-site VPN
gateways for more details.

Required network services
A hybrid cloud setup extends your company network to your instances in IBM Cloud®. Servers and clients in this hybrid network need to
communicate with each other.
A hybrid cloud setup helps with the following points:
Routing between both networks works
Firewall rules permit traffic through required ports
DNS name resolution for both networks works

Testing network connections for an SAP workload
SAP provides a tool niping that checks the network interface up to OSI layer 4, which means it verifies that transport layer TCP/UDP
packages can be exchanged. This SAP tool demonstrates a working connection, even if ICMP packages are dropped and a simple ping would
fail.
Refer to SAP Note 500235 - Network Diagnosis with NIPING for further NIPING details.
For migrating SAP systems by using SAP HANA database replication between SAP HANA databases on-premises and PowerVS, the source and
target servers are the two database servers. The following two commands verify the connection between a source- and a target-system.
1. NIPING server: Use the following command to run the niping server on one system, for example named host1 .
$ niping -s

2. NIPING client: Then, run the niping client application on the second system to verify the connection to the first system

host1 .

$ niping -c -H host1

Note: An SAP Router is typically not involved in server-to-server communication. Consult the niping documentation to determine the
proper connection string if you are using an SAP Router.

Migrating SAP S/4HANA to IBM Power Virtual Server
Steps before you migrate an SAP S/4HANA database
The following sections cover several important advisories to prepare for the SAP HANA database migration. Read and implement the relevant
SAP notes.
Before you attempt any data migration or replication action, check the source database for any existing issues.
If issues exist, it might be one of the following issues.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 563

Interrupted or failed garbage collection.
Source databases still contain entries, tables, or data from actions such as client deletion, which leads to a false positive on the true size
of the database.
Reported inconsistencies during the database check.
Extreme load or unload actions that lead to orphaned entries.
Hardware issues that occurred during a delta merge from memory to disk.
Excessive page memory dumps were detected, which can indicate page corruptions.
Alerts that are displayed during an SAP HANA Mini Check.
Important: Incorrectly performing any data migration or replication action can result in data loss and application inconsistencies. Make
sure that you read and understand the associated SAP Notes and correction notes before you perform any related task. IBM Cloud® is
not liabil for any data loss or application integrity.
The following sections contain SAP-advised pre-steps to help make sure that the source database is in a consistent state. Before any migration
or backup or recovery operation begins that the consistency (such as Row store, Column Store, Pages) and trace files that are on the source
database are closely examined for any existing issues. These recommended steps must be completed before you start the migration.

Checking and confirming database health
Check the health of your database to reduce the risk of the transferring existing issues to your target system. Health checks prevent preexisting issues (such as consistency or block corruption) from migrating onto the target SAP HANA system. SAP HANA System Replication can't
help you in this scenario, so it is important to perform these necessary checks. Use the following SAP Notes to assist you.
SAP Note 2116157 - FAQ: SAP HANA Consistency Checks and Corruptions
SAP Note 2272121 - How To: Analyzing Physical Corruptions with the SAP HANA Persistence Diagnosis Tool
SAP Note 2380176 - FAQ: SAP HANA Database Trace

Checking the database trace files
The database trace is written to service specific files on operating system level. The trace directory is located here:
/usr/sap/<SID>/HDB<inst>/<host>/trace/DB_<SID>/

The following alias in the environment of the <sid>adm user helps you to quickly switch to the trace directory on the OS level:
cdtrace

The database trace files use the following naming convention:
<service>_<host>.<port>.<counter>.trc

In the context of dynamic tiering, a file with the following convention can exist (SAP Note 2871785):
esserver_console_<host>.<port>.<counter>.trc Example:
indexserver_saphana01.30003.024.trc You can access these files either directly, at the operating system level, or in one of the following

ways:
SAP HANA Studio -> Administration -> Diagnosis Files
DBACOCKPIT -> Diagnostics -> Diagnosis Files

More checking information
SAP HANA Administration Guide - Persistence Consistency Check
The SQL statements that are in the following SAP notes indicate whether a database reorganization is required and the amount of space that is
saved after the reorg action takes place.
This check serves two purposes.
1. Highlights whether the reorg action is required on the SAP HANA database.
2. If a reorg action is required, it provides an estimated size after space saving actions are completed.

Reorganizing database row store
If your database is heavily fragmented, a row store reorganization is required.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 564

Starting from SAP HANA 2.0 SPS04, online row store reorganization automatically triggers for large row store (allocated size >= 3.2 GB) if the
utilization ratio is less than the defined threshold.
By default, the threshold is 60% and the utilization ratio is checked in the background once an hour.
SAP Note 2789255 - Automatic Online Row Store Reorganization
If your database is version is less than SAP HANA 2.0 SPS04 , then follow the instructions that are in
SAP Note 1813245 - SAP HANA Row Store Reorganization
SAP Note 1977584 - Technical Consistency Checks for SAP HANA Databases This SAP Note contains useful SQL statements to check
the CATALOG, DEPENDENCY, and TABLE CONSISTENCY.
Important: Make sure that you pay attention to the instructions that are in these SAP Notes and follow each step that relates to your
existing SAP HANA version.

SQL mini checks
Use this SQL statement to show the current size of the SAP HANA database.
SELECT HOST, PORT, TO_DECIMAL( SUM(FREE_SIZE)*100 / SUM(ALLOCATED_SIZE), 10,2) "Free Space Ratio in %",TO_DECIMAL(
SUM(ALLOCATED_SIZE)/1048576, 10, 2) "Allocated Size in MB",TO_DECIMAL( SUM(FREE_SIZE)/1048576, 10, 2) "Free Size in MB"
FROM
M_RS_MEMORY WHERE ( CATEGORY = 'TABLE' ) and ( ALLOCATED_SIZE > 0 ) GROUP BY HOST, PORT

For more useful SQL statements, you can use the following SAP Note. This SAP Note includes some useful SQL statements that you can run
from the command line by using the hdbsql executable file. Or, you can use the SQL Console that is built into SAP HANA Studio.
1969700 - SQL Statement Collection for SAP HANA
Important: Commands from SQLStatements_Internal.zip impose an increased risk of instabilities such as crashes or terminations. If
you run these commands, run them with care. Perhaps running them first on a DEV or POC system first.
The following SQL statement helps you identify critical technical issues. When you download the SQL Collection compressed files, search for
SQL: "HANA_Configuration_MiniChecks" .
SQL: "HANA_Configuration_MiniChecks" performs several mini checks and returns C = 'X' if it finds a potentially critical situation. You

can use the following SAP Note to interpret the results.
SAP Note 1999993 - How-To: Interpreting SAP HANA Mini Check Results

Scheduling an SAP HANA sizing report on the source system
If you plan to migrate an existing SAP system from an on-premise site to your IBM Cloud® environment, you need fristto run an SAP Sizing
report. The current version for the SAP HANA memory sizing report is Advanced correction version 17 .
SAP Note 3338309 HANA memory Sizing report - Advanced correction 17
If you want to run the SAP HANA Sizing report, see the following SAP Note.
SAP Note 1872170 - ABAP on HANA sizing report (S/4HANA, Suite on HANA...)
It is advised that you use the most recent Advanced Correction of the SAP Sizing report. When you run the report, make sure that you include
the forecast for SAP HANA database growth. The generated report states the anticipated required CPU, memory, and storage
recommendations for your PowerVS instance target. Go to IBM Cloud® and select the most recent certified profile that is available for IBM
Power Virtual Servers.
SAP 2947579 - SAP HANA on IBM Power Virtual Servers
SAP 2188482 - SAP HANA on IBM Power Systems: Supported hardware and features

Extra sizing SAP Notes
SAP Note 2363248 - SAP BW/4HANA Hardware Sizing
SAP SD benchmark results
Measuring in SAPS (SAP Application Performance Standard)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 565

Using the EarlyWatch Alert reports as an early indicator
If your on-premises landscape has an SAP Solution Manager set up, you can generate the EarlyWatch Alert report for your source system.
The report outlines specific issues that your on-premises source system might have. You must address SQL performance indicators, Urgent
performance KPI indicators immediately. Issues that are classified as Red or Severe problems detected must be handled as soon as
possible.
Check the EarlyWatch Alert report for existing issues with the source SAP HANA database and act upon each finding in the

Service Summary

or Alert Overview sections, based on its severity.

More related SAP Notes for EarlyWatch Alert reports
SAP Note 1257308 - FAQ: Using EarlyWatch Alert
SAP Note 1958910 - EarlyWatch Alert For HANA Database
SAP Note 1911180 - HANA EarlyWatch Alerts (EWA) Issues
SAP Solution Manager - Help Portal Documentation

Source database credentials
When you add an SAP HANA system to the SAP HANA System Replication setup, remember that the replication process from source primary to
the target secondary server overwrites the MDC User Tables SAP${sid}.USR02 . So, it is important to know (by checking the SAP HANA Studio)
what the current user with SYS privileges that was used to register the MDC in SAP HANA Studio on the source. As a Best Practice , make
sure that you know the login credentials for the database user and the password for the source system. If, for example, you forget the
passwords and proceed with the SAP HANA System Replication from the source to the target you can test the secondary target by swapping
the primary and secondary servers. If you do not know the login credentials for the database user and the password on the source system then
you can't register the system in either SAP HANA Studio or an SAP HANA Cockpit setup.

Creating the Target SAP HANA System on IBM Power Virtual Server
Planning the IBM Power Virtual Server deployment
A Power Server workspace in your IBM Cloud account is a prerequisite for the following steps. Read details in

Hybrid Cloud Network

Considerations for SAP on IBM Power Virtual Server.
A hybrid cloud network connection needs to be in place, as described in Hybrid Cloud Network Considerations for SAP on IBM Power Virtual
Server.
The Planning for a deployable SAP HANA infrastructure is described in Planning your deployment.
The sizing aspect of the target system is vital to your planning. Follow the recommendations mentioned in the SAP HANA Sizing report on the
source system. Also, consider the findings of the EarlyWatch Alert report (EWA report). Both factors provide a realistic approach on the
recommended size of your target system, see Sizing process for SAP Systems .

Comparing the required CPU, cores and storage for your target system
IBM Cloud Doclink SAP Planning/Sizing
Check that the certified profiles in IBM Cloud® are close to or match the recommendations that are mentioned in the source system sizing
report and also consider the EWA report summary.
Select the correct IBM Power Systems Virtual Server Certified Profile from the following two links:
IBM Power VS Certified Profiles SAP HANA
SAP Note 2947579 - SAP HANA on IBM Power Virtual Servers

Target server must have equal or greater storage capacity than the source system and be sized
correctly
Remember to take SAP HANA database growth into consideration and the need to follow the IBM System Storage Architecture and
Configuration Guidelines for SAP HANA TDI.
The following document outlines the required storage configuration for the target server in IBM Cloud:
IBM System Storage Architecture and Configuration Guide for SAP HANA TDI
Consider the extra space that you need to create a file system mount point to store software executable files and the initial SAP HANA system
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 566

backup. Depending on your planned IBM Cloud PowerVS infrastructure, you can create the file system as an NFS mount to export to other
systems in the architecture.

Creating the software repository file system and transfer the installation packages
As used in previous demo systems, the mount point swrepo is created with at least 200 GB of free space. Download the SAP HANA Software
from SAP Marketplace - the version that matches your SAP HANA version from the source system.
Software Downloads main page
Access Software Downloads in SAP for Me
Enter your SAP "S" user ID and password to proceed.
Software Center Catalog view
Support Packages & Upgrades
By Alphabetical Index (A-Z)
"H"
SAP HANA PLATFORM EDITION
SAP HANA PLATFORM EDITION 2.0
SAP HANA DATABASE 2.0
Make sure that the Selection box shows LINUX ON POWER LE 64BIT
Select the IMDB_SERVER20 that is installed on the Source System, and download to your laptop or PC
Go back to the SAP HANA PLATFORM EDITION 2.0 page
SAP HANA CLIENT 2.0
Make sure that the Selection box shows LINUX ON POWER LE 64BIT
Select the release that you installed on the source system (or one version higher if your version is not on the list)
Navigate back to * Software Center Catalog view
Support Packages & Upgrades
On the right side, is a search box, search for SAPCAR
On the Displayed results list, select SAPCAR 7.53 Maintenance Software Component
Select the file SAPCAR_1200-70007726.EXE and make sure that the Selection box shows LINUX ON POWER LE 64BIT
Download to your laptop or PC or Jump Host
Create a directory /swrepo on the target system.
$ sudo mkdir /swrepo

Make sure that your user owns this directory, so the user can work and extract files.
$ sudo chown $USER: /swrepo

Transfer the installation files and sapcar utility downloads to the target SAP HANA server /swrepo mount point. The SAPCAR utility needs
executable permissions to unpack the .SAR archive files.
$ chmod -R 755 /swrepo/SAPCAR_1200-70007726.EXE

Tip: You can set an alias SAPCAR for this utility in the .bash_profile . This setting enables the SAPCAR command from any directory.
To add a line to your bash profile, use the following command.
$ echo "alias SAPCAR='/swrepo/SAPCAR_1200-70007726.EXE'" >>$HOME/.bash_profile

Use the source command to enable the new defined alias.
$ source $HOME/.bash_profile

Check whether it works by running SAPCAR -v to get the version list:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 567

$ SAPCAR -v

Unpacking the files
Use the following examples to unpack the files.
$ SAPCAR -xvf IMDB_CLIENT20_XXX_XX-XXXXXXXX.SAR -manifest /SAP_HANA_CLIENT/SIGNATURE.SMF

The sapcar file extraction output looks like the following example.
x SAP_HANA_CLIENT/SIGNATURE.SMF
SAPCAR: 98 file(s) extracted
SAPCAR -xvf IMDB_SERVER20_XXX_XX-XXXXXXXX.SAR -manifest /SAP_HANA_DATABASE/SIGNATURE.SMF
x /SAP_HANA_DATABASE/SIGNATURE.SMF
SAPCAR: 355 file(s) extracted

During extraction directories /swrepo/SAP_HANA_DATABASE and /swrepo/SAP_HANA_CLIENT are created and contain the files that are
required for the installation.

Making sure that the target server OS and patch level match the source server
Check the operating system version and patch level on the target system. For productive systems, the same level makes sure that the
installation performs similar and migrating runs with ease. For nonproductive systems, for example, a proof of concept system (POC) in IBM
PowerVS, a higher operating system version is a valid option.

Target server - Both RHEL and SLES
To determine the operating system version and patch level, run the following command.
$ cat /etc/os-release

Alternatively on Red Hat Linux systems you can use a second file.
$ cat /etc/redhat-release

On SUSE Linux Enterprise Server (for SAP Applications) the release and patch level can be listed with the following command.
$ lsb_release -a

Making sure that the file system and mount points match the source system
The source and target systems must have the identical mapping for storage, LVM, and file systems. Only on target is the larger storage capacity
that is needed or the Migration. File system structure requirements are also highlighted in the beginning of this section with the TDI
requirements. Also, consider that the mount point and file ownership UID and GUID match the source system. Also, mount points need the
same <SID> defined on both systems. When you install SAP HANA on the target system, the same <SID> and <instance number> from the
source system are used.
$ export SID=<SID>

# SAP HANA System ID (uppercase)

export sid=<sid>

# SAP HANA System ID (lowercase)

export INSTNO=<INSTNO>

# SAP HANA Instance Number

export SiteOnPrem=<PrimarySiteName>

# HANA System Replication Site Name 1 - Migration from On-Prem - Source

export SiteOnCloud=<secondarySiteName>

# HANA System Replication Site Name 2 - Migration to On-Cloud - Target

export NODE1=<Hostname 1>

# Hostname of On-Prem Server

export NODE2=<Hostname 2>

# Hostname of IBM Cloud PowerVS Instance

Entries in /etc/hosts for all systems involved in the migration project
The /etc/hosts file needs to contain entries for the Source System and any dependent SAP Netweaver or S/4 FES Application Server. You
can use a DNS server for your network resource resolution, but it helps if you include the IP addresses, short name, FQDN, and description to
help identify servers in the landscape in the /etc/hosts file, especially if issues occur with network resolution or the DNS services.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 568

Preparing and tuning the OS for SAP HANA
Use the following SAP Notes to begin the preparation phase of the target system for the installation of SAP HANA.
SAP Note 2777782 - SAP HANA DB: Recommended OS Settings for RHEL 8
SAP Note 2772999 - Red Hat Enterprise Linux 8.x: Installation and Configuration
SAP Note 3018133 - Linux: Running SAP applications compiled with GCC 10.x
Make sure that you completed the tasks that are mentioned in the Recommended OS Settings for RHEL 8 as these tasks are important
tuning and performance settings that need to be applied. If ignored, it can impact the installation of SAP products and the performance
thereafter.

Pre-SAP HANA checks by using the hcmt tool
The SAP HANA hardware and cloud measurement tools hcmt help measure and analyze your hardware or cloud systems before you deploy
SAP HANA or apply for SAP HANA certification. The tools consist of the following components:
SAP HANA hardware and cloud measurement tool
SAP HANA hardware and cloud measurement analysis
Use the following SAP Note to check and verify the OS and configuration before you install SAP HANA.
SAP Note 2493172 - SAP HANA Hardware and Cloud Measurement Tools
Tip: If you have a port issue when you run hcmt , open a second Terminal session. Navigate to the setup directory of hcmt , now start a
session that keeps the required port open.
To run hcmt in server-client mode, you need to start two sessions:
1. hcmt server mode on - a jump host to collect test result from remote servers
2. hcmt client on the target systems that are intended to run SAP HANA, run

hcmt performance test by using the full execution plan.

Hcmt server session
The hcmt server collects data that is measured on hcmt client systems. A typical system to run the hcmt server is a jump host or similar
system. Navigate to the directory where hcmt is installed, and run the following command
$ sudo ./hcmt -v -S

The following example is the expected output.
hcmt-2.00.062.00.1650891137 (2022-04-25 15:12:20)
Server started, listening on port 50000 ...

Hcmt client session
On the target system that you want to be the SAP HANA server, run the

hcmt command as a client by using the full execution plan.

$ sudo ./hcmt -v -p /swrepo/HCMT/setup/config/full_executionplan.json

System output:
hcmt-2.00.062.00.1650891137 (2022-04-25 15:12:20)
Loading executionplan
LogVolume (/hana/log):
DataVolume (/hana/data):
Hosts: <`Leave Blank!!!!`>

Leave this field blank, otherwise it will affect the test.

Start execution of plan
Executing Test C9C9F832-854F-492D-8E7EFB4609AC435C
Note: CPU Micro Benchmark

Tip: If you receive an error 'Port 50000 is already used', SAP HANA is probably installed already. Stop the SAP HANA system and then
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 569

run the hcmt command again.
Plan Variant: CPU Performance
This command generates a hcmresult-YYYMMDDHHMMSS.zip file in the setup directory. You need to upload this file to the HCMT SAP website
and review the results to make sure that the HANA is set up and configured correctly.
SAP HCMT Cloud Server URL
If you experience issues, you can still use the old check tool.
SAP Note 1943937 – Hardware Configuration Check Tool

Installing SAP HANA on the target system
Remember the following variables:
$ export SID=<SID>

# SAP HANA System ID (uppercase)

export sid=<sid>

# SAP HANA System ID (lowercase)

export INSTNO=<INSTNO>

# SAP HANA Instance Number

For this example, the installation is up to the point where you need to enter "Y" to continue. Navigate back to the HANA_DATABASE directory.
Run the SAP HANA database lifecycle manager command.
$ sudo ./hdblcm

The following example is the expected output.
SAP HANA Lifecycle Management - SAP HANA Database 2.00.061.00.1644229038
************************************************************************

This will scan the directories for the required software.
Scanning software locations...
Detected components:
SAP HANA Database (2.00.061.00.1644229038) in /swrepo/HANA/SAP_HANA_DATABASE/server
SAP HANA Database Client (2.11.20.1644165757) in /swrepo/HANA/SAP_HANA_CLIENT/client

Do you want to specify additional components location? (y/n) [n]: `n`

Choose n for no additional components location and continue.
Choose an action
Index | Action

| Description

------------------------------------------------------------1

| install

| Install new system

2

| extract_components

| Extract components

3

| print_detected_components | Print detected components

4

| Exit (do nothing)

|

Enter selected action index [4]: `1`

Enter 1 and press <enter> key to install a new system.
Output continues with the following example.
SAP HANA Database version '2.00.061.00.1644229038' will be installed.
Select additional components for installation:
Index | Components | Description
-------------------------------------------------------------------------------1

| all

| All components

2

| server

| No additional components

3

| client

| Install SAP HANA Database Client version 2.11.20.1644165757
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 570

Enter comma-separated list of the selected indices [3]: `1`

Enter 1 and press <enter> to install all SAP HANA components.
Output continues with the following example.

SAP HANA Database version '2.00.061.00.1644229038' will be installed.
Select additional components for installation:
Index | Components | Description
-------------------------------------------------------------------------------1

| all

| All components

2

| server

| No additional components

3

| client

| Install SAP HANA Database Client version 2.11.20.1644165757

Enter comma-separated list of the selected indices [3]: `1`

Enter 1 and press <enter> to install all components. Accept a series of defaults on the next line in the output.
Enter Installation Path [`/hana/shared`]:
Enter Local Host Name [`Yourhostname`]:
Do you want to add hosts to the system? (y/n) [`n`]:

Enter `n' for no additional systems. Check the source SAP HANA database system parameters:
source SAP HANA SID
source SAP HANA Instance Number
Continue with the same values for the target system:
Enter SAP HANA System ID: `<Needs to match the source system>`
Enter Instance Number [00]: `<Needs to match the source system>`
Enter Local Host Worker Group [default]:
Index | System Usage | Description
------------------------------------------------------------------------------1

| production

| System is used in a production environment

2

| test

| System is used for testing, not production

3

| development

| System is used for development, not production

4

| custom

| System usage is neither production, test nor development

Select System Usage / Enter Index [4]: 2

Enter a number that represents the planned function. In the example, 2 indicates a system for testing.
Accept more default values:
Do you want to enable data and log volume encryption? [n]:
Enter Location of Data Volumes [/hana/data/<SID>]:
Enter Location of Log Volumes [/hana/log/<SID>]:
Restrict maximum memory allocation? [n]:
Apply System Size Dependent Resource Limits? (SAP Note 3014176) [y]:

Determine these passwords as set on the source system:
sapadm password
<sid>adm password

System Database User SYSTEM password
Set the same passwords on the target system:
Enter SAP Host Agent User (sapadm) Password: <Use the same password used on the source system>
Confirm SAP Host Agent User (sapadm) Password: <Use the same password used on the source system>
Enter System Administrator (<sid>adm) Password:

<Use the same password used on the source system>

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 571

Confirm System Administrator (<sid>adm) Password: <Use the same password used on the source system>
Enter System Administrator Home Directory [/usr/sap/<SID>/home]:
Enter System Administrator Login Shell [/bin/sh]:
Enter System Administrator User ID [1001]: <check that the user ID number matches the source system>
Enter ID of User Group (sapsys) [79]:

<Check that the GUID number matches the source system>

Enter System Database User (SYSTEM) Password: <Use the same password used on the source system>
Confirm System Database User (SYSTEM) Password: <Use the same password used on the source system>
Restart system after machine reboot? [n]:
Summary before execution

At the summary, you can check to make sure that the selections that you made for the installation are correct. Then, select "Y" to begin. After
about 20 minutes, you see the following message.
Registering SAP HANA Database Components on Local Host...
- Deploying SAP Host Agent configurations...
Creating Component List...
SAP HANA Database System installed
Log file written to xxxxxx

Checking that SAP HANA is running and determining the version
Run the following HDB proc command to verify that all services started on the primary and secondary SAP HANA system.
$ sudo -i -u ${sid}adm -- HDB proc

SAP HANA version needs to be equal or greater than the primary server
To verify the SAP HANA database version, use the following command on both nodes.
$ sudo -i -u ${sid}adm -- HDB version

Initial backup of the MDC/SYSTEMDB SAP HANA database
Backup SYSTEMDB
Add both the SYSTEMDB entry and the MDC to the HANA Studio Application. Or, If you have an SAP HANA Cockpit in your landscape, you can
add the target system to your HANA Cockpit instead. After both systems are added, complete an initial system backup. On the SYSTEMDB
entry, -> right click and select.
Backup & Recovery
Backup Up System Database
Backup Type Complete Data Backup
Destination File
Backup Destination /swrepo/backup/data/SYSTEMDB make sure that this directory structure exists and is writable with user
${sid}adm .

Backup Prefix COMPLETE_DATA_BACKUP_INITIAL_DDMMYYY Next
Review Backup Setup and then select Finish

Make sure that the SYSTEMDB@${SID} backup completes successfully.

Backup MDC
Backup & Recovery
Backup Up Tenant Database
Specify the Tenant Database ${sid} . Next
Backup Type Complete Data Backup .
Destination File .
Backup Destination /swrepo/backup/data/DB_${sid} make sure that this directory structure exists and is writable with user
${sid}adm .

Backup Prefix COMPLETE_DATA_BACKUP_INITIAL_DDMMYYY . Next

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 572

Review Backup Setup and then select Finish .

Make sure that the backup of DB_${sid} completes without errors.

Check backup status
On the SYSTEMDB entry, -> right click and select the following actions.
Backup & Recovery
Select Open Backup Console
Select the tab Backup Catalog
In the Database Field select ${sid} for the MDC
In the Database Field select <SYSTEMDB> for the SYSTEMDB

Optional check of the trace log files
The database trace is written to service specific files on operating system level. The trace directory is in the following location:
/usr/sap/${sid}/HDB<inst>/<host>/trace/DB_${sid}/

The following alias in the environment of the ${sid}adm user allows to you quickly switch to the trace directory on the OS level:
cdtrace

The database trace files use the following naming convention:
<service>_<host>.<port>.<counter>.trc

In the context of dynamic tiering, a file with the following convention can exist (SAP Note 2871785):
esserver_console_<host>.<port>.<counter>.trc

Example:
indexserver_saphana01.30003.024.trc You can access these files either directly on the operating system level or in one of the following

ways:
SAP HANA Studio -> Administration -> Diagnosis Files
DBACOCKPIT -> Diagnostics -> Diagnosis Files

Migrating SAP S/4HANA by using SAP HANA System Replication
Pre-checks before you configure SAP HANA System Replication
Before you configure SAP HANA System Replication, a few prerequisites must be checked. The described Steps are valid for Red Hat
Enterprise Linux 8 (RHEL) and SUSE Enterprise Linux (SLES).

Check the SAP HANA database user on the source system
Check with your SAP basis administration team or SAP HANA administrators, which SAP HANA database user is used to access the system.
Typically this user the SYSTEM user, or the SAP schema owner user if your SAP basis administration team implemented the SAP security
advisories.

SAP HANA landscape pre-steps for activating SAP HANA System Replication
Set the environment variables on the primary and secondary SAP HANA systems
To simplify the setup, prepare the following environment variables for ${sid}adm on both nodes. These environment variables are used in
subsequent commands in the remainder of the examples.
On both nodes, run the following commands. Remember that the variables must be the same on both systems, source and target.
export SID=<SID>

# SAP HANA System ID (uppercase)

export sid=<sid>

# SAP HANA System ID (lowercase)

export INSTNO=<INSTNO>

# SAP HANA Instance Number

export DIR_INSTANCE=/usr/sap/${SID}/HDB${INSTNO} # "${sid}adm" home directory

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 573

export SiteOnPrem=<PrimarySiteName>

# HANA System Replication Site Name 1 - Migration from On-Prem - Source

export SiteOnCloud=<secondarySiteName>

# HANA System Replication Site Name 2 - Migration to On-Cloud - Target

export NODE1=<Hostname 1>

# Hostname of On-Prem Server

export NODE2=<Hostname 2>

# Hostname of IBM Cloud PowerVS Instance

Make sure that SAP HANA is running on both systems
As the operating system user ${sid}adm , the command HDB proc can be used to verify that all services are started.
Run the following command on both systems, primary and secondary SAP HANA server.
$ sudo -i -u ${sid}adm -- HDB proc

SAP HANA version must be equal or greater than the primary server
Run the following command on each node to determine the SAP HANA server version.
$ sudo -i -u ${sid}adm -- HDB version

The target system version must be equal or larger compared with the source system version. The only exception for the version is for an
Active/Active read enabled configuration, here the HDB version must be identical on source and target system.

Therefore, make sure that the system configuration is identical on both the source and target servers. Then, compare the settings in the
ini-files on both systems.
For a scale-out configuration, make sure that the number of worker nodes (scale-out) and roles are identical on both the source and
target servers.
The same ${sid} and instance numbers must be used on both systems.
Back up PKI SSFS .key and the .dat files from the primary and secondary systems.
Copy existing PKI keys from the primary to the secondary system.
To make sure that you can recover to the original installed state, if needed, back up the existing keys on both primary and secondary systems.
$ sudo -i -u ${sid}adm -- cp -p /usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT
/usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT_<hostname>

After the backup of the existing PKI SSFS .key and .dat files is done, you now need to copy the PKI SSFS .key and .dat files from
primary system to the target system.
The SAP HANA 2.0 data and log transmission channels for the replication process require authentication by using the system PKI SSFS storage
certificate files.
SAP Note 2369981 - Required configuration steps for authentication with HANA System Replication
The system PKI SSFS storage certificate files are stored in /usr/sap/${SID}/SYS/global/security/rsecssfs/ in subdirectories data and
key .

On NODE2, run the following commands to copy files SSFS_${SID}.DAT and SSFS_${SID}.KEY from NODE1.
As ${sid}adm user, run the following two commands on NODE2.
$ scp ${NODE1}:/usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT
/usr/sap/${SID}/SYS/global/security/rsecssfs/data/SSFS_${SID}.DAT

$ scp ${NODE1}:/usr/sap/${SID}/SYS/global/security/rsecssfs/key/SSFS_${SID}.KEY
/usr/sap/${SID}/SYS/global/security/rsecssfs/key/SSFS_${SID}.KEY

The copied PKI SSFS storage certificates on NODE2 become active during the start of the SAP HANA system.

Check that the configuration parameter log_mode is set to normal
Make sure that the configuration parameter log_mode is set to normal in the persistence section of the global.ini on both the primary and
secondary SAP HANA Servers.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 574

Run the following command on both systems to verify the log_mode setting.
$ sudo -i -u ${sid}adm -- grep -i 'log_mode' /usr/sap/${SID}/HDB${INST}/exe/config/global.ini

The following output is expected.
log_mode=normal

Register the primary server first
On the primary SAP HANA system, run the following command to register this node as the

primary for SAP HANA System Replication.

$ sudo -i -u ${sid}adm -- hdbnsutil -sr_enable --name={SiteOnPrem}

The following output is expected.
nameserver is active, proceeding ...
successfully enabled system as system replication source site
done.

Check whether the primary system is registered
Verify that the primary system is successfully registered by using the following command.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

The following output is expected.
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: primary
operation mode: primary
site id: 1
site name: SiteOnPrem
is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: false
is a takeover active: false
is primary suspended: false
Host Mappings:
~~~~~~~~~~~~~~

Site Mappings:
~~~~~~~~~~~~~~
SiteCloud (primary/)
Tier of SiteCloud: 1
Replication mode of SiteCloud: primary
Operation mode of SiteOnPrem :

Hint based routing site:
done.

Make sure that SAP HANA is not active on the secondary site
The secondary site must not be an active SAP HANA server. Stop SAP HANA database services by using the following command.
$ sudo -i -u ${sid}adm -- HDB stop
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 575

The following output is expected.
hdbdaemon will wait maximal 300 seconds for NewDB services finishing.
Stopping instance using: /usr/sap/${SID}/SYS/exe/hdb/sapcontrol -prot NI_HTTP -nr 10 -function Stop 400
10.08.2023 10:32:07
Stop
OK
Waiting for stopped instance using: /usr/sap/${SID}/SYS/exe/hdb/sapcontrol -prot NI_HTTP -nr 10 -function
WaitforStopped 600 2

10.08.2023 10:32:51
WaitforStopped
OK
hdbdaemon is stopped.

Register the secondary system
Now register the secondary system.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_register --name=<secondarySiteName> --remoteHost=<primary_host> -remoteInstance=<primary_systemnr>
--replicationMode=[sync|syncmem|async]--operationMode=[delta_datashipping|logreplay|logreplay_readaccess]

For example, if you use
SiteOnCloud as the secondary site name
syncmem as replication mode and
logreplay as operation mode

The last command looks like the following example.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_register --name=SiteOnCloud --remoteHost=<primary_host> --remoteInstance=
<primary_systemnr>

--replicationMode=syncmem --operationMode=logreplay

The following output is expected.
Thu 10 Aug 10:36:13 CEST 2023
adding site ...
collecting information ...
updating local ini files ...
done.

Troubleshoot hdbnsutil errors with SELinux enabled
If security-enhanced Linux (SELinux) is enabled, the output of hdbnsutil is not as expected. You can see one of the following two symptoms.
Command is not recognized error message

Usage information displayed
SELinux, when set to enforcing , prevents the command hdbnsutil from restarting the saphostagent in the ${sid}adm user context. You
can either add proper SELinux security policies or as SAP recommends. Then, disable SELinux.
Check the current SELinux status with the following command.
$ sestatus

The following output is an example.
SELinux status:

enforcing

If sestatus command returns with enforcing , then commands even when run with root privileges can be blocked, depending on security
policy.
To disable SELinux temporarily, run the following command.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 576

$ sudo setenforce 0

SELinux is now temporarily disabled until the next restart.
Now check with sestatus again, the status shows disabled .
Check whether the saphostagent process is running with the following command.
$ sudo ps -ef | grep -i host

If output is empty and no process is displayed, manually restart the saphostagent.
$ sudo -i -u ${sid}adm -- /usr/sap/hostctrl/exe/saphostexec -restart /usr/sap/hostctrl/exe/host_profile

Check the state on both sides of the SAP HANA System Replication
Check the primary system state
Verify the system replication state on the primary node. Run the following command on the primary server:
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

The following output is expected.
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: primary
operation mode: primary
site id: 1
site name: SiteOnPrem_hostname
is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: true
is a takeover active: false
is primary suspended: false
Host Mappings:
~~~~~~~~~~~~~~
<SiteOnCloud_hostname> -> [SiteOnPrem_hostname] <SiteOnPrem_hostname_hostname>
<SiteOnCloud_hostname> -> [SiteOnCloud] <SiteOnPrem_hostname_hostname>

Site Mappings:
~~~~~~~~~~~~~~
SiteOnPrem_hostname (primary/primary)
|---SiteOnCloud (syncmem/logreplay)
Tier of SiteCloud: 1
Tier of SiteOnPrem_hostname: 2
Replication mode of SiteOnPrem_hostname: primary
Replication mode of SiteOnCloud: syncmem
Operation mode of SiteOnPrem_hostname: primary
Operation mode of SiteOnCloud logreplay
Mapping: SiteOnPrem_hostname -> SiteOnCloud
Hint based routing site:
done.

Check the secondary system state
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 577

Now check the system replication state on the second node. Run the same command on the second server.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

The following output is expected.
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: false
mode: syncmem
operation mode: unknown
site id: 2
site name: SiteOnCloud
is source system: unknown
is secondary/consumer system: true
has secondaries/consumers attached: unknown
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 1
primary masters: <SiteOnPrem_hostname_hostname>
done.

Restart the secondary server
So far both SAP HANA servers are configured as replication partners. Now restart the secondary SAP HANA server to complete the replication
setup.
Run the following command on the secondary server.
$ sudo -i -u ${sid}adm -- HDB start

The following output is expected.
StartService
OK
Starting instance using: /usr/sap/${SID}/SYS/exe/hdb/sapcontrol -prot NI_HTTP -nr 10 -function StartWait 2700 2
OK

10.08.2023 10:38:47
Start
OK
10.08.2023 10:40:17
StartWait
OK

Check HDB info or HDB proc on the secondary side to confirm that SAP HANA is running again. When successful, run the

sr_state

command on the primary system.
$ sudo -i -u ${sid}adm -- hdbnsutil -sr_state

The following output is expected.
System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~
online: true
mode: primary

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 578

operation mode: primary
site id: 1
site name: SitePrem
is source system: true
is secondary/consumer system: false
has secondaries/consumers attached: true
is a takeover active: false
is primary suspended: false
Host Mappings:
~~~~~~~~~~~~~~
<SiteOnCloud_hostname> -> [SiteOnPrem] <SiteOnPrem>
<SiteOnCloud_hostname> -> [SiteOnCloud] <SiteOnPrem>

Site Mappings:
~~~~~~~~~~~~~~
SiteOnPrem (primary/primary)
|---SiteOnCloud (syncmem/logreplay)
Tier of SiteOnprem : 1
Tier of SiteOnCloud: 2
Replication mode of SiteOnPrem: primary
Replication mode of SiteOnCloud: syncmem
Operation mode of SiteOnPrem: primary
Operation mode of SiteOnCloud: logreplay
Mapping: SiteOnprem_hostname -> SiteOnCloud
Hint based routing site:
done.

Check replication status
After the secondary system is configured and SAP HANA is started on the secondary server, the replication process automatically starts
synchronizing data with a full replica . You can verify the initial replication on the primary server and watch the current completion status
of the full replication action.
Run the Python script with the following command.
$ sudo -i -u ${sid}adm -- python ${DIR_INSTANCE}/exe/python_support/systemReplicationStatus.py

The following output is expected.
|Database |Host
|Secondary
|

|Port

|Service Name |Volume ID |Site ID |Site Name |Secondary |Secondary |Secondary |Secondary

|Replication |Replication |Replication
|

|Active Status |Mode

|

|

|
|Status

|Secondary

|

|

|

|Host

|Port

|Site ID

|Site Name

|Status Details |Fully Synced |

|-------- |-------- |----- |------------ |--------- |------- |--------- |----------|--------- |--------- |---------|------------- |----------- |----------- |-------------- |-------------|
|SYSTEMDB |<NODE1>
|SiteOnCloud|YES
|S4H

|<NODE1>

|SiteOnCloud|YES
|S4H

|<NODE1>

|SiteOnCloud|YES
|S4H

|<NODE1>

|SiteOnCloud|YES
|S4H

|<NODE1>

|SiteOnCloud|YES

|31001 |nameserver
|SYNCMEM

|
|ACTIVE

|31007 |xsengine
|SYNCMEM

|
|

|SYNCMEM

|
|
|ACTIVE

|
1 |SiteOnPrem|

|
5 |

|
1 |SiteOnPrem|

|
3 |

|ACTIVE

|31011 |dpserver
|SYNCMEM

2 |

|ACTIVE

|31003 |indexserver

1 |SiteOnPrem|
|

|ACTIVE

|31040 |docstore
|SYNCMEM

1 |

|
1 |SiteOnPrem|

|
4 |

|
1 |SiteOnPrem|

|

|

<NODE2> |

31001 |

2

31007 |

2

31040 |

2

31003 |

2

31011 |

2

True|
<NODE2> |
True|
<NODE2> |
True|
<NODE2> |
True|
<NODE2> |
True|

status system replication site "1": ACTIVE
overall system replication status: ACTIVE
Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 579

mode: PRIMARY
site id: 1
site name: SiteOnPrem_hostname

Four methods to check the system replication status
Option 1. landscapeHostConfiguration.py
The first option uses the Python script landscapeHostConfiguration.py for a server point of view. This script displays a status line per SAP
HANA server system.
Run the following command.
$ sudo -i -u ${sid}adm -- python ${DIR_INSTANCE}/exe/python_support/landscapeHostConfiguration.py

Make sure that each server that is listed in the output shows OK in the host status column.

Option 2. systemReplicationStatus.py
The second alternative option uses the Python script systemReplicationStatus.py for a database view of the SAP HANA system replication.
This script displays one status line for each database and an overall status after the database table.
Run the Python script with the following command.
$ sudo -i -u ${sid}adm -- python python ${DIR_INSTANCE}/exe/python_support/systemReplicationStatus.py

Make sure that each database listed shows an ACTIVE in replication status column. The expected script output contains the following line:
overall system replication status: ACTIVE

Option 3. hdbcons
Check the detailed status of the system replication with the hdbcons command and run as ${sid}adm user. This third option is a technical
per server and per service view.
Run the SAP HANA DB Management Client Console hdbcons with the following command.
$ sudo -i -u ${sid}adm -- hdbcons -e hdbindexserver "replication info"

Option 4. Sql script
The fourth alternative uses an SQL statement that can be run, for example, in SAP HANA studio or cockpit. This option is a hosts-per-site-view
of SAP HANA system replication.
Check by running the following SQL statement.
$ select host, SECONDARY_HOST, PORT, SITE_NAME, SECONDARY_SITE_NAME, REPLICATION_MODE, REPLICATION_STATUS,
REPLICATION_STATUS_DETAILS,SECONDARY_ACTIVE_STATUS from M_SERVICE_REPLICATION;

Check especially columns REPLICATION_STATUS and REPLICATION_STATUS_DETAILS in the SQL output.

Post replication completion
Before you disable the replication setup, check the trace logs for any inconsistencies or anomalies after the replication action is performed.
After the replication completes, the database contains all active services on the primary system only. But you can still examine the trace logs
for any inconsistencies or issues.

Checking the database trace files
The database trace is written to service specific files on operating system level. The trace directory is located here:
/usr/sap/<SID>/HDB<inst>/<host>/trace/DB_<SID>/

The following alias in the ${sid}adm user environment allows the ${sid}adm user to quickly change to the trace directory on the operating
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 580

system level:
$ cdtrace

The database trace files have the following naming convention: <service>_<host>.<port>.<counter>.trc
In the context of dynamic tiering also a file with the following convention can exist (SAP Note 2871785): esserver_console_<host>.<port>.
<counter>.trc

Example: indexserver_saphana01.30003.024.trc
You can access database trace files in three ways:
Directly on the operating system level
SAP HANA Studio -> Administration -> Diagnosis Files
DBACOCKPIT -> Diagnostics -> Diagnosis Files

SAP HANA System Replication resources
For more information, see the following links:
SAP Note 1999880 - HANA System Replication FAQ
SAP Note 11969700 - SQL Statement Collection for SAP HANA
SAP Note 3357978 - Configuring SAP HANA Multi Target System Replication
SAP HANA Replication Setups
SAP HANA System Replication
SAP HANA multitarget System Replication
SAP HANA System Replication
SAP Help Portal Documentation HSR HANA 2.0 SP07

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 581

Case Studies of SAP-certified Infrastructure
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
The following links are a compilation of case studies where IBM provided infrastructure for SAP workloads (including on-premises and Cloud).

SAP S/4HANA
Fulcrum on IBM Cloud
https://www.ibm.com/case-studies/fulcrum-cloud-sap-legal-services

SAP BW/4HANA
SAP ECC on SAP HANA (BSoH)
SAP BW on SAP HANA (BWoH)
SAP ECC on AnyDB
SAP BW on AnyDB

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 582

Infrastructure Reference Architectures for SAP
Deprecated: This document is out of date, it is being updated and replaced in November-2020 with new content.

SAP HANA scale-up Reference Architecture
Intel Bare Metal
Reference architecture (RA) for a landscape comprised of
$ * Vyatta network components
* SAP Web Dispatcher
* SAP NetWeaver Application Servers
* SAP HANA databases
* Other relational database management systems (RDBMS)

The example RA is configured with high availability and disaster recovery. Note that in Figure 1, the database servers can be any database
system supported by SAP NetWeaver, for example, SAP HANA.

Figure 1. Sample reference architecture

Understanding the architecture behind the SAP reference architecture
The architecture example in Figure 1 might differ from your architecture; it shows the general concepts of an SAP IBM Cloud®-based
deployment. Your on-premises systems are connected through the internet to your IBM Cloud infrastructure.
After your environment is ordered and deployed, you connect through an administrative VPN to your IBM Cloud infrastructure. The VPN might
not be sufficient for connecting your on-premises systems with cloud-based systems, which is why you can deploy a Vyatta Network appliance
in the IBM Cloud environment. For higher bandwidth and lower latency requirements, an Ethernet circuit handover into the cloud environment
is also supported.
There are two different data centers that are shown in Figure 1 that consist of several SAP-certified Bare Metal Servers for both SAP NetWeaver
and SAP HANA. The Bare Metal Servers in the diagram can be different, depending on your environment and the database technology you're
using. In addition, the SAP HANA data in the architectural overview is transferred from the primary data center to the secondary data center for

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 583

disaster recovery (DR). Other databases also allow for setups like Figure 1, with the setup being different.
In Figure 1, on the DR data center site, replicated systems are configured to maintain DR capabilities, which need to be implemented on
different layers. For more information, see Disaster recovery considerations.

SAP systems
The SAP systems (Advanced Business Application Programming (ABAP), Java, and SAP HANA) have a granular set of authorization objects for
user management. Because of this, only remote access from desktops or other front-end devices to the IBM Cloud-based environment need to
be set up. No user access needs to be granted and managed in the cloud environment. There might be several users with different
responsibilities who need access to a database through a specific interface, command line, or have latency restrictions that require Remote
Desktop Protocol (RDP)-based access. To manage RDP access, a "jump host" can be deployed in the environment to serve as a central point of
access for these scenarios. Apart from these specific requirements, users have access to the cloud-based systems within your corporate
network and do not need to be administered in any specific way.

Network
Any device in an IBM Cloud environment can be ordered with a choice of internal and optional external LAN access. The external address is a
routable public IP address and should be handled with care. The internal address is determined by the ordered VLAN and chosen from a
subrange of 10.0.0.0/8. By ordering multiple VLANs, different environments, or traffic types, can be segregated according to your network
design and security requirements.
While a public interface with a configured firewall can cover some scenarios - for example, short term, rapid prototyping proof of concept with
non-critical data - a firewall device should be considered for most cases. The example reference architecture maps a production scenario, so
public network interfaces are out-of-scope.

Vyatta Network Gateway
Vyatta provides software-based virtual router, virtual firewall/NAT, and VPN capabilities for both IPV4 and IPV6. If users are to connect
remotely into your IBM Cloud-based systems, these devices can serve as end-points for both side-to-side VPN or the so-called "road warrior
VPN" (access point). Different kinds of VPN technologies - IPSec, or SSL VPN tunnels, such as OpenVPN - can be used. Depending on the SAP
technology you're using, these VPN connections can be used to interconnect SAP systems (even with non-SAP systems) for traditional GUI
technology, and browser-based SAP UI5 technology. Connecting an SAP Web Dispatcher behind a Vyatta Gateway allows for further features to
be used, such as load balancing or single sign-on scenarios. For more information on the SAP Web Dispatcher, see High availability.
The Vyatta device can be deployed in a high-availability cluster configuration with a bandwidth up to 10 Gbps. For more information, see
Vyatta 5400 High Availability Configuration .

Jump box server
SAP systems contain user management and do not require centralized user administration. You can, of course, set up centralized user
management. For more information, see Central User Administration) .
You can use a jump box server to give specific users low-level access to your IBM Cloud environment through command-line access-based
tools or other special purpose tools, such as SAP HANA Studio. Database administration tools, and the users who are granted access to the
tools, are managed centrally on the jump box server. Users can log in to your IBM Cloud environment from their desktops through Remote
Desktop Protocol, which is routed through the VPN gateway.

SAP servers - SAP HANA and SAP NetWeaver
IBM offers various of SAP-certified servers for SAP HANA and SAP NetWeaver from the IBM Cloud® for SAP portfolio. The servers are Bare
Metal Servers with your choice of operating system (OS) (Red Hat Linux, SUSE Linux, Microsoft Windows Server, or deployed with the VMware
ESX hypervisor). For more information on the SAP NetWeaver-certified servers, see SAP Note 2414097).
Note: On the hypervisor, you deploy one of the operating systems that are listed in SAP Note 2414097 as a guest OS.
SAP HANA servers come with a preselected storage layout that fulfills SAP's storage Key Performance Indicators (KPIs) for SAP HANA. You
cannot change these layouts and you're urged not to use external storage for SAP HANA. External storage of different quality and accessible
through different protocols - NFS, CIFS, iSCSI - can be used for backup and other purposes. Also, for the SAP NetWeaver servers, you have a
choice to run other supported database systems on external storage.
All SAP Software solutions based on either SAP HANA or on SAP NetWeaver include the entire SAP Business Suite, and SAP S/4HANA can be
deployed in the IBM Cloud environment. For other software components outside of these components, you need to contact SAP Support.
Follow the SAP sizing process to determine the right server size for your project, and choose from the servers that are listed for either the SAP
HANA or SAP NetWeaver offering.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 584

For more information on the SAP HANA-certified servers, see the SAP Certified and Supported SAP HANA Hardware Directory - Certified IaaS
Platforms - IBM Cloud.
For more information on SAP HANA and SAP NetWeaver sizing, see Sizing process for SAP Systems) .

Guidance for your IBM Cloud SAP-Certified Infrastructure
Your requirements might differ from the offered guidance; however, it serves as a starting point for building your SAP-certified server in the
IBM Cloud® environment.

VLANs
The SAP guidelines for landscape design recommend a segregation of server traffic on different network interface controllers (NICs). For
example, business data should be separated from administrative and backup traffic. Assigning multiple NICs to different subnets enables this
data segregation. For more information, see the Network section in Building High Availability for SAP NetWeaver and SAP HANA (PDF).
To follow the NIC recommendation, you can configure multiple VLANs on the servers. The VLAN interfaces can be made high availability (HA)
through multiple NICs to be configured under bond interfaces (Linux) or teaming interfaces (Microsoft Windows). Consult SAP installation
documentation for support on how to assign addresses during the installation with the SAP Software Provisioning Manager (SWPM). For virtual
machines (VMs), the address of the main interface of the VM is usually sufficient.
Tip: A best practice is to reserve additional IP addresses and assign the addresses to the different SAP services as the services are
implemented for both HA and disaster recovery (DR) capabilities on the IBM Cloud® Bare Metal Servers.
By default, IBM Cloud Bare Metal Servers have a public and a private interface. In general, it's not recommended to keep the public LAN
configured for all servers in your IBM Cloud infrastructure. Specific instances of the Vyatta Network Gateway should be deployed to allow
public access to your environment, if needed. For more information, see Vyatta Network Gateway.

IBM Cloud storage
IBM Cloud servers certified for SAP NetWeaver can be configured with a different number of internal disks and with different layouts for those
disks for RAID configuration. Be aware that the layouts might not be sufficient for project requirements, for example, insufficient size, or shared
access to storage.
Storage requirements differ to the point that the guidance is to clearly define the project Key Performance Indicators (KPIs) in terms of backup
and restore time slots, HA and failover requirements, and then decide on the storage type to use. Covering all options is beyond the scope of
this content; however, some guidance can be provided.
$ * Use shared iSCSI devices for HA setups with a database that fails over between nodes. You will need to look at the
required maximum IOPS/sec.
* Use internal storage for HA setups with a database that is replicated; for example, SAP HANA system replication. SAP
NetWeaver application servers can either reside on internal storage or on shared network-attached storage (NAS).
* Use shared storage to facilitate failover capabilities with VMware-based installations. For more information on
selecting the right storage type, see [Storage to use with VMware Systems](/docs/vmware?topic=vmware-vmware-storage).

All the options can be selected from within the IBM Cloud infrastructure.

High availability
In a distributed installation of SAP applications on a centralized database, the base installation is replicated to achieve HA. For each layer of the
architecture, the HA design varies.
$ * **SAP Web Dispatcher**. HA is achieved with multiple redundant SAP Web Dispatcher instances with SAP application
traffic. The SAP Web Dispatcher serves as a potential entry point for a set of SAP systems and other `https`-based
services. It typically lies between the internet and the backend systems and deals with web protocol-based requests
from the "outside world." The SAP Web Dispatcher works like a reverse proxy with a variety of supported features, such
as load balancing and single sign on. For more information, see [SAP Web Dispatcher]
(https://help.sap.com/viewer/product/SAP_NETWEAVER_731/7.31.25/en-US){: external}.
* **ABAP SAP Central Services (ASCS)**. For HA of ASCS in an IBM Cloud environment, the cluster software of the target
operating system needs to be installed, for example, Linux Pacemaker or Microsoft Cluster. The single point of failure
of the ASCS (SAP's enqueue service) needs to be configured to replicate its data to an Enqueue Replication Service
(ERS). An ERS instance needs to be installed as part of the SAP installation process and is supported by SAP's SWPM.
For details on installing and configuring the cluster components for both ASCS and ERS, consult the documentation of

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 585

the operating system vendor's offering.
* **SAP NetWeaver application servers**. HA is achieved by load balancing traffic within a pool of application servers.
If only a limited amount of resources are required, a single application server can be configured as HA. The
application server needs to be installed with storage that is accessible by all potential cluster nodes, which can be
used for failover. Also, the SAP NetWeaver stack needs to use a virtual hostname. Consult the operating system
documentation of the operating system vendor for details on the required configuration and SAP documentation for HA. If
your configuration requires multiple application servers, the configuration of the SAP application servers needs to
cover load balancing, too, for example, in SAP logon groups and RFC server groups. For more information, see the
administration guide for your SAP NetWeaver version.
* **Database tier**. The example reference architecture deploys a single SAP HANA, or other database, instance. For
high availability, deploy more than one instance and use HANA System Replication (HSR) to implement manual failover. To
enable automatic failover, a high availability extension for the specific Linux distribution is required. For other
databases, either

a failover of the database instance on shared storage can be configured, or a replication technique

similar to the SAP HANA case can be used. Consult the documentation of the supported database system for the set of
options that are required to set up either high availability or replication.
For additional information, see [IBM Cloud high-availability support](/docs/sap?topic=sap-hana-design-considerations).

Disaster recovery
Each tier uses a different strategy to provide disaster recovery protection.
SAP NetWeaver application servers . SAP application servers contain no business data; however, the installation and configuration of the
server needs to be preserved for continued operation after a disaster. One disaster recovery strategy is to have SAP application servers in
another region. Any changes to configuration or kernel updates on the primary application server must be copied to the virtual machines
or servers in the disaster recovery region.
SAP Central Services (SCS). The SCS component of the SAP application stack doesn't persist business data. You can build a server or a
VM in the disaster recovery region to run the SCS role. The only content from the primary SCS note to synchronize is the /sapmnt share
content. Also, if configuration changes or kernel updates take place on the primary SCS servers, the changes must be replicated on the
disaster recovery SCS. To synchronize the two servers, use a regularly scheduled copy job to copy /sapmnt to the disaster recovery
servers. For more information on SCS, see Central Services Instance.
Database tier. For SAP HANA-based systems, use HANA-supported replication solutions such as HANA System Replication or IBM Cloud
storage replication features. For other supported databases, refer to the database documentation for its supported features. In general,
choosing from the available options requires a clear understanding of the business requirements of the underlying SAP application. The
impact of a potential loss of single transactions or even all data within a time window needs to be determined.
Infrastructure. Depending on where the SAP clients are in your IBM Cloud infrastructure, other components within it need to be
prepared for disaster recovery scenarios. In the example reference architecture, clients access the SAP systems from the on-premises
side, or from within the customer's corporate network.

Security
User management
SAP has its own Users Management Engine (UME) to control role-based access and authorization with the SAP application. For more
information, see SAP HANA Security - An Overview . From a user management perspective, it's not relevant if your SAP systems run onpremises IBM Cloud. Exceptions to that rule are mentioned under Jump box server.

Network security
Since there are different ways for you to access an IBM Cloud-based environment, security measures need to be differentiated.
The use of a public interface for external access should only be considered in proof-of-concept type deployments. For production scenarios,
the deployment of Vyatta appliances is available since the appliances feature all required functionality (VPN firewall, and so on). Should latency
and or through-put requirements not be met by Vyatta appliances, contact IBM Cloud Support to discuss all the possible steps and
configurations that are available beyond the Vyatta appliances.

SAP HANA scale-out Reference Architecture
The IBM Cloud® architecture provides superior technical capabilities, such as a software definable environment critical to a cloud
infrastructure, programmable interfaces, and hundreds of hardware and network configurations. It is designed to deliver a higher level of
flexibility by mixing virtual and dedicated servers to fit various workloads, automation of interfaces, and hybrid deployment options. The IBM

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 586

Cloud SAP-Certified Infrastructure offering for SAP HANA and SAP NetWeaver provides you with a best-fit selection. This selection includes
bare metal and virtualization-based servers on which the SAP software stack is run.

Intel Bare Metal servers on Classic Infrastructure
Reviewing the network topology and storage layout
Figure 1 shows the network topology that is required for the IBM Cloud Classic Infrastructure as a Service SAP HANA TDI scale-out setup.

Figure 1. IBM Cloud Classic IaaS SAP HANA TDI scale-out network topology

Available SAP HANA certified IBM Cloud configurations
For Intel Bare Metal, the following solutions are certified to serve as OLAP or OLTP scale-out configuration SAP HANA nodes:
OLTP:
BI.S4.H8.12000
OLAP:
BI.S4.H8.12000
BI.S4.H8.6000
BI.S4.H4.3000
BI.S4.H4.6000
BI.S4.H2.3000
BI.S2.H8401
BI.S2.H4101
BI.S2.H4201
Check SAP' Certified and Supported SAP HANA Hardware Directory for details of the supported configurations.

Network layout for Scale-out configurations
For Intel Bare Metal scale-out configurations, contact IBM Cloud support for assisting you to set-up the required networking. Depending on the
hardware used, the choice of networks might be restricted, or special configurations might have to be adapted. See the following diagram, for
the layout to use. The diagram describes the use of three fully redundant (LACP config), physically separate networks, for:
Storage traffic,
Internal SAP HANA inter-node communication
Communication with the client(s), for example SAP ABAP application servers or SAP HANA Studio for administration purposes.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 587

Use the network that holds the default route of your environment to pass the NFS traffic through it, the storage servers are reachable through
that gateway, only.

Storage for Scale-out configurations
For scale-out configuration, the ability of storage volumes to be accessed from different server nodes is required for failover purposes. Thus,
local storage is out of scope, and NFS volumes need to be deployed. The deployed volumes can vary in size and number (see details here:
Persistent Data Storage in the SAP HANA Database ). In any case, they have to comply with the TDI performance KPIs (see SAP Note
2613646) verified by SAP HANA Hardware and Cloud Measurement Tools .
IBM Cloud recommends Endurance File Storage at 10 IOPS per GB or Performance File Storage with IOPS equal or greater than 10K. For the
network configuration, use the primary network as storage network to guide the traffic to the NFS servers through it.

Intel Virtual Servers in VPC Infrastructure (Gen2)
Available SAP HANA certified IBM Cloud configurations
For Intel-based VSIs in VPC, the following configuration is available for OLAP scale-out configuration with SAP HANA:
OLAP:
vx2-176x2464
Check SAP' Certified and Supported SAP HANA Hardware Directory for details of the supported configurations.
These configurations can either be run on-top of dedicated hosts (DHs) or on shared hosts.

Network layout for Scale-out configurations
For Intel Bare Metal scale-out configurations, contact IBM Cloud support for assisting you to set-up the required networking. On the VPC
(Gen2) infrastructure, underlying host systems are laid out for full redundance, no matter if they are dedicated or shared hosts. As a result,
VSIs in VPC do not require for redundant network adapter. Throughput for all VSI level adapters in one VSI is limited to 60 Gbps, by default. A
single adapter is limited to 25 Gbps maximum throughput. Therefore, the HANA network layout for scale-out configurations requires three
separate networks, 3 adapters to be configured with a throughput of 20 Gbps, each. See the following diagram for the network layout for VSIs.
Read the following chapter on storage before you decide on the details of your storage layout and the according networks to use.
Figure 2 shows the network topology that is required for the IBM Cloud VPC Infrastructure as a Service SAP HANA TDI scale-out setup.

Figure 2. IBM Cloud VPC IaaS SAP HANA TDI scale-out network topology for VSIs

Storage for Scale-out configurations
For scale-out configuration, the ability of storage volumes to be accessed from different server nodes is required for failover purposes. Thus,
local storage is out of scope, and NFS volumes need to be deployed. These shares are referred to as file shares and their mount
targets in IBM Cloud VPC. The shares can vary in size and number (see details here:

Persistent Data Storage in the SAP HANA Database ). In

any case, they must comply with the TDI performance KPIs (see SAP Note 2613646) verified by SAP HANA Hardware and Cloud
Measurement Tools.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 588

IBM Cloud recommends 10 IOPS per GB or custom profile File Shares for meeting the SAP's KPIs.
Choose one subnet to connect the file shares to. Carefully design and configure your network and SAP HANA configuration in a way that this
network is not used for client nor internal communication. For more information on creating file shares and mount targets, see Planning your
file shares.

SAP NetWeaver scale-up Reference Architecture
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

Intel Bare Metal
Content

Intel Virtual Server (Gen2)
Content

IBM Power Virtual Server
Content

VMware SDDC
Content

SAP NetWeaver scale-out Reference Architecture
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

Intel Bare Metal
Content

Intel Virtual Server (Gen2)
Content

IBM Power Virtual Server
Content

VMware SDDC
Content

SAP NetWeaver 7.x on UNIX with Sybase on IBM Cloud® VPC
Sybase is one of the many databases that can be run with SAP NetWeaver and that is supported on the IBM Cloud®. The most common
architecture deployments are standard and distributed. IBM Cloud is certified for running SAP NetWeaver application servers ABAP, Java, and
SAP products based on these application server stacks.

SAP NetWeaver architecture
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for Advanced Business Application
Programming (ABAP) and Java applications. SAP NetWeaver components are built on the SAP NetWeaver Application Server and are written in
ABAP or Java Platform, Enterprise Edition. ABAP systems, Java systems, and dual-stack systems are distinct systems.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 589

Core platform features
SAP NetWeaver uses ABAP or Java core platforms to support the SAP applications. SAP NetWeaver:
Has application lifecycle management capabilities.
Provides the basic structure for the on-premises versions of SAP Business Suite and other applications, as an application server.
Is the foundation for the on-premises SAP S/4HANA next-generation business suite, with SAP HANA serving as the sole underlying
database.
SAP provides a list of the SAP versions to learn more about the versions available in IBM Cloud. Each support package stack has a leading
software component version. The support package level of each component version is a key part of the stack and a unique identifier for the
support package stack.

Installation types
The three installation types for SAP NetWeaver Application Server are:
ABAP System– You can run ABAP programs and some SAP Java apps
Java System– You can run only Java Platform, Enterprise Edition apps. No ABAP programs can be run on a Java system
Dual Stack – You can run both ABAP and Java Platform, Enterprise Edition in separate instances

Architecture diagram
This diagram shows the SAP NetWeaver 7.X on Sybase DB integrated with IBM Cloud on the SAP NetWeaver 7.x architecture:

Figure 1. SAP NetWeaver 7.x with SYB standard installation with AAS on VSI to VPC IBM Cloud

Access from an external network
Clients on the customer facing network (CFN) use a floating IP to access virtual server instances within the IBM Cloud. Virtual server instances
are hosted in availability zones (data centers) within geographic regions.
Within the Public Subnet, the SAP router and the jumphost provide secure connections to the virtual server instances. The SAP router is a
software application that provides a remote connection between the customer's network and SAP. The SAP Router and jumphost are within a
single security group with rules for inbound and outbound traffic between the private subnets in the zone. SAP routers are used with traditional
SAP products and analytics solutions and offerings that are acquired from Sybase. For a comprehensive list of which SAP Business Analytics
products benefits from SAP router connections, see SAP Note 1478974.
A jumphost is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their
premises. These SAP virtual server instances can be in a separate security zone but should be on same IBM Cloud region. The customer
connection to the jumphost follows the same rules as the direct connection from customer premises to the virtual server instance SAP
instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. In this architecture, there are
two security groups defined; this arrangement is the simplest method for separating the public and private subnets. You can add more security
groups if you require more isolation.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 590

Virtual server instances on SAP NetWeaver 7.x APAB stack, Java stack, and dual stack
(ABAP+Java) architectural design on IBM Cloud® VPC on Unix
Standard system
In a standard system, all main instances run on a single virtual server instance within a private subnet. about virtual servers for VPC. The
virtual server instance has these components:

Figure 2. SAP NetWeaver 7.x SYB standard installation with AAS

Architecture of SAP NetWeaver AS for ABAP
SAP tools create a PAS Instance and an ASCS Instance. This method is the standard for Java Stack (System) and is now standard for ABAP
Stack.
1. The Primary Application Server (PAS) - An instance is an administrative unit that contains various components of an SAP system. The
components of an instance are parameterized in a shared instance profile. Each instance is identified by a system ID and an instance
number and includes:
SAP Web Dispatcher & Work Process (DIA,BTC,UPD,SPOOL) - The SAP Web Dispatcher lies between the internet and your SAP
system. The SAP Web Dispatcher is the entry point for HTTP and HTTPs requests into your system, which consists of one or more
SAP NetWeaver application servers. As a “software web switch”, the SAP Web dispatcher can reject or accept connections. When it
accepts a connection, it balances the load to ensure an even distribution across the servers. The SAP Web Dispatcher contributes
to security and also balances the load in your SAP system.
You can use the SAP Web Dispatcher in ABAP and Java systems, in pure Java systems, and in pure ABAP systems.
SAP Gateway Service - The SAP Gateway carries out RFC services within the SAP world, which are based on TCP/IP. These
services enable SAP Systems and external programs to communicate with one another. RFC services can be used either in the
ABAP program or for the external programs that use the interfaces. RFC can be used between processes of an instance or a
system, or between systems.
ICM (Internet Communication Manager) Service - Application server component that receives and dispatches Web requests
(HTTP(S), SMTP, …). ICM evaluates the URL and forwards requests to AS ABAP or AS Java.
IGS (Internet Graphic Server)
2. The ABAP Central Services Instances (ASCS) – This instance contains the message server, the enqueue server, and a separate start. The
ASCS instance cannot process any dialog requests. It is used to manage locks, exchange messages, and balance workload in the SAP
system. The ASCS instance includes:
Message Server - The SAP message server runs as a separate process, mostly on the same host as the central instance. If an SCS
instance (SAP Central Services) or ASCS instance (ABAP SCS) is configured in the system, the message server is part of this
instance.
Stand-alone Enqueue Server - Part of the central instance (ABAP or Java) that manages the SAP locks. In combination with the
enqueue replication server, this single point-of-failure can be made into a high availability solution.
ABAP Central services instance (ASCS instance) - Contains the ABAP message server and the stand-alone Enqueue Server
The enqueue replication server instance is only mandatory in a high-availability system.
Optionally, you can install the ASCS instance with an integrated:
SAP Web Dispatcher. For more information, see ASCS Instance with Integrated SAP Web Dispatcher .
Gateway. For more information, see ASCS Instance with Integrated Gateway .
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 591

Architecture of SAP NetWeaver AS for Java
1. Java central instance (J< nn > instance) – A Java instance is a unit in the AS Java cluster that is identified by its instance number. The
elements that form an instance that is run on one physical machine. Also, it is possible to run several instances on one physical machine,
but it is recommended that you split the different instances among different physical machines. A Java Central Instance consists of:
Internet Communication Manager (ICM) - The ICM is an element of the Java instance that handles requests coming from clients
and dispatches them to the available server processes. Data is transferred from the ICM to the server processes and vice versa by
using the Fast Channel Architecture (FCA), which allows fast and reliable communication between them
One or several server processes - The server processes of AS Java run the Java application. They are responsible for processing
incoming requests that are assigned to them by the ICM. Each server process is multi-threaded, and can therefore process many
requests simultaneously.
2. System Central Services instance (SCS instance) - Central services form the basis of communication and synchronization for the AS Java
cluster. They are responsible for lock administration, message exchange, and load balancing within the cluster. Central services that are
run on one physical machine and constitute a separate instance. This SAP Central Services Instance (SCS) comprises:
Message Server - The message server keeps a list of all server processes in the AS Java cluster and provides information about
their availability to Internet Communication Manager (ICM). It also represents the infrastructure for data exchange between the
participating server processes.
Enqueue Server - The enqueue server manages logical locks. The enqueue server runs on the Central Services instance of the Java
cluster. It manages the lock table in the main memory and receives requests for setting or releasing locks. It maps the logical
locks to the database.
Sybase for standard system
Database instance (DB) - SAP Adaptive Server Enterprise (SAP ASE) in this case. The SAP systems in a landscape have specific
requirements for servers, operating systems, network setup, and supported storage. Deployment of SAP AnyDB on IBM Cloud is similar
to deployments with infrastructure with on-premises data centers. Therefore, use the information that is provided from SAP and the
RDBMS providers. For more information, see SAP AnyDB - SAP ASE and Infrastructure certified for SAP.
Primary application server instance (PAS instance) - The global directories of the ASCS instance can be used as the global file system.
That means that the host with the ASCS instance is the SAP global host. However, you can also separately install the global directories on
any host of your SAP system landscape. You can also use the SAP transport host or the host with the global file system (SAP global host)
as your primary application server instance host. Optionally, you can install one or more additional application server instances.
Additional Application Server (AAS) - You can install one or more additional application server instances for an existing SAP system.
Additional application server instances are optional and can be installed on separate hosts.
An additional application server instance can run on:
The host of any instance of the existing SAP system
On a dedicated host
SAP Dialog Instance (DI) / Additional Application Instance (AAS) - Dialog Instance (DI) is an additional application instance on top of the
Central Instance (CI). Normally the DI is set up on a different host.
Dialog instance consists of Gateway (GW), Internet Communication Manager (ICM), and Dispatcher Process (Disp) only. The DI has no
Message Server and Enqueue Work Process.
DI always starts after the CI starts because the DI depends on CI as the main instance where message server and enqueue server exist.
DI is used to balance the load and handle more workload rather than use only the Central Instance. The new name for DI is Additional
Application Server (AAS).
Structure:
DI/AAS = GW + ICM + Disp
For more information about configuring and adding a AAS instance in heterogeneous SAP environment, see SAP Note - 680617 INST:
Appl. Server in Heterogeneous SAP System Environment.
The benefit of an AAS and DI is to balance the load from the PAS instance by distributing a significant percent of the workload, to an
additional DI and AAS server. With help of SAP load balancer mechanism, the AAS and DI provide good performance. Having an AAS and
additional DI increases the processing power as well, using the resources of its new server capacity for all system business workload.
For more information, see SAP Note 26317 - Set up for LOGON group for autom load balancing .

Distributed system
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 592

In a distributed system, there are multiple virtual server instances and every instance can run on a separate host:

Figure 3. SAP NetWeaver SYB standard installation with AAS

The components in a distributed system are the same as the components in a standard system, but there are restrictions as to which instances
can go on which hosts.
The Sybase db and the ASE components must reside on the same virtual server instance. The SAP systems in a landscape have specific
requirements for servers, operating systems, network setup, and supported storage. Deployment of SAP AnyDB on IBM Cloud is similar to
deployments with infrastructure with on-premises data centers. Therefore, use the information that is provided from SAP and the RDBMS
providers. To assist your project's planning phase, more design considerations are provided for SAP AnyDB - SAP ASE with IBM Cloud for SAP.

Related information
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP NetWeaver 7.x on UNIX with Db2 on IBM Cloud® VPC
Db2 is one of the many databases that can be run with SAP NetWeaver and deployed on the IBM Cloud®. The most common architecture
deployments are standard and distributed. IBM Cloud is certified for running SAP NetWeaver application servers ABAP, Java, and SAP products
based on these application server stacks.

SAP NetWeaver architecture
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for Advanced Business Application
Programming (ABAP) and Java applications. SAP NetWeaver components are built on the SAP NetWeaver Application Server and are written in
ABAP or Java Platform, Enterprise Edition. ABAP systems, Java systems, and dual-stack systems are distinct systems.

Core platform features
SAP NetWeaver uses ABAP or Java core platforms to support the SAP applications. SAP NetWeaver:
Has application lifecycle management capabilities.
Provides the basic structure for the on-premises versions of SAP Business Suite and other applications, as an application server.
Is the foundation for the on-premises SAP S/4HANA next-generation business suite, with SAP HANA serving as the sole underlying
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 593

database.
SAP provides a list of the SAP versions to learn more about the versions available in IBM Cloud. Each support package stack has a leading
software component version. The support package level of each component version is a key part of the stack and a unique identifier for the
support package stack.

Installation types
The three installation types for SAP NetWeaver Application Server are:
ABAP System– You can run ABAP programs and some SAP Java apps
Java System– You can run only Java Platform, Enterprise Edition apps. No ABAP programs can be run on a Java system
Dual Stack – You can run both ABAP and Java Platform, Enterprise Edition in separate instances

Architecture diagram
This diagram shows the SAP NetWeaver 7.X on Db2 integrated with IBM Cloud on the SAP NetWeaver 7.x architecture:

Figure 1. SAP NetWeaver 7.x with Db2 standard installation with AAS on VSI to IBM Cloud VPC

Access from an external network
Clients on the customer facing network (CFN) use a floating IP to access virtual server instances within the IBM Cloud. Virtual server instances
are hosted in availability zones (data centers) within geographic regions. For more information about access, see Connectivity to your SAP
system landscape and Getting started with IBM Cloud Transit Gateway .
Within the Public Subnet, the SAP router and the jump host provide secure connections to the virtual server instances. The SAP router is a
software application that provides a remote connection between the customer's network and SAP. The SAP Router and jump host are within a
single security group with rules for inbound and outbound traffic between the private subnets in the zone. SAP routers are used with traditional
SAP products and analytics solutions and offerings that are acquired from Sybase. For a comprehensive list of which SAP Business Analytics
products benefits from SAP router connections, see SAP Note 1478974.
A jump host is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their
premises. These SAP virtual server instances can be in a separate security zone but must be on same IBM Cloud region. The customer
connection to the jump host follows the same rules as the direct connection from customer premises to the virtual server instance SAP
instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. This architecture uses two
defined security groups; this arrangement is the simplest method for separating the public and private subnets. You can add more security
groups if you require more isolation.

Virtual server instances on SAP NetWeaver 7.x APAB stack, Java stack, and dual stack
(ABAP+Java) architectural design on IBM Cloud® VPC on Unix

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 594

Standard system
In a standard system, all main instances run on a single virtual server instance within a private subnet. For more information, see

About virtual

server instances for VPC. The virtual server instance has these components:

Figure 2. SAP NetWeaver 7.x with Db2 standard installation with AAS

Architecture of SAP NetWeaver AS for ABAP
SAP tools create a PAS Instance and an ASCS Instance. This method is the standard for Java Stack (System) and is now standard for ABAP
Stack.
1. The Primary Application Server (PAS) - An instance is an administrative unit that contains various components of an SAP system. The
components of an instance are parameterized in a shared instance profile. Each instance is identified by a system ID and an instance
number and includes:
SAP Web Dispatcher & Work Process (DIA,BTC,UPD,SPOOL) - The SAP Web Dispatcher lies between the internet and your SAP
system. The SAP Web Dispatcher is the entry point for HTTP and HTTPs requests into your system, which consists of one or more
SAP NetWeaver application servers. As a “software web switch”, the SAP Web dispatcher can reject or accept connections. When it
accepts a connection, it balances the load to ensure an even distribution across the servers. The SAP Web Dispatcher contributes
to security and also balances the load in your SAP system.
You can use the SAP Web Dispatcher in ABAP and Java systems, in pure Java systems, and in pure ABAP systems.
SAP Gateway Service - The SAP Gateway carries out RFC services within the SAP world, which are based on TCP/IP. These
services enable SAP Systems and external programs to communicate with one another. RFC services can be used either in the
ABAP program or for the external programs that use the interfaces. RFC can be used between processes of an instance or a
system, or between systems.
ICM (Internet Communication Manager) Service - Application server component that receives and dispatches Web requests
(HTTP(S), SMTP, …). ICM evaluates the URL and forwards requests to AS ABAP or AS Java.
IGS (Internet Graphic Server)
2. The ABAP Central Services Instances (ASCS) – This instance contains the message server, the enqueue server, and a separate start. The
ASCS instance cannot process any dialog requests. It is used to manage locks, exchange messages, and balance workload in the SAP
system. The ASCS instance includes:
Message Server - The SAP message server runs as a separate process, mostly on the same host as the central instance. If an SCS
instance (SAP Central Services) or ASCS instance (ABAP SCS) is configured in the system, the message server is part of this
instance.
Stand-alone Enqueue Server - Part of the central instance (ABAP or Java) that manages the SAP locks. In combination with the
enqueue replication server, this single point-of-failure can be made into a high availability solution.
ABAP Central services instance (ASCS instance) - Contains the ABAP message server and the stand-alone Enqueue Server
The enqueue replication server instance is only mandatory in a high-availability system.
Optionally, you can install the ASCS instance with an integrated:
SAP Web Dispatcher. For more information, see ASCS Instance with Integrated SAP Web Dispatcher .
Gateway. For more information, see ASCS Instance with Integrated Gateway .
Architecture of SAP NetWeaver AS for Java
1. Java central instance (J< nn > instance) – A Java instance is a unit in the AS Java cluster that is identified by its instance number. The
elements that form an instance that is run on one physical machine. Also, it is possible to run several instances on one physical machine,
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 595

but it is recommended that you split the different instances among different physical machines. A Java Central Instance consists of:
Internet Communication Manager (ICM) - The ICM is an element of the Java instance that handles requests coming from clients
and dispatches them to the available server processes. Data is transferred from the ICM to the server processes and vice versa by
using the Fast Channel Architecture (FCA), which allows fast and reliable communication between them
One or several server processes - The server processes of AS Java run the Java application. They are responsible for processing
incoming requests that are assigned to them by the ICM. Each server process is multi-threaded, and can therefore process many
requests simultaneously.
2. System Central Services instance (SCS instance) - Central services form the basis of communication and synchronization for the AS Java
cluster. They are responsible for lock administration, message exchange, and load balancing within the cluster. Central services that are
run on one physical machine and constitute a separate instance. This SAP Central Services Instance (SCS) comprises:
Message Server - The message server keeps a list of all server processes in the AS Java cluster and provides information about
their availability to Internet Communication Manager (ICM). It also represents the infrastructure for data exchange between the
participating server processes.
Enqueue Server - The enqueue server manages logical locks. The enqueue server runs on the Central Services instance of the Java
cluster. It manages the lock table in the main memory and receives requests for setting or releasing locks. It maps the logical
locks to the database.
Db2 for standard system
Database instance (DB) - Db2 in this case. For more information, see AnyDB - IBM Db2 and Infrastructure certified for SAP.
Primary application server instance (PAS instance) - The global directories of the ASCS instance can be used as the global file system.
That means that the host with the ASCS instance is the SAP global host. However, you can also separately install the global directories on
any host of your SAP system landscape. You can also use the SAP transport host or the host with the global file system (SAP global host)
as your primary application server instance host. Optionally, you can install one or more extra application server instances.
Additional Application Server (AAS) - You can install one or more extra application server instances for an existing SAP system. Additional
application server instances are optional and can be installed on separate hosts.
An extra application server instance can run on:
The host of any instance of the existing SAP system
On a dedicated host

Distributed system
In a distributed system, there are multiple virtual server instances and every instance can run on a separate host:

Figure 3. SAP NetWeaver 7.x with Db2 distributed installation with AAS

The components in a distributed system are the same as the components in a standard system, but there are restrictions as to which instances
can go on which hosts.

Related information
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux on IBM Cloud (IaaS): Adaption of your SAP License
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 596

SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP NetWeaver 7.x on Windows Servers with MS SQL on IBM Cloud® VPC
MS SQL Server is one of several databases that can be deployed on SAP NetWeaver in the IBM Cloud®. The most common architecture
deployments are standard and distributed systems. IBM Cloud is certified for running SAP NetWeaver application servers ABAP, Java, and SAP
products based on these application server stacks.
The MS SQL Server database for SAP is supported only on Windows servers and using only the Enterprise Edition of the software. Other SQL
Server editions are currently not supported.

SAP NetWeaver architecture
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for Advanced Business Application
Programming (ABAP) and Java applications. SAP NetWeaver components are built on the SAP NetWeaver Application Server and are written in
ABAP or Java Platform, Enterprise Edition. ABAP systems, Java systems, and dual-stack systems are distinct systems.

Core platform features
SAP NetWeaver uses ABAP or Java core platforms to support the SAP applications. SAP NetWeaver:
Has application lifecycle management capabilities.
Provides the basic structure for the on-premises versions of SAP Business Suite and other applications, as an application server.
Is the foundation for the on-premises SAP S/4HANA next-generation business suite, with SAP HANA serving as the sole underlying
database.
SAP provides a list of the SAP versions to learn more about the versions available in IBM Cloud. Each support package stack has a leading
software component version. The support package level of each component version is a key part of the stack and a unique identifier for the
support package stack.

Installation types
The three installation types for SAP NetWeaver Application Server are:
ABAP System– You can run ABAP programs and some SAP Java apps
Java System– You can run only Java Platform, Enterprise Edition apps. No ABAP programs can be run on a Java system
Dual Stack – You can run both ABAP and Java Platform, Enterprise Edition in separate instances

Architecture diagram
This diagram shows the SAP NetWeaver 7.X on MS SQL Server database integrated with IBM Cloud on the SAP NetWeaver 7.x architecture:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 597

Figure 1. SAP NetWeaver 7.x with MS SQL Server standard installation with AAS

Access from an external network
Clients on the customer facing network (CFN) use a floating IP to access virtual server instances within the IBM Cloud. Virtual server instances
are hosted in availability zones (data centers) within geographic regions.
Within the Public Subnet, the SAP router and the jumphost provide secure connections to the virtual server instances. The SAP router is a
software application that provides a remote connection between the customer's network and SAP. The SAP Router and jumphost are within a
single security group with rules for inbound and outbound traffic between the private subnets in the zone. SAP routers are used with traditional
SAP products and analytics solutions and offerings that are acquired from MS SQL Server database. For a comprehensive list of which SAP
Business Analytics products benefits from SAP router connections, see SAP Note 1478974.
A jumphost is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their
premises. These SAP virtual server instances can be in a separate security zone but should be on same IBM Cloud region. The customer
connection to the jumphost follows the same rules as the direct connection from customer premises to the virtual server instance SAP
instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. In this architecture, there are
two security groups defined; this arrangement is the simplest method for separating the public and private subnets. You can add more security
groups if you require more isolation.

Virtual server instances on SAP NetWeaver 7.x APAB stack, Java stack, and dual stack
(ABAP+Java) stack on Windows Servers with MS SQL Server DB
Standard system
In a standard system, all main instances run on a single virtual server instance within a private subnet. For more information, see

about virtual

servers for VPC. The virtual server instance has these components:

Figure 2. SAP NetWeaver 7.x MS SQL Server standard installation with AAS

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 598

Architecture of SAP NetWeaver AS for ABAP
SAP tools create a PAS Instance and an ASCS Instance. This method is the standard for Java Stack (System) and is now standard for ABAP
Stack.
1. The Primary Application Server (PAS) - An instance is an administrative unit that contains various components of an SAP system. The
components of an instance are parameterized in a shared instance profile. Each instance is identified by a system ID and an instance
number and includes:
SAP Web Dispatcher & Work Process (DIA,BTC,UPD,SPOOL) - The SAP Web Dispatcher lies between the internet and your SAP
system. The SAP Web Dispatcher is the entry point for HTTP and HTTPs requests into your system, which consists of one or more
SAP NetWeaver application servers. As a “software web switch”, the SAP Web dispatcher can reject or accept connections. When it
accepts a connection, it balances the load to ensure an even distribution across the servers. The SAP Web Dispatcher contributes
to security and also balances the load in your SAP system.
You can use the SAP Web Dispatcher in ABAP and Java systems, in pure Java systems, and in pure ABAP systems.
SAP Gateway Service - The SAP Gateway carries out RFC services within the SAP world, which are based on TCP/IP. These
services enable SAP Systems and external programs to communicate with one another. RFC services can be used either in the
ABAP program or for the external programs that use the interfaces. RFC can be used between processes of an instance or a
system, or between systems.
ICM (Internet Communication Manager) Service - Application server component that receives and dispatches Web requests
(HTTP(S), SMTP, …). ICM evaluates the URL and forwards requests to AS ABAP or AS Java.
IGS (Internet Graphic Server)
2. The ABAP Central Services Instances (ASCS) – This instance contains the message server, the enqueue server, and a separate start. The
ASCS instance cannot process any dialog requests. It is used to manage locks, exchange messages, and balance workload in the SAP
system. The ASCS instance includes:
Message Server - The SAP message server runs as a separate process, mostly on the same host as the central instance. If an SCS
instance (SAP Central Services) or ASCS instance (ABAP SCS) is configured in the system, the message server is part of this
instance.
Stand-alone Enqueue Server - Part of the central instance (ABAP or Java) that manages the SAP locks. In combination with the
enqueue replication server, this single point-of-failure can be made into a high availability solution.
ABAP Central services instance (ASCS instance) - Contains the ABAP message server and the stand-alone Enqueue Server
The enqueue replication server instance is only mandatory in a high-availability system.
Optionally, you can install the ASCS instance with an integrated:
SAP Web Dispatcher. For more information, see ASCS Instance with Integrated SAP Web Dispatcher .
Gateway. For more information, see ASCS Instance with Integrated Gateway .
Architecture of SAP NetWeaver AS for Java
1. Java central instance (J< nn > instance) – A Java instance is a unit in the AS Java cluster that is identified by its instance number. The
elements that form an instance that is run on one physical machine. Also, it is possible to run several instances on one physical machine,
but it is recommended that you split the different instances among different physical machines. A Java Central Instance consists of:
Internet Communication Manager (ICM) - The ICM is an element of the Java instance that handles requests coming from clients
and dispatches them to the available server processes. Data is transferred from the ICM to the server processes and vice versa by
using the Fast Channel Architecture (FCA), which allows fast and reliable communication between them
One or several server processes - The server processes of AS Java run the Java application. They are responsible for processing
incoming requests that are assigned to them by the ICM. Each server process is multi-threaded, and can therefore process many
requests simultaneously.
2. System Central Services instance (SCS instance) - Central services form the basis of communication and synchronization for the AS Java
cluster. They are responsible for lock administration, message exchange, and load balancing within the cluster. Central services that are
run on one physical machine and constitute a separate instance. This SAP Central Services Instance (SCS) comprises:
Message Server - The message server keeps a list of all server processes in the AS Java cluster and provides information about
their availability to Internet Communication Manager (ICM). It also represents the infrastructure for data exchange between the
participating server processes.
Enqueue Server - The enqueue server manages logical locks. The enqueue server runs on the Central Services instance of the Java
cluster. It manages the lock table in the main memory and receives requests for setting or releasing locks. It maps the logical
locks to the database.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 599

MS SQL for standard system
Database instance (DB) - MS SQL Server in this case. The SAP systems in a landscape have specific requirements for servers, operating
systems, network setup, and supported storage. Deployment of SAP AnyDB on IIBM Cloud is similar to deployments with infrastructure
with on-premises data centers. Use the information that is provided from SAP and the RDBMS providers. For more information, see
AnyDB - Microsoft SQL Server and Infrastructure certified for SAP.
Primary application server instance (PAS instance) - The global directories of the ASCS instance can be used as the global file system.
That means that the host with the ASCS instance is the SAP global host. However, you can also separately install the global directories on
any host of your SAP system landscape. You can also use the SAP transport host or the host with the global file system (SAP global host)
as your primary application server instance host. Optionally, you can install one or more additional application server instances.
Additional Application Server (AAS) - You can install one or more additional application server instances for an existing SAP system.
Additional application server instances are optional and can be installed on separate hosts.
An additional application server instance can run on:
The host of any instance of the existing SAP system
On a dedicated host
SAP Dialog Instance (DI) / Additional Application Instance (AAS) - Dialog Instance (DI) is an additional application instance on top of the
Central Instance (CI). Normally the DI is set up on a different host.
Dialog instance consists of Gateway (GW), Internet Communication Manager (ICM), and Dispatcher Process (Disp) only. The DI has no
Message Server and Enqueue Work Process.
DI always starts after the CI starts because the DI depends on CI as the main instance where message server and enqueue server exist.
DI is used to balance the load and handle more workload rather than use only the Central Instance. The new name for DI is Additional
Application Server (AAS).
Structure:
DI/AAS = GW + ICM + Disp
For more information about configuring and adding a AAS instance in heterogeneous SAP environment, see SAP Note 680617 - INST:
Appl. Server in Heterogeneous SAP System Environment.
The benefit of an AAS and DI is to balance the load from the PAS instance by distributing a significant percent of the workload, to an
additional DI and AAS server. With help of SAP load balancer mechanism, the AAS and DI provide good performance. Having an AAS and
additional DI increases the processing power as well, using the resources of its new server capacity for all system business workload.
For more information, see SAP Note 26317 - Set up for LOGON group for autom load balancing .

Distributed system
In a distributed system, there are multiple virtual server instances and every instance can run on a separate host:

Figure 3. SAP NetWeaver 7.x MS SQL Server distributed installation with AAS

The components in a distributed system are the same as the components in a standard system, but there are restrictions as to which instances
can go on which hosts.

Related information
SAP One Support Notes that apply to this document:
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 600

SAP Note 84555 - Windows Server, Linux, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

SAP NetWeaver 7.x with SAP HANA IBM Cloud® VPC
SAP HANA is one of several databases that can be deployed on SAP NetWeaver in the IBM Cloud®. SAP HANA is an in-memory database
installed on a dedicated database server. The main architecture deployments for SAP HANA are single-host or multiple-host systems. IBM
Cloud is certified for running SAP NetWeaver application servers ABAP, Java, and SAP products based on these application server stacks.

SAP NetWeaver architecture
SAP NetWeaver is the core foundation of the SAP technology stacks and is the platform that is used for Advanced Business Application
Programming (ABAP) and Java applications. SAP NetWeaver components are built on the SAP NetWeaver Application Server and are written in
ABAP or Java Platform, Enterprise Edition. ABAP systems, Java systems, and dual-stack systems are distinct systems.

Core platform features
SAP NetWeaver uses ABAP or Java core platforms to support the SAP applications. SAP NetWeaver:
Has application lifecycle management capabilities.
Provides the basic structure for the on-premises versions of SAP Business Suite and other applications, as an application server.
Is the foundation for the on-premises SAP S/4HANA next-generation business suite, with SAP HANA serving as the sole underlying
database.
SAP provides a list of the SAP versions to learn more about the versions available in IBM Cloud. Each support package stack has a leading
software component version. The support package level of each component version is a key part of the stack and a unique identifier for the
support package stack.

Installation types
The three installation types for SAP NetWeaver Application Server are:
ABAP System– You can run ABAP programs and some SAP Java apps
Java System– You can run only Java Platform, Enterprise Edition apps. No ABAP programs can be run on a Java system
Dual Stack – You can run both ABAP and Java Platform, Enterprise Edition in separate instances

Architecture diagram
This diagram shows the SAP NetWeaver 7.X on SAP HANA Server database integrated with IBM Cloud on the SAP NetWeaver 7.x architecture:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 601

Figure 1. SAP NetWeaver 7.x with SAP HANA database single-host installation with AAS

Access from an external network
Clients on the customer facing network (CFN) use a floating IP to access virtual server instances within the IBM Cloud. Virtual server instances
are hosted in availability zones (data centers) within geographic regions.
Within the Public Subnet, the SAP router and the jumphost provide secure connections to the virtual server instances. The SAP router is a
software application that provides a remote connection between the customer's network and SAP. The SAP Router and jumphost are within a
single security group with rules for inbound and outbound traffic between the private subnets in the zone. SAP routers are used with traditional
SAP products and analytics solutions and offerings that are acquired from MS SQL Server database. For a comprehensive list of which SAP
Business Analytics products benefits from SAP router connections, see SAP Note 1478974.
A jumphost is used to access, manage, and administer SAP virtual server instances from the same customer ZONE directly from their
premises. These SAP virtual server instances can be in a separate security zone but should be on same IBM Cloud region. The customer
connection to the jumphost follows the same rules as the direct connection from customer premises to the virtual server instance SAP
instances. The connection uses the CFN IP and security group 1 firewall rules from a designated public subnet. In this architecture, there are
two security groups defined; this arrangement is the simplest method for separating the public and private subnets. You can add more security
groups if you require more isolation.

Virtual server instances on SAP NetWeaver 7.x with SAP HANA database
The number of hosts in an SAP HANA system landscape determines the SAP HANA system type.
An SAP HANA system can be configured as either:
A single-host system - One SAP HANA instance on one host.
A distributed system (multiple-host system) - Multiple SAP HANA instances distributed over multiple hosts,

Single-host HANA system
A single-host system is the simplest system installation type that runs an SAP HANA system entirely on one host. You can scale the system up
as needed. The single-host system has these components:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 602

Figure 2. SAP NetWeaver 7.x SAP HANA single-host installation with AAS

Architecture of SAP NetWeaver AS for ABAP
SAP tools create a PAS Instance and an ASCS Instance. This method is the standard for Java Stack (System) and is now standard for ABAP
Stack.
1. The Primary Application Server (PAS) - An instance is an administrative unit that contains various components of an SAP system. The
components of an instance are parameterized in a shared instance profile. Each instance is identified by a system ID and an instance
number and includes:
SAP Web Dispatcher & Work Process (DIA,BTC,UPD,SPOOL) - The SAP Web Dispatcher lies between the internet and your SAP
system. The SAP Web Dispatcher is the entry point for HTTP and HTTPs requests into your system, which consists of one or more
SAP NetWeaver application servers. As a “software web switch”, the SAP Web dispatcher can reject or accept connections. When it
accepts a connection, it balances the load to ensure an even distribution across the servers. The SAP Web Dispatcher contributes
to security and also balances the load in your SAP system.
You can use the SAP Web Dispatcher in ABAP and Java systems, in pure Java systems, and in pure ABAP systems.
SAP Gateway Service - The SAP Gateway carries out RFC services within the SAP world, which are based on TCP/IP. These
services enable SAP Systems and external programs to communicate with one another. RFC services can be used either in the
ABAP program or for the external programs that use the interfaces. RFC can be used between processes of an instance or a
system, or between systems.
ICM (Internet Communication Manager) Service - Application server component that receives and dispatches Web requests
(HTTP(S), SMTP, …). ICM evaluates the URL and forwards requests to AS ABAP or AS Java.
IGS (Internet Graphic Server)
2. The ABAP Central Services Instances (ASCS) – This instance contains the message server, the enqueue server, and a separate start. The
ASCS instance cannot process any dialog requests. It is used to manage locks, exchange messages, and balance workload in the SAP
system. The ASCS instance includes:
Message Server - The SAP message server runs as a separate process, mostly on the same host as the central instance. If an SCS
instance (SAP Central Services) or ASCS instance (ABAP SCS) is configured in the system, the message server is part of this
instance.
Stand-alone Enqueue Server - Part of the central instance (ABAP or Java) that manages the SAP locks. In combination with the
enqueue replication server, this single point-of-failure can be made into a high availability solution.
ABAP Central services instance (ASCS instance) - Contains the ABAP message server and the stand-alone Enqueue Server

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 603

The enqueue replication server instance is only mandatory in a high-availability system.
Optionally, you can install the ASCS instance with an integrated:
SAP Web Dispatcher. For more information, see ASCS Instance with Integrated SAP Web Dispatcher .
Gateway. For more information, see ASCS Instance with Integrated Gateway .
Architecture of SAP NetWeaver AS for Java
1. Java central instance (J< nn > instance) – A Java instance is a unit in the AS Java cluster that is identified by its instance number. The
elements that form an instance that is run on one physical machine. Also, it is possible to run several instances on one physical machine,
but it is recommended that you split the different instances among different physical machines. A Java Central Instance consists of:
Internet Communication Manager (ICM) - The ICM is an element of the Java instance that handles requests coming from clients
and dispatches them to the available server processes. Data is transferred from the ICM to the server processes and vice versa by
using the Fast Channel Architecture (FCA), which allows fast and reliable communication between them
One or several server processes - The server processes of AS Java run the Java application. They are responsible for processing
incoming requests that are assigned to them by the ICM. Each server process is multi-threaded, and can therefore process many
requests simultaneously.
2. System Central Services instance (SCS instance) - Central services form the basis of communication and synchronization for the AS Java
cluster. They are responsible for lock administration, message exchange, and load balancing within the cluster. Central services that are
run on one physical machine and constitute a separate instance. This SAP Central Services Instance (SCS) comprises:
Message Server - The message server keeps a list of all server processes in the AS Java cluster and provides information about
their availability to Internet Communication Manager (ICM). It also represents the infrastructure for data exchange between the
participating server processes.
Enqueue Server - The enqueue server manages logical locks. The enqueue server runs on the Central Services instance of the Java
cluster. It manages the lock table in the main memory and receives requests for setting or releasing locks. It maps the logical
locks to the database.
SAP HANA for standard system
Primary application server instance (PAS) - The global directories of the ASCS instance can be used as the global file system. That means
that the host with the ASCS instance is the SAP global host. However, you can also separately install the global directories on any host of
your SAP system landscape. You can also use the SAP transport host or the host with the global file system (SAP global host) as your
primary application server instance host. Optionally, you can install one or more additional application server instances.
Database instance (DB) - To assist your project's planning phase, more design considerations are provided at SAP AnyDB – SAP HANA
database with IBM Cloud for SAP. For more information, see AnyDB - SAP HANA and Infrastructure certified for SAP.
Additional Application Server (AAS) - You can install one or more additional application server instances for an existing SAP system.
Additional application server instances are optional and can be installed on separate hosts.
SAP Dialog Instance (DI) / Additional Application Instance (AAS) - Dialog Instance (DI) is an additional application instance on top of the
Central Instance (CI). Normally the DI is set up on a different host.
Dialog instance consists of Gateway (GW), Internet Communication Manager (ICM), and Dispatcher Process (Disp) only. The DI has no
Message Server and Enqueue Work Process.
DI always starts after the CI starts because the DI depends on CI as the main instance where message server and enqueue server exist.
DI is used to balance the load and handle more workload rather than use only the Central Instance. The new name for DI is Additional
Application Server (AAS).
Structure:
DI/AAS = GW + ICM + Disp
For more information about configuring and adding a AAS instance in heterogeneous SAP environment, see SAP Note - 680617 INST:
Appl. Server in Heterogeneous SAP System Environment.
The benefit of an AAS and DI is to balance the load from the PAS instance by distributing a significant percent of the workload, to an
additional DI and AAS server. With help of SAP load balancer mechanism, the AAS and DI provide good performance. Having an AAS and
additional DI increases the processing power as well, using the resources of its new server capacity for all system business workload.
For more information, see SAP Note 26317 - Set up for LOGON group for autom load balancing .

Multiple-host SAP HANA system
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 604

A multiple-host system is a system with more than one host, which can be configured as active worker hosts or idle standby hosts. The server
software is based on a flexible architecture that enables a distributed installation in which loads are balanced between different hosts. The
server software has to be installed in a shared file system. This file system has to be mounted by all hosts that are part of the system.
This diagram shows a multiple-host system configuration:

Figure 3. SAP NetWeaver 7.x SAP HANA multiple-host installation with AAS

The SAP components in a multi-host SAP HANA system are the same as the components in a single-host SAP HANA system, the difference
consists of multiple connected hosts for the SAP HANA database.
A multi-host SAP HANA system might be necessary to scale SAP HANA either by increasing RAM for a single server, or by adding hosts to the
system to deal with larger workloads. This allows you to go beyond the limits of a single physical server.
When configuring a multiple-host system, the individual hosts must be defined as master, worker, slave, and standby depending on the task.
Worker machines process data; standby machines do not handle any processing and instead just wait to take over processes in the case of
worker machine failure.

Related information
SAP One Support Notes that apply to this document:
SAP Note 84555 - Windows Server, Linux, and UNIX: Certified hardware
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2923773 - Linux on IBM Cloud (IaaS): Adaption of your SAP License
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2369910 - SAP Software on Linux: General information
SAP Note 171380 - Released IBM hardware (Intel processors) and IBM cloud services offers
SAP Note 1380654 - SAP support in IaaS environments
This document is referenced by:
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 605

SAP automated workload responsibilities on IBM Cloud VPC
Understanding your responsibilities when using SAP automated workloads on IBM
Cloud VPC
SAP automated workloads on IBM Cloud VPC involves several management responsibilities and terms and conditions:
For more information about the responsibilities when using the deployable architecture, see Understanding your responsibilities when
you use deployable architectures.
For a high-level view of the service types in IBM Cloud® and the breakdown of responsibilities between the customer and IBM for each
type, see Shared responsibilities for using IBM Cloud products .
For all the terms of use, see IBM Cloud® Terms and Notices .

Security and regulation compliance
Security and regulation compliance responsibilities are divided between you and IBM:
IBM Responsibilities

Your Responsibilities

Ensure that the
operating system
image does not
contain any
vulnerabilities.

IBM Cloud provided and verified RHEL and SLES operating
system images are used. After deployment, operating system
images are updated to the newest state in the defined minor
release. Official RHEL and SLES software repositories are used
for installation of additional software components (like SQUID
proxy).

Customer is responsible for keeping the
operating system secure and compliant after
deployment.

Ensure that the SAP
software does not
contain any
vulnerabilities.

N/A

Customer is responsible to provide the SAP
software only from SAP legal repositories:
https://me.sap.com/softwarecenter.
Customer is responsible for keeping the SAP
software secure and compliant after
deployment.

Updates: Activities
to maintain or
enhance a system,
for example:

IBM is not responsible in maintaining or supporting a Live
System, if is not contracted IBM is not responsible for any
human errors, software malfunction, or supporting operational
customer phases. After the new system is deployed with IBM
automations, this is validated and accepted by the customer.

Customer is responsible for keeping the SAP
live/operational system secure and compliant
after deployment.

N/A

Customer is responsible for keeping the SAP
live/operational system secure and
configured with SAP recommended security
notes after deployment completes. The
process and procedures are covered in the
References section.

Installing
enhancement
packages
Installing
add-ons
Applying
support
package
stacks or
support
packages
Upgrades:
The switch
from an older
software
version to a
new version.

SAP Software
security
recommendations,
security patches,
and configurations

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 606

Note: Hdblcm verifies the authenticity and integrity of the software packages prior to the installation or update. For SAP HANA, follow
the SAP recommendations in verifying the authenticity of the downloaded software. The SAP HANA system can be installed using the
SAP HANA Database Lifecycle Manager (HDBLCM). The installation software is downloaded from outside of your network and cannot be
trusted. Therefore, you should ensure that the components are authentic before starting the SAP HANA Database Lifecycle Manager
(HDBLCM).
To verify the authenticity of a HANA software SAR archive, use this command: /usr/sap/hostctrl/exe/SAPCAR -dVf <archive name>
/usr/sap/hostctrl/exe/libsapcrypto.so . To verify the signature of the additional components, run

hdblcm with the parameter

verify_signature . For more information, see SAP Note 2577617.

References
SAP compliance and security
SAP/My Trust Center
SAP Assurance and Compliance Software
Security Configurations for SAP Cloud Services

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 607

Infrastructure Deployment Patterns for SAP
Intel Bare Metal and Intel Virtual Server (Gen2)
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

Networking considerations
Content

Connectivity
Content

Usage considerations
Content

Common Scenarios
Content

Intel Bare Metal and VMware SDDC
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

Networking considerations
Content

Connectivity
Content

Usage considerations
Content

Common Scenarios
Content

IBM Power Virtual Server and Intel Virtual Server (Gen2)
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

Networking considerations
Content

Connectivity
Content

Usage considerations
Content
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 608

Common Scenarios
Content

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 609

Example SAP Scenario Solution Architectures
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published

Example SAP application deployment scenarios
The below are simplified examples of SAP Business Application deployments, to assist understanding of various components across the stack.
These diagrams do not constitute a best practices setup and do not replace any SAP diagrams; they are only to be used as examples to support
learning.

Example SAP application deployment scenario of SAP S/4HANA deployment (One Host) with SAP
Two-Tier logical architecture
Deployment scenario diagram of SAP S/4HANA deployment (One Host) with SAP Two-Tier logical architecture; using Intel Virtual Server
(Gen2) as infrastructure

Example SAP application deployment scenario of SAP S/4HANA deployment (Dual Host) with SAP
Three-Tier logical architecture
Deployment scenario diagram of SAP S/4HANA deployment (Dual Host) with SAP Three-Tier logical architecture; using Intel Virtual Server
(Gen2) as infrastructure

Example SAP application deployment scenario of SAP S/4HANA deployment (Dual Host) with SAP
Multi-Tier logical architecture
Deployment scenario diagram of SAP S/4HANA deployment (Dual Host) with SAP Multi-Tier logical architecture; using Intel Virtual Server
(Gen2) as infrastructure

Example SAP landscape scenarios
Example SAP landscape scenario of SAP Landscape single-track with SAP S/4HANA
Landscape scenario diagram of SAP S/4HANA deployment (Dual Host) with SAP Multi-Tier logical architecture in single-track 5-system
landscape; using Intel Virtual Server (Gen2) as infrastructure

Example SAP landscape scenario of SAP Landscape dual-track with SAP S/4HANA
Landscape scenario diagram of SAP S/4HANA deployment (Dual Host) with SAP Multi-Tier logical architecture in dual-track 5-system
landscape; using Intel Virtual Server (Gen2) as infrastructure

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 610

Roadmap of IBM Cloud® for SAP
Important: INCOMPLETE: This page only appears in Test/Staging, it is not complete or ready to be published
Introduction

Infrastructure-as-a-Service
Intel
Certifications ongoing for larger system sizes.

IBM Power
Certifications ongoing for larger system sizes.

Platform-as-a-Service
Kubernetes clusers for SAP Data Hub
Upon release of SAP Data Hub x.y.z, new certification process will begin

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 611

Getting help and support from IBM Cloud or SAP
If you experience problems with IBM Cloud, you have several options to get help with determining the cause of the problem and finding a
solution.
Which support option depends on the level of support (and urgency), and whether the problem is with the Offering or running SAP Workloads
using the Offering.
Options include:
IBM Cloud Support Case, using the IBM Cloud Support Center
SAP support incident, using the SAP ONE Support Launchpad
IBM Cloud Docs
Note: For previous users of IBM Cloud Classic Infrastructure (formerly Softlayer), please be aware these Support Cases were previously
termed Support Tickets.

IBM Cloud Support
IBM Cloud Support handles any support questions and issues that might arise - available through live web chat, phone, and case-based
support.
Each IBM Cloud account automatically comes with customer support at no cost and covers most cases which are placed each day; this is the
Basic level of support.
The types of available and response time of support, depends on the support level of the account. Your support plan also determines the
severity level that you can assign to support cases. For more information, see Basic, Advanced, and Premium Support plans .
You can change your current support plan at any time by contacting IBM Cloud sales expert.
For full information about opening an IBM Cloud Support case, or about support levels and ticket severities, see Enabling the EU Supported
setting.
Your resources are in the appropriate European data center. For more information, see Data centers.
You select the EU supported case level when you open the case.
Note: IBM Cloud offerings hosted in the Frankfurt location must be supported by a team that is physically located in Europe.
Enabling the EU Support setting for your account applies to all future cases that you open for issues on any service or data center that is hosted in the
EU region. However, if you add resources outside of an EU location, issues for those resources are not necessarily handled by a support team in
Europe. Any cases that are opened before you enable the EU Supported setting aren not affected.

SAP ONE Support
You can also continue to create tickets through SAP Support that are related to your IBM Cloud IaaS and SAP products. For more information, see
SAP Support and SAP Note 2414820 - SAP on IBM Cloud: Support prerequisites .
The SAP ONE Support Launchpad provides access to task-driven support resources from SAP, available with live web chat or incidnt tickets, and the
following features:
Knowledge Base for SAP Notes
Incidents for connection with SAP Product Support teams
Software Downloads
Systems, Installations and License Keys
Full information on SAP Support provides additional details, including guidance on how to use the SAP ONE Support Launchpad.

SAP ONE Support process for IBM Power
If the issue is related to IBM Power and SAP, open a case by going to support.sap.com and click Report an Incident.
All performance-related issues must be checked by IBM Cloud Customer Support first to rule out any infrastructure-related issues before a case on
the software stack is opened.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 612

Provide details and run the following commands to attach the output to the case:
For AIX:
perfsap on SAP Note 1170252

For Linux:
sapsysinfo on SAP Note 618104
supportconfig on SAP Note 1642802

and for SAP HANA also use full-system-info-dump on SAP Note 1732157

Stack Overflow
The Stack Overflow forum provides a wide variety of searchable answers for your IBM Cloud questions. If you don't find an existing answer, ask a new
question. Go to Stack Overflow.
IBM Cloud development and support teams actively monitor Stack Overflow and follow the questions that are tagged with ibm-cloud. When you
create a question, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 613

FAQs
FAQ of IBM Cloud® for SAP
Introduction
This FAQ provides answers for the following:
IBM Cloud® for SAP portfolio questions
Licensing and pricing
SAP-certified IBM Power Virtual Servers
SAP HANA generic questions
SAP NetWeaver generic questions
SAP Notes full list of the IBM Cloud® for SAP portfolio
Due to their length on specific topics, there are separate FAQs for:
Moving SAP Workloads
Profile List with Benchmarks and Specifications

IBM Cloud® for SAP portfolio questions
Can SAP be run on any IBM Cloud server?
No, SAP HANA or SAP NetWeaver can run only on the server models that are SAP-certified. Using SAP-certified servers ensures that the SAP
workloads function correctly, a critical consideration since these applications run entire businesses.
IBM and SAP are stringent in our certification checks. These checks are key to our 40+ year partnership that helps businesses to run and succeed
with their SAP Business Applications.
For POC or evaluation (for example, non-productive) purposes, a non-certified server can be used to evaluate IBM Cloud without incurring the higher
costs of the SAP-certified servers. However, on a non-certified server, the SAP software might not work as designed and is not supported by SAP.
Note: Production SAP systems and development and testing (dev/test) SAP systems are both considered productive systems by SAP
Support. Dev/Test SAP systems are considered productive because they also require support from SAP if errors occur.

Can I download the SAP software installation media and distributions directly from IBM Cloud?
All SAP software installation media is available from SAP directly, at sap.com. The single distribution point ensures the governance of licensing,
compliance, and export control.
Each customer needs to generate an SAP Software Download Center basket (optionally created through SAP Maintenance Planner) and download
the software to their target server.
Note: SAP ID credentials are required to download SAP software installation media.

Who is responsible for deployment of SAP software on IBM Cloud?
The IBM Cloud® for SAP portfolio is primarily Infrastructure-as-a-Service which is certified for SAP workloads. All IaaS is considered "customermanaged" by Cloud Service Providers. All changes to the OS and any applications that are deployed are the customer's responsibility (or the
responsibility of a contracted Business Partner).
The customer (or contracted Business Partner) is responsible for the installation and configuration of SAP software on IBM Cloud, which must follow
SAP's guidance for the business scenario and usage.
While IBM Cloud does not provide SAP application-level services, the various IBM Cloud Business Partners (including IBM Services) do provide their
service capabilities by using IBM Cloud® for SAP portfolio.
This table shows a brief list of services and the Business Partner types who can provide the services for IBM Cloud® for SAP:

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 614

Service type

Provided by

Description

Consulting and
advisory and
implementation

SAP "Global
Systems Integrator"
(GSI) providers

These providers advise and run SAP implementation and deployment projects.

Application
management

SAP "Application
Management
Services" (AMS)
providers

These providers manage and maintain an existing deployment of SAP Applications (optional:
incremental functional or development changes).

End-to-end
managed
services

SAP "Managed
Services Providers"
(MSP)

These providers run the SAP implementation and deployment and manage the Infrastructure, OS,
SAP Technical Applications, and SAP Business Applications. These services often do not include
incremental functional or development changes).

For example, some of the services that are available in partnership between IBM Cloud and IBM Services include:
GSI and IBM Services: SAP Consulting & Implementation Services
AMS and IBM Services: SAP Application Management and Development Solutions
MSP and IBM Services: Managed Applications for SAP

Do I need IBM Db2 to run SAP NetWeaver on IBM Cloud?
Multiple SAP AnyDB options and SAP HANA are available for use with SAP NetWeaver certified infrastructure on IBM Cloud. You are not required to
use IBM Db2.
Check SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment regularly and also reference the SAP Product
Availability Matrix for details.
For more information about IBM Db2, see SAP Note 2927211 and SAP on IBM Db2 for Linux®, UNIX, and Windows (LUW) on the SAP Community
page.
Note: Pay close attention to the provided operating systems in the SAP Note because different sets of service packs are required by your
database.

Why was Db2 on Cloud chosen for certification for IBM Cloud?
IBM Db2 is an IBM product that is seamlessly integrated into SAP. IBM Db2 is a mature database solution for SAP applications with many
advantages, including: reduced total cost of ownership, excellent performance, and simplified administration. Over the past four decades, most of
the benchmark tests by IBM Systems used IBM Db2, and we continue this tradition.

Can I split my distributed SAP environment between different data centers?
For a distributed SAP installation, it is best to have all nodes in the same location (for example, Availability Zone or Datacenter) and networking
constructs (for example, Subnet and VPC/Subnet and VLAN). Deviation from this setup can cause latency and timeouts, which render your SAP
system unresponsive.

Can I split my distributed SAP environment between IBM Cloud® Bare Metal and IBM Cloud® Virtual
Servers?
RDBMs on Intel Bare Metal Servers in the older IBM Cloud Classic Infrastructure environment that comply to SAP Note 2414097, are supported
when connected to the SAP AS on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment - when placed in the same location (i.e.
Datacenter / Availability Zone) and using an IBM Cloud Transit Gateway local routing.

Can I achieve SAP high availability as defined by SAP architecture?
High availability for SAP can be achieved for:
SAP NetWeaver High Availability
SAP HANA High Availability
SAP AnyDB High Availability (for example, IBM Db2, MS SQL etc.)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 615

You can set up high availability at either the:
SAP Technical Application layer (for example, system replication, system clustering)
Hardware layer (for example, storage replication)
How you set up high availability differs depending on the infrastructure types and network types:
For Intel Bare Metal that uses Classic Infrastructure network
For Intel Virtual Servers that use VPC Infrastructure network (does not currently support SAP NetWeaver high availability or SAP HANA high
availability)
For IBM Power Virtual Servers, on IBM Cloud that use IBM Power Virtual Server Group network
For VMware that uses Classic Infrastructure network
See the respective topics in the Get Started section for:
SAP HANA design considerations for High Availability and Disaster Recovery (HA/DR)
SAP HANA backups - Storage impacts on Recovery Time Objective (RTO)
SAP NetWeaver design considerations for High Availability configuration

How do I connect my SAP Systems running on IBM Cloud to my on-premises systems?
You have several connectivity options to create secure connections between your on-premises systems and the IBM Cloud. These options are your
responsibility to configure, and IBM Cloud operates the underlying services according to the configuration. For more information see Connectivity to
your SAP system landscape.

Licensing and pricing
How does SAP licensing work with the IBM Cloud® for SAP infrastructure-as-a-service?
The IBM Cloud® SAP-certified infrastructure uses the Bring Your Own License (BYOL) model. This model follows the industry standard of IaaS for SAP
workloads and is the same approach that is used for many decades with SAP software.
No IBM Cloud® for SAP portfolio offering contains any SAP licensing.
This arrangement applies to:
SAP Business Application licenses (for example, SAP S/4HANA, SAP ECC)
SAP Technical Application licenses (for example, SAP HANA, SAP NetWeaver)
Any OEM license from SAP (for example, SAP AnyDB OEM such as MS SQL)

How does Operating System (OS) licensing work with the IBM Cloud® for SAP Infrastructure-as-aService?
The cost of the OS license (and applicable subscription additions for SAP-specific OS Packages and Support), is included when you select your OS on
the order form for your SAP-certified server.

How are the SAP-certified IBM Cloud servers priced?
Prices are provided through the IBM Cloud catalog when you begin the ordering process. Any discounts available from Reserved Instances pricing
agreements or usage of Subscription Accounts are also calculated.
For SAP-certified bare metal servers that are certified as HANA appliances, pricing includes the high-performance local storage.
Note: As an industry practice across Cloud Service Providers, virtual servers from IBM Cloud® for SAP use redundant network block or file
storage. These storage costs might not be included in the initial price estimation. In addition, there are no network bandwidth charges for
local network traffic to or from the virtual server host and the storage host on IBM Cloud.

SAP-certified IBM Power Virtual Servers
Which version of Db2 can I use to run SAP NetWeaver on IBM Power Virtual Servers?
For information check SAP Note 2855850 regularly. You can also reference SAP Product Availability Matrix.
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 616

What are the operating system requirements for Db2, AIX and SAP NetWeaver?
For operating system requirements, see:
SAP Note 1780629 - AIX: Minimal OS Requirements for SAP Kernel
SAP Note 2267287 - Using SAP systems with AIX 7.2

For Oracle installs, I have to activate aioservers but it's missing in AIX 7x. Where is this setting?
The smit fast path is missing because the AIO server setting is automatically updated when the kernel extension notices that the aio sync operation is
requested. View the main pages for ioo to see command settings and examples. For the required settings, see Checking Asynchronous Input
Output Processes AIX 64-Bit.

With an Oracle install, how do I activate the iocp device when it's "Defined"?
Use the smit menu with fast path command smitty iocp . Select Change/Show Characteristics of I/O Completion Ports and set the state to be
configured at system restart to Available. This setting ensures that the device is available even after a system restart.
Note: If you use the mkdev -l iocp0 command on the command line, the devíce is available only when the system is rebooted, and the
device shows as Defined again. To ensure that this device is activated after a system restart, add the -P flag so the ODM is updated: mkdev
-l iocp0 -P

When I run the Oracle installer precheck, failed items are listed. What should I do?
Part of the RUNINSTALLER function is to ensure that you complete the necessary pre-checks before you install the product. Two of the common
errors are:
You don't have enough free space in /tmp . Oracle 12.2 requires 5 GB of free space. If necessary, increase the amount of free space.
You don't have 12 GB of paging space available. You can define paging multiple ways. You can extend the Paging Logical Volume

hd6 in the

volume group. You can also create a new paging space on a different volume by using smit mklv . When you see the LV type, specify paging.
This setting creates a new paging space that is called paging00 on the hard disk you selected.
When you finish making adjustments and defined at least the minimum required amount of space, go back to the Oracle INSTALLER and select rerun
checks. If you see no errors, you can proceed with the installation.

Is there a central SAP Note for installing NetWeaver on Oracle?
SAP Note 2172935 - Installation - SAP Systems based on SAP NetWeaver: Oracle Database provides hardware and storage requirements for Oracle
and details the required file systems and mount points.

Is there a central SAP Note for using MaxDB for NetWeaver installations?
SAP Note 2365014 - Installation of SAP Systems Based on SAP NetWeaver: SAP MaxDB outlines the installation and provides other useful
information for MaxDB users.

SAP HANA generic questions
What hardware database virtualization/sharing/isolation options are supported in the IBM Cloud
infrastructure?
IBM Cloud SAP-certified infrastructure offerings are certified for SAP and do not include database virtualization/sharing/isolation options such as
Multitenant Database Containers (MDC) testing. The customer is responsible for following SAP guidance to:
Correctly set up the SAP HANA features and functions
Ensure that the infrastructure remains compliant with the SAP certification

Is scale-out supported for SAP HANA?
Yes. For OLTP (i.e. SAP S/4HANA) see SAP S/4HANA - Scale-up/Scale-out , and for OLAP (i.e. BW/4HANA) see SAP BW/4HANA - Scale-up/Scale-out .
Alternatively view the latest top specific available in the summary table on FAQ of Profile List with Benchmarks and Specifications .

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 617

How do I back up my SAP HANA-certified servers?
Server backup isn't included with Cloud Infrastructure-as-a-Service (IaaS).
You can add backup options during the ordering process from the IBM Cloud catalog, or install your own backup solution onto regular IBM Cloud
IaaS options.

Is there a best practice configuration check for SAP HANA?
Yes, see SAP Note 2903141 - Best practice configuration checks for SAP HANA

How can I check parameters in SAP HANA?
See SAP Note 2600030 - Parameter Recommendations in SAP HANA Environments

How can I optimize my network for SAP HANA?
The OS image that IBM® provides has the parameters set to optimize network performance. You can adjust them if necessary. For more information,
see:
SAP Note 2382421 - Optimizing the Network Configuration on HANA- and OS-Level
SAP Note 2477204 - FAQ: SAP HANA Services and Ports

Is there information on the ports and services that are used by SAP?
See TCP/IP Ports of All SAP Products for detailed explanations of SAP ports and services

How can I optimize my SAP HANA performance?
See SAP Note 2000000 - FAQ: SAP HANA Performance Optimization

How can I use SAP HANA Mini Checks to monitor and highlight potential issues with my HANA
implementation?
See SAP Note 1999993 - How-To: Interpreting SAP HANA Mini Check Results

I see that HANA is using large SWAP memory. What is going on?
See SAP Note 2779331 - HANA services use large SWAP memory

SAP NetWeaver generic questions
Which versions of SAP NetWeaver are supported?
Most versions of SAP NetWeaver Application Server (ABAP or Java) from 7.0 or higher are supported across the IBM Cloud® for SAP portfolio.
For a full updated list of SAP NetWeaver versions and SAP Kernel Patch Levels supported for the various IaaS options, see the following SAP Notes:
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment
SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers

Full list of SAP Notes for the IBM Cloud® for SAP portfolio
SAP Notes that are related to IBM Cloud Classic Infrastructure
SAP Note 2414820 - SAP on IBM Cloud: Support prerequisites
SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment
SAP Note 2279688 - SAP on IBM Cloud: Support for SAP BusinessObjects
SAP Note 2686169 - Prerequisites for installing SAP Data Hub 2

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 618

SAP Notes that are related to IBM Cloud VPC Infrastructure
SAP Note 2414820 - SAP on IBM Cloud: Support prerequisites
SAP Note 2927211 - SAP Applications on IBM Cloud Virtual Private Cloud (VPC) Infrastructure environment

SAP Notes that are related to IBM Power Infrastructure connected to IBM Cloud
SAP Note 2923984 - SAP on IBM Power Virtual Servers: Support prerequisites
SAP Note 2947579 - SAP HANA on IBM Power Virtual Servers
SAP Note 2855850 - SAP Applications on IBM Power Virtual Servers
SAP Note 2932766 - SAP on IBM Power Virtual Servers: Key Monitoring Metrics

SAP Notes that are related to any Public Cloud or Virtualized Environments
SAP Note 1380654 - SAP support in IaaS environments
SAP Note 1122387 - Linux: SAP Support in virtualized environments
SAP Note 1409608 - Virtualization on Windows
SAP Note 1409604 - Virtualization on Windows: Enhanced Monitoring
SAP Note 2134316 - Can SAP ASE run in a cloud environment?
SAP Note 2923773 - Linux on IBM Cloud (IaaS): Adaption of your SAP License

SAP Notes generic for IBM Cloud
SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities

FAQ of Moving SAP Workloads
How do I move an existing SAP workload to IBM Cloud?
An existing IBM Cloud® for SAP workload can either be:
Moved as-is, from on-premises data centers to Cloud IaaS. This method is often called "lift-and-shift"
Migrating from one vendor or version to another:
Changing vendor or version of the database server (for example, IBM Db2 to SAP HANA)
Changing the version of the Application server (for example, SAP NetWeaver AS ABAP 7.0 to SAP NetWeaver AS ABAP 7.52)
Changing the version of the Business Application (for example, SAP ECC to SAP S/4HANA)
Moving workloads is an infrastructure-level change that affects the SAP systems because networking and storage changes are involved.
Migrating workloads is an application-level change that affects the SAP system installation because new software is being used.
For VMware-based SAP workloads that are running in on-premises data centers, depending on the existing setup, the movement of these virtual
machines into IBM Cloud for VMware may potentially be simplified with the usage of VMware HCX

How do I move an existing SAP HANA database or relational database to an SAP HANA-certified
server in the IBM Cloud?
No move or migration services are included with Cloud Infrastructure-as-a-Service (IaaS).
Any move or migration activities are your responsibility.
While IBM Cloud does not provide SAP application-level services, the various IBM Cloud Business Partners (including IBM Services) do provide their
service capabilities by using IBM Cloud® for SAP portfolio.
This table shows a brief list of services and the Business Partner types who can provide the services for IBM Cloud® for SAP:
Service

Provided by

Description

SAP "Global
Systems Integrator"
(GSI) providers

These providers advise and run SAP implementation and deployment projects.

Partner type
Consulting and
advisory and
implementation

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 619

Application
management

SAP "Application
Management
Services" (AMS)
providers

These providers manage and maintain an existing deployment of SAP Applications (optional:
incremental functional or development changes).

End-to-end
managed
services

SAP "Managed
Services Providers"
(MSP)

These providers run the SAP implementation and deployment and manage the Infrastructure, OS,
SAP Technical Applications, and SAP Business Applications. These services often do not include
incremental functional or development changes.
Table 1. Services Partner types

For example, some of the services that are available in partnership between IBM Cloud and IBM Services include:
GSI and IBM Services: SAP Consulting & Implementation Services
AMS and IBM Services: SAP Application Management and Development Solutions
MSP and IBM Services: Managed Applications for SAP

At a high level, what are my options for moving and migrating an existing SAP system to Cloud?
This table is a high-level list of the options for moving and migrating existing SAP systems to cloud. For more information, see all of the necessary SAP
documentation on moving and migrating SAP workloads, and liaise with your Systems Implementer for SAP.
Move and

Description

Common Usage

Downtime

Migrate SAP

Pre/Post

Data Transfer

Migration Work

workloads
approach
Heterogeneous
System Copy
that uses
SWPM

Move or RePlatform to
different CPU
Architecture, OS, or
database. Uses
System Copy
Export/Import of
SWPM

Commonly used to change
database server in
preparation for more
significant move; for
example, move to SAP
HANA DB with a Classical
Migration approach

Yes

Significant
preparation and
post processing
required.

System Copy
Export dump

Homogeneous
System Copy
that uses
SWPM (Only
option for
System Copies
that are
running SAP
HANA DB)

Move or RePlatform to more to
newer OS or
database version.
Cannot be used to
move between
CPU Architecture
or Endianness.
Uses SAP Database
Backup with
SWPM.

Move to new SAP HANA
target, or to move to new
OS target with existing
AnyDB. Also used to create
fresh sandboxes of an
existing system (with or
without Logical System
Name change).

Yes. Some reduction in
downtime possible
depending on
preparation, change
freeze, and delta change
sync (of log files) in
failover to target

Less preparation
than
heterogeneous
System Copy;
moderate to
significant post
processing
required
depending on
scenario (in most
cases, the Logical
System Name is
changed, for
example, BDLS)

SAP Database
Backup

SAP HANA
System
Replication
(HSR) with
replicated
database
mirror on cloud

Secondary failover
site is hosted on
cloud

HA and DR scenarios

Yes minimal, depends
on design and failover
factors (for example,
cost-optimised or
performance)

Using SAP
Landscape
Management
(LaMa), set up and
execution can be
automated

Log or memory
shipping;
SYNCMEM,
FULLSYNC,
SYNC, or
ASYNC modes

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 620

System
Relocation that
uses SAP LaMa
to orchestrate
move

Physically or
virtually relocate
running or
shutdown
instances. Uses
SAP LaMa. Cannot
relocate SAP HANA
DB MDC Tenants.

Moving individual SAP
instances to new
infrastructure landscape
that is already set up.

Yes minimal, running
systems have
downtimes as they are
stopped, unprepared,
then prepared and
started

Using SAP LaMa,
relocation can be
automated

Package
network
transfer that
uses LaMa or
LaMa adapter
for VMware

DMO for SUM
with System
Move
execution
(Combines
Migration,
Unicode
conversion,
Upgrades, and
more tasks)

Supported for App
Server
(NetWeaver)
upgrade or
database
conversion to SAP
HANA. Moves the
NW PAS +
database server
and upgrade - all at
the same time.

Migrations to Business
Suite on SAP HANA or part
of SAP S/4HANA
conversion migration
(Brownfield)

Yes. Both PAS Target
and database host in the
target landscape (for
example, IBM Cloud)
needs to be ready before
DMO for SUM with
System Move execution.

Significant
preparation is
required.

System Export
is performed in
source
landscape.
Import is
performed in
target
landscape. The
export/import
can also be
done in
parallel.

Selective Data
Transition, with
Shell
Conversion

Create shell of SAP
System with
Customizing and
Development only;
then upgrade /
conversion to
either SAP ECC or
SAP S/4HANA.
Migrate selective
data from ECC to
the upgraded shell
system

Used in Business split
scenarios (e.g.
Divestitures), and
Transformation/Conversion
projects with SAP
S/4HANA

Yes minimal, the target
can be built and tested
in advance (repeatedly
testing the conversion
steps and remediation).
Data can be replicated to
target in advance, so
downtime is only for the
delta data
synchronization and
replacing the old system
with target.

Significant
preparation is
required.

SAP Landscape
Transformation
Replication
Server,
handled
through a
direct SAP
engagement

Selective Data
Transition, with
Mix & Match

Merge of two or
more system
configurations to
create a new SAP
System with
required
configuration; then
upgrade /
conversion to SAP
S/4HANA

Used in Business merge
scenarios (e.g.
Acquisitions) or multiple
SAP system consolidation
(e.g. ERPs for each
Geographic Region or
Business Units), and
Transformation/Conversion
projects with SAP
S/4HANA

Yes minimal, the target
can be built and tested
in advance (repeatedly
testing the conversion
steps and remediation).
Data can be replicated to
target in advance, so
downtime is only for the
delta data
synchronization and
replacing the old system
with target.

Significant
preparation is
required.

SAP Landscape
Transformation
Replication
Server,
handled
through a
direct SAP
engagement

Table 2. List of Move and Migrate SAP workloads approaches

FAQ of Profile List with Benchmarks and Specifications
What are the certifications, highest benchmarks, and highest specifications available for different
offerings?
This table is a summary table of the certifications, highest benchmark scores, and maximum RAM configurations for each offering are shown in this
table:
IaaS Type

IBM Cloud Bare Metal (Local
SSD)

SAPS

OLTP scale-up

OLAP scale-up

benchmark

memory (GB)

memory (GB)

550,670

18,432 GB
(6,144 GB RAM plus
12,288 GB PMEM)

18,432 GB
(6,144 GB RAM plus
12,288 GB PMEM)

OLAP scale-out memory (GB)

184,320 GB from 15x of 12,288 GB
nodes (excl. 1 standby)
(world record of all IaaS)

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 621

IBM Cloud Virtual Server

215,570

5,600 GB

2,464 GB

17,248 GB from 7x of 2,464 GB
nodes (excl. 1 standby)

IBM Power Virtual Server
(complementary offering from
IBM Power Systems)

840,000

23,040 GB

14,000 GB

42,000 GB from 7x of 6,000 GB
nodes (excl. 1 standby)

IBM Cloud for VMware

495,603

6,144 GB

3,072 GB

30,720 GB from 15x of 2,048 GB
nodes (excl. 1 standby)

Table 1. Highest specifications of the SAP-certified IaaS

Do you have a full list of Profile specifications, including SAP sizing for different workloads?
Each list of Infrastructure profiles for SAP HANA database server:
Intel Bare Metal server (Classic) certified profiles for SAP HANA
Intel Virtual Server (VPC) certified profiles for SAP HANA
Intel Bare Metal server (VPC) certified profiles for SAP HANA
IBM Power Virtual Server certified profiles for SAP HANA This is a complementary offering from IBM Power Systems
VMware SDDC certified profiles for SAP HANA
Each list of Infrastructure profiles for SAP NetWeaver Application Server:
Intel Bare Metal server (Classic) certified profiles for SAP NetWeaver
Intel Virtual Server (VPC) certified profiles for SAP NetWeaver
Intel Bare Metal server (VPC) certified profiles for SAP NetWeaver
IBM Power Virtual Server certified profiles for SAP NetWeaver This is a complementary offering from IBM Power Systems
VMware SDDC certified profiles for SAP NetWeaver
All SAP-certified infrastructure for SAP HANA also includes certification for SAP NetWeaver and SAP AnyDB. However, this certification is not viceversa. Any SAP-certified infrastructure for SAP NetWeaver includes only SAP AnyDB.
For a full list of all Infrastructure-as-a-Service Profile specifications in the IBM Cloud® for SAP portfolio (including complementary offerings from
IBM Power Systems), see the following table:
Note: The following table can be copied into spreadsheet software. All profiles - without exception - are supported for SAP NetWeaver.

Profile

IaaS

CPU

CPU

Memory

SD Two-

CPU

DRAM

SAP HANA

SAP HANA

IBM Cloud

Type

Cores

Threads

(DRAM

Tier

Architecture

per

Deployment

Processing

environment

(also

GB)

benchmark

CPU

Method

Type

(SAPS)

Thread

known
as.
vCPU)
BI.S3.H2.192

IBM
Cloud
Bare
Metal
(Local
SSD)

36

72

192

78,850

Intel Skylake
SP

2.67

Appliance

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S3.H2.384

IBM
Cloud
Bare
Metal
(Local
SSD)

36

72

384

79,430

Intel Skylake
SP

5.33

Appliance

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 622

BI.S3.H2.768

IBM
Cloud
Bare
Metal
(Local
SSD)

36

72

768

79,630

Intel Skylake
SP

10.67

Appliance

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S4.H2.192

IBM
Cloud
Bare
Metal
(Local
SSD)

32

64

192

82,470

Intel
Cascade
Lake SP

3.00

Appliance

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S4.H2.384

IBM
Cloud
Bare
Metal
(Local
SSD)

32

64

384

85,130

Intel
Cascade
Lake SP

6.00

Appliance

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S4.H2.384_v3

IBM
Cloud
Bare
Metal
(Local
SSD)

16

32

384

60,420

Intel
Cascade
Lake SP

12.00

Appliance

OLAP/OLTP

Classic

BI.S4.H2.768

IBM
Cloud
Bare
Metal
(Local
SSD)

40

80

768

112,830

Intel
Cascade
Lake SP

9.60

Appliance

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S4.H2.768_v2

IBM
Cloud
Bare
Metal
(Local
SSD)

48

96

768

124,620

Intel
Cascade
Lake SP

8.00

Appliance

OLAP/OLTP

Classic

BI.S4.H2.768_v3

IBM
Cloud
Bare
Metal
(Local
SSD)

16

32

768

60,420

Intel
Cascade
Lake SP

24.00

Appliance

OLAP/OLTP

Classic

BI.S4.H2.1500

IBM
Cloud
Bare
Metal
(Local
SSD)

56

112

1,536

147,220

Intel
Cascade
Lake SP

13.71

Appliance

OLAP/OLTP,
Scale-Out

Classic

BI.S4.H2.3000

IBM
Cloud
Bare
Metal
(Local
SSD)

56

112

3,072

135,127

Intel
Cascade
Lake SP

27.43

Appliance

OLAP/OLTP,
Scale-Out

Classic

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 623

BI.S4.H4.3000

IBM
Cloud
Bare
Metal
(Local
SSD)

112

224

3,072

285,970

Intel
Cascade
Lake SP

13.71

Appliance

OLAP/OLTP

Classic

BI.S4.H4.6000

IBM
Cloud
Bare
Metal
(Local
SSD)

112

224

6,144

285,970

Intel
Cascade
Lake SP

27.43

Appliance

OLAP/OLTP,
Scale-Out

Classic

BI.S4.H8.6000

IBM
Cloud
Bare
Metal
(Local
SSD)

224

448

6,144

550,670

Intel
Cascade
Lake SP

13.71

Appliance

OLAP/OLTP,
Scale-Out

Classic

BI.S4.H8.12000

IBM
Cloud
Bare
Metal
(Local
SSD)

224

448

12,288

550,670

Intel
Cascade
Lake SP

27.43

Appliance/TDI

OLAP/OLTP,
Scale-Out

Classic

bx2d-metal96x384

IBM
Cloud
Bare
Metal
(Local
SSD)

48

96

384

124,130

Intel
Cascade
Lake SP

4.00

Appliance

OLAP/OLTP

VPC

mx2d-metal96x768

IBM
Cloud
Bare
Metal
(Local
SSD)

48

96

768

127,620

Intel
Cascade
Lake SP

8.00

Appliance

OLAP/OLTP

VPC

ux2d-metal112x3072

IBM
Cloud
Bare
Metal
(Local
SSD)

56

112

3,072

140,730

Intel
Cascade
Lake SP

27.43

Appliance

OLAP/OLTP

VPC

ux2d-metal224x6144

IBM
Cloud
Bare
Metal
(Local
SSD)

112

224

6,144

294,730

Intel
Cascade
Lake SP

27.43

Appliance

OLAP/OLTP

VPC

mx2-8x64

IBM
Cloud
Virtual
Server

--

8

64

10,283

Intel
Cascade
Lake SP

8.00

TDI

SAP
Business
One for
HANA

VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 624

mx2-16x128

IBM
Cloud
Virtual
Server

--

16

128

20,565

Intel
Cascade
Lake SP

8.00

TDI

OLTP and
SAP
Business
One for
HANA

VPC

mx2-32x256

IBM
Cloud
Virtual
Server

--

32

256

41,130

Intel
Cascade
Lake SP

8.00

TDI

OLTP and
SAP
Business
One for
HANA

VPC

mx2-48x384

IBM
Cloud
Virtual
Server

--

48

384

56,970

Intel
Cascade
Lake SP

8.00

TDI

OLTP and
SAP
Business
One for
HANA

VPC

vx2d-16x224

IBM
Cloud
Virtual
Server

--

16

224

17,046

Intel
Cascade
Lake SP

14.00

TDI

OLTP

VPC

vx2d-44x616

IBM
Cloud
Virtual
Server

--

44

616

46,875

Intel
Cascade
Lake SP

14.00

TDI

OLAP/OLTP

VPC

vx2d-88x1232

IBM
Cloud
Virtual
Server

--

88

1,232

93,750

Intel
Cascade
Lake SP

14.00

TDI

OLAP/OLTP

VPC

vx2d-144x2016

IBM
Cloud
Virtual
Server

--

144

2,016

153,410

Intel
Cascade
Lake SP

14.00

TDI

OLAP/OLTP

VPC

vx2d-176x2464

IBM
Cloud
Virtual
Server

--

176

2,464

187,500

Intel
Cascade
Lake SP

14.00

TDI

OLAP/OLTP,
Scale-Out

VPC

ux2d-8x224

IBM
Cloud
Virtual
Server

--

8

224

8,623

Intel
Cascade
Lake SP

28.00

TDI

OLTP

VPC

ux2d-16x448

IBM
Cloud
Virtual
Server

--

16

448

17,246

Intel
Cascade
Lake SP

28.00

TDI

OLTP

VPC

ux2d-36x1008

IBM
Cloud
Virtual
Server

--

36

1,008

38,803

Intel
Cascade
Lake SP

28.00

TDI

OLTP

VPC

ux2d-48x1344

IBM
Cloud
Virtual
Server

--

48

1,344

51,737

Intel
Cascade
Lake SP

28.00

TDI

OLTP

VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 625

ux2d-72x2016

IBM
Cloud
Virtual
Server

--

72

2,016

77,606

Intel
Cascade
Lake SP

28.00

TDI

OLTP

VPC

ux2d-100x2800

IBM
Cloud
Virtual
Server

--

100

2,800

107,785

Intel
Cascade
Lake SP

28.00

TDI

OLTP

VPC

ux2d-200x5600

IBM
Cloud
Virtual
Server

--

200

5,600

215,570

Intel
Cascade
Lake SP

28.00

TDI

OLTP

VPC

bh1-16x1600

IBM
Power
Virtual
Server

16

128

1,600

96,000

IBM
POWER9

12.50

Appliance

OLAP/OLTP

Power
Systems

bh1-20x2000

IBM
Power
Virtual
Server

20

160

2,000

120,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-22x2200

IBM
Power
Virtual
Server

22

176

2,200

132,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-25x2500

IBM
Power
Virtual
Server

25

200

2,500

150,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-30x3000

IBM
Power
Virtual
Server

30

240

3,000

180,000

IBM
POWER9

12.50

Appliance

OLAP/OLTP,
Scale-Out

Power
Systems

bh1-35x3500

IBM
Power
Virtual
Server

35

280

3,500

210,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-40x4000

IBM
Power
Virtual
Server

40

320

4,000

240,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-50x5000

IBM
Power
Virtual
Server

50

400

5,000

300,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-60x6000

IBM
Power
Virtual
Server

60

480

6,000

360,000

IBM
POWER9

12.50

Appliance

OLAP/OLTP,
Scale-Out

Power
Systems

bh1-70x7000

IBM
Power
Virtual
Server

70

560

7,000

420,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 626

bh1-80x8000

IBM
Power
Virtual
Server

80

640

8,000

480,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-100x10000

IBM
Power
Virtual
Server

100

800

10,000

600,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-120x12000

IBM
Power
Virtual
Server

120

960

12,000

720,000

IBM
POWER9

12.50

Appliance

OLAP *

Power
Systems

bh1-140x14000

IBM
Power
Virtual
Server

140

1,120

14,000

840,000

IBM
POWER9

12.50

Appliance

OLAP/OLTP

Power
Systems

ch1-60x3000

IBM
Power
Virtual
Server

60

480

3,000

360,000

IBM
POWER9

6.25

Appliance

OLAP/OLTP,
Scale-Out

Power
Systems

ch1-70x3500

IBM
Power
Virtual
Server

70

560

3,500

420,000

IBM
POWER9

6.25

Appliance

OLAP/OLTP
*

Power
Systems

ch1-80x4000

IBM
Power
Virtual
Server

80

640

4,000

480,000

IBM
POWER9

6.25

Appliance

OLAP/OLTP
*

Power
Systems

ch1-100x5000

IBM
Power
Virtual
Server

100

800

5,000

600,000

IBM
POWER9

6.25

Appliance

OLAP/OLTP

Power
Systems

ch1-120x6000

IBM
Power
Virtual
Server

120

960

6,000

720,000

IBM
POWER9

6.25

Appliance

OLAP/OLTP
*

Power
Systems

ch1-140x7000

IBM
Power
Virtual
Server

140

1,120

7,000

840,000

IBM
POWER9

6.25

Appliance

OLAP/OLTP

Power
Systems

mh1-8x1440

IBM
Power
Virtual
Server

8

64

1,440

48,000

IBM
POWER9

22.50

Appliance

OLAP/OLTP

Power
Systems

mh1-10x1800

IBM
Power
Virtual
Server

10

80

1,800

60,000

IBM
POWER9

22.50

Appliance

OLAP

Power
Systems

mh1-12x2160

IBM
Power
Virtual
Server

12

96

2,160

72,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 627

mh1-16x2880

IBM
Power
Virtual
Server

16

128

2,880

96,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-20x3600

IBM
Power
Virtual
Server

20

160

3,600

120,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-22x3960

IBM
Power
Virtual
Server

22

176

3,960

132,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-25x4500

IBM
Power
Virtual
Server

25

200

4,608

150,000

IBM
POWER9

23.00

Appliance

OLAP

Power
Systems

mh1-30x5400

IBM
Power
Virtual
Server

30

240

5,400

180,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-35x6300

IBM
Power
Virtual
Server

35

280

6,300

210,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-40x7200

IBM
Power
Virtual
Server

40

320

7,200

240,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-50x9000

IBM
Power
Virtual
Server

50

400

9,216

300,000

IBM
POWER9

23.00

Appliance

OLAP

Power
Systems

mh1-60x10800

IBM
Power
Virtual
Server

60

480

10,800

360,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-70x12600

IBM
Power
Virtual
Server

70

560

12,600

420,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-80x14400

IBM
Power
Virtual
Server

80

640

14,400

480,000

IBM
POWER9

22.50

Appliance

OLAP/OLTP

Power
Systems

mh1-90x16200

IBM
Power
Virtual
Server

90

720

16,200

540,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

mh1-100x18000

IBM
Power
Virtual
Server

100

800

18,000

600,000

IBM
POWER9

22.50

Appliance

OLAP *

Power
Systems

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 628

mh1-125x22500

IBM
Power
Virtual
Server

125

1000

23,040

750,000

IBM
POWER9

23.00

Appliance

OLAP

Power
Systems

umh-4x960

IBM
Power
Virtual
Server

4

32

960

24,000

IBM
POWER9

30.00

Appliance

OLTP

Power
Systems

umh-6x1440

IBM
Power
Virtual
Server

6

48

1,440

36,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-8x1920

IBM
Power
Virtual
Server

8

64

1,920

48,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-10x2400

IBM
Power
Virtual
Server

10

80

2,400

60,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-12x2880

IBM
Power
Virtual
Server

12

96

2,880

72,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-16x3840

IBM
Power
Virtual
Server

16

128

3,840

96,000

IBM
POWER9

30.00

Appliance

OLTP

Power
Systems

umh-20x4800

IBM
Power
Virtual
Server

20

160

4,800

120,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-22x5280

IBM
Power
Virtual
Server

22

176

5,280

132,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-25x6000

IBM
Power
Virtual
Server

25

200

6,000

150,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-30x7200

IBM
Power
Virtual
Server

30

240

7,200

180,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-35x8400

IBM
Power
Virtual
Server

35

280

8,400

210,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-40x9600

IBM
Power
Virtual
Server

40

320

9,600

240,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 629

umh-50x12000

IBM
Power
Virtual
Server

50

400

12,000

300,000

IBM
POWER9

30.00

Appliance

OLTP *

Power
Systems

umh-60x14400

IBM
Power
Virtual
Server

60

480

14,400

360,000

IBM
POWER9

30.00

Appliance

OLTP

Power
Systems

ush1-4x128

IBM
Power
Virtual
Server

4

32

128

24,000

IBM
POWER9

4.00

Appliance

OLAP/OLTP

Power
Systems

ush1-4x256

IBM
Power
Virtual
Server

4

32

256

24,000

IBM
POWER9

8.00

Appliance

OLAP/OLTP

Power
Systems

ush1-4x384

IBM
Power
Virtual
Server

4

32

384

24,000

IBM
POWER9

12.00

Appliance

OLAP/OLTP

Power
Systems

ush1-4x512

IBM
Power
Virtual
Server

4

32

512

24,000

IBM
POWER9

16.00

Appliance

OLAP/OLTP

Power
Systems

ush1-4x768

IBM
Power
Virtual
Server

4

32

768

24,000

IBM
POWER9

24.00

Appliance

OLAP/OLTP

Power
Systems

BI.S3.H2.192
(VMware)

IBM
Cloud
for
VMware

36

72

192

70,965

Intel Skylake
SP

2.67

TDI

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S3.H2.384
(VMware)

IBM
Cloud
for
VMware

36

72

384

71,487

Intel Skylake
SP

5.33

TDI

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S3.H2.768
(VMware)

IBM
Cloud
for
VMware

36

72

768

71,667

Intel Skylake
SP

10.67

TDI

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S4.H2.192
(VMware)

IBM
Cloud
for
VMware

32

64

192

74,223

Intel
Cascade
Lake SP

3.00

TDI

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S4.H2.384
(VMware)

IBM
Cloud
for
VMware

32

64

384

76,617

Intel
Cascade
Lake SP

6.00

TDI

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 630

BI.S4.H2.768
(VMware)

IBM
Cloud
for
VMware

40

80

768

101,547

Intel
Cascade
Lake SP

9.60

TDI

OLAP/OLTP
and SAP
Business
One for
HANA

Classic

BI.S4.H2.1500
(VMware)

IBM
Cloud
for
VMware

56

112

1,536

132,498

Intel
Cascade
Lake SP

13.71

TDI

OLAP/OLTP

Classic

BI.S4.H2.3000
(VMware)

IBM
Cloud
for
VMware

56

112

3,072

121,614

Intel
Cascade
Lake SP

27.43

TDI

OLAP/OLTP

Classic

BI.S4.H4.3000
(VMware)

IBM
Cloud
for
VMware

112

224

3,072

257,373

Intel
Cascade
Lake SP

13.71

TDI

OLAP/OLTP

Classic

BI.S4.H4.6000
(VMware)

IBM
Cloud
for
VMware

112

224

6,144

257,373

Intel
Cascade
Lake SP

27.43

TDI

OLAP/OLTP

Classic

BI.S4.H8.6000
(VMware)

IBM
Cloud
for
VMware

224

448

6,144

495,603

Intel
Cascade
Lake SP

13.71

TDI

OLAP/OLTP

Classic

BI.S4.H2.384GB
RAM + 1.5TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

56

112

1,884

135,127

Intel
Cascade
Lake SP

16.82

TDI

OLTP

Classic

BI.S4.H2.768GB
RAM + 1.5TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

56

112

2,268

135,127

Intel
Cascade
Lake SP

20.25

TDI

OLTP

Classic

BI.S4.H2.768GB
RAM + 3TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

56

112

3,072

135,127

Intel
Cascade
Lake SP

27.43

TDI

OLTP

Classic

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 631

BI.S4.H2.1.5TB
RAM + 1.5TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

56

112

3,768

135,127

Intel
Cascade
Lake SP

33.64

TDI

OLAP/OLTP

Classic

BI.S4.H2.1.5TB
RAM + 3TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

112

224

3,768

135,127

Intel
Cascade
Lake SP

16.82

TDI

OLAP/OLTP

Classic

BI.S4.H4.768GB
RAM + 3TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

56

112

4,608

285,970

Intel
Cascade
Lake SP

41.14

TDI

OLTP

Classic

BI.S4.H4.1.5TB
RAM + 3TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

112

224

4,608

285,970

Intel
Cascade
Lake SP

20.57

TDI

OLAP/OLTP

Classic

BI.S4.H4.1.5TB
RAM + 6TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

112

224

6,144

285,970

Intel
Cascade
Lake SP

27.43

TDI

OLTP

Classic

BI.S4.H4.3TB
RAM + 3TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

112

224

7,680

285,970

Intel
Cascade
Lake SP

34.29

TDI

OLAP/OLTP

Classic

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 632

BI.S4.H4.3TB
RAM + 6TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

112

224

9,216

285,970

Intel
Cascade
Lake SP

41.14

TDI

OLAP/OLTP

Classic

BI.S4.H8.1.5TB
RAM + 6TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

224

448

7,680

550,670

Intel
Cascade
Lake SP

17.14

TDI

OLTP

Classic

BI.S4.H8.3TB
RAM + 6TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

224

448

9,216

550,670

Intel
Cascade
Lake SP

20.57

TDI

OLAP/OLTP

Classic

BI.S4.H8.3TB
RAM + 12TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

224

448

12,288

550,670

Intel
Cascade
Lake SP

27.43

TDI

OLTP

Classic

BI.S4.H8.6TB
RAM + 6TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

224

448

15,360

550,670

Intel
Cascade
Lake SP

34.29

TDI

OLAP/OLTP

Classic

BI.S4.H8.6TB
RAM + 12TB
PMEM

IBM
Cloud
Bare
Metal
(Local
SSD +
Intel
Optane
DC
PMEM)

224

448

18,432

550,670

Intel
Cascade
Lake SP

41.14

TDI

OLAP/OLTP

Classic

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 633

--

--

--

--

--

--

--

--

--

--

--

The following profiles are certified for SAP
NetWeaver only - not SAP HANA

--

--

--

--

--

--

BI.S3.NW32

IBM
Cloud
Bare
Metal
(Local
SSD)

4

8

32

11,970

Intel Kaby
Lake

4.00

--

--

Classic

BI.S3.NW64

IBM
Cloud
Bare
Metal
(Local
SSD)

4

8

64

12,750

Intel Kaby
Lake

8.00

--

--

Classic

BI.S3.NW192

IBM
Cloud
Bare
Metal
(Local
SSD)

36

72

192

78,850

Intel Skylake
SP

2.67

--

--

Classic

BI.S3.NW384

IBM
Cloud
Bare
Metal
(Local
SSD)

36

72

384

79,430

Intel Skylake
SP

5.33

--

--

Classic

BI.S3.NW768

IBM
Cloud
Bare
Metal
(Local
SSD)

36

72

768

79,630

Intel Skylake
SP

10.67

--

--

Classic

BI.S4.NW192

IBM
Cloud
Bare
Metal
(Local
SSD)

32

64

192

82,470

Intel
Cascade
Lake SP

3.00

--

--

Classic

BI.S4.NW384

IBM
Cloud
Bare
Metal
(Local
SSD)

32

64

384

85,130

Intel
Cascade
Lake SP

6.00

--

--

Classic

BI.S4.NW384_v3

IBM
Cloud
Bare
Metal
(Local
SSD)

16

32

384

60,420

Intel
Cascade
Lake SP

12.00

--

--

Classic

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 634

BI.S4.NW768

IBM
Cloud
Bare
Metal
(Local
SSD)

40

80

768

112,830

Intel
Cascade
Lake SP

9.60

--

--

Classic

BI.S4.NW768_v2

IBM
Cloud
Bare
Metal
(Local
SSD)

148

96

768

124,620

Intel
Cascade
Lake SP

8.00

--

--

Classic

BI.S4.NW768_v3

IBM
Cloud
Bare
Metal
(Local
SSD)

16

32

768

60,420

Intel
Cascade
Lake SP

24.00

--

--

Classic

cx2d-metal96x192

IBM
Cloud
Bare
Metal
(Local
SSD)

48

96

192

101,070

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-2x4

IBM
Cloud
Virtual
Server

--

2

4

2,238

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-4x8

IBM
Cloud
Virtual
Server

--

4

8

4,475

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-8x16

IBM
Cloud
Virtual
Server

--

8

16

8,950

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-16x32

IBM
Cloud
Virtual
Server

--

16

32

17,900

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-32x64

IBM
Cloud
Virtual
Server

--

32

64

35,800

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-48x96

IBM
Cloud
Virtual
Server

--

48

96

53,700

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-64x128

IBM
Cloud
Virtual
Server

--

64

128

71,600

Intel
Cascade
Lake SP

2.00

--

--

VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 635

cx2-96x192

IBM
Cloud
Virtual
Server

--

96

192

107,400

Intel
Cascade
Lake SP

2.00

--

--

VPC

cx2-128x256

IBM
Cloud
Virtual
Server

--

128

256

143,200

Intel
Cascade
Lake SP

2.00

--

--

VPC

bx2-2x8

IBM
Cloud
Virtual
Server

--

2

8

2,306

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-4x16

IBM
Cloud
Virtual
Server

--

4

16

4,613

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-8x32

IBM
Cloud
Virtual
Server

--

8

32

9,225

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-16x64

IBM
Cloud
Virtual
Server

--

16

64

18,450

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-32x128

IBM
Cloud
Virtual
Server

--

32

28

36,900

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-48x192

IBM
Cloud
Virtual
Server

--

48

192

55,350

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-64x256

IBM
Cloud
Virtual
Server

--

64

256

81,685

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-96x384

IBM
Cloud
Virtual
Server

--

96

384

122,528

Intel
Cascade
Lake SP

4.00

--

--

VPC

bx2-128x512

IBM
Cloud
Virtual
Server

--

128

512

163,370

Intel
Cascade
Lake SP

4.00

--

--

VPC

mx2-2x16

IBM
Cloud
Virtual
Server

--

2

16

2,571

Intel
Cascade
Lake SP

8.00

--

--

VPC

mx2-4x32

IBM
Cloud
Virtual
Server

--

4

32

5,141

Intel
Cascade
Lake SP

8.00

--

--

VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 636

mx2-64x512

IBM
Cloud
Virtual
Server

--

64

512

81,015

Intel
Cascade
Lake SP

8.00

--

--

VPC

mx2-96x768

IBM
Cloud
Virtual
Server

--

96

768

121,523

Intel
Cascade
Lake SP

8.00

--

--

VPC

mx2-128x1024

IBM
Cloud
Virtual
Server

--

128

1,024

162,030

Intel
Cascade
Lake SP

8.00

--

--

VPC

vx2d-2x28

IBM
Cloud
Virtual
Server

--

2

28

2,131

Intel
Cascade
Lake SP

14.00

--

--

VPC

vx2d-4x56

IBM
Cloud
Virtual
Server

--

4

56

4,262

Intel
Cascade
Lake SP

14.00

--

--

VPC

vx2d-8x112

IBM
Cloud
Virtual
Server

--

8

112

8,523

Intel
Cascade
Lake SP

14.00

--

--

VPC

ux2d-2x56

IBM
Cloud
Virtual
Server

--

2

56

2,156

Intel
Cascade
Lake SP

28.00

--

--

VPC

ux2d-4x112

IBM
Cloud
Virtual
Server

--

4

112

4,312

Intel
Cascade
Lake SP

28.00

--

--

VPC

cx3d-2x5

IBM
Cloud
Virtual
Server

--

2

5

2,661

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-4x10

IBM
Cloud
Virtual
Server

--

4

10

5,321

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-8x20

IBM
Cloud
Virtual
Server

--

8

20

10,642

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-16x40

IBM
Cloud
Virtual
Server

--

16

40

21,284

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-24x60

IBM
Cloud
Virtual
Server

--

24

60

31,926

Intel
Sapphire
Rapids

2.50

--

--

VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 637

cx3d-32x80

IBM
Cloud
Virtual
Server

--

32

80

42,568

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-48x120

IBM
Cloud
Virtual
Server

--

48

120

63,852

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-64x160

IBM
Cloud
Virtual
Server

--

64

160

85,136

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-96x240

IBM
Cloud
Virtual
Server

--

96

240

127,703

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-128x320

IBM
Cloud
Virtual
Server

--

128

320

170,270

Intel
Sapphire
Rapids

2.50

--

--

VPC

cx3d-176x440

IBM
Cloud
Virtual
Server

--

176

440

234,120

Intel
Sapphire
Rapids

2.50

--

--

VPC

bx3d-2x10

IBM
Cloud
Virtual
Server

--

2

10

2,616

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-4x20

IBM
Cloud
Virtual
Server

--

4

20

5,232

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-8x40

IBM
Cloud
Virtual
Server

--

8

40

10,463

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-16x80

IBM
Cloud
Virtual
Server

--

16

80

20,926

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-24x120

IBM
Cloud
Virtual
Server

--

24

120

31,388

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-32x160

IBM
Cloud
Virtual
Server

--

32

160

41,850

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-48x240

IBM
Cloud
Virtual
Server

--

48

240

62,775

Intel
Sapphire
Rapids

5.00

--

--

VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 638

bx3d-64x320

IBM
Cloud
Virtual
Server

--

64

320

83,699

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-96x480

IBM
Cloud
Virtual
Server

--

96

480

125,548

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-128x640

IBM
Cloud
Virtual
Server

--

128

640

167,397

Intel
Sapphire
Rapids

5.00

--

--

VPC

bx3d-176x880

IBM
Cloud
Virtual
Server

--

176

880

230,170

Intel
Sapphire
Rapids

5.00

--

--

VPC

mx3d-2x20

IBM
Cloud
Virtual
Server

--

2

20

2,590

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-4x40

IBM
Cloud
Virtual
Server

--

4

40

5,180

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-8x80

IBM
Cloud
Virtual
Server

--

8

80

10,359

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-16x160

IBM
Cloud
Virtual
Server

--

16

160

20,718

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-24x240

IBM
Cloud
Virtual
Server

--

24

240

31,076

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-32x320

IBM
Cloud
Virtual
Server

--

32

320

41,434

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-48x480

IBM
Cloud
Virtual
Server

--

48

480

62,150

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-64x640

IBM
Cloud
Virtual
Server

--

64

640

82,866

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-96x960

IBM
Cloud
Virtual
Server

--

96

960

124,299

Intel
Sapphire
Rapids

10.00

--

--

VPC

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 639

mx3d-128x1280

IBM
Cloud
Virtual
Server

--

128

1,280

165,731

Intel
Sapphire
Rapids

10.00

--

--

VPC

mx3d-176x1760

IBM
Cloud
Virtual
Server

--

176

1,760

227,880

Intel
Sapphire
Rapids

10.00

--

--

VPC

BI.S3.NW192
(VMware)

IBM
Cloud
for
VMware

36

72

192

70,965

Intel Skylake
SP

2.67

--

--

Classic

BI.S3.NW384
(VMware)

IBM
Cloud
for
VMware

36

72

384

71,487

Intel Skylake
SP

5.33

--

--

Classic

BI.S3.NW768
(VMware)

IBM
Cloud
for
VMware

36

72

768

71,667

Intel Skylake
SP

10.67

--

--

Classic

BI.S4.NW192
(VMware)

IBM
Cloud
for
VMware

32

64

192

74,223

Intel
Cascade
Lake SP

3.00

--

--

Classic

BI.S4.NW384
(VMware)

IBM
Cloud
for
VMware

32

64

384

76,617

Intel
Cascade
Lake SP

6.00

--

--

Classic

BI.S4.NW768
(VMware)

IBM
Cloud
for
VMware

40

80

68

101,547

Intel
Cascade
Lake SP

9.60

--

--

Classic

BI.S4.NW768_v2
(VMware)

IBM
Cloud
for
VMware

48

96

768

124,620

Intel
Cascade
Lake SP

8.00

--

--

Classic

BI.S4.NW1500
(VMware)

IBM
Cloud
for
VMware

56

112

1,536

132,498

Intel
Cascade
Lake SP

13.71

--

--

Classic

BI.S4.NW3000
(VMware)

IBM
Cloud
for
VMware

56

112

3,072

121,614

Intel
Cascade
Lake SP

27.43

--

--

Classic

Table 2. Full list of SAP-certified IaaS

Note: The profiles marked with * asterisk, are not listed on the SAP HANA Hardware Directory by SAP but are certified for running SAP
HANA production systems. The directory lists the smallest, median, and largest within each profile family. This action has been taken by SAP
to avoid too many records, as the scalability of IBM POWER hardware enables significantly more granular sizing. See SAP Note 2947579 SAP HANA on IBM Power Virtual Servers for more detail.

Do you have a full list of Profile specifications for SAP HANA scale-out?
IBM Cloud for SAP | IBM Power Virtual Servers for SAP 640

For a full list of all SAP HANA scale-out certified Infrastructure-as-a-Service Profile specifications in the IBM Cloud® for SAP portfolio (including
complementary offerings from IBM Power Systems), see the following table:
Note: The following table can be copied into spreadsheet software.

Profile

IaaS

Scale-

Scale-out

SAP HANA

SAP HANA

Scale-

Scale-

SAP

SAP BWH

SAP BWH

Type

out

Configuration

Deployment

Processing

out

out CPU

HANA

Benchmark

Certification

Method

Type

CPU

Threads

Directory

Directory

Doc.

Cores

(also

Memory
(GB)

known
as
vCPU)
BI.S4.H2.1500

IBM
Cloud
Bare
Metal
(Local
SDD)

23,040

Up to 16
nodes:
15
active nodes
(1 parent, 14
worker nodes)
and 1
standby node

TDI

OLAP

840

1,680

OLAP
Record

OLAP
Scale-Out
Record

Certification
#2020048

BI.S4.H2.3000

IBM
Cloud
Bare
Metal
(Local
SDD)

46,080

Up to 16
nodes:
15
active nodes
(1 parent, 14
worker nodes)
and 1
standby node

TDI

OLAP

840

1,680

OLAP
Record

OLAP
Scale-Out
Record

Certification
#2021015

BI.S4.H4.3000

IBM
Cloud
Bare
Metal
(Local
SDD)

46,080

Up to 16
nodes:
15
active nodes
(1 parent, 14
worker nodes)
and 1
standby node

TDI

OLAP

1,680

3,360

OLAP
Record

OLAP
Scale-Out
Record

Certification
#2020027

BI.S4.H4.6000

IBM
Cloud
Bare
Metal
(Local
SDD)

92,160

Up to 16
nodes:
15 active
nodes (1
parent, 14
worker nodes)
and 1
standby node

TDI

OLAP

1,680

3,360

OLAP
Record

OLAP
Scale-Out
Record

Certification
#2020032

BI.S4.H8.6000

IBM
Cloud
Bare
Metal
(Local
SDD)

92,160

Up to 16
nodes:
15
active nodes
(1 parent, 14
worker nodes)
and 1
standby node

TDI

OLAP

3,360

6,720

OLTP
Record

OLAP
Scale-Out
Record

Certification
#2021014

BI.S4.H8.12000

IBM
Cloud
Bare
Metal
(Local
SDD)

184,320

Up to 16
nodes:
15
active nodes
(1 parent, 14
worker nodes)
and 1
standby node

TDI

OLAP

3,360

6,720

OLAP
Record

OLAP
Scale-Out
Record

Certification
#2021065

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 641

BI.S4.H8.12000

IBM
Cloud
Bare
Metal
(Local
SDD)

36,864

Up to 4
nodes:
3
active nodes
(1 parent, 2
worker nodes)
and 1
standby node

TDI

OLTP

672

1,344

OLTP
Record

n/a

n/a

vx2d-176x2464

IBM
Cloud
Virtual
Server

17,248

Up to 8
nodes:
7
active nodes
(1 parent, 6
worker nodes)
and 1
standby node

TDI

OLAP

--

1,232

OLAP
Record

n/a

[ n/a

bh1-30x3000

IBM
Power
Virtual
Server

21,000

Up to 8
nodes:
7
active nodes
(1 parent, 6
worker nodes)
and 1
standby node

TDI

OLAP

210

1,680

OLAP
Record

n/a

n/a

bh1-60x6000

IBM
Power
Virtual
Server

42,000

Up to 8
nodes:
7
active nodes
(1 parent, 6
worker nodes)
and 1
standby node

TDI

OLAP

420

3,360

OLAP
Record

n/a

n/a

ch1-60x3000

IBM
Power
Virtual
Server

21,000

Up to 8
nodes:
7
active nodes
(1 parent, 6
worker nodes)
and 1
standby node

TDI

OLAP

210

1,680

OLAP
Record

n/a

n/a

Table 3. Full list of SAP-certified IaaS in scale-out deployment

Do you have a full list of Profiles on the SAP HANA Hardware Directory?
For a full list of all SAP HANA Directory records for each certified Infrastructure-as-a-Service Profile specifications in the IBM Cloud® for SAP
portfolio (including complementary offerings from IBM Power Systems) , see the following table:
Note: ( * ) in the link to the SAP HANA Directory record means that this profile is also certified for scale-out of the related application.

Profile

IaaS Type

BI.S3.H2.192

IBM Cloud Bare Metal (Local SSD)

SAP HANA Directory
OLAP Record
OLTP Record
Business One Record

BI.S3.H2.384

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record
Business One Record

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 642

BI.S3.H2.768

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record
Business One Record

BI.S4.H2.192

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record
Business One Record

BI.S4.H2.384

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record
Business One Record

BI.S4.H2.384_v3

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record

BI.S4.H2.768

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record
Business One Record

BI.S4.H2.768_v2

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record

BI.S4.H2.768_v3

IBM Cloud Bare Metal (Local SSD)

OLAP Record
OLTP Record

BI.S4.H2.1500

IBM Cloud Bare Metal (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H2.3000

IBM Cloud Bare Metal (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H4.3000

IBM Cloud Bare Metal (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H4.6000

IBM Cloud Bare Metal (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H8.6000

IBM Cloud Bare Metal (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H8.12000

IBM Cloud Bare Metal (Local SSD)

OLAP (*) Record
OLTP (*) Record

BI.S4.H2.384GB RAM + 1.5TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLTP Record

BI.S4.H2.768GB RAM + 1.5TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLTP Record

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 643

BI.S4.H2.768GB RAM + 3TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLTP Record

BI.S4.H2.1.5TB RAM + 1.5TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S4.H2.1.5TB RAM + 3TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S4.H4.768GB RAM + 3TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLTP Record

BI.S4.H4.1.5TB RAM + 3TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S4.H4.1.5TB RAM + 6TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLTP Record

BI.S4.H4.3TB RAM + 3TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S4.H4.3TB RAM + 6TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S4.H8.1.5TB RAM + 6TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLTP Record

BI.S4.H8.3TB RAM + 6TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S4.H8.3TB RAM + 12TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLTP Record

BI.S4.H8.6TB RAM + 6TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S4.H8.6TB RAM + 12TB PMEM

IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM)

OLAP Record
OLTP Record

BI.S3.H2.192 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP Record
OLTP Record

BI.S3.H2.384 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP Record
OLTP Record

BI.S3.H2.768 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP Record
OLTP Record

BI.S4.H2.192 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP Record
OLTP Record

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 644

BI.S4.H2.384 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP Record
OLTP Record

BI.S4.H2.768 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP Record
OLTP Record

BI.S4.H2.1500 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H2.3000 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H4.3000 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H4.6000 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP (*) Record
OLTP Record

BI.S4.H8.6000 (VMware)

IBM Cloud for VMware (Local SSD)

OLAP (*) Record
OLTP Record

mx2-8x64

IBM Cloud Virtual Server

Business One Record

mx2-16x128

IBM Cloud Virtual Server

OLTP Record
Business One Record

mx2-32x256

IBM Cloud Virtual Server

OLTP Record
Business One Record

mx2-48x384

IBM Cloud Virtual Server

OLTP Record
Business One Record

ux2d-8x224

IBM Cloud Virtual Server

OLTP Record

ux2d-16x448

IBM Cloud Virtual Server

OLTP Record

ux2d-36x1008

IBM Cloud Virtual Server

OLTP Record

ux2d-48x1344

IBM Cloud Virtual Server

OLTP Record

ux2d-72x2016

IBM Cloud Virtual Server

OLTP Record

ux2d-100x2800

IBM Cloud Virtual Server

OLTP Record

ux2d-200x5600

IBM Cloud Virtual Server

OLTP Record

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 645

vx2d-16x224

IBM Cloud Virtual Server

OLTP Record

vx2d-44x616

IBM Cloud Virtual Server

OLAP Record
OLTP Record

vx2d-88x1232

IBM Cloud Virtual Server

OLAP Record
OLTP Record

vx2d-144x2016

IBM Cloud Virtual Server

OLAP Record
OLTP Record

vx2d-176x2464

IBM Cloud Virtual Server

OLAP (*) Record
OLTP Record

cx2d-metal-96x192

IBM Cloud Bare Metal Server on VPC

Business One Record

bx2d-metal-96x384

IBM Cloud Bare Metal Server on VPC

OLAP Record
OLTP Record
Business One Record

mx2d-metal-96x768

IBM Cloud Bare Metal Server on VPC

OLAP Record
OLTP Record
Business One Record

ux2d-metal-112x3072

IBM Cloud Bare Metal Server on VPC

OLAP Record
OLTP Record

ux2d-metal-224x6144

IBM Cloud Bare Metal Server on VPC

OLAP Record
OLTP Record

bh1-16x1600

IBM Power Virtual Server

OLAP Record
OLTP Record

bh1-30x3000

IBM Power Virtual Server

OLAP (*) Record
OLTP Record

bh1-60x6000

IBM Power Virtual Server

OLAP (*) Record
OLTP Record

bh1-140x14000

IBM Power Virtual Server

OLAP Record
OLTP Record

ch1-60x3000

IBM Power Virtual Server

OLAP (*) Record
OLTP Record

ch1-100x5000

IBM Power Virtual Server

OLTP Record

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 646

ch1-140x7000

IBM Power Virtual Server

OLAP Record
OLTP Record

mh1-8x1440

IBM Power Virtual Server

OLAP Record
OLTP Record

mh1-10x1800

IBM Power Virtual Server

OLAP Record

mh1-25x4500

IBM Power Virtual Server

OLTP Record

mh1-50x9000

IBM Power Virtual Server

OLTP Record

mh1-80x14400

IBM Power Virtual Server

OLAP Record
OLTP Record

mh1-125x22500

IBM Power Virtual Server

OLTP Record

umh-4x960

IBM Power Virtual Server

OLTP Record

umh-16x3840

IBM Power Virtual Server

OLTP Record

umh-60x14400

IBM Power Virtual Server

OLTP Record

ush1-4x128

IBM Power Virtual Server

OLTP Record

ush1-4x512

IBM Power Virtual Server

OLTP Record

Table 4. Full list of profiles on SAP HANA Hardware Directory

IBM Cloud for SAP | IBM Power Virtual Servers for SAP 647

© Copyright IBM Corporation 2024
IBM Corporation
New Orchard Road
Armonk, NY 10504
Produced in the United States of America
2024-07-02
IBM, the IBM logo, and ibm.com are trademarks or registered trademarks of
International Business Machines Corp., registered in many jurisdictions
worldwide. Other product and service names might be trademarks of IBM or
other companies. A current list of IBM trademarks is available on the web at
https://www.ibm.com/legal/copytrade.
This document is current as of the initial date of publication and may be changed
by IBM at any time. Not all offerings are available in every country in which IBM
operates.
THE INFORMATION IN THIS DOCUMENT IS PROVIDED "AS IS" WITHOUT ANY
WARRANTY, EXPRESS OR IMPLIED, INCLUDING WITHOUT ANY WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND ANY
WARRANTY OR CONDITION OF NON-INFRINGEMENT.
IBM products are warranted according to the terms and conditions of the
agreements under which they are provided.

